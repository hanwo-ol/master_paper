<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="김한울">
<meta name="dcterms.date" content="2025-11-13">
<meta name="description" content="메타 러닝 관련 논문 요약 및 주요 내용">

<title>Meta Learning in Neural Networks — A Survey – Master Thesis Literature Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e31584831b205ffbb2d98406f31c2a5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Master Thesis Literature Review</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Posts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="../posts/index.html">
 <span class="dropdown-text">All posts</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Meta Learning in Neural Networks — A Survey</h1>
                  <div>
        <div class="description">
          메타 러닝 관련 논문 요약 및 주요 내용
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">MetaLearning</div>
                <div class="quarto-category">Survey</div>
                <div class="quarto-category">Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>김한울 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 13, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#paper-review-meta-learning-in-neural-networks-a-survey" id="toc-paper-review-meta-learning-in-neural-networks-a-survey" class="nav-link active" data-scroll-target="#paper-review-meta-learning-in-neural-networks-a-survey">Paper Review: Meta Learning in Neural Networks: A Survey</a></li>
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">BackGround</a>
  <ul class="collapse">
  <li><a href="#메타러닝을-공식화-해보자" id="toc-메타러닝을-공식화-해보자" class="nav-link" data-scroll-target="#메타러닝을-공식화-해보자">메타러닝을 공식화 해보자</a>
  <ul class="collapse">
  <li><a href="#기존-머신러닝" id="toc-기존-머신러닝" class="nav-link" data-scroll-target="#기존-머신러닝">기존 머신러닝</a></li>
  <li><a href="#과제-분포task-distribution-관점에서-본-메타러닝" id="toc-과제-분포task-distribution-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#과제-분포task-distribution-관점에서-본-메타러닝">과제 분포(Task-Distribution) 관점에서 본 메타러닝</a></li>
  <li><a href="#이중-최적화bilevel-optimization-관점에서-본-메타러닝" id="toc-이중-최적화bilevel-optimization-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#이중-최적화bilevel-optimization-관점에서-본-메타러닝">이중 최적화(Bilevel Optimization) 관점에서 본 메타러닝</a></li>
  <li><a href="#피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" id="toc-피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#피드-포워드-모델feed-forward-model-관점에서-본-메타러닝">피드-포워드 모델(Feed-Forward Model) 관점에서 본 메타러닝</a></li>
  </ul></li>
  <li><a href="#메타러닝의-역사적-배경" id="toc-메타러닝의-역사적-배경" class="nav-link" data-scroll-target="#메타러닝의-역사적-배경">메타러닝의 역사적 배경</a></li>
  <li><a href="#관련-분야" id="toc-관련-분야" class="nav-link" data-scroll-target="#관련-분야">관련 분야</a>
  <ul class="collapse">
  <li><a href="#전이-학습-transfer-learning-tl" id="toc-전이-학습-transfer-learning-tl" class="nav-link" data-scroll-target="#전이-학습-transfer-learning-tl">전이 학습 (Transfer Learning, TL)</a></li>
  <li><a href="#도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" id="toc-도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" class="nav-link" data-scroll-target="#도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg">도메인 적응(Domain Adaptation, DA) 및 도메인 일반화(Domain Generalization, DG)</a></li>
  <li><a href="#연속-학습-continual-learning-cl" id="toc-연속-학습-continual-learning-cl" class="nav-link" data-scroll-target="#연속-학습-continual-learning-cl">연속 학습 (Continual Learning, CL)</a></li>
  <li><a href="#다중과제-학습-multi-task-learning-mtl" id="toc-다중과제-학습-multi-task-learning-mtl" class="nav-link" data-scroll-target="#다중과제-학습-multi-task-learning-mtl">다중과제 학습 (Multi-Task Learning, MTL)</a></li>
  <li><a href="#하이퍼파라미터-최적화-hyperparameter-optimization-ho" id="toc-하이퍼파라미터-최적화-hyperparameter-optimization-ho" class="nav-link" data-scroll-target="#하이퍼파라미터-최적화-hyperparameter-optimization-ho">하이퍼파라미터 최적화 (Hyperparameter Optimization, HO)</a></li>
  <li><a href="#계층적-베이즈-모델-hierarchical-bayesian-models-hbm" id="toc-계층적-베이즈-모델-hierarchical-bayesian-models-hbm" class="nav-link" data-scroll-target="#계층적-베이즈-모델-hierarchical-bayesian-models-hbm">계층적 베이즈 모델 (Hierarchical Bayesian Models, HBM)</a></li>
  <li><a href="#automl" id="toc-automl" class="nav-link" data-scroll-target="#automl">AutoML</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#taxonomy" id="toc-taxonomy" class="nav-link" data-scroll-target="#taxonomy">Taxonomy</a>
  <ul class="collapse">
  <li><a href="#이전의-분류-체계들" id="toc-이전의-분류-체계들" class="nav-link" data-scroll-target="#이전의-분류-체계들">이전의 분류 체계들</a>
  <ul class="collapse">
  <li><a href="#최적화-optimization" id="toc-최적화-optimization" class="nav-link" data-scroll-target="#최적화-optimization">최적화 (Optimization)</a></li>
  <li><a href="#블랙박스-모델-기반-black-box-model-based" id="toc-블랙박스-모델-기반-black-box-model-based" class="nav-link" data-scroll-target="#블랙박스-모델-기반-black-box-model-based">블랙박스 / 모델 기반 (Black Box / Model-based)</a></li>
  <li><a href="#측정-학습-metric-learning" id="toc-측정-학습-metric-learning" class="nav-link" data-scroll-target="#측정-학습-metric-learning">측정 학습 (Metric-Learning)</a></li>
  <li><a href="#comments" id="toc-comments" class="nav-link" data-scroll-target="#comments">comments</a></li>
  </ul></li>
  <li><a href="#제안하는-분류-체계" id="toc-제안하는-분류-체계" class="nav-link" data-scroll-target="#제안하는-분류-체계">제안하는 분류 체계</a>
  <ul class="collapse">
  <li><a href="#메타-표현-무엇을-what" id="toc-메타-표현-무엇을-what" class="nav-link" data-scroll-target="#메타-표현-무엇을-what">메타-표현 (“무엇을?” / “What?”)</a></li>
  <li><a href="#메타-optimzer-어떻게-how" id="toc-메타-optimzer-어떻게-how" class="nav-link" data-scroll-target="#메타-optimzer-어떻게-how">메타-optimzer (“어떻게?” / “How?”)</a></li>
  <li><a href="#메타-목적-왜-why" id="toc-메타-목적-왜-why" class="nav-link" data-scroll-target="#메타-목적-왜-why">메타-목적 (“왜?” / “Why?”)</a></li>
  <li><a href="#comments-1" id="toc-comments-1" class="nav-link" data-scroll-target="#comments-1">comments</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#survey-methodologies" id="toc-survey-methodologies" class="nav-link" data-scroll-target="#survey-methodologies">SURVEY: METHODOLOGIES</a>
  <ul class="collapse">
  <li><a href="#메타-표현-meta-representation" id="toc-메타-표현-meta-representation" class="nav-link" data-scroll-target="#메타-표현-meta-representation">메타-표현 (Meta-Representation)</a>
  <ul class="collapse">
  <li><a href="#파라미터-초기화-parameter-initialization" id="toc-파라미터-초기화-parameter-initialization" class="nav-link" data-scroll-target="#파라미터-초기화-parameter-initialization">파라미터 초기화 (Parameter Initialization)</a></li>
  <li><a href="#optimizer" id="toc-optimizer" class="nav-link" data-scroll-target="#optimizer">Optimizer</a></li>
  <li><a href="#피드-포워드-모델-ffms.-aka-black-box-amortized" id="toc-피드-포워드-모델-ffms.-aka-black-box-amortized" class="nav-link" data-scroll-target="#피드-포워드-모델-ffms.-aka-black-box-amortized">피드-포워드 모델 (FFMs. aka, Black-Box, Amortized)</a></li>
  <li><a href="#임베딩-함수-embedding-functions-metric-learning" id="toc-임베딩-함수-embedding-functions-metric-learning" class="nav-link" data-scroll-target="#임베딩-함수-embedding-functions-metric-learning">임베딩 함수 (Embedding Functions, Metric Learning)</a></li>
  <li><a href="#손실-및-보조-과제-losses-and-auxiliary-tasks" id="toc-손실-및-보조-과제-losses-and-auxiliary-tasks" class="nav-link" data-scroll-target="#손실-및-보조-과제-losses-and-auxiliary-tasks">손실 및 보조 과제 (Losses and Auxiliary Tasks)</a></li>
  <li><a href="#구조-architectures" id="toc-구조-architectures" class="nav-link" data-scroll-target="#구조-architectures">구조 (Architectures)</a></li>
  <li><a href="#어텐션-모듈-attention-modules" id="toc-어텐션-모듈-attention-modules" class="nav-link" data-scroll-target="#어텐션-모듈-attention-modules">어텐션 모듈 (Attention Modules)</a></li>
  <li><a href="#모듈-modules" id="toc-모듈-modules" class="nav-link" data-scroll-target="#모듈-modules">모듈 (Modules)</a></li>
  <li><a href="#하이퍼파라미터-hyper-parameters" id="toc-하이퍼파라미터-hyper-parameters" class="nav-link" data-scroll-target="#하이퍼파라미터-hyper-parameters">하이퍼파라미터 (Hyper-parameters)</a></li>
  <li><a href="#데이터-증강-data-augmentation" id="toc-데이터-증강-data-augmentation" class="nav-link" data-scroll-target="#데이터-증강-data-augmentation">데이터 증강 (Data Augmentation)</a></li>
  <li><a href="#미니배치-선택-샘플-가중치-및-커리큘럼-학습-minibatch-selection-sample-weights-and-curriculum-learning" id="toc-미니배치-선택-샘플-가중치-및-커리큘럼-학습-minibatch-selection-sample-weights-and-curriculum-learning" class="nav-link" data-scroll-target="#미니배치-선택-샘플-가중치-및-커리큘럼-학습-minibatch-selection-sample-weights-and-curriculum-learning">미니배치 선택, 샘플 가중치, 및 커리큘럼 학습 (Minibatch Selection, Sample Weights, and Curriculum Learning)</a></li>
  <li><a href="#데이터셋-레이블-및-환경-datasets-labels-and-environments" id="toc-데이터셋-레이블-및-환경-datasets-labels-and-environments" class="nav-link" data-scroll-target="#데이터셋-레이블-및-환경-datasets-labels-and-environments">데이터셋, 레이블 및 환경 (Datasets, Labels and Environments)</a></li>
  <li><a href="#논의-추론적-표현과-방법-discussion-transductive-representations-and-methods" id="toc-논의-추론적-표현과-방법-discussion-transductive-representations-and-methods" class="nav-link" data-scroll-target="#논의-추론적-표현과-방법-discussion-transductive-representations-and-methods">논의: 추론적 표현과 방법 (Discussion: Transductive Representations and Methods)</a></li>
  <li><a href="#논의-해석-가능한-기호적-표현-discussion-interpretable-symbolic-representations" id="toc-논의-해석-가능한-기호적-표현-discussion-interpretable-symbolic-representations" class="nav-link" data-scroll-target="#논의-해석-가능한-기호적-표현-discussion-interpretable-symbolic-representations">논의: 해석 가능한 기호적 표현 (Discussion: Interpretable Symbolic Representations)</a></li>
  <li><a href="#논의-상각-discussion-amortization" id="toc-논의-상각-discussion-amortization" class="nav-link" data-scroll-target="#논의-상각-discussion-amortization">논의: 상각 (Discussion: Amortization)</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="paper-review-meta-learning-in-neural-networks-a-survey" class="level1">
<h1>Paper Review: Meta Learning in Neural Networks: A Survey</h1>
<pre><code>@article{hospedales2021meta,
  title={Meta-learning in neural networks: A survey},
  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={9},
  pages={5149--5169},
  year={2021},
  publisher={IEEE}
}</code></pre>
<p><code>업데이트 내역</code></p>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td>2025-11-14</td>
<td>태스크 분포 관점 업데이트</td>
<td></td>
</tr>
<tr class="even">
<td>2025-11-15</td>
<td>Bilevel optimization View 업데이트</td>
<td></td>
</tr>
<tr class="odd">
<td>2025-11-16</td>
<td>2.2-2.3 업데이트</td>
<td>배고프군</td>
</tr>
<tr class="even">
<td>2025-11-17</td>
<td>4.1 업데이트</td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="abstract" class="level1">
<h1>Abstract</h1>
<p><code>Learning-to-learn</code>이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 <strong>학습 알고리즘 자체를 개선하는 것을 목표</strong>로 합니다.</p>
<p>이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다.</p>
<p>본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다.</p>
<ul>
<li>먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다.</li>
<li>다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다.</li>
<li>또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다.</li>
<li>마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다.</li>
</ul>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음</p>
<blockquote class="blockquote">
<p>Meta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.</p>
</blockquote>
<ol type="1">
<li>provides an alternative paradigm?</li>
</ol>
<ul>
<li>기존 방식?<br>
기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.<br>
</li>
<li>대안(메타러닝):<br>
기계에게 숙제 하나만 주는 게 아니라, <strong>“스스로 공부하는 법”</strong>을 터득하게 만들자!</li>
</ul>
<ol start="2" type="1">
<li>a machine learning model gains experience over multiple learning episodes</li>
</ol>
<ul>
<li>비유를 해보자면<br>
사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 <strong>여러 과목의 문제(관련된 과제들)</strong>를 풀게 하는 행위랑 비슷함.<br>
이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 <strong>‘요령(패턴)’</strong>을 깨닫게 됨. 이것이 바로 <strong>“경험”</strong>이라고 할 수 있음.</li>
<li><code>learning episodes</code>: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.</li>
</ul>
<p>보통의 경우에, 그리고 역사적으로 보면,</p>
<ol type="1">
<li>머신러닝<br>
</li>
</ol>
<ul>
<li>기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.
<ul>
<li>hand-engineered features<br>
</li>
</ul></li>
<li>그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.
<ul>
<li>이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.<br>
</li>
</ul></li>
<li>즉, 머신러닝에서 <strong>특징 추출 단계</strong>와 <strong>모델 학습 단계</strong>는 분리 되어 있음.</li>
</ul>
<ol start="2" type="1">
<li>딥러닝<br>
</li>
</ol>
<ul>
<li>위 머신러닝의 두 단계인 <strong>특징 추출 단계</strong>와 <strong>모델 학습 단계</strong>를 하나의 단계로 통합해버림.
<ul>
<li>특징과 모델의 공동 학습 (Joint feature and model learning)<br>
</li>
</ul></li>
<li>예전 처럼 특징을 정성스럽게 추출할 필요가 없음.
<ul>
<li>원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,<br>
</li>
<li>모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.<br>
</li>
</ul></li>
<li>고양이 사진 분류하는 모델을 예로 들어보면…
<ul>
<li>초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.<br>
</li>
<li>중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.<br>
</li>
<li>후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.</li>
</ul></li>
<li>어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.<br>
</li>
<li>사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.</li>
<li>이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.</li>
</ul>
<ol start="3" type="1">
<li>신경망에서의 메타러닝?</li>
</ol>
<ul>
<li>특징 추출 단계, 모델 학습 단계, 그리고 <code>알고리즘</code>을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.</li>
</ul>
<p>Thrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.</p>
<blockquote class="blockquote">
<p>Thrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.<br>
<em>해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 </em></p>
</blockquote>
<blockquote class="blockquote">
<p>학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,<br>
즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.</p>
</blockquote>
<ul>
<li>task family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.
<ul>
<li>예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 <strong>“동물 분류”</strong>라는 하나의 task family에 속합니다.<br>
</li>
<li>AI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.</li>
<li>즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>conventional machine learning performance improves as more data from a single task is seen</p>
</blockquote>
<ul>
<li>기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.</li>
</ul>
<p><strong>공짜 점심은 없다(no free lunch) Theorem</strong> 에 대항하는 알고리즘 ㅋㅋ</p>
<blockquote class="blockquote">
<p>This perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.</p>
</blockquote>
<blockquote class="blockquote">
<p>이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.</p>
</blockquote>
<blockquote class="blockquote">
<p>하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.</p>
</blockquote>
<ul>
<li>“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.</li>
</ul>
<p>이 논문이 Review하려고 하는 대상 논문?</p>
<ul>
<li>본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.
<ul>
<li>참고문헌 [27], [28]에 따라 <strong>‘알고리즘 학습’</strong>으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.</li>
<li>이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.</li>
</ul></li>
<li>본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.
<ul>
<li>먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다</li>
<li>그런 다음, <strong>메타-표현(meta-representation), 메타-목적(meta-objective), 메타-optimzer(meta-optimizer)</strong>라는 관점에서 새로운 분류 체계를 제공할 것입니다.</li>
<li>이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 <strong>설계 공간(design-space)</strong>을 제시합니다.</li>
<li>우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.</li>
<li>마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다.</li>
</ul></li>
</ul>
</section>
<section id="background" class="level1">
<h1>BackGround</h1>
<p>메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.</p>
<ul>
<li>이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.</li>
</ul>
<section id="메타러닝" class="level4">
<h4 class="anchored" data-anchor-id="메타러닝">메타러닝?</h4>
<p><strong>‘학습하는 방법을 학습하는 것(learning to learn)’</strong></p>
<ul>
<li><p>이는 <strong>여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미</strong>함.</p></li>
<li><p>기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.</p></li>
<li><p><strong>기반 학습(base learning)</strong> 중에는 <strong>내부(inner)</strong> (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임<br>
</p></li>
<li><p><strong>메타러닝</strong> 중에는 <strong>외부(outer)</strong>(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.</p>
<ul>
<li>예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.</li>
<li>(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.</li>
</ul>
<blockquote class="blockquote">
<p>inner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.</p>
</blockquote></li>
</ul>
<blockquote class="blockquote">
<p>메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?</p>
</blockquote>
<p>위에 정의된 대로라면, <code>Cross Validtion</code>을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.</p>
</section>
<section id="현대의-neural-network-meta-learning의-두드러지는-특징" class="level4">
<h4 class="anchored" data-anchor-id="현대의-neural-network-meta-learning의-두드러지는-특징">현대의 neural-network meta-learning의 두드러지는 특징</h4>
<ul>
<li><strong>명시적으로 정의된 메타 수준의 목적 함수</strong>이 있고,<br>
</li>
<li>이 목적 함수에 대한 내부 알고리즘의 <strong>end-to-end 최적화</strong>가 이루어짐.</li>
</ul>
</section>
<section id="메타러닝을-공식화-해보자" class="level2">
<h2 class="anchored" data-anchor-id="메타러닝을-공식화-해보자">메타러닝을 공식화 해보자</h2>
<section id="기존-머신러닝" class="level3">
<h3 class="anchored" data-anchor-id="기존-머신러닝">기존 머신러닝</h3>
<p>기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 <span class="math inline">\(D = \{(x_1, y_1), \dots, (x_N, y_N)\}\)</span>이 주어짐.</p>
<p><span class="math inline">\(\theta\)</span>로 매개변수화된 예측 모델 <span class="math inline">\(\hat{y} = f_{\theta}(x)\)</span>를 다음 식을 풀어 훈련시키게 됨:</p>
<p><span class="math display">\[
\theta^* = \arg\min_{\theta} \mathcal{L}(D; \theta, \omega) \quad (1)
\]</span></p>
<ul>
<li><span class="math inline">\(\mathcal{L}\)</span>은 실제 레이블과 <span class="math inline">\(f_{\theta}(\cdot)\)</span>가 예측한 값 사이의 오차를 측정하는 손실 함수.</li>
<li><span class="math inline">\(\omega\)</span>라는 조건이 걸려 있음.
<ul>
<li>이는 학습하는 방법 <span class="math inline">\(\omega\)</span>에 따라 이 식(1)의 해인 <span class="math inline">\(\theta\)</span>가 달라질 수 있다는 의미임.<br>
</li>
<li><span class="math inline">\(\omega\)</span> 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.</li>
</ul></li>
<li>일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.</li>
</ul>
<section id="기존-머신러닝의-2가지-가정" class="level5">
<h5 class="anchored" data-anchor-id="기존-머신러닝의-2가지-가정">기존 머신러닝의 2가지 가정</h5>
<ol type="1">
<li>최적화 과정이 모든 문제 <span class="math inline">\(D\)</span>에 대해 매번 처음부터 수행됨(from scratch)<br>
</li>
<li>학습 방법 <span class="math inline">\(\omega\)</span>는 사전에 지정됨.</li>
</ol>
<p>이때, <span class="math inline">\(\omega\)</span>의 <strong>specification</strong>, 즉 <code>학습 방법을 어떻게 정하느냐</code>는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.</p>
<ul>
<li><p>메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 <em>사전에 지정하고 고정하는 대신</em> 학습 알고리즘 자체를 학습하게 됨.</p></li>
<li><p>Specification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음</p>
<blockquote class="blockquote">
<p>optimzer(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?<br>
학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?<br>
모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?<br>
정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?</p>
</blockquote></li>
</ul>
</section>
</section>
<section id="과제-분포task-distribution-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="과제-분포task-distribution-관점에서-본-메타러닝">과제 분포(Task-Distribution) 관점에서 본 메타러닝</h3>
<blockquote class="blockquote">
<p>메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,<br>
이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 <strong>범용 학습 알고리즘</strong>을 학습하자.</p>
</blockquote>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math inline">\(p(\mathcal{T})\)</span>: 과제들의 분포</li>
<li><span class="math inline">\(\omega\)</span>: 어떤 학습 방법</li>
<li><span class="math inline">\(\mathcal{T} = \{D, L\}\)</span>: 어떤 과제(<span class="math inline">\(\mathcal{T}\)</span>)는 데이터셋(<span class="math inline">\(D\)</span>)과 손실 함수(<span class="math inline">\(L\)</span>)의 조합이다.</li>
<li><span class="math inline">\(D\)</span>: 데이터 셋</li>
<li><span class="math inline">\(\mathcal{L}(D, \omega)\)</span>: 데이터 셋 <span class="math inline">\(D\)</span>에서 학습 방법 <span class="math inline">\(\omega\)</span>를 사용해 훈련했을 때의 loss 값</li>
</ul>
<p>위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.</p>
<p><span class="math display">\[
\min_{\omega} \mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})} \mathcal{L}(D; \omega) \quad (2)
\]</span></p>
<p>‘학습 방법’, 즉 <span class="math inline">\(\omega\)</span>는 <strong>과제 전반의 지식(across-task knowledge)</strong> 또는 <strong>메타 지식(meta-knowledge)</strong> 이라고 할 수 있음.</p>
<p><strong>식 (2)를 실제로 해결하려면?</strong></p>
<ul>
<li>목표: 세상의 모든 과제 분포 <span class="math inline">\(p(\mathcal{T})\)</span>에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 <span class="math inline">\(\omega\)</span>를 찾자!<br>
</li>
<li>현실: 모든 과제 분포의 모든 문제인 <span class="math inline">\(p(\mathcal{T})\)</span>를 다룰 수는 없음.</li>
<li>타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 <span class="math inline">\(p(\mathcal{T})\)</span>를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)</li>
</ul>
<p><strong>Notation 2</strong></p>
<p><span class="math inline">\(\mathcal{D}_{\text{source}} = \{(D_{\text{source}}^{\text{train}}, D_{\text{source}}^{\text{val}})^{(i)}\}_{i=1}^M\)</span></p>
<ul>
<li><strong>메타-훈련(meta-training)에 사용할 전체 데이터셋</strong>을 나타내는 기호.</li>
</ul>
<p>하나씩 뜯어보면</p>
<ul>
<li><span class="math inline">\(\mathcal{D}_{\text{source}}\)</span> : <strong>‘소스 데이터셋(Source Dataset)’</strong>이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 <strong>원천(Source)</strong>이 된다는 의미. 즉, <strong>“훈련용”</strong>이라는 뜻.</li>
<li><span class="math inline">\(M\)</span>: 우리가 가지고 있는 <strong>훈련용 과제(task)의 총 개수</strong>. (예: 50개의 다른 종류의 동물 분류 문제)</li>
<li><span class="math inline">\(\{ \dots \}_{i=1}^M\)</span>: 괄호 안의 내용이 <strong>1번부터 M번까지 M개</strong>가 있다는 뜻.</li>
<li><span class="math inline">\(( \dots )^{(i)}\)</span>: 그중에서 <strong>i번째 과제</strong>를 의미. (예: 50개 중 17번째 과제)</li>
<li><span class="math inline">\((D_{\text{source}}^{\text{train}}, D_{\text{source}}^{\text{val}})\)</span>: 하나의 과제(<span class="math inline">\(i\)</span>)가 두 종류의 데이터로 구성되어 있다는 뜻.
<ul>
<li><span class="math inline">\(D_{\text{train}}^{\text{source}}\)</span>: <strong>‘훈련용’ 데이터(train data)</strong>. 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 <strong>서포트셋(support set)</strong>이라고 함.</li>
<li><span class="math inline">\(D_{\text{val}}^{\text{source}}\)</span>: <strong>‘검증용’ 데이터(validation data)</strong>. 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 <strong>쿼리셋(query set)</strong>이라고 함.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>“<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>란, 총 M개의 훈련용 과제 묶음인데, 각 과제<span class="math inline">\(i\)</span>는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”</p>
</blockquote>
<p>아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.</p>
<p><span class="math display">\[
\omega^* = \arg\max_{\omega} \log p(\omega|\mathcal{D}_{\text{source}}) \quad (3)
\]</span></p>
<p>또, 식을 하나씩 요소별로 뜯어보자.</p>
<ul>
<li><span class="math inline">\(\omega\)</span> (오메가): 우리가 찾고 싶은 <strong>‘학습 방법’ 또는 ‘공부법’</strong></li>
<li><span class="math inline">\(\omega^{\ast}\)</span> (오메가 스타): 수많은 가능한 공부법(<span class="math inline">\(\omega\)</span>) 중에서 우리가 찾아낸 <strong>최고의(optimal) 공부법</strong>을 의미함.</li>
<li><span class="math inline">\(\arg\max_{\omega}\)</span>: “괄호 안의 값을 <strong>최대(max)로 만드는</strong> <span class="math inline">\(\omega\)</span>를 <strong>찾아라(arg)</strong>”라는 명령어.</li>
<li><span class="math inline">\(p(\omega|\mathcal{D}_{\text{source}})\)</span>: <strong>사후 확률(posterior probability)</strong>.
<ul>
<li><strong>“우리가 가진 훈련용 과제 데이터(<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>)를 관찰했을 때, 어떤 공부법(<span class="math inline">\(\omega\)</span>)이 가장 그럴듯한가(정답일 확률이 높은가)?”</strong>.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>“우리가 가진 <strong>훈련용 과제 데이터(<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>)를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(<span class="math inline">\(\omega\)</span>)을 찾아서, 그것을 우리의 최종 학습법(<span class="math inline">\(\omega^{\ast}\)</span>)으로 삼아라!“</strong></p>
</blockquote>
<p>이제 메타-테스트 단계에서 사용되는 <span class="math inline">\(Q\)</span>개의 타겟 과제(target tasks) 집합을 <span class="math inline">\(\mathcal{D}_{\text{target}} = \{(D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})^{(i)}\}_{i=1}^Q\)</span> 로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 <span class="math inline">\(\omega^*\)</span>를 사용하여 이전에 보지 못한 각 타겟 과제 <span class="math inline">\(i\)</span>에 대한 기반 모델을 훈련합니다:</p>
<p><span class="math display">\[
\theta^{*(i)} = \arg\max_{\theta} \log p(\theta|\omega^*, D_{\text{target}}^{\text{train }(i)}) \quad (4)
\]</span></p>
<p>식 (1)의 기존 학습과 대조적으로, 타겟 과제 <span class="math inline">\(i\)</span>의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 <span class="math inline">\(\omega^*\)</span>의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 <span class="math inline">\(D_{\text{test}}^{\text{target}}(i)\)</span>에 대한 <span class="math inline">\(\theta^{*(i)}\)</span>의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.</p>
<p>이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 <strong>메타-과소적합(meta-underfitting)</strong> 과 <strong>메타-과적합(meta-overfitting)</strong> 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 <span class="math inline">\(\theta\)</span>를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 <span class="math inline">\(\omega\)</span>를 학습하는 것으로 볼 수 있습니다.</p>
<p><strong>다음 섹션 넘어가기 전 수식 해설:</strong></p>
<p><span class="math inline">\(\mathcal{D}_{\text{target}} = \{(D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})^{(i)}\}_{i=1}^Q\)</span></p>
<p>이 수식은 <strong>메타-테스팅(Meta-Testing) 단계</strong>, 즉 최종 실력을 평가하는 데 사용되는 <strong>“실전 시험 문제지 묶음”</strong> 전체를 정의합니다.</p>
<p>이 구조를 세 단계로 나누어 이해하면 가장 쉽습니다.</p>
<section id="단계-mathcald_texttarget---전체-시험지-묶음" class="level4">
<h4 class="anchored" data-anchor-id="단계-mathcald_texttarget---전체-시험지-묶음">1단계: <span class="math inline">\(\mathcal{D}_{\text{target}}\)</span> - 전체 시험지 묶음</h4>
<ul>
<li><strong>이름</strong>: 타겟 데이터셋 (The Target Dataset)</li>
<li><strong>역할</strong>: 메타-훈련을 통해 학습된 ’만능 공부법(<span class="math inline">\(\omega^*\)</span>)’이 얼마나 효과적인지 최종적으로 평가하기 위한 <strong>전체 시험 문제들의 집합</strong>입니다.</li>
<li><strong>표기 규칙</strong>: <code>target</code>이 <strong>아래 첨자(subscript)</strong>로 붙어, 이 데이터셋 묶음의 <strong>소속(Group)</strong>이 ’소스(훈련용)’가 아닌 ’타겟(시험용)’임을 나타냅니다.</li>
</ul>
</section>
<section id="단계-dots-i-와-dots-_i1q---i번째-시험지" class="level4">
<h4 class="anchored" data-anchor-id="단계-dots-i-와-dots-_i1q---i번째-시험지">2단계: <span class="math inline">\(( \dots )^{(i)}\)</span> 와 <span class="math inline">\(\{ \dots \}_{i=1}^Q\)</span> - i번째 시험지</h4>
<ul>
<li><strong>이름</strong>: i번째 타겟 과제 (The i-th Target Task)</li>
<li><strong>역할</strong>: 전체 시험지 묶음(<span class="math inline">\(\mathcal{D}_{\text{target}}\)</span>)은 총 <strong>Q개의 개별 시험 문제(과제)</strong>로 이루어져 있습니다. 이 표기는 그중 <strong>i번째 시험 문제</strong> 하나를 가리킵니다.</li>
<li><strong>비유</strong>: ‘수능 시험’이라는 전체 묶음 속의 ’수학 시험지’ 하나에 해당합니다.</li>
</ul>
</section>
<section id="단계-d_texttargettexttrain-d_texttargettexttest---시험지-한-장의-구성" class="level4">
<h4 class="anchored" data-anchor-id="단계-d_texttargettexttrain-d_texttargettexttest---시험지-한-장의-구성">3단계: <span class="math inline">\((D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})\)</span> - 시험지 한 장의 구성</h4>
<p>이것이 가장 중요한 부분입니다. ‘수학 시험지’ 한 장은 두 부분으로 구성됩니다.</p>
<section id="가.-d_texttargettexttrain-시험지-속-참고-예시-또는" class="level5">
<h5 class="anchored" data-anchor-id="가.-d_texttargettexttrain-시험지-속-참고-예시-또는">가. <span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span>: 시험지 속 “참고 예시” 또는 “&lt;보기&gt;”</h5>
<ul>
<li><strong>정확한 표기</strong>: <code>target</code>은 <strong>아래 첨자</strong>, <code>train</code>은 <strong>윗 첨자</strong>.</li>
<li><strong>역할</strong>:
<ol type="1">
<li>이 데이터는 이미 학습이 끝난 <strong>’만능 공부법(<span class="math inline">\(\omega^*\)</span>)’을 개선하는 데 사용되지 않습니다.</strong></li>
<li>대신, <span class="math inline">\(i\)</span>번째 새로운 문제를 만난 모델이 이 데이터를 <strong>딱 몇 번만 보고</strong> “아, 이 문제는 이런 유형이구나!”하고 <strong>빠르게 적응(adaptation)</strong>하는 데 사용됩니다.</li>
<li>이 적응 과정을 통해 <span class="math inline">\(i\)</span>번째 문제에만 특화된 모델(<span class="math inline">\(\theta^{*(i)}\)</span>)이 만들어집니다.</li>
</ol></li>
<li><strong>비유</strong>: 시험 문제에 나오는 <strong><code>&lt;보기&gt;</code> 자료</strong>와 같습니다. <code>&lt;보기&gt;</code>를 읽고 문제의 의도를 파악하고 적응하는 것이지, <code>&lt;보기&gt;</code>를 읽는다고 해서 근본적인 국어 실력(<span class="math inline">\(\omega\)</span>)이 오르는 것은 아닙니다.</li>
</ul>
</section>
<section id="나.-d_texttargettexttest-시험지-속-실제-채점-문제" class="level5">
<h5 class="anchored" data-anchor-id="나.-d_texttargettexttest-시험지-속-실제-채점-문제">나. <span class="math inline">\(D_{\text{target}}^{\text{test}}\)</span>: 시험지 속 “실제 채점 문제”</h5>
<ul>
<li><strong>정확한 표기</strong>: <code>target</code>은 <strong>아래 첨자</strong>, <code>test</code>은 <strong>윗 첨자</strong>.</li>
<li><strong>역할</strong>:
<ol type="1">
<li>위에서 <code>&lt;보기&gt;</code>(<span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span>)를 보고 적응을 마친 모델(<span class="math inline">\(\theta^{*(i)}\)</span>)에게 이 문제를 풀게 합니다.</li>
<li>모델의 답과 정답을 비교하여 <strong>최종 성능(정확도)을 채점</strong>합니다. 이 점수가 바로 메타 학습기의 <span class="math inline">\(i\)</span>번째 과제에 대한 최종 실력입니다.</li>
</ol></li>
<li><strong>비유</strong>: <code>&lt;보기&gt;</code>를 참고하여 풀어야 하는 <strong>실제 문제 1번, 2번, 3번</strong>에 해당합니다.</li>
</ul>
</section>
</section>
<section id="최종-정리" class="level4">
<h4 class="anchored" data-anchor-id="최종-정리">최종 정리</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">표기법</th>
<th style="text-align: left;">소속 (아래 첨자)</th>
<th style="text-align: left;">역할 (윗 첨자)</th>
<th style="text-align: left;">비유</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\mathcal{D}_{\text{target}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;">(없음)</td>
<td style="text-align: left;"><strong>수능 시험 전체</strong> (최종 평가 목적)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;"><strong>훈련(Train)</strong></td>
<td style="text-align: left;">시험지 속 <strong><code>&lt;보기&gt;</code></strong> (새로운 유형에 적응)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(D_{\text{target}}^{\text{test}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;"><strong>테스트(Test)</strong></td>
<td style="text-align: left;">시험지 속 <strong>채점 문제</strong> (최종 성능 평가)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="이중-최적화bilevel-optimization-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="이중-최적화bilevel-optimization-관점에서-본-메타러닝">이중 최적화(Bilevel Optimization) 관점에서 본 메타러닝</h3>
<p>이전 섹션의 논의는 다중 과제 시나리오에서 메타러닝의 일반적인 흐름을 설명했지만, 식 (3)의 메타-훈련 단계를 어떻게 풀어야 하는지는 명시하지 않았습니다. 이는 보통 메타-훈련 단계를 <strong>이중 최적화(bilevel optimization)</strong> 문제로 구성함으로써 수행됩니다. 이 그림은 optimzer 기반(optimizer-based) 방법론(섹션 3.1 참조)에만 정확하게 들어맞는다고 할 수 있지만, 메타러닝의 작동 방식을 더 보편적으로 시각화하는 데 도움이 됩니다. 이중 최적화[40]는 계층적 최적화 문제로, 하나의 최적화가 다른 최적화를 제약 조건으로 포함하는 구조를 의미합니다[17], [41].</p>
<p>이 표기법을 사용하면, 메타-훈련은 다음과 같이 정형화될 수 있습니다:</p>
<p><span class="math display">\[
\omega^* = \arg\min_{\omega} \sum_{i=1}^{M} \mathcal{L}^{\text{meta}}(\theta^{*(i)}(\omega), \omega, D_{\text{source}}^{\text{val }(i)}) \quad (5)
\]</span></p>
<p><span class="math display">\[
\text{s.t. } \theta^{*(i)}(\omega) = \arg\min_{\theta} \mathcal{L}^{\text{task}}(\theta, \omega, D^{\text{train }(i)}_{\text{source}}) \quad (6)
\]</span></p>
<p>여기서 <span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span> 와 <span class="math inline">\(\mathcal{L}^{\text{task}}\)</span> 는 각각 <strong>외부(outer) 및 내부(inner) 목적 함수</strong>를 의미하며, 퓨샷 분류의 경우 교차 엔트로피와 같은 것입니다. 외부와 내부 수준 사이의 <strong>리더-팔로워(leader-follower) 비대칭성</strong>에 주목하십시오: <em>내부 수준 최적화인 식 (6)은 외부 수준에서 정의된 학습 전략 <span class="math inline">\(\omega\)</span>에 따라 조건부로 결정되지만, 자신의 훈련 중에는 <span class="math inline">\(\omega\)</span>를 변경할 수 없습니다.</em></p>
<p>여기서 <span class="math inline">\(\omega\)</span>는 비볼록(non-convex) 최적화에서의 초기 조건[16], 정규화 강도와 같은 하이퍼파라미터[17], 또는 최적화할 손실 함수 <span class="math inline">\(\mathcal{L}^{\text{task}}\)</span>의 매개변수화[42]까지도 나타낼 수 있습니다.</p>
<ul>
<li>섹션 4.1에서 <span class="math inline">\(\omega\)</span>에 대한 선택의 공간을 자세히 논의합니다.</li>
</ul>
<p>외부 수준 최적화는 훈련 후 검증 세트에서 좋은 성능을 보이는 모델 <span class="math inline">\(\theta^{*(i)}(\omega)\)</span>를 생성하도록 <span class="math inline">\(\omega\)</span>를 학습합니다.</p>
<ul>
<li>섹션 4.2에서는 <span class="math inline">\(\omega\)</span>를 최적화하는 방법을 자세히 논의합니다.</li>
<li>섹션 4.3에서는 <span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span>가 검증 성능, 학습 속도, 모델 강건성 등 무엇을 측정할 수 있는지 고려합니다.</li>
</ul>
<p>마지막으로, 위의 정형화는 과제 분포라는 개념을 사용한다는 점에 주목합니다.</p>
<ul>
<li>이는 메타러닝 문헌에서 일반적이지만, 메타러닝의 필수 조건은 아닙니다.</li>
</ul>
<p>더 공식적으로, 만약 단일 훈련 및 테스트 데이터셋(<span class="math inline">\(M=Q=1\)</span>)이 주어진다면, 우리는 훈련 세트를 분할하여 메타-훈련을 위한 <span class="math inline">\(\mathcal{D}_{\text{source}} = (D^{\text{train}}_{\text{source}},
D^{\text{val}}_{\text{source}})\)</span> 와 메타-테스트를 위한 <span class="math inline">\(\mathcal{D}_{\text{target}} = (D^{\text{train}}_{\text{source}} \cup D^{\text{val}}_{\text{source}}, D^{\text{test}}_{\text{target}})\)</span>를 얻을 수 있습니다. 우리는 여전히 여러 에피소드에 걸쳐 <span class="math inline">\(\omega\)</span>를 학습하며, 메타-훈련 중에는 보통 다른 훈련-검증 분할이 사용됩니다.</p>
<p><strong>comment</strong></p>
<p>메타러닝의 작동 방식을 <strong>“두 단계로 이루어진 최적화”</strong>라는 틀로 설명합니다. 마치 회사에서 <strong>팀장(외부 루프)</strong>과 <strong>팀원(내부 루프)</strong>이 협업하는 것과 같습니다.</p>
<section id="두-개의-최적화-문제-내부-루프와-외부-루프" class="level4">
<h4 class="anchored" data-anchor-id="두-개의-최적화-문제-내부-루프와-외부-루프">1. 두 개의 최적화 문제: 내부 루프와 외부 루프</h4>
<ul>
<li><strong>내부 최적화 (식 6) - 팀원의 임무</strong>:
<ul>
<li>팀장은 <strong>업무 가이드라인(<span class="math inline">\(\omega\)</span>)</strong>을 줍니다. (예: “이런 방식으로 초기 모델을 설정해봐”, “학습률은 0.01로 해”)</li>
<li>팀원은 주어진 가이드라인(<span class="math inline">\(\omega\)</span>)과 훈련 데이터(<span class="math inline">\(D^{\text{train}}\)</span>)를 가지고, <strong>자신의 과제(<span class="math inline">\(\theta\)</span>)를 가장 잘 해결하기 위해 최선을 다합니다.</strong></li>
<li><strong>중요한 점</strong>: 팀원은 팀장이 준 가이드라인(<span class="math inline">\(\omega\)</span>)을 바꿀 수 없습니다. 그냥 따라야 합니다. 그 결과물이 바로 <strong>최적의 모델(<span class="math inline">\(\theta^*\)</span>)</strong>입니다.</li>
</ul></li>
<li><strong>외부 최적화 (식 5) - 팀장의 임무</strong>:
<ul>
<li>팀장은 팀원이 과제를 수행한 결과물(<span class="math inline">\(\theta^*\)</span>)을 가져와서 <strong>실전 테스트(<span class="math inline">\(D^{\text{val}}\)</span>)</strong>를 해봅니다.</li>
<li>테스트 결과(성능)를 보고, <strong>“내가 처음에 줬던 가이드라인(<span class="math inline">\(\omega\)</span>)이 과연 최선이었을까?”</strong>를 고민합니다.</li>
<li><strong>목표</strong>: 팀원의 최종 성과(<span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span>)가 가장 좋아지도록, <strong>최초의 가이드라인(<span class="math inline">\(\omega\)</span>) 자체를 수정하고 개선</strong>합니다. 이것이 바로 팀장의 최적화, 즉 메타러닝입니다.</li>
</ul></li>
</ul>
</section>
<section id="omega는-무엇인가-팀장의-가이드라인" class="level4">
<h4 class="anchored" data-anchor-id="omega는-무엇인가-팀장의-가이드라인">2. <span class="math inline">\(\omega\)</span>는 무엇인가? (팀장의 가이드라인)</h4>
<p>팀장이 주는 가이드라인(<span class="math inline">\(\omega\)</span>)은 여러 형태일 수 있습니다. * <strong>초기 조건</strong>: “업무를 이 지점(<span class="math inline">\(\theta_0\)</span>)에서 시작하면 가장 빨리 끝낼 수 있을 거야.” (MAML 방식) * <strong>하이퍼파라미터</strong>: “이 업무는 꼼꼼함(정규화)이 중요하니, 정규화 강도를 0.5로 설정해.” * <strong>손실 함수</strong>: “이 업무의 목표는 단순히 정확도를 높이는 게 아니라, 안정성도 고려해야 해.” 라며 목표 자체를 재정의해 줌.</p>
</section>
<section id="꼭-여러-과제가-필요한가-no" class="level4">
<h4 class="anchored" data-anchor-id="꼭-여러-과제가-필요한가-no">3. 꼭 여러 과제가 필요한가? No!</h4>
<ul>
<li>보통 메타러닝은 여러 팀(과제)의 성과를 보고 최고의 가이드라인을 찾지만, 꼭 그럴 필요는 없습니다.</li>
<li><strong>단 하나의 매우 중요한 프로젝트(single task)</strong>가 있다면, 프로젝트를 여러 단계로 나누고 각 단계마다 팀원이 업무를 수행하게 한 뒤, 그 결과를 보고 팀장이 계속해서 가이드라인을 수정해주는 방식도 가능합니다. 이것이 <strong>‘단일 과제 메타러닝’</strong>입니다.</li>
</ul>
</section>
</section>
<section id="피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="피드-포워드-모델feed-forward-model-관점에서-본-메타러닝">피드-포워드 모델(Feed-Forward Model) 관점에서 본 메타러닝</h3>
<p>앞서 살펴본 바와 같이, 식 (5)-(6)과 같은 명시적인 반복 최적화를 통하지 않고, 피드-포워드 방식으로 모델을 합성하는 여러 메타러닝 접근법이 있습니다. 이들은 복잡도에 차이가 있지만, 이 접근법 계열을 이해하기 위해서는 식 (2)의 추상적인 목표를 구체화하여 선형 회귀 메타-훈련을 위한 간단한 예시[43]를 정의하는 것이 도움이 될 수 있습니다.</p>
<p><span class="math display">\[\min_{\omega} \underset{(\mathcal{D}^{tr}, \mathcal{D}^{val}) \in \mathcal{T}}{\mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}} \sum_{(\mathbf{x}, y) \in \mathcal{D}^{val}} \left[ (\mathbf{x}^T \mathbf{g}_{\omega}(\mathcal{D}^{tr}) - y)^2 \right] \quad (7)\]</span></p>
<p>여기서 우리는 과제 분포에 대해 메타-훈련을 수행합니다. 각 과제에 대해 훈련 세트와 검증 세트가 주어집니다.</p>
<ul>
<li>훈련 세트 <span class="math inline">\(D^{\text{tr}}\)</span>은 벡터 <span class="math inline">\(g_\omega\)</span>로 임베딩[44]되며, 이 벡터는 검증 세트의 예시 <span class="math inline">\(x\)</span>를 예측하기 위한 선형 회귀 가중치를 정의합니다.</li>
<li>식 (7)을 최적화하는 것은 함수 <span class="math inline">\(g_\omega\)</span>가 훈련 세트를 가중치 벡터로 매핑하도록 훈련함으로써 ’학습하는 법을 배우는 것’입니다.</li>
<li>따라서 <span class="math inline">\(g_\omega\)</span>는 <span class="math inline">\(p(\mathcal{T})\)</span>에서 추출된 새로운 메타-테스트 과제 <span class="math inline">\(^{\text{te}}\)</span>에 대해서도 좋은 해법을 제공해야 합니다. 이 계열의 방법들은 사용되는 예측 모델 <span class="math inline">\(g\)</span>의 복잡성과 서포트셋이 어떻게 임베딩되는지(예: 풀링, CNN, RNN 사용)[44]에 따라 다양합니다.</li>
</ul>
<p>이러한 모델들은 <strong>상각(amortized)</strong>[45] 모델로도 알려져 있는데, 이는 새로운 과제를 학습하는 비용이 <span class="math inline">\(g_\omega(\cdot)\)</span>를 통한 피드-포워드 연산 한 번으로 줄어들기 때문입니다. 반복 최적화에 드는 비용은 이미 <span class="math inline">\(\omega\)</span>의 메타-훈련 중에 지불되었습니다.</p>
<p><strong>comments</strong></p>
<p>이 섹션은 이전의 ‘이중 최적화’ 방식과는 완전히 다른, <strong>매우 빠르고 효율적인 메타러닝 방식</strong>을 설명합니다.</p>
<section id="이전-방식-이중-최적화의-문제점" class="level4">
<h4 class="anchored" data-anchor-id="이전-방식-이중-최적화의-문제점">이전 방식 (이중 최적화)의 문제점</h4>
<ul>
<li>새로운 문제가 주어질 때마다, 내부 루프에서 <strong>느린 최적화 과정(경사 하강법 등)을 여러 번 반복</strong>해야 합니다.</li>
<li>비유: 학생이 새로운 수학 문제를 만날 때마다, 공책에 여러 번 계산을 반복하며 풀어야 합니다.</li>
</ul>
</section>
<section id="새로운-방식-피드-포워드-모델의-아이디어" class="level4">
<h4 class="anchored" data-anchor-id="새로운-방식-피드-포워드-모델의-아이디어">새로운 방식 (피드-포워드 모델)의 아이디어</h4>
<ul>
<li>“느린 반복 계산 과정을 없애버리고, 그냥 <strong>문제를 척 보면 바로 답이 나오는 ‘만능 공식 생성기’(<span class="math inline">\(g_\omega\)</span>)</strong>를 만들자!”</li>
<li>비유: 학생이 문제 유형과 주어진 숫자들을 ’만능 공식 생성기’에 넣으면, 계산 과정 없이 바로 그 문제에 맞는 ’최적의 공식’이 튀어나오고, 그 공식으로 답을 구합니다.</li>
</ul>
</section>
<section id="수식-7-해설" class="level4">
<h4 class="anchored" data-anchor-id="수식-7-해설">수식 (7) 해설</h4>
<p><span class="math display">\[\min_{\omega} \underset{(\mathcal{D}^{tr}, \mathcal{D}^{val}) \in \mathcal{T}}{\mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}} \sum_{(\mathbf{x}, y) \in \mathcal{D}^{val}} \left[ (\mathbf{x}^T \mathbf{g}_{\omega}(\mathcal{D}^{tr}) - y)^2 \right] \quad (7)\]</span></p>
<ul>
<li><strong><span class="math inline">\(D^{\text{tr}}\)</span> (훈련 세트)</strong>: 학생에게 주어진 <strong>‘참고 예제’</strong> 데이터입니다.</li>
<li><strong><span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span></strong>: 이것이 바로 <strong>‘만능 공식 생성기’</strong>입니다. 이 함수(<span class="math inline">\(g\)</span>)는 참고 예제 데이터(<span class="math inline">\(D^{\text{tr}}\)</span>)를 입력으로 받아서, 이 문제를 푸는 데 필요한 <strong>최적의 모델 파라미터(가중치)</strong>를 <strong>한 방에(피드-포워드 연산으로) 출력</strong>합니다.</li>
<li><strong><span class="math inline">\(x^T g_{\omega}(D^{\text{tr}})\)</span></strong>: ’만능 공식 생성기’가 만들어준 공식(<span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span>)을 가지고 실제 문제(<span class="math inline">\(x\)</span>)를 푸는 과정입니다.</li>
<li><strong><span class="math inline">\(( \dots - y)^2\)</span></strong>: 예측값과 실제 정답(<span class="math inline">\(y\)</span>) 사이의 오차입니다.</li>
<li><strong>전체 의미</strong>: 여러 종류의 과제에 대해, “주어진 참고 예제(<span class="math inline">\(D^{\text{tr}}\)</span>)를 보고 최적의 공식(<span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span>)을 한 번에 만들어내는 생성기(<span class="math inline">\(g_\omega\)</span>)를 훈련시켜라! 이 생성기는 어떤 문제가 주어져도 항상 좋은 공식을 만들어내야 한다.”</li>
</ul>
</section>
<section id="상각amortized이라는-용어의-의미" class="level4">
<h4 class="anchored" data-anchor-id="상각amortized이라는-용어의-의미">상각(Amortized)이라는 용어의 의미</h4>
<ul>
<li><strong>‘상각(Amortize)’</strong>은 회계 용어로, 큰 비용을 여러 기간에 걸쳐 나누어 처리한다는 의미입니다.</li>
<li>메타러닝에서 이 용어는, <strong>가장 비용이 많이 드는 ‘느린 반복 최적화’ 과정을 메타-훈련 때 미리 다 해치워버리고(<span class="math inline">\(\omega\)</span>를 학습),</strong> 정작 새로운 문제를 풀 때는 그 비용을 거의 치르지 않는다는 의미에서 사용됩니다.</li>
<li><strong>메타-훈련 (비용이 비쌈)</strong>: 수많은 과제를 풀어보며 ‘만능 공식 생성기’(<span class="math inline">\(g_\omega\)</span>)를 만드는 데는 엄청난 시간과 계산이 필요합니다. (비용을 미리 지불)</li>
<li><strong>메타-테스트 (비용이 거의 0)</strong>: 일단 생성기만 만들어지면, 새로운 문제는 그냥 함수에 데이터 한 번 넣는 것으로 끝나므로 거의 즉시 해결됩니다. (미리 지불한 비용의 혜택을 봄)</li>
</ul>
<p>이 피드-포워드 방식은 특히 <strong>새로운 문제에 대한 반응 속도가 매우 빨라야 하는 응용 분야</strong>에 매우 유용합니다.</p>
</section>
</section>
</section>
<section id="메타러닝의-역사적-배경" class="level2">
<h2 class="anchored" data-anchor-id="메타러닝의-역사적-배경">메타러닝의 역사적 배경</h2>
<p>메타러닝과 러닝-투-런(learning-to-learn)은 1987년 문헌에 처음 등장합니다.</p>
<p><strong>위르겐 슈미트후버(J. Schmidhuber)</strong> + <strong>자기 참조 학습(self-referential learning)</strong>을 사용하여 ’학습하는 방법을 학습’할 수 있는 방법론의 한 갈래를 소개했습니다. 자기 참조 학습은 신경망이 자신의 가중치를 입력으로 받아 해당 가중치에 대한 업데이트 값을 예측하도록 훈련하는 것을 포함합니다. 슈미트후버는 진화 알고리즘을 사용하여 모델 자체를 학습할 것을 제안했습니다.</p>
<p>메타러닝은 이후 여러 분야로 확장되었습니다.</p>
<p><strong>요슈아 벤지오(Bengio)</strong> + <strong>생물학적으로 타당한 학습 규칙(biologically plausible learning rules)</strong>을 메타-학습하는 방법을 제안했습니다. + 슈미트후버 등은 자기 참조 시스템과 메타러닝을 계속해서 탐구했습니다.</p>
<p><strong>세바스찬 스런(S. Thrun)</strong> + ’learning to learn’이라는 용어를 더 명확하게 정의하는 데 힘썼으며, 초기의 이론적 정당성과 실용적인 구현 방법을 소개했습니다. + 경사 하강법과 역전파를 사용하여 메타러닝 시스템을 훈련시키자는 제안은 1991년에 처음으로 나왔고, 2001년에 더 확장된 연구들이 뒤따랐으며 당시 문헌에 대한 개요를 제공합니다. 메타러닝은 1995년에 강화 학습의 맥락에서 사용되었고, 이후 다양한 확장 연구가 이어졌습니다.</p>
<p><strong>comments</strong></p>
<p>이 섹션은 메타러닝의 아이디어가 어떻게 시작되고 발전했는지를 시간 순서대로 보여줍니다.</p>
<ul>
<li><strong>1987년, 슈미트후버의 시작</strong>:
<ul>
<li><strong>“자기 참조 학습(Self-referential Learning)”</strong>이라는 혁신적인 아이디어를 제시합니다.</li>
<li><strong>아이디어</strong>: 보통 신경망은 외부 데이터(예: 이미지)를 입력받습니다. 하지만 슈미트후버는 신경망이 <strong>자기 자신의 설계도(가중치)</strong>를 들여다보고, “내 설계도를 어떻게 수정해야 더 똑똑해질까?”를 <strong>스스로 예측</strong>하게 만들자고 제안했습니다. 마치 AI가 자기 자신을 성찰하고 개선하는 것과 같습니다.</li>
<li><strong>방법</strong>: 당시에는 경사 하강법으로 이런 복잡한 구조를 훈련하기 어려웠기 때문에, 다윈의 진화론처럼 좋은 해결책은 살아남고 나쁜 해결책은 도태되는 <strong>진화 알고리즘</strong>을 사용하자고 제안했습니다.</li>
</ul></li>
<li><strong>1990년대 초, 벤지오와 스런의 발전</strong>:
<ul>
<li><strong>벤지오</strong>: “실제 뇌가 학습하는 방식과 유사한, <strong>생물학적으로 그럴듯한 학습 규칙</strong>을 AI가 스스로 배우게 만들 수는 없을까?”라는 방향으로 연구를 확장했습니다.</li>
<li><strong>스런</strong>: ’learning-to-learn’이 무엇인지 개념적으로 명확하게 다듬고, “이것이 왜 이론적으로 타당한가?”에 대한 근거를 제시하며 연구의 기틀을 다졌습니다.</li>
</ul></li>
<li><strong>1991년, 경사 하강법의 도입</strong>:
<ul>
<li>“진화 알고리즘 말고, 우리가 신경망 훈련에 흔히 쓰는 <strong>경사 하강법과 역전파</strong>를 메타러닝에도 적용해보자!”라는 제안이 처음 등장합니다. 이것이 현대 메타러닝 방법론의 시초가 됩니다. (예: MAML 같은 알고리즘의 먼 조상)</li>
</ul></li>
<li><strong>1995년, 강화 학습과의 만남</strong>:
<ul>
<li>메타러닝은 지도 학습뿐만 아니라, 로봇 제어나 게임처럼 시행착오를 통해 학습하는 <strong>강화 학습(RL)</strong> 분야에도 적용되기 시작하며 그 활용 범위를 넓혔습니다.</li>
</ul></li>
</ul>
</section>
<section id="관련-분야" class="level2">
<h2 class="anchored" data-anchor-id="관련-분야">관련 분야</h2>
<p>여기서는 메타러닝과 자주 혼동을 일으키는 관련 분야들과 비교하여 메타러닝의 위상을 정립합니다.</p>
<section id="전이-학습-transfer-learning-tl" class="level3">
<h3 class="anchored" data-anchor-id="전이-학습-transfer-learning-tl">전이 학습 (Transfer Learning, TL)</h3>
<p>전이 학습(TL)은 소스 과제(source task)의 과거 경험을 사용하여 타겟 과제(target task)의 학습(속도, 데이터 효율성, 정확도)을 향상시키는 것을 목표로 합니다. TL은 이러한 문제 영역과 해결책 계열을 모두 지칭하며, 가장 흔한 방법은 파라미터 전이 후 선택적으로 미세 조정(fine tuning)을 하는 것입니다 (물론 다른 수많은 접근법도 있습니다[34]).</p>
<blockquote class="blockquote">
<p>[34] survey: S. J. Pan and Q. Yang, “A Survey On Transfer Learning,” IEEE TKDE, 2010.</p>
</blockquote>
<p>반면, 메타러닝은 다른 문제들뿐만 아니라 TL을 개선하는 데 사용될 수 있는 패러다임입니다. TL에서는 <strong>메타-목적(meta-objective)을 사용하지 않고</strong> 소스 과제에 대한 일반적인(vanilla) 학습을 통해 사전 지식(prior)을 추출합니다.</p>
<p>메타러닝에서는, MAML[16]에서 보여주듯이,</p>
<ul>
<li>새로운 과제를 학습할 때 사전 지식의 이점을 평가하는 <strong>외부 최적화(outer optimization)</strong>를 통해 해당 사전 지식이 정의됩니다.</li>
<li>더 일반적으로, 메타러닝은 단지 모델 파라미터뿐만 아니라 훨씬 더 넓은 범위의 meta-representation을 다룹니다 (섹션 4.1 참조).</li>
</ul>
<blockquote class="blockquote">
<p>[16] MAML: C.Finn,P. Abbeel, and S. Levine, “Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks,” in ICML, 2017.</p>
</blockquote>
<p><strong>comments</strong></p>
<ul>
<li><strong>전이 학습(TL)이란?</strong>: 어떤 분야에서 얻은 지식을 다른 분야에 써먹는 것입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>‘어떻게’ 지식을 옮길지를 최적화하는가?</strong>
<ul>
<li><strong>전이 학습</strong>: 일단 A라는 과제를 열심히 공부해서 지식을 쌓고 (예: 이미지넷으로 모델 훈련), 그 지식을 B라는 과제에 가져가서 약간 수정해서(fine-tuning) 씁니다. ’어떻게 하면 B에 더 잘 써먹을 수 있을까?’를 고민하며 A를 공부하지는 않습니다.</li>
<li><strong>메타러닝</strong>: “나중에 B, C, D 같은 과제들을 <strong>가장 빠르고 쉽게 배울 수 있도록</strong>, 지금 A를 <strong>어떤 방식으로</strong> 공부해 둬야 할까?”라는 <strong>’학습 전략 자체’를 최적화</strong>합니다.</li>
</ul></li>
</ul>
</section>
<section id="도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" class="level3">
<h3 class="anchored" data-anchor-id="도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg">도메인 적응(Domain Adaptation, DA) 및 도메인 일반화(Domain Generalization, DG)</h3>
<p><strong>도메인 이동(Domain-shift)</strong></p>
<ul>
<li>소스 문제와 타겟 문제가 동일한 목표를 공유하지만, 타겟 문제의 입력 데이터 분포가 소스 과제와 달라 모델 성능이 저하되는 상황을 말합니다[34], [58].</li>
</ul>
<p><strong>DA</strong></p>
<ul>
<li>타겟 도메인의 희소하거나 레이블이 없는 데이터를 사용하여 소스에서 훈련된 모델을 조정함으로써 이 문제를 완화하려는 전이 학습의 한 변형입니다.</li>
</ul>
<p><strong>DG</strong></p>
<ul>
<li>추가적인 적응 없이 이러한 도메인 이동에 강건한 소스 모델을 훈련시키는 방법을 말합니다.</li>
</ul>
<p>TL과 마찬가지로, 일반적인(vanilla) DA와 DG는 여러 도메인에 걸쳐 ’학습하는 방법’을 최적화하기 위한 메타-목적을 사용하지 않습니다. 반면, 메타러닝 방법은 DA[59]와 DG[42]를 모두 수행하는 데 사용될 수 있습니다 (섹션 5.8 참조).</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>DA/DG란?</strong>: 같은 문제인데 데이터의 ’스타일’이 다른 상황에 대처하는 것입니다. (예: 낮에 찍은 사진으로 학습한 자율주행차가 밤에도 운전해야 하는 상황)</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>’스타일 변화에 대한 강건함’을 직접적인 목표로 최적화하는가?</strong>
<ul>
<li><strong>DA/DG</strong>: 특정 기술(예: 밤 사진을 낮 사진처럼 보이게 변환)을 사용하여 스타일 차이를 줄이려고 노력합니다. ’어떻게 훈련해야 어떤 스타일 변화에도 강해질까?’를 최적화하지는 않습니다.</li>
<li><strong>메타러닝</strong>: 훈련 단계에서 일부러 <strong>다양한 스타일의 데이터(낮, 밤, 비 오는 날, 흐린 날)를 경험</strong>하게 하고, “어떤 스타일의 데이터가 들어와도 성능이 떨어지지 않는 <strong>‘강건한 학습법’</strong>” 자체를 찾도록 최적화합니다.</li>
</ul></li>
</ul>
</section>
<section id="연속-학습-continual-learning-cl" class="level3">
<h3 class="anchored" data-anchor-id="연속-학습-continual-learning-cl">연속 학습 (Continual Learning, CL)</h3>
<p>연속 또는 평생 학습(lifelong learning)[60]-[62]은 잠재적으로 비정상(non-stationary) 분포에서 추출된 일련의 과제들을 학습하는 능력을 말하며, 특히 새로운 과제를 더 빠르게 배우면서 오래된 과제는 잊지 않는 것을 목표로 합니다.</p>
<p>메타러닝과 유사하게 과제 분포가 고려되며, 목표의 일부는 타겟 과제의 학습을 가속화하는 것입니다. 그러나 대부분의 연속 학습 방법론은 이 메타-목표를 명시적으로 풀지 않기 때문에 메타러닝 방법론이 아닙니다. 반면에, 메타러닝은 연속 학습을 발전시키기 위한 잠재적인 프레임워크를 제공하며, 최근 몇몇 연구들은 연속 학습 성능을 인코딩하는 메타-목표를 개발함으로써 이를 시도하기 시작했습니다[63]–[65].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>연속 학습(CL)이란?</strong>: 과제 A를 배운 뒤, 과제 B를 배우고, 이어서 과제 C를 배울 때, 이전에 배운 A와 B를 잊어버리지 않는(catastrophic forgetting 방지) 능력입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>’연속 학습 자체’를 하나의 학습 목표로 삼는가?</strong>
<ul>
<li><strong>연속 학습</strong>: 특정 기술(예: 중요한 지식은 얼려서 보존)을 사용하여 과거의 지식을 잊지 않으려고 노력합니다.</li>
<li><strong>메타러닝</strong>: “어떻게 훈련해야 <strong>‘새로운 것을 배우면서도 옛것을 잊지 않는 능력’</strong> 자체를 극대화할 수 있을까?”라는 메타-목표를 설정하고, 이 목표를 달성하는 학습 전략을 찾습니다.</li>
</ul></li>
</ul>
</section>
<section id="다중과제-학습-multi-task-learning-mtl" class="level3">
<h3 class="anchored" data-anchor-id="다중과제-학습-multi-task-learning-mtl">다중과제 학습 (Multi-Task Learning, MTL)</h3>
<p>다중과제 학습(MTL)은 여러 관련 과제를 동시에 학습하여, 파라미터 공유와 그로 인한 공유 표현의 다양성 덕분에 정규화 효과를 보고[66]–[68], 컴퓨팅/메모리 절약 효과를 얻는 것을 목표로 합니다. TL, DA, CL과 마찬가지로, 전통적인 MTL은 메타-목적이 없는 단일-수준 최적화입니다.</p>
<p>더욱이, MTL의 목표는 <strong>이미 알려진 고정된 수의 과제</strong>를 푸는 것인 반면, 메타러닝의 핵심은 종종 <strong>미래에 보게 될 미지의 과제</strong>를 푸는 것입니다. 그럼에도 불구하고, 메타러닝은 MTL에 이점을 가져다줄 수 있습니다. 예를 들어, 과제 간의 관련성을 학습하거나[69] 여러 과제 간의 우선순위를 정하는 방법을 배우는 것[70]입니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>다중과제 학습(MTL)이란?</strong>: 여러 과제를 <strong>동시에</strong> 학습시켜서 서로 도움을 주고받게 하는 것입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>‘알려진 과제’ vs ‘미지의 과제’</strong>
<ul>
<li><strong>다중과제 학습</strong>: 목표는 <strong>“주어진 A, B, C 과제 모두”</strong>에서 최고의 성능을 내는 것입니다. 미래에 D라는 과제가 나타날 것은 고려하지 않습니다.</li>
<li><strong>메타러닝</strong>: A, B, C 과제를 학습하는 이유는 <strong>“미래에 나타날 미지의 과제 D”</strong>를 더 잘 풀기 위함입니다. A, B, C 자체의 성능보다는 일반화 능력이 더 중요합니다.</li>
</ul></li>
</ul>
</section>
<section id="하이퍼파라미터-최적화-hyperparameter-optimization-ho" class="level3">
<h3 class="anchored" data-anchor-id="하이퍼파라미터-최적화-hyperparameter-optimization-ho">하이퍼파라미터 최적화 (Hyperparameter Optimization, HO)</h3>
<p>하이퍼파라미터 최적화(HO)는 학습률이나 정규화 강도와 같은 하이퍼파라미터가 ’학습하는 방법’을 기술한다는 점에서 메타러닝의 영역에 속합니다. 여기서 우리는 경사 하강법 기반 하이퍼파라미터 학습[69], [71] 및 신경망 구조 탐색[18]과 같이 신경망으로 종단간(end-to-end) 훈련되는 메타-목표를 정의하는 HO 과제들을 포함합니다. 그러나 우리는 무작위 탐색[72]이나 베이지안 하이퍼파라미터 최적화[73]와 같이, 메타러닝으로 거의 간주되지 않는 다른 접근법들은 제외합니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>하이퍼파라미터 최적화(HO)란?</strong>: 모델 학습에 영향을 주는 설정값(학습률, 층의 개수 등)들을 사람이 아니라 기계가 자동으로 찾게 하는 것입니다.</li>
<li><strong>메타러닝과의 관계</strong>: ’학습하는 방법(<span class="math inline">\(\omega\)</span>)’을 찾는다는 점에서 메타러닝과 매우 유사합니다.</li>
<li><strong>이 논문에서의 구분 기준</strong>: <strong>’신경망’과 ’종단간 최적화’를 사용하는가?</strong>
<ul>
<li><strong>메타러닝으로 간주</strong>: 학습률이나 모델 구조 자체를 또 다른 신경망을 이용해, 전체 학습 과정에 대한 경사 하강법으로 최적화하는 방식. (과정이 매끄럽게 연결됨)</li>
<li><strong>메타러닝에서 제외</strong>: 단순히 여러 하이퍼파라미터 조합을 무작위로 시도해 보거나(무작위 탐색), 통계적 추정(베이지안 최적화)을 통해 최적값을 탐색하는 전통적인 방식. (학습 과정과 분리되어 있음)</li>
</ul></li>
</ul>
</section>
<section id="계층적-베이즈-모델-hierarchical-bayesian-models-hbm" class="level3">
<h3 class="anchored" data-anchor-id="계층적-베이즈-모델-hierarchical-bayesian-models-hbm">계층적 베이즈 모델 (Hierarchical Bayesian Models, HBM)</h3>
<p>계층적 베이즈 모델(HBM)은 사전 확률 <span class="math inline">\(p(\theta|\omega)\)</span> 하에서 파라미터 <span class="math inline">\(\theta\)</span>의 베이지안 학습을 포함합니다.</p>
<p>이 사전 확률은 자체적인 사전 확률 <span class="math inline">\(p(\omega)\)</span>를 갖는 다른 변수 <span class="math inline">\(\omega\)</span>에 대한 조건부 밀도 함수로 작성됩니다.</p>
<p>계층적 베이즈 모델은 <span class="math inline">\(D = \{D_i | i = 1, 2, ..., M\}\)</span>과 같이 그룹화된 데이터 모델로 강력하게 사용되며, 각 그룹 <span class="math inline">\(i\)</span>는 자체적인 <span class="math inline">\(\theta_i\)</span>를 가집니다.</p>
<p>전체 모델은 아래와 같습니다.</p>
<p><span class="math display">\[[\prod_{i=1}^{M} P(D_i|\theta_i) p(\theta_i|\omega)] p(\omega)\]</span></p>
<p>계층 구조는 더 확장될 수 있으며, 특히 <span class="math inline">\(\omega\)</span> 자체가 매개변수화되어 <span class="math inline">\(p(\omega)\)</span>가 학습될 수 있습니다.</p>
<p>학습은 보통 전체 파이프라인에 걸쳐 이루어지지만, 베이지안 주변화(Bayesian marginalisation)의 한 형태를 사용하여 <span class="math inline">\(\omega\)</span>에 대한 사후 확률을 계산하기도 합니다.</p>
<p><span class="math display">\[P(\omega|D) \propto p(\omega) \prod_{i=1}^{M} \int d\theta_i p(D_i|\theta_i)p(\theta_i|\omega)\]</span></p>
<p>주변화를 수행하는 용이성은 모델에 따라 다릅니다.</p>
<ul>
<li>어떤 모델(예: 잠재 디리클레 할당[74])에서는 켤레 지수 모델(conjugate exponential models) 선택 덕분에 주변화가 정확하지만,</li>
<li>다른 모델(예: [75])에서는 확률적 변분 추론(stochastic variational approach)을 사용하여 근사적인 사후 확률을 계산하고, 이를 통해 주변 우도(marginal likelihood)의 하한(lower bound)을 계산합니다.</li>
</ul>
<p>베이지안 계층 모델은 메타러닝 과정을 이해하기 위한 알고리즘적 프레임워크보다는 모델링 프레임워크를 제공함으로써, 메타러닝에 대한 가치 있는 관점을 제공합니다. 실제로는, HBM에 대한 이전 연구들은 주로 다루기 쉬운 간단한 모델 <span class="math inline">\(\theta\)</span>를 학습하는 데 초점을 맞춘 반면, 대부분의 메타러닝 연구는 여러 번의 반복을 포함하는 복잡한 내부-루프 학습 과정을 고려합니다. 그럼에도 불구하고, MAML[16]과 같은 일부 메타러닝 방법은 HBM의 렌즈를 통해 이해될 수 있습니다[76].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>계층적 베이즈 모델(HBM)이란?</strong>: “개별 그룹(과제)의 특성(<span class="math inline">\(\theta_i\)</span>)은 전체 그룹(과제 분포)의 공통적인 특성(<span class="math inline">\(\omega\)</span>)으로부터 나온다”는 계층적 가정을 사용하는 통계 모델입니다.</li>
<li><strong>메타러닝과의 관계</strong>: <strong>구조가 매우 유사합니다.</strong>
<ul>
<li><code>전체 그룹 특성(ω)</code> ↔︎ <code>메타 지식(ω)</code></li>
<li><code>개별 그룹 특성(θ_i)</code> ↔︎ <code>개별 과제 모델(θ_i)</code></li>
</ul></li>
<li><strong>핵심 차이점</strong>: <strong>‘관점’과 ’복잡성’</strong>
<ul>
<li><strong>관점</strong>: HBM은 “이 데이터가 어떻게 생성되었을까?”를 확률적으로 <strong>모델링</strong>하는 데 초점을 맞춥니다. 반면, 메타러닝은 “어떻게 하면 성능을 최적화할까?”라는 <strong>알고리즘적</strong> 관점에 더 가깝습니다.</li>
<li><strong>복잡성</strong>: 전통적인 HBM은 수학적으로 다루기 쉬운 간단한 모델에 주로 사용된 반면, 현대 메타러닝은 수백만 개의 파라미터를 가진 복잡한 딥러닝 모델의 학습 과정을 다룹니다.</li>
</ul></li>
<li><strong>결론</strong>: HBM은 메타러닝의 철학적, 구조적 배경을 이해하는 데 훌륭한 이론적 틀을 제공하지만, 오늘날 딥러닝에서 다루는 문제의 규모와 복잡성에는 직접 적용하기 어렵습니다.</li>
</ul>
</section>
<section id="automl" class="level3">
<h3 class="anchored" data-anchor-id="automl">AutoML</h3>
<p>AutoML[31]-[33]은 데이터 준비, 알고리즘 선택, 하이퍼파라미터 튜닝, 구조 탐색과 같이 일반적으로 수동으로 이루어지는 <strong>머신러닝 과정의 일부를 자동화하려는 접근법들을 포괄하는 다소 넓은 분야를 통칭하는 말</strong>입니다.</p>
<p>AutoML은 종종 여기서 정의한 메타러닝의 범위를 벗어나는 수많은 휴리스틱을 사용하며, 데이터 정제와 같이 메타러닝에서는 덜 중심적인 과제에 초점을 맞춥니다.</p>
<p>하지만, AutoML은 때때로 메타-목표의 종단간 최적화를 사용하기도 하므로, 메타러닝은 <strong>AutoML의 한 전문 분야(specialization)</strong>로 볼 수 있습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>AutoML이란?</strong>: 머신러닝의 A부터 Z까지(데이터 정제, 모델 선택, 튜닝 등) 모든 과정을 자동화하려는 기술 분야입니다.</li>
<li><strong>메타러닝과의 관계</strong>:
<ul>
<li><strong>AutoML이 더 넓은 개념</strong>: AutoML은 ’자동화’라는 목표를 위해 메타러닝뿐만 아니라 온갖 종류의 기법(휴리스틱, 탐색 알고리즘 등)을 모두 사용합니다.</li>
<li><strong>메타러닝은 AutoML의 한 도구</strong>: AutoML이 여러 단계를 자동화할 때, 특히 ‘최적의 학습 전략을 찾는’ 부분에서 메타러닝의 아이디어(메타-목표의 종단간 최적화)를 강력한 도구로 사용할 수 있습니다.</li>
</ul></li>
<li><strong>결론</strong>: 메타러닝은 <strong>AutoML이라는 거대한 목표를 달성하기 위한, 특히 ’학습 원리’에 초점을 맞춘 정교하고 전문화된 방법론 중 하나</strong>라고 볼 수 있습니다.</li>
</ul>
</section>
</section>
</section>
<section id="taxonomy" class="level1">
<h1>Taxonomy</h1>
<section id="이전의-분류-체계들" class="level2">
<h2 class="anchored" data-anchor-id="이전의-분류-체계들">이전의 분류 체계들</h2>
<p>이전의[77], [78] 메타러닝 방법론 분류는 주로</p>
<ol type="1">
<li><strong>최적화 기반(optimization-based)</strong> 방법,</li>
<li><strong>모델 기반(model-based)</strong> (또는 블랙박스) 방법,</li>
<li><strong>측정 기반(metric-based)</strong> (또는 비모수적) 방법</li>
</ol>
<p>과 같은 세 갈래의 분류 체계를 따르는 경향이 있었습니다.</p>
<section id="최적화-optimization" class="level3">
<h3 class="anchored" data-anchor-id="최적화-optimization">최적화 (Optimization)</h3>
<p><span class="math display">\[
\omega^* = \arg\min_{\omega} \sum_{i=1}^{M} \mathcal{L}^{\text{meta}}(\theta^{*(i)}(\omega), \omega, D_{\text{source}}^{\text{val }(i)}) \quad (5)
\]</span></p>
<p><span class="math display">\[
\text{s.t. } \theta^{*(i)}(\omega) = \arg\min_{\theta} \mathcal{L}^{\text{task}}(\theta, \omega, D^{\text{train }(i)}_{\text{source}}) \quad (6)
\]</span></p>
<p>최적화 기반 방법은 내부 수준의 과제(식 6)가 말 그대로 최적화 문제로 해결되며, 최적화 성능을 향상시키는 데 필요한 메타 지식 <span class="math inline">\(\omega\)</span>를 추출하는 데 초점을 맞춥니다.</p>
<ul>
<li>유명한 예시인 MAML[16]은 초기화 <span class="math inline">\(\omega = \theta_0\)</span>를 학습하여, 적은 수의 내부 스텝만으로도 검증 데이터에서 좋은 성능을 내는 분류기를 만들도록 하는 것을 목표로 합니다.</li>
</ul>
<p>이 과정은 기반 모델의 업데이트 과정을 미분함으로써 경사 하강법으로 수행됩니다. 더 정교한 대안들은 스텝 사이즈(step sizes)[79], [80]를 학습하거나, gradient로부터 스텝을 예측하는 순환 신경망(recurrent networks)을 훈련시키기도 합니다[19], [39], [81]. 긴 내부 최적화 과정에 대한 gradient를 이용한 메타-최적화는 여러 계산 및 메모리 문제를 야기하며, 이는 섹션 6에서 논의됩니다. 기존의 많은 방법들을 일반화된 내부 루프 메타러닝 프레임워크의 특수한 경우로 표현하는, gradient 기반 메타러닝에 대한 통합된 관점이 제안된 바 있습니다[82].</p>
</section>
<section id="블랙박스-모델-기반-black-box-model-based" class="level3">
<h3 class="anchored" data-anchor-id="블랙박스-모델-기반-black-box-model-based">블랙박스 / 모델 기반 (Black Box / Model-based)</h3>
<p><span class="math display">\[
\theta^{*(i)} = \arg\max_{\theta} \log p(\theta|\omega^*, D_{\text{target}}^{\text{train }(i)}) \quad (4)
\]</span></p>
<p><span class="math display">\[
\text{s.t. } \theta^{*(i)}(\omega) = \arg\min_{\theta} \mathcal{L}^{\text{task}}(\theta, \omega, D^{\text{train }(i)}_{\text{source}}) \quad (6)
\]</span></p>
<p>모델 기반(또는 블랙박스) 방법에서는 내부 학습 스텝(식 6, 식 4)이 단일 모델의 피드-포워드(feed-forward) 패스 안에 전부 포함되며, 이는 식 (7)에서 설명된 바와 같습니다.</p>
<p><span class="math display">\[\min_{\omega} \underset{(\mathcal{D}^{tr}, \mathcal{D}^{val}) \in \mathcal{T}}{\mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}} \sum_{(\mathbf{x}, y) \in \mathcal{D}^{val}} \left[ (\mathbf{x}^T \mathbf{g}_{\omega}(\mathcal{D}^{tr}) - y)^2 \right] \quad (7)\]</span></p>
<p>이 모델은 현재 데이터셋 <span class="math inline">\(D\)</span>를 활성화 상태(activation state)로 임베딩하고, 이 상태를 기반으로 테스트 데이터에 대한 예측을 수행합니다.</p>
<ul>
<li>대표적인 구조로는 훈련 인스턴스와 레이블을 임베딩하여 테스트 샘플에 대한 예측기를 정의하는 순환 신경망[39], [51], 합성곱 신경망[38] 또는 하이퍼네트워크[83], [84]가 있습니다.</li>
<li>이 경우, 모든 내부 수준의 학습은 모델의 활성화 상태에 포함되며 전적으로 피드-포워드 방식입니다.</li>
<li>외부 수준의 학습은 CNN, RNN 또는 하이퍼네트워크 파라미터를 포함하는 <span class="math inline">\(\omega\)</span>로 수행됩니다.</li>
<li>외부와 내부 수준의 최적화는 <span class="math inline">\(\omega\)</span>와 <span class="math inline">\(D\)</span>가 직접적으로 <span class="math inline">\(\theta\)</span>를 명시하기 때문에 긴밀하게 결합되어 있습니다.</li>
</ul>
<p>메모리 증강 신경망(Memory-augmented neural networks)[85]은 명시적인 저장 버퍼를 사용하며, 모델 기반 방법의 한 종류로 볼 수 있습니다[86], [87]. 최적화 기반 접근법과 비교할 때, 이들은 2차 미분(second-order gradients)을 요구하지 않는 더 간단한 최적화를 즐깁니다.</p>
<p>그러나 <strong>모델 기반 접근법은 최적화 기반 방법보다 분포를 벗어난(out-of-distribution) 과제에 대해 일반화하는 능력이 보통 더 떨어진다</strong>고 관찰되었습니다[88].</p>
<p>더욱이, 이들은 데이터 효율적인 퓨샷 학습에는 매우 능숙하지만, 풍부한 기반 모델에 대규모 훈련 세트를 임베딩하는 데 어려움을 겪기 때문에 점근적으로는(asymptotically) 더 약하다는 비판을 받아왔습니다[88].</p>
</section>
<section id="측정-학습-metric-learning" class="level3">
<h3 class="anchored" data-anchor-id="측정-학습-metric-learning">측정 학습 (Metric-Learning)</h3>
<p>측정 학습 또는 비모수적 알고리즘은 지금까지 메타러닝의 인기 있지만 특수한 응용 분야인 퓨샷(Section 5.1.1)에 주로 국한되어 왔습니다. 아이디어는 내부 (과제) 수준에서 검증 포인트를 훈련 포인트와 단순히 비교하고, 일치하는 훈련 포인트의 레이블을 예측함으로써 비모수적인 ’학습’을 수행하는 것입니다.</p>
<p>시간 순서대로, 이는 샴(siamese)[89], 매칭(matching)[90], 프로토타입(prototypical)[20], 관계(relation)[91], 그래프[92] 신경망으로 달성되었습니다.</p>
<p>여기서 외부 수준의 학습은 데이터를 비교에 적합하게 표현하는 특징 추출기 <span class="math inline">\(\omega\)</span>를 찾는 측정 학습에 해당합니다. 이전과 마찬가지로 <span class="math inline">\(\omega\)</span>는 소스 과제에서 학습되고, 타겟 과제에 사용됩니다.</p>
</section>
<section id="comments" class="level3">
<h3 class="anchored" data-anchor-id="comments">comments</h3>
<p>과거에는 메타러닝 방법들을 크게 세 가지 스타일로 나누어 설명했습니다.</p>
<section id="최적화-기반-가장-좋은-출발점방법을-찾아라" class="level4">
<h4 class="anchored" data-anchor-id="최적화-기반-가장-좋은-출발점방법을-찾아라">1. 최적화 기반: “가장 좋은 출발점/방법을 찾아라!”</h4>
<ul>
<li><strong>핵심 아이디어</strong>: 새로운 문제를 만났을 때, <strong>가장 빨리 정답에 도달할 수 있는 ‘최적화 과정’ 자체를 학습</strong>합니다.</li>
<li><strong>대표 주자 (MAML)</strong>: “어떤 <strong>출발점(초기 가중치 <span class="math inline">\(\theta_0\)</span>)</strong>에서 시작해야, 경사 하강법을 몇 걸음만 가도 바로 정답 근처에 도달할까?”를 학습합니다. 마치 산 정상으로 가는 가장 좋은 베이스캠프 위치를 찾는 것과 같습니다.</li>
<li><strong>장점</strong>: 원리가 명확하고, 다양한 문제에 적용할 수 있는 일반성이 높습니다.</li>
<li><strong>단점</strong>: 학습 과정(최적화 과정)을 통째로 미분해야 해서 <strong>계산이 매우 복잡하고 느립니다.</strong> (미분의 미분을 계산해야 할 수도 있음)</li>
</ul>
</section>
<section id="모델-기반-블랙박스-문제를-척-보면-답이-나오는-만능-함수를-만들어라" class="level4">
<h4 class="anchored" data-anchor-id="모델-기반-블랙박스-문제를-척-보면-답이-나오는-만능-함수를-만들어라">2. 모델 기반 (블랙박스): “문제를 척 보면 답이 나오는 만능 함수를 만들어라!”</h4>
<ul>
<li><strong>핵심 아이디어</strong>: 느린 최적화 과정을 없애고, <strong>문제 데이터 자체를 입력받으면 모델 파라미터나 예측값을 한 방에 출력하는 거대한 신경망 하나</strong>를 만듭니다.</li>
<li><strong>작동 방식</strong>: RNN이나 CNN 같은 모델이 문제의 예시 데이터들을 ‘읽고’ 그 정보를 자신의 메모리(활성화 상태)에 저장한 뒤, 새로운 질문이 들어오면 메모리를 참고해서 즉시 답을 내놓습니다.</li>
<li><strong>장점</strong>: 새로운 문제에 대한 <strong>반응 속도가 매우 빠릅니다.</strong> (피드-포워드 한 번이면 끝) 계산도 훨씬 간단합니다.</li>
<li><strong>단점</strong>:
<ul>
<li>훈련 때 본 적 없는 <strong>생소한 유형의 문제(out-of-distribution)에는 매우 취약</strong>합니다. (마치 암기 과목만 잘하는 학생 같음)</li>
<li>데이터가 아주 많아지면, 그 많은 정보를 작은 메모리에 다 담기 어려워져서 성능 한계에 부딪힐 수 있습니다.</li>
</ul></li>
</ul>
</section>
<section id="측정-기반-비슷한-놈들끼리-묶어라" class="level4">
<h4 class="anchored" data-anchor-id="측정-기반-비슷한-놈들끼리-묶어라"><strong>3. 측정 기반: “비슷한 놈들끼리 묶어라!”</strong></h4>
<ul>
<li><strong>핵심 아이디어</strong>: “학습”이란 결국 <strong>데이터 간의 ’거리’나 ’유사도’를 잘 재는 방법을 배우는 것</strong>과 같다는 철학입니다.</li>
<li><strong>작동 방식</strong>:
<ol type="1">
<li>신경망을 이용해 모든 데이터를 <strong>’특징 공간’이라는 지도</strong>에 점으로 표시합니다.</li>
<li>이때, 같은 클래스(예: 고양이)의 데이터는 서로 가깝게, 다른 클래스(예: 개)의 데이터는 서로 멀리 떨어지도록 신경망(특징 추출기 <span class="math inline">\(\omega\)</span>)을 훈련시킵니다.</li>
<li>새로운 데이터가 들어오면, 지도 위에서 <strong>가장 가까운 이웃이 누구인지 보고</strong> 그 이웃의 클래스를 따라갑니다.</li>
</ol></li>
<li><strong>장점</strong>: 개념이 직관적이고, 특히 <strong>퓨샷 학습(few-shot learning)</strong>처럼 데이터가 매우 적을 때 강력한 성능을 보입니다.</li>
<li><strong>단점</strong>: 퓨샷 분류라는 특정 문제 외의 다른 다양한 메타러닝 문제에는 적용하기 어렵습니다.</li>
</ul>
</section>
</section>
</section>
<section id="제안하는-분류-체계" class="level2">
<h2 class="anchored" data-anchor-id="제안하는-분류-체계">제안하는 분류 체계</h2>
<p>우리는 세 개의 독립적인 축을 따라 새로운 분류를 도입합니다. 각 축에 대해, 우리는 현재 메타러닝의 지형을 반영하는 분류 체계를 제공합니다.</p>
<section id="메타-표현-무엇을-what" class="level3">
<h3 class="anchored" data-anchor-id="메타-표현-무엇을-what">메타-표현 (“무엇을?” / “What?”)</h3>
<p>첫 번째 축은 메타-학습할 <strong>메타 지식 <span class="math inline">\(\omega\)</span>의 선택</strong>입니다. 이는 초기 모델 파라미터[16]부터 프로그램 귀납(program induction)의 경우 읽을 수 있는 코드[93]에 이르기까지 무엇이든 될 수 있습니다.</p>
</section>
<section id="메타-optimzer-어떻게-how" class="level3">
<h3 class="anchored" data-anchor-id="메타-optimzer-어떻게-how">메타-optimzer (“어떻게?” / “How?”)</h3>
<p>두 번째 축은 메타-훈련 중에 외부 수준에서 사용할 <strong>optimzer의 선택</strong>입니다 (식 5 참조). <span class="math inline">\(\omega\)</span>에 대한 외부 수준 optimzer는 경사 하강법[16]부터 강화 학습[93] 및 진화 탐색[23]에 이르기까지 다양한 형태를 취할 수 있습니다.</p>
</section>
<section id="메타-목적-왜-why" class="level3">
<h3 class="anchored" data-anchor-id="메타-목적-왜-why">메타-목적 (“왜?” / “Why?”)</h3>
<p>세 번째 축은 <strong>메타-목적 함수 <span class="math inline">\(\mathcal{L}_{\text{meta}}\)</span>(식 5), 과제 분포 <span class="math inline">\(p(\mathcal{T})\)</span>, 그리고 두 수준 간의 데이터 흐름</strong>의 선택에 의해 결정되는 메타러닝의 목표입니다. 이들을 종합하여 샘플 효율적인 퓨샷 학습[16], [38], 빠른 다중샷(many-shot) 최적화[93], [94], 도메인 이동에 대한 강건성[42], [95], 레이블 노이즈[96], 그리고 적대적 공격[97]과 같은 다양한 목적을 위해 메타러닝을 맞춤화할 수 있습니다.</p>
<p>이 축들은 함께 새로운 알고리즘의 개발과 특정 응용 분야에 대한 맞춤화를 이끌 수 있는 메타러닝 방법론의 <strong>설계 공간(design-space)</strong>을 제공합니다. 기반 모델 표현 <span class="math inline">\(\theta\)</span>는 이 분류 체계에 포함되지 않는데, 이는 그것이 당면한 응용 분야에 특화된 방식으로 결정되고 최적화되기 때문입니다.</p>
</section>
<section id="comments-1" class="level3">
<h3 class="anchored" data-anchor-id="comments-1">comments</h3>
<p>이 논문의 저자들은 기존의 3가지 분류(최적화/모델/측정 기반)가 너무 단순해서 현대의 복잡한 메타러닝 연구들을 제대로 설명하지 못한다고 생각했습니다. 그래서 <strong>“메타러닝 알고리즘을 설계할 때 우리가 내려야 하는 3가지 핵심 결정”</strong>이라는 새로운 기준을 제시합니다.</p>
<section id="메타-표현-meta-representation-무엇을-학습할-것인가" class="level4">
<h4 class="anchored" data-anchor-id="메타-표현-meta-representation-무엇을-학습할-것인가"><strong>1. 메타-표현 (Meta-Representation): “무엇을” 학습할 것인가?</strong></h4>
<ul>
<li><strong>핵심 질문</strong>: 우리가 ’학습하는 법을 배운다’고 할 때, 그 ’법’의 <strong>실체(<span class="math inline">\(\omega\)</span>)가 무엇인가?</strong></li>
<li><strong>선택지 (예시)</strong>:
<ul>
<li><strong>초기 파라미터</strong>: 가장 좋은 ’출발점’을 배운다. (MAML)</li>
<li><strong>optimzer</strong>: 가장 효율적인 ’업데이트 규칙’을 배운다.</li>
<li><strong>특징 추출기</strong>: 데이터의 핵심을 가장 잘 꿰뚫어 보는 ’눈’을 배운다. (측정 기반 학습)</li>
<li><strong>모델 생성기</strong>: 문제를 보면 바로 모델을 ‘뚝딱’ 만들어내는 함수를 배운다. (모델 기반 학습)</li>
<li><strong>프로그램 코드</strong>: 심지어 사람이 읽을 수 있는 파이썬 코드 자체를 생성하도록 학습할 수도 있다.</li>
</ul></li>
</ul>
</section>
<section id="메타-optimzer-meta-optimizer-어떻게-학습시킬-것인가" class="level4">
<h4 class="anchored" data-anchor-id="메타-optimzer-meta-optimizer-어떻게-학습시킬-것인가"><strong>2. 메타-optimzer (Meta-Optimizer): “어떻게” 학습시킬 것인가?</strong></h4>
<ul>
<li><strong>핵심 질문</strong>: 위에서 정한 ’무엇(<span class="math inline">\(\omega\)</span>)’을 <strong>어떤 방법으로 최적화</strong>할 것인가? (외부 루프의 최적화 방식)</li>
<li><strong>선택지 (예시)</strong>:
<ul>
<li><strong>경사 하강법</strong>: 가장 일반적인 방법. 미분을 통해 점진적으로 개선한다.</li>
<li><strong>강화 학습</strong>: 미분이 불가능할 때, 여러 시도를 해보고 ’보상’이 가장 큰 방향으로 학습한다.</li>
<li><strong>진화 알고리즘</strong>: 여러 후보(<span class="math inline">\(\omega\)</span>)를 만들어 경쟁시키고, 가장 좋은 놈만 살아남게 하는 ‘적자생존’ 방식으로 학습한다.</li>
</ul></li>
</ul>
</section>
<section id="메타-목적-meta-objective-왜-학습하는가-최종-목표는-무엇인가" class="level4">
<h4 class="anchored" data-anchor-id="메타-목적-meta-objective-왜-학습하는가-최종-목표는-무엇인가"><strong>3. 메타-목적 (Meta-Objective): “왜” 학습하는가? (최종 목표는 무엇인가?)</strong></h4>
<ul>
<li><strong>핵심 질문</strong>: 이 메타러닝을 통해 <strong>궁극적으로 달성하고 싶은 목표</strong>는 무엇인가?</li>
<li><strong>선택지 (예시)</strong>:
<ul>
<li><strong>퓨샷 학습</strong>: 아주 적은 데이터만으로도 빠르게 학습하는 능력.</li>
<li><strong>빠른 수렴</strong>: 데이터가 많더라도, 최대한 빨리 최적의 성능에 도달하는 능력.</li>
<li><strong>강건성 (Robustness)</strong>: 데이터에 노이즈가 있거나, 훈련 환경과 테스트 환경이 달라도 성능이 떨어지지 않는 ‘맷집’.</li>
<li><strong>적대적 방어</strong>: 누군가 악의적으로 데이터를 변조해도 속지 않는 능력.</li>
</ul></li>
</ul>
<p>이 세 가지 축을 어떻게 조합하느냐에 따라 무수히 많은 종류의 새로운 메타러닝 알고리즘을 설계할 수 있다는 것이 이 논문이 제안하는 새로운 관점입니다.</p>
</section>
</section>
</section>
</section>
<section id="survey-methodologies" class="level1">
<h1>SURVEY: METHODOLOGIES</h1>
<p>이 섹션에서는 우리가 제안한 새로운 방법론적 분류 체계에 따라 기존 문헌을 세분화하여 분석합니다.</p>
<section id="메타-표현-meta-representation" class="level2">
<h2 class="anchored" data-anchor-id="메타-표현-meta-representation">메타-표현 (Meta-Representation)</h2>
<p>메타러닝 방법들은 메타 지식 <span class="math inline">\(\omega\)</span>가 무엇이어야 하는지, 즉 학습 전략의 어떤 측면을 학습하고, (배제함으로써) 어떤 측면을 고정된 것으로 간주해야 하는지에 대해 서로 다른 선택을 합니다.</p>
<section id="파라미터-초기화-parameter-initialization" class="level3">
<h3 class="anchored" data-anchor-id="파라미터-초기화-parameter-initialization">파라미터 초기화 (Parameter Initialization)</h3>
<p>여기서 <span class="math inline">\(\omega\)</span>는 내부 최적화에서 사용될 신경망의 <strong>초기 파라미터</strong>에 해당하며, MAML이 가장 대표적인 예시입니다[16], [98], [99].</p>
<p>좋은 초기화는 과제 분포 <span class="math inline">\(p(\mathcal{T})\)</span>에서 추출된 어떤 과제 <span class="math inline">\(T\)</span>의 해답으로부터 단 몇 번의 경사 하강 스텝만으로 도달할 수 있는 위치에 있으며, 퓨샷 학습에서 과적합 없이 학습하는 데 도움을 줄 수 있습니다.</p>
<ul>
<li>이 접근법의 핵심적인 난제는 외부 최적화가 내부 최적화만큼이나 많은 파라미터(대형 CNN의 경우 잠재적으로 수억 개)를 풀어야 한다는 점입니다.</li>
<li>이로 인해 부분 공간(subspace)[78], [100], 레이어별[83], [100], [101], 또는 스케일과 시프트 분리[102] 등을 통해 메타-학습할 파라미터의 일부를 분리하려는 연구 흐름이 생겨났습니다.</li>
<li>또 다른 우려는 단일 초기 조건이 광범위한 잠재적 과제에 대해 빠른 학습을 제공하기에 충분한지, 아니면 좁은 분포 <span class="math inline">\(p(\mathcal{T})\)</span>에 국한되는지에 대한 것입니다. 이는 여러 초기 조건에 대한 혼합(mixtures)을 모델링하는 변형 연구들로 이어졌습니다[100], [103], [104].</li>
</ul>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“최고의 출발점”</strong>을 배웁니다.</li>
<li><strong>비유</strong>: 산 정상으로 가는 가장 빠른 길을 찾기 위해, 모든 등산로에서 가장 접근하기 좋은 <strong>‘만능 베이스캠프’</strong>의 위치(<span class="math inline">\(\omega = \theta_0\)</span>)를 찾는 것과 같습니다.</li>
<li><strong>문제점</strong>: 베이스캠프의 위치를 정하는 것(외부 최적화)이 등산 자체(내부 최적화)만큼이나 어렵고 복잡합니다. (파라미터 수가 너무 많음)</li>
<li><strong>해결책</strong>:
<ol type="1">
<li><strong>일부만 배우기</strong>: 전체 파라미터가 아니라, 가장 중요한 일부 레이어나 특정 부분만 학습하자.</li>
<li><strong>여러 개 배우기</strong>: ‘만능 베이스캠프’ 하나 대신, ‘한라산용 베이스캠프’, ‘설악산용 베이스캠프’ 등 여러 개의 좋은 출발점을 배우자.</li>
</ol></li>
</ul>
</section>
<section id="optimizer" class="level3">
<h3 class="anchored" data-anchor-id="optimizer">Optimizer</h3>
<p>위의 파라미터 중심 방법들은 보통 새로운 과제가 주어졌을 때 초기화를 개선하기 위해 모멘텀이 있는 SGD나 Adam[105]과 같은 기존의 optimzer에 의존합니다.</p>
<p>대신, optimzer 중심 접근법[19], [39], [81], [94]은 <span class="math inline">\(\theta\)</span>와 <span class="math inline">\(\nabla_{\theta}\mathcal{L}_{\text{task}}\)</span> 와 같은 최적화 상태를 입력으로 받아 각 기반 학습 반복에 대한 최적화 스텝을 생성하는 함수를 훈련함으로써 <strong>내부 optimzer를 학습</strong>하는 데 초점을 맞춥니다.</p>
<p>훈련 가능한 구성 요소 <span class="math inline">\(\omega\)</span>는 고정된 스텝 사이즈[79], [80]와 같은 간단한 하이퍼파라미터부터 더 정교한 사전 조건화 행렬(pre-conditioning matrices)[106], [107]까지 다양할 수 있습니다.</p>
<p>궁극적으로 <span class="math inline">\(\omega\)</span>는 입력 gradient와 다른 메타데이터의 복잡한 비선형 변환을 통해 완전한 gradient 기반 optimzer를 정의하는 데 사용될 수 있습니다[19], [39], [93], [94]. 만약 optimzer가 가중치별로 좌표 단위(coordinate-wise)로 적용된다면 여기서 학습할 파라미터는 적을 수 있습니다[19].</p>
<p>초기화 중심 방법과 optimzer 중심 방법은 함께 학습함으로써 병합될 수 있는데, 즉 전자가 후자의 초기 조건을 학습하는 방식입니다[39], [79]. optimzer 학습 방법은 퓨샷 학습[39]과 다중샷 학습의 가속 및 개선[19], [93], [94] 모두에 적용되었습니다.</p>
<p>마지막으로, gradient와 같은 optimzer 상태 대신 <span class="math inline">\(\mathcal{L}_{\text{task}}\)</span>의 평가값만 요구하는 0차 optimzer(zeroth-order optimizers)[108]를 메타-학습할 수도 있습니다. 이들은 기존의 베이지안 최적화[73] 대안들과 경쟁력 있음이 보여졌습니다[108].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“가장 효율적인 등산 방법(최적화 규칙)”</strong> 자체를 배웁니다.</li>
<li><strong>비유</strong>: ’최고의 베이스캠프’를 찾는 대신, 어떤 지점에서든 가장 빨리 정상으로 갈 수 있는 <strong>‘네비게이션 앱’(<span class="math inline">\(\omega\)</span>)</strong>을 만드는 것과 같습니다. 이 앱은 현재 위치(파라미터 <span class="math inline">\(\theta\)</span>)와 gradient(<span class="math inline">\(\nabla\mathcal{L}\)</span>)를 입력받아 “다음 발걸음은 이쪽으로 이만큼 가세요”라고 알려줍니다.</li>
<li><strong>다양한 수준</strong>:
<ul>
<li><strong>단순한 수준</strong>: “보폭(learning rate)은 항상 0.5m로 하세요.”</li>
<li><strong>복잡한 수준</strong>: 지형(gradient)에 따라 보폭과 방향을 동적으로 조절하는 정교한 규칙을 배웁니다.</li>
</ul></li>
<li><strong>장점</strong>: 초기화 학습과 결합할 수 있으며, 퓨샷(빠른 적응)과 다중샷(최종 성능) 모두에 효과적입니다.</li>
</ul>
</section>
<section id="피드-포워드-모델-ffms.-aka-black-box-amortized" class="level3">
<h3 class="anchored" data-anchor-id="피드-포워드-모델-ffms.-aka-black-box-amortized">피드-포워드 모델 (FFMs. aka, Black-Box, Amortized)</h3>
<p>또 다른 계열의 모델들은 gradient 기반의 반복적인 <span class="math inline">\(\theta\)</span> 최적화에 의존하는 대신, 서포트셋에서 테스트 인스턴스를 분류하는 데 필요한 파라미터로 직접 매핑하는 피드-포워드 매핑을 제공하는 학습기 <span class="math inline">\(\omega\)</span>를 훈련시킵니다. 즉, <span class="math inline">\(\theta = g_{\omega}(D^{\text{train}})\)</span>입니다.</p>
<p>이들은 기존 분류 체계의 블랙박스 모델 기반 학습(섹션 3.1)에 해당하며, 고전적인 방법[109]부터 CNAPs[110]와 같이 도전적인 교차-도메인 퓨샷 벤치마크[111]에서 강력한 성능을 보이는 최근 접근법까지 다양합니다.</p>
<p>이러한 방법들은 어떤 임베딩에 따라 다른 신경망의 가중치를 생성하는 하이퍼네트워크(Hypernetworks)[112], [113]와 연결되며, 종종 압축이나 다중과제 학습에 사용됩니다. 여기서 <span class="math inline">\(\omega\)</span>는 하이퍼네트워크이며, 소스 데이터셋이 주어지면 피드-포워드 패스를 통해 <span class="math inline">\(\theta\)</span>를 합성합니다[100], [114]. 서포트셋의 임베딩은 종종 순환 신경망[51], [115], [116], 합성곱[38], 또는 집합 임베딩(set embeddings)[45], [110]을 통해 달성됩니다.</p>
<p>여기서의 연구는 종종 과제-임베딩 네트워크로 분류기를 매개변수화하는 구조를 탐구합니다.</p>
<ol type="i">
<li>어떤 파라미터를 모든 과제에 걸쳐 전역적으로 공유하고, 대조적으로 하이퍼네트워크에 의해 과제별로 합성할 것인가 (예: 특징 추출기는 공유하고 분류기는 합성[83], [117])<br>
</li>
<li><span class="math inline">\(\omega\)</span>에 필요한 파라미터 수를 제한하기 위해 하이퍼네트워크를 어떻게 매개변수화할 것인가 (예: 특징 추출기 내의 경량 어댑터 레이어만 합성[110]하거나, 클래스별 분류기 가중치 합성[45]).</li>
</ol>
<p>일부 FFM은 확률 모델에서의 상각 추론(amortized inference)[45], [109]의 관점에서 우아하게 이해될 수 있으며, 테스트 데이터 <span class="math inline">\(x\)</span>에 대한 예측을 다음과 같이 합니다:</p>
<p><span class="math display">\[
q_{\omega}(y|x, D^{tr}) = \int p(y|x, \theta) q_{\omega}(\theta|D^{tr}) d\theta \quad (8)
\]</span></p>
<p>여기서 메타-표현 <span class="math inline">\(\omega\)</span>는 훈련 데이터 <span class="math inline">\(D^{tr}\)</span>로 과제를 해결하는 파라미터 <span class="math inline">\(\theta\)</span>에 대한 다루기 힘든 베이지안 추론을 근사하는 네트워크 <span class="math inline">\(q_{\omega}(\cdot)\)</span>이며, 적분은 정확하게 계산되거나[109], 샘플링[45] 또는 점 추정[110]으로 근사될 수 있습니다. 그 후 모델 <span class="math inline">\(\omega\)</span>는 훈련 과제 분포에 대한 검증 손실을 최소화하도록 훈련됩니다 (식 7 참조).</p>
<p>마지막으로, 오래된 데이터를 기억하고 새로운 데이터를 빠르게 동화시키는 능력을 가진 메모리 증강 신경망도 일반적으로 FFM 범주에 속합니다[86], [87].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“문제지를 보면 바로 정답지를 만들어내는 기계(<span class="math inline">\(\omega\)</span>)”</strong>를 배웁니다.</li>
<li><strong>비유</strong>: 학생이 문제를 푸는 것이 아니라, 문제지(<span class="math inline">\(D^{\text{train}}\)</span>)를 스캔하면 그 문제에 맞는 <strong>맞춤형 해설지(<span class="math inline">\(\theta\)</span>)</strong>를 즉시 출력해주는 ‘마법 복사기’(<span class="math inline">\(g_\omega\)</span>)를 만드는 것과 같습니다.</li>
<li><strong>핵심 아이디어</strong>: 느린 반복 최적화 과정을 완전히 생략하고, 함수 한 번 통과시키는 것으로 학습을 끝냅니다.</li>
<li><strong>주요 연구 주제</strong>:
<ol type="1">
<li><strong>어디까지 복사할까?</strong>: 해설지의 모든 내용을 새로 만들까(분류기 합성), 아니면 기존 교과서(특징 추출기)는 그대로 두고 핵심 공식만 새로 만들어줄까?</li>
<li><strong>어떻게 효율적으로 복사할까?</strong>: 복사기 자체(<span class="math inline">\(\omega\)</span>)가 너무 크고 복잡하지 않도록 어떻게 설계할까?</li>
</ol></li>
<li><strong>이론적 배경 (상각 추론)</strong>: 이 방식은 복잡한 베이지안 확률 계산을 “미리 학습된 신경망 한 번 통과시키는” 간단한 과정으로 근사하는 것과 같다는 깊은 이론적 해석이 가능합니다.</li>
</ul>
</section>
<section id="임베딩-함수-embedding-functions-metric-learning" class="level3">
<h3 class="anchored" data-anchor-id="임베딩-함수-embedding-functions-metric-learning">임베딩 함수 (Embedding Functions, Metric Learning)</h3>
<p>여기서 메타-최적화 과정은 원시 입력(raw inputs)을 쿼리와 서포트 인스턴스 간의 간단한 유사도 비교를 통해 인식하기에 적합한 표현으로 변환하는 <strong>임베딩 네트워크 <span class="math inline">\(\omega\)</span></strong>를 학습합니다[20], [83], [90], [117] (예: 코사인 유사도 또는 유클리드 거리 사용).</p>
<p>이러한 방법들은 기존 분류 체계(섹션 3.1)에서 측정 학습으로 분류되지만, 위의 피드-포워드 블랙박스 모델의 특수한 경우로도 볼 수 있습니다. 이는 서포트와 쿼리 이미지 <span class="math inline">\(x_s\)</span>와 <span class="math inline">\(x_q\)</span>의 임베딩 내적에 기반하여 로짓(logits)을 생성하는 방법, 즉 <span class="math inline">\(g_{w}(x_q)^T g_{w}(x_s)\)</span>[83], [117]을 보면 쉽게 알 수 있습니다.</p>
<ul>
<li>여기서 서포트 이미지는 쿼리 예제를 해석하기 위한 ’가중치’를 생성하며, 이는 ’하이퍼네트워크’가 쿼리셋에 대한 선형 분류기를 생성하는 FFM의 특수한 경우로 만듭니다.</li>
</ul>
<p>이 계열의 기본 방법들은 임베딩을 과제-조건부(task-conditional)로 만들거나[101], [118], 더 정교한 비교 측정 기준을 학습하거나[91], [92], 또는 확률적 정규화기와 같은 다른 하이퍼파라미터를 훈련시키기 위해 gradient 기반 메타러닝과 결합함으로써[119] 더욱 향상되었습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“데이터를 분류하기 좋은 지도(임베딩 공간)”</strong>를 만드는 방법을 배웁니다.</li>
<li><strong>비유</strong>: 도서관 사서가 책을 정리하는 것과 같습니다. 좋은 사서(<span class="math inline">\(\omega\)</span>)는 관련 있는 책(같은 클래스)은 같은 서가에 모아두고, 관련 없는 책(다른 클래스)은 멀리 떨어진 서가에 둡니다.</li>
<li><strong>작동 방식</strong>:
<ol type="1">
<li>새로운 책(쿼리 데이터)이 들어오면,</li>
<li>그 책과 가장 가까운 곳에 있는 책들(서포트 데이터)을 보고,</li>
<li>“아, 이 책은 과학 섹션에 있으니 과학 책이구나!”라고 판단합니다.</li>
</ol></li>
<li><strong>FFM과의 관계</strong>: 이것은 FFM의 매우 <strong>특수한 형태</strong>로 볼 수 있습니다. ‘서포트 데이터’가 일종의 ’분류 기준(가중치)’ 역할을 하여 ’쿼리 데이터’를 판단하기 때문입니다. ’마법 복사기’가 아주 단순한 형태의 ’선형 분류기’만 출력하는 경우와 같습니다.</li>
</ul>
</section>
<section id="손실-및-보조-과제-losses-and-auxiliary-tasks" class="level3">
<h3 class="anchored" data-anchor-id="손실-및-보조-과제-losses-and-auxiliary-tasks">손실 및 보조 과제 (Losses and Auxiliary Tasks)</h3>
<p>optimzer 설계에 대한 메타러닝 접근법과 유사하게, 이들은 기반 모델을 위한 <strong>내부 과제-손실 <span class="math inline">\(\mathcal{L}^{\text{task}}_{\omega}(\cdot)\)</span>을 학습</strong>하는 것을 목표로 합니다. 손실-학습 접근법은 일반적으로 손실과 관련된 양(예: 예측, 특징, 또는 모델 파라미터)을 입력받아 스칼라 값을 출력하는 작은 신경망을 정의하며, 이 출력은 내부 (과제) optimzer에 의해 손실로 취급됩니다.</p>
<ul>
<li>이는 일반적으로 사용되는 손실 함수들보다 최적화하기 더 쉬운(예: 지역 최솟값이 적은) 학습된 손실로 이어지거나[23], [120], [121],</li>
<li>개선된 일반화와 함께 더 빠른 학습으로 이어지거나[43], [122]-[124],</li>
<li>또는 그 최솟값이 도메인 이동에 더 강건한 모델에 해당하는 손실[42]로 이어지는 등의 잠재적 이점을 가집니다.</li>
</ul>
<p>손실 학습 방법은 또한 레이블이 없는 인스턴스로부터 학습하는 법을 배우거나[101], [125], 또는 정밀도-재현율 곡선 아래 면적과 같이 미분 불가능한 실제 과제 손실에 대한 미분 가능한 근사치로서 <span class="math inline">\(\mathcal{L}^{\text{task}}(\cdot)\)</span>를 학습하는 데[126], [127] 사용되었습니다.</p>
<p>손실 학습은 자기-지도(self-supervised)[128] 또는 보조 과제(auxiliary task)[129] 학습의 일반화에서도 발생합니다. 이러한 문제들에서는 주 과제에 대한 표현을 향상시킬 목적으로 비지도 예측 과제(예: 비전 분야의 픽셀 색칠하기[128] 또는 RL 분야의 단순히 픽셀 바꾸기[129])가 정의되고 최적화됩니다. 이 경우, 사용할 최상의 보조 과제(손실)를 미리 예측하기 어려울 수 있으므로, 메타러닝을 사용하여 주 과제 학습 개선에 미치는 영향에 따라 여러 보조 손실 중에서 선택할 수 있습니다. 즉, <span class="math inline">\(\omega\)</span>는 보조 과제별 가중치입니다[70]. 더 일반적으로는, 예시에 보조 레이블을 달아주는 보조 과제 생성기를 메타-학습할 수도 있습니다[130].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“가장 이상적인 채점 기준(손실 함수)”</strong>을 배웁니다.</li>
<li><strong>비유</strong>: 학생을 평가할 때, 단순히 ’정답 개수’로만 점수를 매기는 것이 최선이 아닐 수 있습니다. “어떤 방식으로 채점(<span class="math inline">\(\mathcal{L}^{\text{task}}\)</span>)해야 학생이 가장 빠르고 깊이 있게 성장할까?”라는 <strong>‘최고의 채점 방식’(<span class="math inline">\(\omega\)</span>)</strong> 자체를 학습하는 것입니다.</li>
<li><strong>목표</strong>:
<ol type="1">
<li><strong>더 쉬운 최적화</strong>: 정답으로 가는 길이 울퉁불퉁하지 않고 매끄러운 손실 함수를 만듭니다.</li>
<li><strong>더 나은 일반화</strong>: 최종 시험에서 더 높은 점수를 받게 유도하는 손실 함수를 만듭니다.</li>
<li><strong>보조 과제 선택</strong>: 주 과제(예: 자율주행)에 도움이 되는 최적의 보조 과제(예: ‘도로선 예측하기’, ‘신호등 색깔 맞추기’)의 중요도를 자동으로 학습합니다.</li>
</ol></li>
</ul>
</section>
<section id="구조-architectures" class="level3">
<h3 class="anchored" data-anchor-id="구조-architectures">구조 (Architectures)</h3>
<p>구조 발견은 신경망에서 항상 중요한 영역이었으며[37], [131], 간단한 전체 탐색(exhaustive search)이 불가능한 분야입니다. 메타러닝은 구조를 학습함으로써 이 매우 비용이 많이 드는 과정을 자동화하는 데 사용될 수 있습니다.</p>
<ul>
<li>초기 시도들은 진화 알고리즘을 사용하여 LSTM 셀의 토폴로지를 학습했으며[132],</li>
<li>이후 접근법들은 좋은 CNN 구조에 대한 설명을 생성하기 위해 RL을 활용했습니다[26].</li>
<li>진화 알고리즘[25]은 그래프로 모델링된 구조 내의 블록을 학습할 수 있으며, 이 그래프를 편집하여 돌연변이를 일으킬 수 있습니다.</li>
<li>DARTS[18] 형태의 경사도 기반 구조 표현도 탐구되었는데, 여기서 훈련 중 순전파는 주어진 블록 내의 모든 가능한 레이어의 출력에 대한 소프트맥스로 구성되며, 이는 메타-학습될 계수(즉, <span class="math inline">\(\omega\)</span>)에 의해 가중치가 부여됩니다. 메타-테스트 중에는 가장 높은 계수에 해당하는 레이어만 유지하여 구조가 이산화(discretized)됩니다.</li>
<li>DARTS를 개선하기 위한 최근 노력들은 더 효율적인 미분 가능한 근사[133], 이산화 단계의 강건성 향상[134], 적응하기 쉬운 초기화 학습[135], 또는 구조 사전 확률(priors) 학습[136]에 초점을 맞추었습니다. 자세한 내용은 섹션 5.4를 참조하십시오.</li>
</ul>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“가장 성능이 좋은 모델의 설계도(구조)”</strong>를 배웁니다.</li>
<li><strong>비유</strong>: 최고의 자동차를 만들기 위해, 엔진, 바퀴, 차체를 어떻게 조합하고 연결해야 하는지에 대한 <strong>‘최적의 설계도’(<span class="math inline">\(\omega\)</span>)</strong>를 컴퓨터가 자동으로 찾게 하는 것입니다.</li>
<li><strong>어떻게?</strong>:
<ol type="1">
<li><strong>진화/강화학습</strong>: 여러 설계도를 무작위로 만들어보고, 성능 테스트를 거쳐 가장 좋은 설계도만 살아남게 하거나, 좋은 설계도를 만드는 ’설계 에이전트’를 훈련시킵니다.</li>
<li><strong>경사도 기반 (DARTS)</strong>: 모든 가능한 부품(레이어)을 일단 전부 연결해두고, 각 연결의 ’중요도(<span class="math inline">\(\omega\)</span>)’를 학습합니다. 학습이 끝난 뒤, 중요도가 낮은 연결은 끊어버리고 가장 중요한 연결만 남겨 최종 설계도를 완성합니다.</li>
</ol></li>
</ul>
</section>
<section id="어텐션-모듈-attention-modules" class="level3">
<h3 class="anchored" data-anchor-id="어텐션-모듈-attention-modules">어텐션 모듈 (Attention Modules)</h3>
<p>어텐션 모듈은 측정 기반 메타-학습기에서 비교기로 사용되거나[137], 퓨샷 연속 학습에서 치명적 망각(catastrophic forgetting)을 방지하거나[138], 텍스트 분류 과제들의 분포를 요약하는 데[139] 사용되었습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“어디에 집중해야 하는지”</strong>를 배웁니다.</li>
<li><strong>비유</strong>: 학생이 문제를 풀 때, 문제의 어느 부분(키워드, 조건 등)에 집중해야 정답을 찾을 수 있는지를 알려주는 <strong>‘형광펜’(<span class="math inline">\(\omega\)</span>)</strong>의 역할을 학습합니다.</li>
<li><strong>용도</strong>:
<ul>
<li>두 이미지를 비교할 때 어느 부분이 유사한지 집중합니다.</li>
<li>새로운 것을 배울 때, 이전에 배운 지식 중 어느 부분을 건드리지 말아야 할지 집중합니다.</li>
</ul></li>
</ul>
</section>
<section id="모듈-modules" class="level3">
<h3 class="anchored" data-anchor-id="모듈-modules">모듈 (Modules)</h3>
<p>모듈러 메타러닝[140], [141]은 과제에 구애받지 않는 지식 <span class="math inline">\(\omega\)</span>가 <strong>모듈 집합</strong>을 정의하고, 이 모듈들이 마주치는 각 과제를 해결하기 위해 <span class="math inline">\(\theta\)</span>에 의해 정의된 과제-특화 방식으로 재구성된다고 가정합니다. 이러한 전략들은 다중과제 및 전이 학습에서 잘 연구된 지식 공유에 대한 일반적인 구조적 접근법의 메타러닝 일반화로 볼 수 있으며[67], [68], [142], 궁극적으로는 구성적 학습(compositional learning)[143]의 기반이 될 수 있습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“재사용 가능한 레고 블록(모듈) 세트”</strong>를 배웁니다.</li>
<li><strong>비유</strong>: 자동차, 비행기, 배를 각각 처음부터 설계하는 대신, ‘바퀴’, ‘날개’, ‘엔진’, ’조종석’과 같은 <strong>‘표준 부품’(<span class="math inline">\(\omega\)</span>)</strong> 세트를 미리 만들어 둡니다.</li>
<li><strong>작동 방식</strong>: 새로운 과제(예: ‘잠수함 만들기’)가 주어지면, 이 표준 부품들을 <strong>어떻게 조합(<span class="math inline">\(\theta\)</span>)</strong>해야 할지만 빠르게 학습합니다. 이는 훨씬 효율적입니다.</li>
</ul>
</section>
<section id="하이퍼파라미터-hyper-parameters" class="level3">
<h3 class="anchored" data-anchor-id="하이퍼파라미터-hyper-parameters">하이퍼파라미터 (Hyper-parameters)</h3>
<p>여기서 <span class="math inline">\(\omega\)</span>는 정규화 강도[17], [71], 파라미터별 정규화[95], 다중과제 학습에서의 과제-관련성[69], 또는 데이터 정제에서의 희소성 강도[69]와 같은 기반 학습기의 하이퍼파라미터를 나타냅니다. 스텝 사이즈[71], [79], [80]와 같은 하이퍼파라미터는 optimzer의 일부로 볼 수 있어, 하이퍼파라미터와 optimzer 학습 범주 간에 중첩이 발생합니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“학습 과정을 조절하는 각종 설정값”</strong>을 배웁니다.</li>
<li><strong>비유</strong>: 요리를 할 때 ‘불의 세기’, ‘조리 시간’, ‘소금의 양’(<span class="math inline">\(\omega\)</span>)과 같은 <strong>‘최적의 레시피 설정값’</strong>을 학습하는 것입니다. 이 설정값들이 최종 요리의 맛(성능)을 결정합니다.</li>
</ul>
</section>
<section id="데이터-증강-data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="데이터-증강-data-augmentation">데이터 증강 (Data Augmentation)</h3>
<p>지도 학습에서는 기존 데이터에 레이블을 보존하는 변환을 가하여 더 많은 훈련 데이터를 합성함으로써 일반화를 개선하는 것이 일반적입니다. 데이터 증강 연산은 내부 문제(식 6)의 최적화 단계에 포함되며, 전통적으로는 사람이 직접 설계합니다. 그러나 <span class="math inline">\(\omega\)</span>가 데이터 증강 전략을 정의할 때, 이는 검증 성능을 최대화하기 위해 외부 최적화(식 5)에 의해 학습될 수 있습니다[144].</p>
<p>증강 연산은 일반적으로 미분 불가능하기 때문에, 이는 강화 학습[144], discrete gradient-estimators[145], 또는 진화[146] 방법을 필요로 합니다. 강력한 GAN 기반 데이터 증강 방법[147]이 내부-수준 학습에 사용되고 외부-수준 학습에서 최적화될 수 있는지 여부는 아직 미해결 질문입니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“가장 효과적인 데이터 뻥튀기 방법”</strong>을 배웁니다.</li>
<li><strong>비유</strong>: 고양이 사진이 10장밖에 없을 때, 이 사진들을 ‘좌우 반전’, ‘회전’, ‘밝기 조절’ 등을 해서 1000장처럼 만드는 것이 데이터 증강입니다. 메타러닝은 “어떤 종류의 ‘뻥튀기’(<span class="math inline">\(\omega\)</span>)를 해야 모델 성능이 가장 많이 오를까?”라는 <strong>‘최고의 뻥튀기 전략’</strong>을 학습합니다.</li>
</ul>
</section>
<section id="미니배치-선택-샘플-가중치-및-커리큘럼-학습-minibatch-selection-sample-weights-and-curriculum-learning" class="level3">
<h3 class="anchored" data-anchor-id="미니배치-선택-샘플-가중치-및-커리큘럼-학습-minibatch-selection-sample-weights-and-curriculum-learning">미니배치 선택, 샘플 가중치, 및 커리큘럼 학습 (Minibatch Selection, Sample Weights, and Curriculum Learning)</h3>
<p>기반 알고리즘이 미니배치 기반 확률적 경사 하강법일 때, 학습 전략의 설계 파라미터는 배치 선택 과정입니다. 무작위로 샘플링된 미니배치를 개선하기 위해 사람이 설계한 다양한 방법[148]이 존재합니다. 메타러닝 접근법은 <span class="math inline">\(\omega\)</span>를 인스턴스 선택 확률[149] 또는 미니배치에 포함할 인스턴스를 선택하는 신경망[150]으로 정의할 수 있습니다. 미니배치 선택 정책과 관련된 방법으로는 훈련 세트에 대한 샘플별 손실 가중치 <span class="math inline">\(\omega\)</span>를 학습하는 방법이 있습니다[151], [152]. 이는 노이즈가 있는 샘플의 가중치를 줄이거나[151], [152], 이상치의 가중치를 줄이거나[69], 또는 클래스 불균형을 보정하는 데[151] 사용될 수 있습니다.</p>
<p>더 일반적으로, 커리큘럼[153]은 항목을 무작위 순서로 학습하는 것보다 더 나은 성능을 내는 데이터 또는 개념의 학습 순서를 의미합니다.</p>
<ul>
<li>예를 들어, 너무 어렵거나 너무 쉬운(이미 학습된) 인스턴스는 거부하고 적절한 난이도의 인스턴스에 집중하는 것입니다.</li>
<li>커리큘럼을 사람이 직접 정의하는 대신[154], 메타러닝은 그 과정을 자동화하고, 메타 지식으로서 가르치는 정책을 정의하고 학생의 발전을 최적화하도록 훈련함으로써 적절한 난이도의 예시를 선택할 수 있습니다[150], [155].</li>
</ul>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“어떤 데이터를, 어떤 순서로, 얼마나 중요하게”</strong> 가르칠지를 배웁니다.</li>
<li><strong>비유</strong>: 최고의 교사는 학생의 수준에 맞춰 <strong>‘맞춤형 교육 계획’(<span class="math inline">\(\omega\)</span>)</strong>을 세웁니다.
<ol type="1">
<li><strong>미니배치 선택</strong>: “지금 단계에서는 이 유형의 문제를 집중적으로 풀어보는 게 좋겠어.” (가장 도움이 될 데이터 선택)</li>
<li><strong>샘플 가중치</strong>: “이 문제는 아주 중요하니 별표 다섯 개 치고, 저 문제는 오타가 있으니 무시해.” (데이터의 중요도 조절)</li>
<li><strong>커리큘럼 학습</strong>: “처음에는 쉬운 덧셈부터 가르치고, 그 다음에 뺄셈, 마지막에 곱셈을 가르쳐야 해.” (가장 효율적인 학습 순서 결정)</li>
</ol></li>
<li>메타러닝은 이러한 <strong>‘최고의 교수법’</strong>을 데이터로부터 자동으로 학습합니다.</li>
</ul>
</section>
<section id="데이터셋-레이블-및-환경-datasets-labels-and-environments" class="level3">
<h3 class="anchored" data-anchor-id="데이터셋-레이블-및-환경-datasets-labels-and-environments">데이터셋, 레이블 및 환경 (Datasets, Labels and Environments)</h3>
<p>또 다른 메타-표현은 <strong>서포트 데이터셋 그 자체</strong>입니다.</p>
<ul>
<li>이는 소스 데이터셋이 고정되어 있다고 간주했던 우리의 초기 정형화(섹션 2.1, 식 2-3)에서 벗어납니다.</li>
<li>그러나 이는 식 5-6의 이중 최적화 관점에서는 쉽게 이해될 수 있습니다.
<ul>
<li>만약 상위 최적화의 검증 세트가 실제이고 고정되어 있고, 하위 최적화의 훈련 세트가 <span class="math inline">\(\omega\)</span>로 매개변수화된다면, 훈련 데이터셋은 검증 성능을 최적화하기 위해 메타-학습에 의해 조정될 수 있습니다.</li>
</ul></li>
</ul>
<p><strong>데이터셋 증류(Dataset distillation)</strong>[156], [157]에서는, 서포트 이미지 자체가 학습되어, 그 이미지들에 대해 몇 스텝만 학습해도 실제 쿼리 이미지에 대한 좋은 일반화를 가능하게 합니다. 이는 대규모 데이터셋을 소수의 이미지로 요약하는 데 사용될 수 있으며, 스트리밍 데이터셋을 저장할 수 없는 연속 학습에서의 리플레이에 유용합니다.</p>
<p>고정된 레이블 <span class="math inline">\(y\)</span>에 대해 입력 이미지 <span class="math inline">\(x\)</span>를 학습하는 대신, 고정된 이미지 <span class="math inline">\(x\)</span>에 대해 <strong>입력 레이블 <span class="math inline">\(y\)</span>를 학습</strong>할 수도 있습니다. 이는 데이터셋 증류에서처럼 핵심 세트(core sets)[158]를 증류하거나, 또는 예를 들어 검증 세트 성능을 최적화하기 위해 레이블이 없는 세트의 레이블을 직접 학습하는 준지도 학습(semi-supervised learning)에 사용될 수 있습니다[159], [160].</p>
<p>컴퓨터 비전이나 강화 학습에서의 <strong>sim2real 학습</strong>[161]의 경우, 훈련 데이터를 생성하기 위해 환경 시뮬레이터를 사용합니다. 이 경우, 섹션 5.3에서 자세히 설명하겠지만, 그 환경 시뮬레이터에서 생성된 데이터로 훈련한 후 다운스트림 모델의 실제 데이터 (검증) 성능을 최적화하기 위해 <strong>그래픽 엔진[162]이나 시뮬레이터[163]를 훈련</strong>시킬 수도 있습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>무엇을 배우는가?</strong>: <strong>“가장 이상적인 교과서/문제집(<span class="math inline">\(\omega\)</span>)”</strong> 자체를 배웁니다.</li>
<li><strong>비유</strong>: 학생에게 기존의 교과서를 주는 것이 아니라, “어떤 내용으로 구성된 교과서를 만들어줘야 학생이 가장 빠르고 깊이 있게 배울까?”를 고민하여 <strong>’맞춤형 교과서’를 직접 저술</strong>하는 것과 같습니다.</li>
<li><strong>다양한 형태</strong>:
<ol type="1">
<li><strong>데이터셋 증류</strong>: 1000페이지짜리 교과서의 모든 핵심 내용을 단 10페이지로 요약한 <strong>‘초압축 요약본’</strong>을 만듭니다. 이 요약본만 봐도 전체 내용을 이해할 수 있습니다.</li>
<li><strong>레이블 학습</strong>: 문제(이미지)는 그대로 두고, <strong>가장 이상적인 정답(레이블)</strong>을 만들어냅니다. (준지도 학습)</li>
<li><strong>환경 학습 (Sim2Real)</strong>: 자율주행차를 훈련시킬 가상현실(시뮬레이터)이 있을 때, 이 가상현실을 <strong>실제 세계와 최대한 비슷하게</strong> 만들도록 시뮬레이터 자체를 학습시킵니다.</li>
</ol></li>
</ul>
</section>
<section id="논의-추론적-표현과-방법-discussion-transductive-representations-and-methods" class="level3">
<h3 class="anchored" data-anchor-id="논의-추론적-표현과-방법-discussion-transductive-representations-and-methods">논의: 추론적 표현과 방법 (Discussion: Transductive Representations and Methods)</h3>
<p>위에서 논의된 대부분의 표현 <span class="math inline">\(\omega\)</span>는 데이터를 처리하거나 생성하는 함수의 파라미터 벡터입니다. 그러나 언급된 표현 중 일부는 <span class="math inline">\(\omega\)</span>가 말 그대로 데이터 포인트[156], 레이블[159], 또는 샘플별 가중치[152]에 해당하는 <strong>추론적(transductive)</strong>인 의미를 가집니다. 따라서 메타-학습할 <span class="math inline">\(\omega\)</span>의 파라미터 수는 데이터셋의 크기에 따라 확장됩니다. 이러한 방법들의 성공은 현대 메타러닝의 역량을 증명하지만[157], 이 속성은 궁극적으로 그들의 확장성을 제한할 수 있습니다.</p>
<p>추론적 표현과는 별개로, 서포트 인스턴스뿐만 아니라 쿼리 인스턴스에 대해서도 작동하는 <strong>추론적인 방법</strong>들이 있습니다[101], [130].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>추론적(Transductive)이란?</strong>: 훈련 데이터뿐만 아니라, <strong>미리 주어진 테스트 데이터(쿼리셋)의 정보까지 활용</strong>하여 학습하는 방식입니다. (반대: 귀납적(Inductive)은 훈련 데이터만 보고 학습)</li>
<li><strong>추론적 표현</strong>: <span class="math inline">\(\omega\)</span>가 모델의 가중치 같은 일반적인 규칙이 아니라, <strong>데이터 자체(이미지 픽셀, 레이블 값 등)</strong>인 경우를 말합니다.
<ul>
<li><strong>장점</strong>: 특정 데이터셋에 매우 강력하게 최적화될 수 있습니다.</li>
<li><strong>단점</strong>: 데이터가 많아지면 학습해야 할 <span class="math inline">\(\omega\)</span>의 크기도 무한정 커져서 <strong>확장성이 떨어집니다.</strong></li>
</ul></li>
<li><strong>추론적 방법</strong>: <span class="math inline">\(\omega\)</span>는 일반적인 규칙이지만, 학습 과정에서 테스트 데이터(쿼리셋)의 특징을 참고하는 방법입니다.</li>
</ul>
</section>
<section id="논의-해석-가능한-기호적-표현-discussion-interpretable-symbolic-representations" class="level3">
<h3 class="anchored" data-anchor-id="논의-해석-가능한-기호적-표현-discussion-interpretable-symbolic-representations">논의: 해석 가능한 기호적 표현 (Discussion: Interpretable Symbolic Representations)</h3>
<p>위에서 논의된 많은 메타-표현들을 가로지르는 또 다른 구분은 <strong>해석 불가능한 (비기호적) 표현</strong>과 <strong>인간이 해석 가능한 (기호적) 표현</strong> 사이의 구분입니다. <span class="math inline">\(\omega\)</span>가 신경망을 매개변수화할 때와 같은 비기호적 표현[19]이 더 일반적이며, 위에서 인용된 연구의 대다수를 차지합니다.</p>
<p>그러나 기호적 표현을 사용한 메타러닝도 가능하며, 여기서 <span class="math inline">\(\omega\)</span>는 최적화 프로그램 코드[93]와 같이 인간이 읽을 수 있는 기호적 함수를 나타냅니다. 신경망 손실 함수[42] 대신, 교차 엔트로피와 유사한 표현식으로 정의된 기호적 손실 <span class="math inline">\(\omega\)</span>를 훈련시킬 수 있습니다[123]. ReLU와 같은 표준 활성화 함수를 능가하는 새로운 기호적 활성화 함수를 메타-학습할 수도 있습니다[164]. 이러한 메타-표현은 매끄럽지 않기 때문에, 메타-목적은 미분 불가능하며 최적화하기 더 어렵습니다 (섹션 4.2 참조). 그래서 <span class="math inline">\(\omega\)</span>에 대한 상위 최적화는 일반적으로 RL[93]이나 진화 알고리즘[123]을 사용합니다. 그러나 기호적 표현은 과제군 전반에 걸쳐 일반화하는 능력에서 이점을 가질 수 있습니다[93], [123], [164]. 즉, 메타-훈련 중 단일 <span class="math inline">\(\omega\)</span>로 더 넓은 분포 <span class="math inline">\(p(\mathcal{T})\)</span>를 포괄하거나, 또는 학습된 <span class="math inline">\(\omega\)</span>가 메타-테스트 중 분포를 벗어난 과제에 대해 일반화하는 것입니다 (섹션 6 참조).</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>비기호적(Sub-symbolic) 표현</strong>: 우리가 이해할 수 없는 <strong>숫자의 나열</strong> (예: 신경망의 가중치 행렬). 대부분의 메타러닝이 여기에 해당합니다.</li>
<li><strong>기호적(Symbolic) 표현</strong>: <strong>인간이 읽고 이해할 수 있는 형태</strong> (예: <code>loss = -y * log(p)</code>)</li>
<li><strong>무엇을 배우는가?</strong>: 신경망 가중치 대신, <strong>수학 공식이나 프로그램 코드 자체</strong>를 배웁니다.</li>
<li><strong>장점</strong>:
<ol type="1">
<li><strong>해석 가능</strong>: AI가 무엇을 배웠는지 우리가 이해할 수 있습니다.</li>
<li><strong>뛰어난 일반화</strong>: 특정 숫자에 얽매이지 않고 추상적인 규칙을 배우기 때문에, 훈련 때 본 적 없는 매우 생소한 문제에도 잘 적응할 수 있는 잠재력이 있습니다.</li>
</ol></li>
<li><strong>단점</strong>: 미분이 불가능해서 경사 하강법으로 학습시키기 어렵습니다. (그래서 RL이나 진화 알고리즘을 사용)</li>
</ul>
</section>
<section id="논의-상각-discussion-amortization" class="level3">
<h3 class="anchored" data-anchor-id="논의-상각-discussion-amortization">논의: 상각 (Discussion: Amortization)</h3>
<p>논의된 표현 중 일부를 연관 짓는 한 가지 방법은 수반되는 <strong>학습 상각(learning amortization)</strong>의 정도입니다[45]. 즉, 메타-테스트 중에 얼마나 많은 과제-특화 최적화가 수행되는가 대 메타-훈련 중에 얼마나 많은 학습이 상각되는가 입니다. 처음부터 훈련하거나 전통적인 미세 조정[57]은 메타-테스트에서 완전한 과제-특화 최적화를 수행하며, 상각은 없습니다. MAML[16]은 초기 조건을 맞춤으로써 제한된 상각을 제공하여, 몇 스텝의 미세 조정으로 새로운 과제를 학습할 수 있게 합니다. 순수한 FFM[20], [90], [110]은 과제-특화 최적화 없이 완전히 상각되어, 새로운 과제를 가장 빠르게 학습할 수 있게 합니다. 한편, 일부 하이브리드 접근법[100], [101], [111], [165]은 단일 프레임워크 내에서 피드-포워드와 최적화 기반 메타러닝 모두를 활용하여 준-상각(semi-amortized) 학습을 구현합니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>상각(Amortization)이란?</strong>: “비싼 계산 비용을 언제 치를 것인가?”의 문제입니다.</li>
<li><strong>비유</strong>: 레스토랑에서 요리하기
<ul>
<li><strong>상각 없음 (전통적 학습)</strong>: 손님이 주문할 때마다(새로운 과제), 처음부터 재료를 손질하고 요리를 시작합니다. (시간이 오래 걸림)</li>
<li><strong>완전 상각 (FFM)</strong>: 영업 시작 전에(메타-훈련), 모든 재료를 미리 손질해두고(밀키트 제작), 소스도 다 만들어 둡니다. 손님이 주문하면(새로운 과제), 그냥 데워서 내기만 하면 됩니다. (매우 빠름)</li>
<li><strong>제한된 상각 (MAML)</strong>: 재료 손질(초기화)까지는 미리 해두지만, 소스를 만들고 볶는 과정(몇 스텝의 최적화)은 주문이 들어오면 합니다. (중간 정도의 속도)</li>
<li><strong>준-상각 (하이브리드)</strong>: 밀키트(FFM)를 사용하면서, 손님의 특별 요청에 따라 약간의 추가 조리(최적화)를 하는 방식입니다.</li>
</ul></li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>