<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="김한울">
<meta name="dcterms.date" content="2025-11-13">
<meta name="description" content="메타 러닝 관련 논문 요약 및 주요 내용">

<title>Meta Learning in Neural Networks — A Survey – Master Thesis Literature Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e31584831b205ffbb2d98406f31c2a5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Master Thesis Literature Review</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Posts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="../posts/index.html">
 <span class="dropdown-text">All posts</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Meta Learning in Neural Networks — A Survey</h1>
                  <div>
        <div class="description">
          메타 러닝 관련 논문 요약 및 주요 내용
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">MetaLearning</div>
                <div class="quarto-category">Survey</div>
                <div class="quarto-category">Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>김한울 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 13, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#paper-review-meta-learning-in-neural-networks-a-survey" id="toc-paper-review-meta-learning-in-neural-networks-a-survey" class="nav-link active" data-scroll-target="#paper-review-meta-learning-in-neural-networks-a-survey">Paper Review: Meta Learning in Neural Networks: A Survey</a></li>
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">BackGround</a>
  <ul class="collapse">
  <li><a href="#메타러닝을-공식화-해보자" id="toc-메타러닝을-공식화-해보자" class="nav-link" data-scroll-target="#메타러닝을-공식화-해보자">메타러닝을 공식화 해보자</a>
  <ul class="collapse">
  <li><a href="#기존-머신러닝" id="toc-기존-머신러닝" class="nav-link" data-scroll-target="#기존-머신러닝">기존 머신러닝</a></li>
  <li><a href="#과제-분포task-distribution-관점에서-본-메타러닝" id="toc-과제-분포task-distribution-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#과제-분포task-distribution-관점에서-본-메타러닝">과제 분포(Task-Distribution) 관점에서 본 메타러닝</a></li>
  <li><a href="#이중-최적화bilevel-optimization-관점에서-본-메타러닝" id="toc-이중-최적화bilevel-optimization-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#이중-최적화bilevel-optimization-관점에서-본-메타러닝">이중 최적화(Bilevel Optimization) 관점에서 본 메타러닝</a></li>
  <li><a href="#피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" id="toc-피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" class="nav-link" data-scroll-target="#피드-포워드-모델feed-forward-model-관점에서-본-메타러닝">피드-포워드 모델(Feed-Forward Model) 관점에서 본 메타러닝</a></li>
  </ul></li>
  <li><a href="#메타러닝의-역사적-배경" id="toc-메타러닝의-역사적-배경" class="nav-link" data-scroll-target="#메타러닝의-역사적-배경">메타러닝의 역사적 배경</a></li>
  <li><a href="#관련-분야" id="toc-관련-분야" class="nav-link" data-scroll-target="#관련-분야">관련 분야</a>
  <ul class="collapse">
  <li><a href="#전이-학습-transfer-learning-tl" id="toc-전이-학습-transfer-learning-tl" class="nav-link" data-scroll-target="#전이-학습-transfer-learning-tl">전이 학습 (Transfer Learning, TL)</a></li>
  <li><a href="#도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" id="toc-도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" class="nav-link" data-scroll-target="#도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg">도메인 적응(Domain Adaptation, DA) 및 도메인 일반화(Domain Generalization, DG)</a></li>
  <li><a href="#연속-학습-continual-learning-cl" id="toc-연속-학습-continual-learning-cl" class="nav-link" data-scroll-target="#연속-학습-continual-learning-cl">연속 학습 (Continual Learning, CL)</a></li>
  <li><a href="#다중과제-학습-multi-task-learning-mtl" id="toc-다중과제-학습-multi-task-learning-mtl" class="nav-link" data-scroll-target="#다중과제-학습-multi-task-learning-mtl">다중과제 학습 (Multi-Task Learning, MTL)</a></li>
  <li><a href="#하이퍼파라미터-최적화-hyperparameter-optimization-ho" id="toc-하이퍼파라미터-최적화-hyperparameter-optimization-ho" class="nav-link" data-scroll-target="#하이퍼파라미터-최적화-hyperparameter-optimization-ho">하이퍼파라미터 최적화 (Hyperparameter Optimization, HO)</a></li>
  <li><a href="#계층적-베이즈-모델-hierarchical-bayesian-models-hbm" id="toc-계층적-베이즈-모델-hierarchical-bayesian-models-hbm" class="nav-link" data-scroll-target="#계층적-베이즈-모델-hierarchical-bayesian-models-hbm">계층적 베이즈 모델 (Hierarchical Bayesian Models, HBM)</a></li>
  <li><a href="#automl" id="toc-automl" class="nav-link" data-scroll-target="#automl">AutoML</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="paper-review-meta-learning-in-neural-networks-a-survey" class="level1">
<h1>Paper Review: Meta Learning in Neural Networks: A Survey</h1>
<pre><code>@article{hospedales2021meta,
  title={Meta-learning in neural networks: A survey},
  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={9},
  pages={5149--5169},
  year={2021},
  publisher={IEEE}
}</code></pre>
<p><code>업데이트 내역</code></p>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td>2025-11-14</td>
<td>태스크 분포 관점 업데이트</td>
<td></td>
</tr>
<tr class="even">
<td>2025-11-15</td>
<td>Bilevel optimization View 업데이트</td>
<td></td>
</tr>
<tr class="odd">
<td>2025-11-16</td>
<td>2.2-2.3 업데이트</td>
<td>배고프군</td>
</tr>
</tbody>
</table>
</section>
<section id="abstract" class="level1">
<h1>Abstract</h1>
<p><code>Learning-to-learn</code>이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 <strong>학습 알고리즘 자체를 개선하는 것을 목표</strong>로 합니다.</p>
<p>이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다.</p>
<p>본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다.</p>
<ul>
<li>먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다.</li>
<li>다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다.</li>
<li>또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다.</li>
<li>마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다.</li>
</ul>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음</p>
<blockquote class="blockquote">
<p>Meta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.</p>
</blockquote>
<ol type="1">
<li>provides an alternative paradigm?</li>
</ol>
<ul>
<li>기존 방식?<br>
기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.<br>
</li>
<li>대안(메타러닝):<br>
기계에게 숙제 하나만 주는 게 아니라, <strong>“스스로 공부하는 법”</strong>을 터득하게 만들자!</li>
</ul>
<ol start="2" type="1">
<li>a machine learning model gains experience over multiple learning episodes</li>
</ol>
<ul>
<li>비유를 해보자면<br>
사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 <strong>여러 과목의 문제(관련된 과제들)</strong>를 풀게 하는 행위랑 비슷함.<br>
이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 <strong>‘요령(패턴)’</strong>을 깨닫게 됨. 이것이 바로 <strong>“경험”</strong>이라고 할 수 있음.</li>
<li><code>learning episodes</code>: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.</li>
</ul>
<p>보통의 경우에, 그리고 역사적으로 보면,</p>
<ol type="1">
<li>머신러닝<br>
</li>
</ol>
<ul>
<li>기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.
<ul>
<li>hand-engineered features<br>
</li>
</ul></li>
<li>그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.
<ul>
<li>이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.<br>
</li>
</ul></li>
<li>즉, 머신러닝에서 <strong>특징 추출 단계</strong>와 <strong>모델 학습 단계</strong>는 분리 되어 있음.</li>
</ul>
<ol start="2" type="1">
<li>딥러닝<br>
</li>
</ol>
<ul>
<li>위 머신러닝의 두 단계인 <strong>특징 추출 단계</strong>와 <strong>모델 학습 단계</strong>를 하나의 단계로 통합해버림.
<ul>
<li>특징과 모델의 공동 학습 (Joint feature and model learning)<br>
</li>
</ul></li>
<li>예전 처럼 특징을 정성스럽게 추출할 필요가 없음.
<ul>
<li>원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,<br>
</li>
<li>모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.<br>
</li>
</ul></li>
<li>고양이 사진 분류하는 모델을 예로 들어보면…
<ul>
<li>초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.<br>
</li>
<li>중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.<br>
</li>
<li>후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.</li>
</ul></li>
<li>어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.<br>
</li>
<li>사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.</li>
<li>이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.</li>
</ul>
<ol start="3" type="1">
<li>신경망에서의 메타러닝?</li>
</ol>
<ul>
<li>특징 추출 단계, 모델 학습 단계, 그리고 <code>알고리즘</code>을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.</li>
</ul>
<p>Thrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.</p>
<blockquote class="blockquote">
<p>Thrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.<br>
<em>해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 </em></p>
</blockquote>
<blockquote class="blockquote">
<p>학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,<br>
즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.</p>
</blockquote>
<ul>
<li>task family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.
<ul>
<li>예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 <strong>“동물 분류”</strong>라는 하나의 task family에 속합니다.<br>
</li>
<li>AI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.</li>
<li>즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>conventional machine learning performance improves as more data from a single task is seen</p>
</blockquote>
<ul>
<li>기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.</li>
</ul>
<p><strong>공짜 점심은 없다(no free lunch) Theorem</strong> 에 대항하는 알고리즘 ㅋㅋ</p>
<blockquote class="blockquote">
<p>This perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.</p>
</blockquote>
<blockquote class="blockquote">
<p>이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.</p>
</blockquote>
<blockquote class="blockquote">
<p>하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.</p>
</blockquote>
<ul>
<li>“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.</li>
</ul>
<p>이 논문이 Review하려고 하는 대상 논문?</p>
<ul>
<li>본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.
<ul>
<li>참고문헌 [27], [28]에 따라 <strong>‘알고리즘 학습’</strong>으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.</li>
<li>이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.</li>
</ul></li>
<li>본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.
<ul>
<li>먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다</li>
<li>그런 다음, <strong>메타-표현(meta-representation), 메타-목적(meta-objective), 메타-최적화기(meta-optimizer)</strong>라는 관점에서 새로운 분류 체계를 제공할 것입니다.</li>
<li>이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 <strong>설계 공간(design-space)</strong>을 제시합니다.</li>
<li>우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.</li>
<li>마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다.</li>
</ul></li>
</ul>
</section>
<section id="background" class="level1">
<h1>BackGround</h1>
<p>메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.</p>
<ul>
<li>이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.</li>
</ul>
<section id="메타러닝" class="level4">
<h4 class="anchored" data-anchor-id="메타러닝">메타러닝?</h4>
<p><strong>‘학습하는 방법을 학습하는 것(learning to learn)’</strong></p>
<ul>
<li><p>이는 <strong>여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미</strong>함.</p></li>
<li><p>기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.</p></li>
<li><p><strong>기반 학습(base learning)</strong> 중에는 <strong>내부(inner)</strong> (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임<br>
</p></li>
<li><p><strong>메타러닝</strong> 중에는 <strong>외부(outer)</strong>(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.</p>
<ul>
<li>예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.</li>
<li>(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.</li>
</ul>
<blockquote class="blockquote">
<p>inner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.</p>
</blockquote></li>
</ul>
<blockquote class="blockquote">
<p>메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?</p>
</blockquote>
<p>위에 정의된 대로라면, <code>Cross Validtion</code>을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.</p>
</section>
<section id="현대의-neural-network-meta-learning의-두드러지는-특징" class="level4">
<h4 class="anchored" data-anchor-id="현대의-neural-network-meta-learning의-두드러지는-특징">현대의 neural-network meta-learning의 두드러지는 특징</h4>
<ul>
<li><strong>명시적으로 정의된 메타 수준의 목적 함수</strong>이 있고,<br>
</li>
<li>이 목적 함수에 대한 내부 알고리즘의 <strong>end-to-end 최적화</strong>가 이루어짐.</li>
</ul>
</section>
<section id="메타러닝을-공식화-해보자" class="level2">
<h2 class="anchored" data-anchor-id="메타러닝을-공식화-해보자">메타러닝을 공식화 해보자</h2>
<section id="기존-머신러닝" class="level3">
<h3 class="anchored" data-anchor-id="기존-머신러닝">기존 머신러닝</h3>
<p>기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 <span class="math inline">\(D = \{(x_1, y_1), \dots, (x_N, y_N)\}\)</span>이 주어짐.</p>
<p><span class="math inline">\(\theta\)</span>로 매개변수화된 예측 모델 <span class="math inline">\(\hat{y} = f_{\theta}(x)\)</span>를 다음 식을 풀어 훈련시키게 됨:</p>
<p><span class="math display">\[
\theta^* = \arg\min_{\theta} \mathcal{L}(D; \theta, \omega) \quad (1)
\]</span></p>
<ul>
<li><span class="math inline">\(\mathcal{L}\)</span>은 실제 레이블과 <span class="math inline">\(f_{\theta}(\cdot)\)</span>가 예측한 값 사이의 오차를 측정하는 손실 함수.</li>
<li><span class="math inline">\(\omega\)</span>라는 조건이 걸려 있음.
<ul>
<li>이는 학습하는 방법 <span class="math inline">\(\omega\)</span>에 따라 이 식(1)의 해인 <span class="math inline">\(\theta\)</span>가 달라질 수 있다는 의미임.<br>
</li>
<li><span class="math inline">\(\omega\)</span> 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.</li>
</ul></li>
<li>일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.</li>
</ul>
<section id="기존-머신러닝의-2가지-가정" class="level5">
<h5 class="anchored" data-anchor-id="기존-머신러닝의-2가지-가정">기존 머신러닝의 2가지 가정</h5>
<ol type="1">
<li>최적화 과정이 모든 문제 <span class="math inline">\(D\)</span>에 대해 매번 처음부터 수행됨(from scratch)<br>
</li>
<li>학습 방법 <span class="math inline">\(\omega\)</span>는 사전에 지정됨.</li>
</ol>
<p>이때, <span class="math inline">\(\omega\)</span>의 <strong>specification</strong>, 즉 <code>학습 방법을 어떻게 정하느냐</code>는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.</p>
<ul>
<li><p>메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 <em>사전에 지정하고 고정하는 대신</em> 학습 알고리즘 자체를 학습하게 됨.</p></li>
<li><p>Specification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음</p>
<blockquote class="blockquote">
<p>최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?<br>
학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?<br>
모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?<br>
정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?</p>
</blockquote></li>
</ul>
</section>
</section>
<section id="과제-분포task-distribution-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="과제-분포task-distribution-관점에서-본-메타러닝">과제 분포(Task-Distribution) 관점에서 본 메타러닝</h3>
<blockquote class="blockquote">
<p>메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,<br>
이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 <strong>범용 학습 알고리즘</strong>을 학습하자.</p>
</blockquote>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math inline">\(p(\mathcal{T})\)</span>: 과제들의 분포</li>
<li><span class="math inline">\(\omega\)</span>: 어떤 학습 방법</li>
<li><span class="math inline">\(\mathcal{T} = \{D, L\}\)</span>: 어떤 과제(<span class="math inline">\(\mathcal{T}\)</span>)는 데이터셋(<span class="math inline">\(D\)</span>)과 손실 함수(<span class="math inline">\(L\)</span>)의 조합이다.</li>
<li><span class="math inline">\(D\)</span>: 데이터 셋</li>
<li><span class="math inline">\(\mathcal{L}(D, \omega)\)</span>: 데이터 셋 <span class="math inline">\(D\)</span>에서 학습 방법 <span class="math inline">\(\omega\)</span>를 사용해 훈련했을 때의 loss 값</li>
</ul>
<p>위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.</p>
<p><span class="math display">\[
\min_{\omega} \mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})} \mathcal{L}(D; \omega) \quad (2)
\]</span></p>
<p>‘학습 방법’, 즉 <span class="math inline">\(\omega\)</span>는 <strong>과제 전반의 지식(across-task knowledge)</strong> 또는 <strong>메타 지식(meta-knowledge)</strong> 이라고 할 수 있음.</p>
<p><strong>식 (2)를 실제로 해결하려면?</strong></p>
<ul>
<li>목표: 세상의 모든 과제 분포 <span class="math inline">\(p(\mathcal{T})\)</span>에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 <span class="math inline">\(\omega\)</span>를 찾자!<br>
</li>
<li>현실: 모든 과제 분포의 모든 문제인 <span class="math inline">\(p(\mathcal{T})\)</span>를 다룰 수는 없음.</li>
<li>타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 <span class="math inline">\(p(\mathcal{T})\)</span>를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)</li>
</ul>
<p><strong>Notation 2</strong></p>
<p><span class="math inline">\(\mathcal{D}_{\text{source}} = \{(D_{\text{source}}^{\text{train}}, D_{\text{source}}^{\text{val}})^{(i)}\}_{i=1}^M\)</span></p>
<ul>
<li><strong>메타-훈련(meta-training)에 사용할 전체 데이터셋</strong>을 나타내는 기호.</li>
</ul>
<p>하나씩 뜯어보면</p>
<ul>
<li><span class="math inline">\(\mathcal{D}_{\text{source}}\)</span> : <strong>‘소스 데이터셋(Source Dataset)’</strong>이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 <strong>원천(Source)</strong>이 된다는 의미. 즉, <strong>“훈련용”</strong>이라는 뜻.</li>
<li><span class="math inline">\(M\)</span>: 우리가 가지고 있는 <strong>훈련용 과제(task)의 총 개수</strong>. (예: 50개의 다른 종류의 동물 분류 문제)</li>
<li><span class="math inline">\(\{ \dots \}_{i=1}^M\)</span>: 괄호 안의 내용이 <strong>1번부터 M번까지 M개</strong>가 있다는 뜻.</li>
<li><span class="math inline">\(( \dots )^{(i)}\)</span>: 그중에서 <strong>i번째 과제</strong>를 의미. (예: 50개 중 17번째 과제)</li>
<li><span class="math inline">\((D_{\text{source}}^{\text{train}}, D_{\text{source}}^{\text{val}})\)</span>: 하나의 과제(<span class="math inline">\(i\)</span>)가 두 종류의 데이터로 구성되어 있다는 뜻.
<ul>
<li><span class="math inline">\(D_{\text{train}}^{\text{source}}\)</span>: <strong>‘훈련용’ 데이터(train data)</strong>. 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 <strong>서포트셋(support set)</strong>이라고 함.</li>
<li><span class="math inline">\(D_{\text{val}}^{\text{source}}\)</span>: <strong>‘검증용’ 데이터(validation data)</strong>. 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 <strong>쿼리셋(query set)</strong>이라고 함.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>“<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>란, 총 M개의 훈련용 과제 묶음인데, 각 과제<span class="math inline">\(i\)</span>는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”</p>
</blockquote>
<p>아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.</p>
<p><span class="math display">\[
\omega^* = \arg\max_{\omega} \log p(\omega|\mathcal{D}_{\text{source}}) \quad (3)
\]</span></p>
<p>또, 식을 하나씩 요소별로 뜯어보자.</p>
<ul>
<li><span class="math inline">\(\omega\)</span> (오메가): 우리가 찾고 싶은 <strong>‘학습 방법’ 또는 ‘공부법’</strong></li>
<li><span class="math inline">\(\omega^{\ast}\)</span> (오메가 스타): 수많은 가능한 공부법(<span class="math inline">\(\omega\)</span>) 중에서 우리가 찾아낸 <strong>최고의(optimal) 공부법</strong>을 의미함.</li>
<li><span class="math inline">\(\arg\max_{\omega}\)</span>: “괄호 안의 값을 <strong>최대(max)로 만드는</strong> <span class="math inline">\(\omega\)</span>를 <strong>찾아라(arg)</strong>”라는 명령어.</li>
<li><span class="math inline">\(p(\omega|\mathcal{D}_{\text{source}})\)</span>: <strong>사후 확률(posterior probability)</strong>.
<ul>
<li><strong>“우리가 가진 훈련용 과제 데이터(<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>)를 관찰했을 때, 어떤 공부법(<span class="math inline">\(\omega\)</span>)이 가장 그럴듯한가(정답일 확률이 높은가)?”</strong>.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>“우리가 가진 <strong>훈련용 과제 데이터(<span class="math inline">\(\mathcal{D}_{\text{source}}\)</span>)를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(<span class="math inline">\(\omega\)</span>)을 찾아서, 그것을 우리의 최종 학습법(<span class="math inline">\(\omega^{\ast}\)</span>)으로 삼아라!“</strong></p>
</blockquote>
<p>이제 메타-테스트 단계에서 사용되는 <span class="math inline">\(Q\)</span>개의 타겟 과제(target tasks) 집합을 <span class="math inline">\(\mathcal{D}_{\text{target}} = \{(D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})^{(i)}\}_{i=1}^Q\)</span> 로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 <span class="math inline">\(\omega^*\)</span>를 사용하여 이전에 보지 못한 각 타겟 과제 <span class="math inline">\(i\)</span>에 대한 기반 모델을 훈련합니다:</p>
<p><span class="math display">\[
\theta^{*(i)} = \arg\max_{\theta} \log p(\theta|\omega^*, D_{\text{target}}^{\text{train }(i)}) \quad (4)
\]</span></p>
<p>식 (1)의 기존 학습과 대조적으로, 타겟 과제 <span class="math inline">\(i\)</span>의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 <span class="math inline">\(\omega^*\)</span>의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 <span class="math inline">\(D_{\text{test}}^{\text{target}}(i)\)</span>에 대한 <span class="math inline">\(\theta^{*(i)}\)</span>의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.</p>
<p>이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 <strong>메타-과소적합(meta-underfitting)</strong> 과 <strong>메타-과적합(meta-overfitting)</strong> 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 <span class="math inline">\(\theta\)</span>를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 <span class="math inline">\(\omega\)</span>를 학습하는 것으로 볼 수 있습니다.</p>
<p><strong>다음 섹션 넘어가기 전 수식 해설:</strong></p>
<p><span class="math inline">\(\mathcal{D}_{\text{target}} = \{(D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})^{(i)}\}_{i=1}^Q\)</span></p>
<p>이 수식은 <strong>메타-테스팅(Meta-Testing) 단계</strong>, 즉 최종 실력을 평가하는 데 사용되는 <strong>“실전 시험 문제지 묶음”</strong> 전체를 정의합니다.</p>
<p>이 구조를 세 단계로 나누어 이해하면 가장 쉽습니다.</p>
<section id="단계-mathcald_texttarget---전체-시험지-묶음" class="level4">
<h4 class="anchored" data-anchor-id="단계-mathcald_texttarget---전체-시험지-묶음">1단계: <span class="math inline">\(\mathcal{D}_{\text{target}}\)</span> - 전체 시험지 묶음</h4>
<ul>
<li><strong>이름</strong>: 타겟 데이터셋 (The Target Dataset)</li>
<li><strong>역할</strong>: 메타-훈련을 통해 학습된 ’만능 공부법(<span class="math inline">\(\omega^*\)</span>)’이 얼마나 효과적인지 최종적으로 평가하기 위한 <strong>전체 시험 문제들의 집합</strong>입니다.</li>
<li><strong>표기 규칙</strong>: <code>target</code>이 <strong>아래 첨자(subscript)</strong>로 붙어, 이 데이터셋 묶음의 <strong>소속(Group)</strong>이 ’소스(훈련용)’가 아닌 ’타겟(시험용)’임을 나타냅니다.</li>
</ul>
</section>
<section id="단계-dots-i-와-dots-_i1q---i번째-시험지" class="level4">
<h4 class="anchored" data-anchor-id="단계-dots-i-와-dots-_i1q---i번째-시험지">2단계: <span class="math inline">\(( \dots )^{(i)}\)</span> 와 <span class="math inline">\(\{ \dots \}_{i=1}^Q\)</span> - i번째 시험지</h4>
<ul>
<li><strong>이름</strong>: i번째 타겟 과제 (The i-th Target Task)</li>
<li><strong>역할</strong>: 전체 시험지 묶음(<span class="math inline">\(\mathcal{D}_{\text{target}}\)</span>)은 총 <strong>Q개의 개별 시험 문제(과제)</strong>로 이루어져 있습니다. 이 표기는 그중 <strong>i번째 시험 문제</strong> 하나를 가리킵니다.</li>
<li><strong>비유</strong>: ‘수능 시험’이라는 전체 묶음 속의 ’수학 시험지’ 하나에 해당합니다.</li>
</ul>
</section>
<section id="단계-d_texttargettexttrain-d_texttargettexttest---시험지-한-장의-구성" class="level4">
<h4 class="anchored" data-anchor-id="단계-d_texttargettexttrain-d_texttargettexttest---시험지-한-장의-구성">3단계: <span class="math inline">\((D_{\text{target}}^{\text{train}}, D_{\text{target}}^{\text{test}})\)</span> - 시험지 한 장의 구성</h4>
<p>이것이 가장 중요한 부분입니다. ‘수학 시험지’ 한 장은 두 부분으로 구성됩니다.</p>
<section id="가.-d_texttargettexttrain-시험지-속-참고-예시-또는" class="level5">
<h5 class="anchored" data-anchor-id="가.-d_texttargettexttrain-시험지-속-참고-예시-또는">가. <span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span>: 시험지 속 “참고 예시” 또는 “&lt;보기&gt;”</h5>
<ul>
<li><strong>정확한 표기</strong>: <code>target</code>은 <strong>아래 첨자</strong>, <code>train</code>은 <strong>윗 첨자</strong>.</li>
<li><strong>역할</strong>:
<ol type="1">
<li>이 데이터는 이미 학습이 끝난 <strong>’만능 공부법(<span class="math inline">\(\omega^*\)</span>)’을 개선하는 데 사용되지 않습니다.</strong></li>
<li>대신, <span class="math inline">\(i\)</span>번째 새로운 문제를 만난 모델이 이 데이터를 <strong>딱 몇 번만 보고</strong> “아, 이 문제는 이런 유형이구나!”하고 <strong>빠르게 적응(adaptation)</strong>하는 데 사용됩니다.</li>
<li>이 적응 과정을 통해 <span class="math inline">\(i\)</span>번째 문제에만 특화된 모델(<span class="math inline">\(\theta^{*(i)}\)</span>)이 만들어집니다.</li>
</ol></li>
<li><strong>비유</strong>: 시험 문제에 나오는 <strong><code>&lt;보기&gt;</code> 자료</strong>와 같습니다. <code>&lt;보기&gt;</code>를 읽고 문제의 의도를 파악하고 적응하는 것이지, <code>&lt;보기&gt;</code>를 읽는다고 해서 근본적인 국어 실력(<span class="math inline">\(\omega\)</span>)이 오르는 것은 아닙니다.</li>
</ul>
</section>
<section id="나.-d_texttargettexttest-시험지-속-실제-채점-문제" class="level5">
<h5 class="anchored" data-anchor-id="나.-d_texttargettexttest-시험지-속-실제-채점-문제">나. <span class="math inline">\(D_{\text{target}}^{\text{test}}\)</span>: 시험지 속 “실제 채점 문제”</h5>
<ul>
<li><strong>정확한 표기</strong>: <code>target</code>은 <strong>아래 첨자</strong>, <code>test</code>은 <strong>윗 첨자</strong>.</li>
<li><strong>역할</strong>:
<ol type="1">
<li>위에서 <code>&lt;보기&gt;</code>(<span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span>)를 보고 적응을 마친 모델(<span class="math inline">\(\theta^{*(i)}\)</span>)에게 이 문제를 풀게 합니다.</li>
<li>모델의 답과 정답을 비교하여 <strong>최종 성능(정확도)을 채점</strong>합니다. 이 점수가 바로 메타 학습기의 <span class="math inline">\(i\)</span>번째 과제에 대한 최종 실력입니다.</li>
</ol></li>
<li><strong>비유</strong>: <code>&lt;보기&gt;</code>를 참고하여 풀어야 하는 <strong>실제 문제 1번, 2번, 3번</strong>에 해당합니다.</li>
</ul>
</section>
</section>
<section id="최종-정리" class="level4">
<h4 class="anchored" data-anchor-id="최종-정리">최종 정리</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">표기법</th>
<th style="text-align: left;">소속 (아래 첨자)</th>
<th style="text-align: left;">역할 (윗 첨자)</th>
<th style="text-align: left;">비유</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\mathcal{D}_{\text{target}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;">(없음)</td>
<td style="text-align: left;"><strong>수능 시험 전체</strong> (최종 평가 목적)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(D_{\text{target}}^{\text{train}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;"><strong>훈련(Train)</strong></td>
<td style="text-align: left;">시험지 속 <strong><code>&lt;보기&gt;</code></strong> (새로운 유형에 적응)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(D_{\text{target}}^{\text{test}}\)</span></td>
<td style="text-align: left;"><strong>타겟(Target)</strong></td>
<td style="text-align: left;"><strong>테스트(Test)</strong></td>
<td style="text-align: left;">시험지 속 <strong>채점 문제</strong> (최종 성능 평가)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="이중-최적화bilevel-optimization-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="이중-최적화bilevel-optimization-관점에서-본-메타러닝">이중 최적화(Bilevel Optimization) 관점에서 본 메타러닝</h3>
<p>이전 섹션의 논의는 다중 과제 시나리오에서 메타러닝의 일반적인 흐름을 설명했지만, 식 (3)의 메타-훈련 단계를 어떻게 풀어야 하는지는 명시하지 않았습니다. 이는 보통 메타-훈련 단계를 <strong>이중 최적화(bilevel optimization)</strong> 문제로 구성함으로써 수행됩니다. 이 그림은 최적화기 기반(optimizer-based) 방법론(섹션 3.1 참조)에만 정확하게 들어맞는다고 할 수 있지만, 메타러닝의 작동 방식을 더 보편적으로 시각화하는 데 도움이 됩니다. 이중 최적화[40]는 계층적 최적화 문제로, 하나의 최적화가 다른 최적화를 제약 조건으로 포함하는 구조를 의미합니다[17], [41].</p>
<p>이 표기법을 사용하면, 메타-훈련은 다음과 같이 정형화될 수 있습니다:</p>
<p><span class="math display">\[
\omega^* = \arg\min_{\omega} \sum_{i=1}^{M} \mathcal{L}^{\text{meta}}(\theta^{*(i)}(\omega), \omega, D_{\text{source}}^{\text{val }(i)}) \quad (5)
\]</span></p>
<p><span class="math display">\[
\text{s.t. } \theta^{*(i)}(\omega) = \arg\min_{\theta} \mathcal{L}^{\text{task}}(\theta, \omega, D^{\text{train }(i)}_{\text{source}}) \quad (6)
\]</span></p>
<p>여기서 <span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span> 와 <span class="math inline">\(\mathcal{L}^{\text{task}}\)</span> 는 각각 <strong>외부(outer) 및 내부(inner) 목적 함수</strong>를 의미하며, 퓨샷 분류의 경우 교차 엔트로피와 같은 것입니다. 외부와 내부 수준 사이의 <strong>리더-팔로워(leader-follower) 비대칭성</strong>에 주목하십시오: <em>내부 수준 최적화인 식 (6)은 외부 수준에서 정의된 학습 전략 <span class="math inline">\(\omega\)</span>에 따라 조건부로 결정되지만, 자신의 훈련 중에는 <span class="math inline">\(\omega\)</span>를 변경할 수 없습니다.</em></p>
<p>여기서 <span class="math inline">\(\omega\)</span>는 비볼록(non-convex) 최적화에서의 초기 조건[16], 정규화 강도와 같은 하이퍼파라미터[17], 또는 최적화할 손실 함수 <span class="math inline">\(\mathcal{L}^{\text{task}}\)</span>의 매개변수화[42]까지도 나타낼 수 있습니다.</p>
<ul>
<li>섹션 4.1에서 <span class="math inline">\(\omega\)</span>에 대한 선택의 공간을 자세히 논의합니다.</li>
</ul>
<p>외부 수준 최적화는 훈련 후 검증 세트에서 좋은 성능을 보이는 모델 <span class="math inline">\(\theta^{*(i)}(\omega)\)</span>를 생성하도록 <span class="math inline">\(\omega\)</span>를 학습합니다.</p>
<ul>
<li>섹션 4.2에서는 <span class="math inline">\(\omega\)</span>를 최적화하는 방법을 자세히 논의합니다.</li>
<li>섹션 4.3에서는 <span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span>가 검증 성능, 학습 속도, 모델 강건성 등 무엇을 측정할 수 있는지 고려합니다.</li>
</ul>
<p>마지막으로, 위의 정형화는 과제 분포라는 개념을 사용한다는 점에 주목합니다.</p>
<ul>
<li>이는 메타러닝 문헌에서 일반적이지만, 메타러닝의 필수 조건은 아닙니다.</li>
</ul>
<p>더 공식적으로, 만약 단일 훈련 및 테스트 데이터셋(<span class="math inline">\(M=Q=1\)</span>)이 주어진다면, 우리는 훈련 세트를 분할하여 메타-훈련을 위한 <span class="math inline">\(\mathcal{D}_{\text{source}} = (D^{\text{train}}_{\text{source}},
D^{\text{val}}_{\text{source}})\)</span> 와 메타-테스트를 위한 <span class="math inline">\(\mathcal{D}_{\text{target}} = (D^{\text{train}}_{\text{source}} \cup D^{\text{val}}_{\text{source}}, D^{\text{test}}_{\text{target}})\)</span>를 얻을 수 있습니다. 우리는 여전히 여러 에피소드에 걸쳐 <span class="math inline">\(\omega\)</span>를 학습하며, 메타-훈련 중에는 보통 다른 훈련-검증 분할이 사용됩니다.</p>
<p><strong>comment</strong></p>
<p>메타러닝의 작동 방식을 <strong>“두 단계로 이루어진 최적화”</strong>라는 틀로 설명합니다. 마치 회사에서 <strong>팀장(외부 루프)</strong>과 <strong>팀원(내부 루프)</strong>이 협업하는 것과 같습니다.</p>
<section id="두-개의-최적화-문제-내부-루프와-외부-루프" class="level4">
<h4 class="anchored" data-anchor-id="두-개의-최적화-문제-내부-루프와-외부-루프">1. 두 개의 최적화 문제: 내부 루프와 외부 루프</h4>
<ul>
<li><strong>내부 최적화 (식 6) - 팀원의 임무</strong>:
<ul>
<li>팀장은 <strong>업무 가이드라인(<span class="math inline">\(\omega\)</span>)</strong>을 줍니다. (예: “이런 방식으로 초기 모델을 설정해봐”, “학습률은 0.01로 해”)</li>
<li>팀원은 주어진 가이드라인(<span class="math inline">\(\omega\)</span>)과 훈련 데이터(<span class="math inline">\(D^{\text{train}}\)</span>)를 가지고, <strong>자신의 과제(<span class="math inline">\(\theta\)</span>)를 가장 잘 해결하기 위해 최선을 다합니다.</strong></li>
<li><strong>중요한 점</strong>: 팀원은 팀장이 준 가이드라인(<span class="math inline">\(\omega\)</span>)을 바꿀 수 없습니다. 그냥 따라야 합니다. 그 결과물이 바로 <strong>최적의 모델(<span class="math inline">\(\theta^*\)</span>)</strong>입니다.</li>
</ul></li>
<li><strong>외부 최적화 (식 5) - 팀장의 임무</strong>:
<ul>
<li>팀장은 팀원이 과제를 수행한 결과물(<span class="math inline">\(\theta^*\)</span>)을 가져와서 <strong>실전 테스트(<span class="math inline">\(D^{\text{val}}\)</span>)</strong>를 해봅니다.</li>
<li>테스트 결과(성능)를 보고, <strong>“내가 처음에 줬던 가이드라인(<span class="math inline">\(\omega\)</span>)이 과연 최선이었을까?”</strong>를 고민합니다.</li>
<li><strong>목표</strong>: 팀원의 최종 성과(<span class="math inline">\(\mathcal{L}^{\text{meta}}\)</span>)가 가장 좋아지도록, <strong>최초의 가이드라인(<span class="math inline">\(\omega\)</span>) 자체를 수정하고 개선</strong>합니다. 이것이 바로 팀장의 최적화, 즉 메타러닝입니다.</li>
</ul></li>
</ul>
</section>
<section id="omega는-무엇인가-팀장의-가이드라인" class="level4">
<h4 class="anchored" data-anchor-id="omega는-무엇인가-팀장의-가이드라인">2. <span class="math inline">\(\omega\)</span>는 무엇인가? (팀장의 가이드라인)</h4>
<p>팀장이 주는 가이드라인(<span class="math inline">\(\omega\)</span>)은 여러 형태일 수 있습니다. * <strong>초기 조건</strong>: “업무를 이 지점(<span class="math inline">\(\theta_0\)</span>)에서 시작하면 가장 빨리 끝낼 수 있을 거야.” (MAML 방식) * <strong>하이퍼파라미터</strong>: “이 업무는 꼼꼼함(정규화)이 중요하니, 정규화 강도를 0.5로 설정해.” * <strong>손실 함수</strong>: “이 업무의 목표는 단순히 정확도를 높이는 게 아니라, 안정성도 고려해야 해.” 라며 목표 자체를 재정의해 줌.</p>
</section>
<section id="꼭-여러-과제가-필요한가-no" class="level4">
<h4 class="anchored" data-anchor-id="꼭-여러-과제가-필요한가-no">3. 꼭 여러 과제가 필요한가? No!</h4>
<ul>
<li>보통 메타러닝은 여러 팀(과제)의 성과를 보고 최고의 가이드라인을 찾지만, 꼭 그럴 필요는 없습니다.</li>
<li><strong>단 하나의 매우 중요한 프로젝트(single task)</strong>가 있다면, 프로젝트를 여러 단계로 나누고 각 단계마다 팀원이 업무를 수행하게 한 뒤, 그 결과를 보고 팀장이 계속해서 가이드라인을 수정해주는 방식도 가능합니다. 이것이 <strong>‘단일 과제 메타러닝’</strong>입니다.</li>
</ul>
</section>
</section>
<section id="피드-포워드-모델feed-forward-model-관점에서-본-메타러닝" class="level3">
<h3 class="anchored" data-anchor-id="피드-포워드-모델feed-forward-model-관점에서-본-메타러닝">피드-포워드 모델(Feed-Forward Model) 관점에서 본 메타러닝</h3>
<p>앞서 살펴본 바와 같이, 식 (5)-(6)과 같은 명시적인 반복 최적화를 통하지 않고, 피드-포워드 방식으로 모델을 합성하는 여러 메타러닝 접근법이 있습니다. 이들은 복잡도에 차이가 있지만, 이 접근법 계열을 이해하기 위해서는 식 (2)의 추상적인 목표를 구체화하여 선형 회귀 메타-훈련을 위한 간단한 예시[43]를 정의하는 것이 도움이 될 수 있습니다.</p>
<p><span class="math display">\[\min_{\omega} \underset{(\mathcal{D}^{tr}, \mathcal{D}^{val}) \in \mathcal{T}}{\mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}} \sum_{(\mathbf{x}, y) \in \mathcal{D}^{val}} \left[ (\mathbf{x}^T \mathbf{g}_{\omega}(\mathcal{D}^{tr}) - y)^2 \right] \quad (7)\]</span></p>
<p>여기서 우리는 과제 분포에 대해 메타-훈련을 수행합니다. 각 과제에 대해 훈련 세트와 검증 세트가 주어집니다.</p>
<ul>
<li>훈련 세트 <span class="math inline">\(D^{\text{tr}}\)</span>은 벡터 <span class="math inline">\(g_\omega\)</span>로 임베딩[44]되며, 이 벡터는 검증 세트의 예시 <span class="math inline">\(x\)</span>를 예측하기 위한 선형 회귀 가중치를 정의합니다.</li>
<li>식 (7)을 최적화하는 것은 함수 <span class="math inline">\(g_\omega\)</span>가 훈련 세트를 가중치 벡터로 매핑하도록 훈련함으로써 ’학습하는 법을 배우는 것’입니다.</li>
<li>따라서 <span class="math inline">\(g_\omega\)</span>는 <span class="math inline">\(p(\mathcal{T})\)</span>에서 추출된 새로운 메타-테스트 과제 <span class="math inline">\(^{\text{te}}\)</span>에 대해서도 좋은 해법을 제공해야 합니다. 이 계열의 방법들은 사용되는 예측 모델 <span class="math inline">\(g\)</span>의 복잡성과 서포트셋이 어떻게 임베딩되는지(예: 풀링, CNN, RNN 사용)[44]에 따라 다양합니다.</li>
</ul>
<p>이러한 모델들은 <strong>상각(amortized)</strong>[45] 모델로도 알려져 있는데, 이는 새로운 과제를 학습하는 비용이 <span class="math inline">\(g_\omega(\cdot)\)</span>를 통한 피드-포워드 연산 한 번으로 줄어들기 때문입니다. 반복 최적화에 드는 비용은 이미 <span class="math inline">\(\omega\)</span>의 메타-훈련 중에 지불되었습니다.</p>
<p><strong>comments</strong></p>
<p>이 섹션은 이전의 ‘이중 최적화’ 방식과는 완전히 다른, <strong>매우 빠르고 효율적인 메타러닝 방식</strong>을 설명합니다.</p>
<section id="이전-방식-이중-최적화의-문제점" class="level4">
<h4 class="anchored" data-anchor-id="이전-방식-이중-최적화의-문제점">이전 방식 (이중 최적화)의 문제점</h4>
<ul>
<li>새로운 문제가 주어질 때마다, 내부 루프에서 <strong>느린 최적화 과정(경사 하강법 등)을 여러 번 반복</strong>해야 합니다.</li>
<li>비유: 학생이 새로운 수학 문제를 만날 때마다, 공책에 여러 번 계산을 반복하며 풀어야 합니다.</li>
</ul>
</section>
<section id="새로운-방식-피드-포워드-모델의-아이디어" class="level4">
<h4 class="anchored" data-anchor-id="새로운-방식-피드-포워드-모델의-아이디어">새로운 방식 (피드-포워드 모델)의 아이디어</h4>
<ul>
<li>“느린 반복 계산 과정을 없애버리고, 그냥 <strong>문제를 척 보면 바로 답이 나오는 ‘만능 공식 생성기’(<span class="math inline">\(g_\omega\)</span>)</strong>를 만들자!”</li>
<li>비유: 학생이 문제 유형과 주어진 숫자들을 ’만능 공식 생성기’에 넣으면, 계산 과정 없이 바로 그 문제에 맞는 ’최적의 공식’이 튀어나오고, 그 공식으로 답을 구합니다.</li>
</ul>
</section>
<section id="수식-7-해설" class="level4">
<h4 class="anchored" data-anchor-id="수식-7-해설">수식 (7) 해설</h4>
<p><span class="math display">\[\min_{\omega} \underset{(\mathcal{D}^{tr}, \mathcal{D}^{val}) \in \mathcal{T}}{\mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}} \sum_{(\mathbf{x}, y) \in \mathcal{D}^{val}} \left[ (\mathbf{x}^T \mathbf{g}_{\omega}(\mathcal{D}^{tr}) - y)^2 \right] \quad (7)\]</span></p>
<ul>
<li><strong><span class="math inline">\(D^{\text{tr}}\)</span> (훈련 세트)</strong>: 학생에게 주어진 <strong>‘참고 예제’</strong> 데이터입니다.</li>
<li><strong><span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span></strong>: 이것이 바로 <strong>‘만능 공식 생성기’</strong>입니다. 이 함수(<span class="math inline">\(g\)</span>)는 참고 예제 데이터(<span class="math inline">\(D^{\text{tr}}\)</span>)를 입력으로 받아서, 이 문제를 푸는 데 필요한 <strong>최적의 모델 파라미터(가중치)</strong>를 <strong>한 방에(피드-포워드 연산으로) 출력</strong>합니다.</li>
<li><strong><span class="math inline">\(x^T g_{\omega}(D^{\text{tr}})\)</span></strong>: ’만능 공식 생성기’가 만들어준 공식(<span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span>)을 가지고 실제 문제(<span class="math inline">\(x\)</span>)를 푸는 과정입니다.</li>
<li><strong><span class="math inline">\(( \dots - y)^2\)</span></strong>: 예측값과 실제 정답(<span class="math inline">\(y\)</span>) 사이의 오차입니다.</li>
<li><strong>전체 의미</strong>: 여러 종류의 과제에 대해, “주어진 참고 예제(<span class="math inline">\(D^{\text{tr}}\)</span>)를 보고 최적의 공식(<span class="math inline">\(g_{\omega}(D^{\text{tr}})\)</span>)을 한 번에 만들어내는 생성기(<span class="math inline">\(g_\omega\)</span>)를 훈련시켜라! 이 생성기는 어떤 문제가 주어져도 항상 좋은 공식을 만들어내야 한다.”</li>
</ul>
</section>
<section id="상각amortized이라는-용어의-의미" class="level4">
<h4 class="anchored" data-anchor-id="상각amortized이라는-용어의-의미">상각(Amortized)이라는 용어의 의미</h4>
<ul>
<li><strong>‘상각(Amortize)’</strong>은 회계 용어로, 큰 비용을 여러 기간에 걸쳐 나누어 처리한다는 의미입니다.</li>
<li>메타러닝에서 이 용어는, <strong>가장 비용이 많이 드는 ‘느린 반복 최적화’ 과정을 메타-훈련 때 미리 다 해치워버리고(<span class="math inline">\(\omega\)</span>를 학습),</strong> 정작 새로운 문제를 풀 때는 그 비용을 거의 치르지 않는다는 의미에서 사용됩니다.</li>
<li><strong>메타-훈련 (비용이 비쌈)</strong>: 수많은 과제를 풀어보며 ‘만능 공식 생성기’(<span class="math inline">\(g_\omega\)</span>)를 만드는 데는 엄청난 시간과 계산이 필요합니다. (비용을 미리 지불)</li>
<li><strong>메타-테스트 (비용이 거의 0)</strong>: 일단 생성기만 만들어지면, 새로운 문제는 그냥 함수에 데이터 한 번 넣는 것으로 끝나므로 거의 즉시 해결됩니다. (미리 지불한 비용의 혜택을 봄)</li>
</ul>
<p>이 피드-포워드 방식은 특히 <strong>새로운 문제에 대한 반응 속도가 매우 빨라야 하는 응용 분야</strong>에 매우 유용합니다.</p>
</section>
</section>
</section>
<section id="메타러닝의-역사적-배경" class="level2">
<h2 class="anchored" data-anchor-id="메타러닝의-역사적-배경">메타러닝의 역사적 배경</h2>
<p>메타러닝과 러닝-투-런(learning-to-learn)은 1987년 문헌에 처음 등장합니다.</p>
<p><strong>위르겐 슈미트후버(J. Schmidhuber)</strong> + <strong>자기 참조 학습(self-referential learning)</strong>을 사용하여 ’학습하는 방법을 학습’할 수 있는 방법론의 한 갈래를 소개했습니다. 자기 참조 학습은 신경망이 자신의 가중치를 입력으로 받아 해당 가중치에 대한 업데이트 값을 예측하도록 훈련하는 것을 포함합니다. 슈미트후버는 진화 알고리즘을 사용하여 모델 자체를 학습할 것을 제안했습니다.</p>
<p>메타러닝은 이후 여러 분야로 확장되었습니다.</p>
<p><strong>요슈아 벤지오(Bengio)</strong> + <strong>생물학적으로 타당한 학습 규칙(biologically plausible learning rules)</strong>을 메타-학습하는 방법을 제안했습니다. + 슈미트후버 등은 자기 참조 시스템과 메타러닝을 계속해서 탐구했습니다.</p>
<p><strong>세바스찬 스런(S. Thrun)</strong> + ’learning to learn’이라는 용어를 더 명확하게 정의하는 데 힘썼으며, 초기의 이론적 정당성과 실용적인 구현 방법을 소개했습니다. + 경사 하강법과 역전파를 사용하여 메타러닝 시스템을 훈련시키자는 제안은 1991년에 처음으로 나왔고, 2001년에 더 확장된 연구들이 뒤따랐으며 당시 문헌에 대한 개요를 제공합니다. 메타러닝은 1995년에 강화 학습의 맥락에서 사용되었고, 이후 다양한 확장 연구가 이어졌습니다.</p>
<p><strong>comments</strong></p>
<p>이 섹션은 메타러닝의 아이디어가 어떻게 시작되고 발전했는지를 시간 순서대로 보여줍니다.</p>
<ul>
<li><strong>1987년, 슈미트후버의 시작</strong>:
<ul>
<li><strong>“자기 참조 학습(Self-referential Learning)”</strong>이라는 혁신적인 아이디어를 제시합니다.</li>
<li><strong>아이디어</strong>: 보통 신경망은 외부 데이터(예: 이미지)를 입력받습니다. 하지만 슈미트후버는 신경망이 <strong>자기 자신의 설계도(가중치)</strong>를 들여다보고, “내 설계도를 어떻게 수정해야 더 똑똑해질까?”를 <strong>스스로 예측</strong>하게 만들자고 제안했습니다. 마치 AI가 자기 자신을 성찰하고 개선하는 것과 같습니다.</li>
<li><strong>방법</strong>: 당시에는 경사 하강법으로 이런 복잡한 구조를 훈련하기 어려웠기 때문에, 다윈의 진화론처럼 좋은 해결책은 살아남고 나쁜 해결책은 도태되는 <strong>진화 알고리즘</strong>을 사용하자고 제안했습니다.</li>
</ul></li>
<li><strong>1990년대 초, 벤지오와 스런의 발전</strong>:
<ul>
<li><strong>벤지오</strong>: “실제 뇌가 학습하는 방식과 유사한, <strong>생물학적으로 그럴듯한 학습 규칙</strong>을 AI가 스스로 배우게 만들 수는 없을까?”라는 방향으로 연구를 확장했습니다.</li>
<li><strong>스런</strong>: ’learning-to-learn’이 무엇인지 개념적으로 명확하게 다듬고, “이것이 왜 이론적으로 타당한가?”에 대한 근거를 제시하며 연구의 기틀을 다졌습니다.</li>
</ul></li>
<li><strong>1991년, 경사 하강법의 도입</strong>:
<ul>
<li>“진화 알고리즘 말고, 우리가 신경망 훈련에 흔히 쓰는 <strong>경사 하강법과 역전파</strong>를 메타러닝에도 적용해보자!”라는 제안이 처음 등장합니다. 이것이 현대 메타러닝 방법론의 시초가 됩니다. (예: MAML 같은 알고리즘의 먼 조상)</li>
</ul></li>
<li><strong>1995년, 강화 학습과의 만남</strong>:
<ul>
<li>메타러닝은 지도 학습뿐만 아니라, 로봇 제어나 게임처럼 시행착오를 통해 학습하는 <strong>강화 학습(RL)</strong> 분야에도 적용되기 시작하며 그 활용 범위를 넓혔습니다.</li>
</ul></li>
</ul>
</section>
<section id="관련-분야" class="level2">
<h2 class="anchored" data-anchor-id="관련-분야">관련 분야</h2>
<p>여기서는 메타러닝과 자주 혼동을 일으키는 관련 분야들과 비교하여 메타러닝의 위상을 정립합니다.</p>
<section id="전이-학습-transfer-learning-tl" class="level3">
<h3 class="anchored" data-anchor-id="전이-학습-transfer-learning-tl">전이 학습 (Transfer Learning, TL)</h3>
<p>전이 학습(TL)은 소스 과제(source task)의 과거 경험을 사용하여 타겟 과제(target task)의 학습(속도, 데이터 효율성, 정확도)을 향상시키는 것을 목표로 합니다. TL은 이러한 문제 영역과 해결책 계열을 모두 지칭하며, 가장 흔한 방법은 파라미터 전이 후 선택적으로 미세 조정(fine tuning)을 하는 것입니다 (물론 다른 수많은 접근법도 있습니다[34]).</p>
<blockquote class="blockquote">
<p>[34] survey: S. J. Pan and Q. Yang, “A Survey On Transfer Learning,” IEEE TKDE, 2010.</p>
</blockquote>
<p>반면, 메타러닝은 다른 문제들뿐만 아니라 TL을 개선하는 데 사용될 수 있는 패러다임입니다. TL에서는 <strong>메타-목적(meta-objective)을 사용하지 않고</strong> 소스 과제에 대한 일반적인(vanilla) 학습을 통해 사전 지식(prior)을 추출합니다.</p>
<p>메타러닝에서는, MAML[16]에서 보여주듯이,</p>
<ul>
<li>새로운 과제를 학습할 때 사전 지식의 이점을 평가하는 <strong>외부 최적화(outer optimization)</strong>를 통해 해당 사전 지식이 정의됩니다.</li>
<li>더 일반적으로, 메타러닝은 단지 모델 파라미터뿐만 아니라 훨씬 더 넓은 범위의 메타-표현을 다룹니다 (섹션 4.1 참조).</li>
</ul>
<blockquote class="blockquote">
<p>[16] MAML: C.Finn,P. Abbeel, and S. Levine, “Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks,” in ICML, 2017.</p>
</blockquote>
<p><strong>comments</strong></p>
<ul>
<li><strong>전이 학습(TL)이란?</strong>: 어떤 분야에서 얻은 지식을 다른 분야에 써먹는 것입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>‘어떻게’ 지식을 옮길지를 최적화하는가?</strong>
<ul>
<li><strong>전이 학습</strong>: 일단 A라는 과제를 열심히 공부해서 지식을 쌓고 (예: 이미지넷으로 모델 훈련), 그 지식을 B라는 과제에 가져가서 약간 수정해서(fine-tuning) 씁니다. ’어떻게 하면 B에 더 잘 써먹을 수 있을까?’를 고민하며 A를 공부하지는 않습니다.</li>
<li><strong>메타러닝</strong>: “나중에 B, C, D 같은 과제들을 <strong>가장 빠르고 쉽게 배울 수 있도록</strong>, 지금 A를 <strong>어떤 방식으로</strong> 공부해 둬야 할까?”라는 <strong>’학습 전략 자체’를 최적화</strong>합니다.</li>
</ul></li>
</ul>
</section>
<section id="도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg" class="level3">
<h3 class="anchored" data-anchor-id="도메인-적응domain-adaptation-da-및-도메인-일반화domain-generalization-dg">도메인 적응(Domain Adaptation, DA) 및 도메인 일반화(Domain Generalization, DG)</h3>
<p><strong>도메인 이동(Domain-shift)</strong></p>
<ul>
<li>소스 문제와 타겟 문제가 동일한 목표를 공유하지만, 타겟 문제의 입력 데이터 분포가 소스 과제와 달라 모델 성능이 저하되는 상황을 말합니다[34], [58].</li>
</ul>
<p><strong>DA</strong></p>
<ul>
<li>타겟 도메인의 희소하거나 레이블이 없는 데이터를 사용하여 소스에서 훈련된 모델을 조정함으로써 이 문제를 완화하려는 전이 학습의 한 변형입니다.</li>
</ul>
<p><strong>DG</strong></p>
<ul>
<li>추가적인 적응 없이 이러한 도메인 이동에 강건한 소스 모델을 훈련시키는 방법을 말합니다.</li>
</ul>
<p>TL과 마찬가지로, 일반적인(vanilla) DA와 DG는 여러 도메인에 걸쳐 ’학습하는 방법’을 최적화하기 위한 메타-목적을 사용하지 않습니다. 반면, 메타러닝 방법은 DA[59]와 DG[42]를 모두 수행하는 데 사용될 수 있습니다 (섹션 5.8 참조).</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>DA/DG란?</strong>: 같은 문제인데 데이터의 ’스타일’이 다른 상황에 대처하는 것입니다. (예: 낮에 찍은 사진으로 학습한 자율주행차가 밤에도 운전해야 하는 상황)</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>’스타일 변화에 대한 강건함’을 직접적인 목표로 최적화하는가?</strong>
<ul>
<li><strong>DA/DG</strong>: 특정 기술(예: 밤 사진을 낮 사진처럼 보이게 변환)을 사용하여 스타일 차이를 줄이려고 노력합니다. ’어떻게 훈련해야 어떤 스타일 변화에도 강해질까?’를 최적화하지는 않습니다.</li>
<li><strong>메타러닝</strong>: 훈련 단계에서 일부러 <strong>다양한 스타일의 데이터(낮, 밤, 비 오는 날, 흐린 날)를 경험</strong>하게 하고, “어떤 스타일의 데이터가 들어와도 성능이 떨어지지 않는 <strong>‘강건한 학습법’</strong>” 자체를 찾도록 최적화합니다.</li>
</ul></li>
</ul>
</section>
<section id="연속-학습-continual-learning-cl" class="level3">
<h3 class="anchored" data-anchor-id="연속-학습-continual-learning-cl">연속 학습 (Continual Learning, CL)</h3>
<p>연속 또는 평생 학습(lifelong learning)[60]-[62]은 잠재적으로 비정상(non-stationary) 분포에서 추출된 일련의 과제들을 학습하는 능력을 말하며, 특히 새로운 과제를 더 빠르게 배우면서 오래된 과제는 잊지 않는 것을 목표로 합니다.</p>
<p>메타러닝과 유사하게 과제 분포가 고려되며, 목표의 일부는 타겟 과제의 학습을 가속화하는 것입니다. 그러나 대부분의 연속 학습 방법론은 이 메타-목표를 명시적으로 풀지 않기 때문에 메타러닝 방법론이 아닙니다. 반면에, 메타러닝은 연속 학습을 발전시키기 위한 잠재적인 프레임워크를 제공하며, 최근 몇몇 연구들은 연속 학습 성능을 인코딩하는 메타-목표를 개발함으로써 이를 시도하기 시작했습니다[63]–[65].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>연속 학습(CL)이란?</strong>: 과제 A를 배운 뒤, 과제 B를 배우고, 이어서 과제 C를 배울 때, 이전에 배운 A와 B를 잊어버리지 않는(catastrophic forgetting 방지) 능력입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>’연속 학습 자체’를 하나의 학습 목표로 삼는가?</strong>
<ul>
<li><strong>연속 학습</strong>: 특정 기술(예: 중요한 지식은 얼려서 보존)을 사용하여 과거의 지식을 잊지 않으려고 노력합니다.</li>
<li><strong>메타러닝</strong>: “어떻게 훈련해야 <strong>‘새로운 것을 배우면서도 옛것을 잊지 않는 능력’</strong> 자체를 극대화할 수 있을까?”라는 메타-목표를 설정하고, 이 목표를 달성하는 학습 전략을 찾습니다.</li>
</ul></li>
</ul>
</section>
<section id="다중과제-학습-multi-task-learning-mtl" class="level3">
<h3 class="anchored" data-anchor-id="다중과제-학습-multi-task-learning-mtl">다중과제 학습 (Multi-Task Learning, MTL)</h3>
<p>다중과제 학습(MTL)은 여러 관련 과제를 동시에 학습하여, 파라미터 공유와 그로 인한 공유 표현의 다양성 덕분에 정규화 효과를 보고[66]–[68], 컴퓨팅/메모리 절약 효과를 얻는 것을 목표로 합니다. TL, DA, CL과 마찬가지로, 전통적인 MTL은 메타-목적이 없는 단일-수준 최적화입니다.</p>
<p>더욱이, MTL의 목표는 <strong>이미 알려진 고정된 수의 과제</strong>를 푸는 것인 반면, 메타러닝의 핵심은 종종 <strong>미래에 보게 될 미지의 과제</strong>를 푸는 것입니다. 그럼에도 불구하고, 메타러닝은 MTL에 이점을 가져다줄 수 있습니다. 예를 들어, 과제 간의 관련성을 학습하거나[69] 여러 과제 간의 우선순위를 정하는 방법을 배우는 것[70]입니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>다중과제 학습(MTL)이란?</strong>: 여러 과제를 <strong>동시에</strong> 학습시켜서 서로 도움을 주고받게 하는 것입니다.</li>
<li><strong>메타러닝과의 핵심 차이</strong>: <strong>‘알려진 과제’ vs ‘미지의 과제’</strong>
<ul>
<li><strong>다중과제 학습</strong>: 목표는 <strong>“주어진 A, B, C 과제 모두”</strong>에서 최고의 성능을 내는 것입니다. 미래에 D라는 과제가 나타날 것은 고려하지 않습니다.</li>
<li><strong>메타러닝</strong>: A, B, C 과제를 학습하는 이유는 <strong>“미래에 나타날 미지의 과제 D”</strong>를 더 잘 풀기 위함입니다. A, B, C 자체의 성능보다는 일반화 능력이 더 중요합니다.</li>
</ul></li>
</ul>
</section>
<section id="하이퍼파라미터-최적화-hyperparameter-optimization-ho" class="level3">
<h3 class="anchored" data-anchor-id="하이퍼파라미터-최적화-hyperparameter-optimization-ho">하이퍼파라미터 최적화 (Hyperparameter Optimization, HO)</h3>
<p>하이퍼파라미터 최적화(HO)는 학습률이나 정규화 강도와 같은 하이퍼파라미터가 ’학습하는 방법’을 기술한다는 점에서 메타러닝의 영역에 속합니다. 여기서 우리는 경사 하강법 기반 하이퍼파라미터 학습[69], [71] 및 신경망 구조 탐색[18]과 같이 신경망으로 종단간(end-to-end) 훈련되는 메타-목표를 정의하는 HO 과제들을 포함합니다. 그러나 우리는 무작위 탐색[72]이나 베이지안 하이퍼파라미터 최적화[73]와 같이, 메타러닝으로 거의 간주되지 않는 다른 접근법들은 제외합니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>하이퍼파라미터 최적화(HO)란?</strong>: 모델 학습에 영향을 주는 설정값(학습률, 층의 개수 등)들을 사람이 아니라 기계가 자동으로 찾게 하는 것입니다.</li>
<li><strong>메타러닝과의 관계</strong>: ’학습하는 방법(<span class="math inline">\(\omega\)</span>)’을 찾는다는 점에서 메타러닝과 매우 유사합니다.</li>
<li><strong>이 논문에서의 구분 기준</strong>: <strong>’신경망’과 ’종단간 최적화’를 사용하는가?</strong>
<ul>
<li><strong>메타러닝으로 간주</strong>: 학습률이나 모델 구조 자체를 또 다른 신경망을 이용해, 전체 학습 과정에 대한 경사 하강법으로 최적화하는 방식. (과정이 매끄럽게 연결됨)</li>
<li><strong>메타러닝에서 제외</strong>: 단순히 여러 하이퍼파라미터 조합을 무작위로 시도해 보거나(무작위 탐색), 통계적 추정(베이지안 최적화)을 통해 최적값을 탐색하는 전통적인 방식. (학습 과정과 분리되어 있음)</li>
</ul></li>
</ul>
</section>
<section id="계층적-베이즈-모델-hierarchical-bayesian-models-hbm" class="level3">
<h3 class="anchored" data-anchor-id="계층적-베이즈-모델-hierarchical-bayesian-models-hbm">계층적 베이즈 모델 (Hierarchical Bayesian Models, HBM)</h3>
<p>계층적 베이즈 모델(HBM)은 사전 확률 <span class="math inline">\(p(\theta|\omega)\)</span> 하에서 파라미터 <span class="math inline">\(\theta\)</span>의 베이지안 학습을 포함합니다.</p>
<p>이 사전 확률은 자체적인 사전 확률 <span class="math inline">\(p(\omega)\)</span>를 갖는 다른 변수 <span class="math inline">\(\omega\)</span>에 대한 조건부 밀도 함수로 작성됩니다.</p>
<p>계층적 베이즈 모델은 <span class="math inline">\(D = \{D_i | i = 1, 2, ..., M\}\)</span>과 같이 그룹화된 데이터 모델로 강력하게 사용되며, 각 그룹 <span class="math inline">\(i\)</span>는 자체적인 <span class="math inline">\(\theta_i\)</span>를 가집니다.</p>
<p>전체 모델은 아래와 같습니다.</p>
<p><span class="math display">\[[\prod_{i=1}^{M} P(D_i|\theta_i) p(\theta_i|\omega)] p(\omega)\]</span></p>
<p>계층 구조는 더 확장될 수 있으며, 특히 <span class="math inline">\(\omega\)</span> 자체가 매개변수화되어 <span class="math inline">\(p(\omega)\)</span>가 학습될 수 있습니다.</p>
<p>학습은 보통 전체 파이프라인에 걸쳐 이루어지지만, 베이지안 주변화(Bayesian marginalisation)의 한 형태를 사용하여 <span class="math inline">\(\omega\)</span>에 대한 사후 확률을 계산하기도 합니다.</p>
<p><span class="math display">\[P(\omega|D) \propto p(\omega) \prod_{i=1}^{M} \int d\theta_i p(D_i|\theta_i)p(\theta_i|\omega)\]</span></p>
<p>주변화를 수행하는 용이성은 모델에 따라 다릅니다.</p>
<ul>
<li>어떤 모델(예: 잠재 디리클레 할당[74])에서는 켤레 지수 모델(conjugate exponential models) 선택 덕분에 주변화가 정확하지만,</li>
<li>다른 모델(예: [75])에서는 확률적 변분 추론(stochastic variational approach)을 사용하여 근사적인 사후 확률을 계산하고, 이를 통해 주변 우도(marginal likelihood)의 하한(lower bound)을 계산합니다.</li>
</ul>
<p>베이지안 계층 모델은 메타러닝 과정을 이해하기 위한 알고리즘적 프레임워크보다는 모델링 프레임워크를 제공함으로써, 메타러닝에 대한 가치 있는 관점을 제공합니다. 실제로는, HBM에 대한 이전 연구들은 주로 다루기 쉬운 간단한 모델 <span class="math inline">\(\theta\)</span>를 학습하는 데 초점을 맞춘 반면, 대부분의 메타러닝 연구는 여러 번의 반복을 포함하는 복잡한 내부-루프 학습 과정을 고려합니다. 그럼에도 불구하고, MAML[16]과 같은 일부 메타러닝 방법은 HBM의 렌즈를 통해 이해될 수 있습니다[76].</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>계층적 베이즈 모델(HBM)이란?</strong>: “개별 그룹(과제)의 특성(<span class="math inline">\(\theta_i\)</span>)은 전체 그룹(과제 분포)의 공통적인 특성(<span class="math inline">\(\omega\)</span>)으로부터 나온다”는 계층적 가정을 사용하는 통계 모델입니다.</li>
<li><strong>메타러닝과의 관계</strong>: <strong>구조가 매우 유사합니다.</strong>
<ul>
<li><code>전체 그룹 특성(ω)</code> ↔︎ <code>메타 지식(ω)</code></li>
<li><code>개별 그룹 특성(θ_i)</code> ↔︎ <code>개별 과제 모델(θ_i)</code></li>
</ul></li>
<li><strong>핵심 차이점</strong>: <strong>‘관점’과 ’복잡성’</strong>
<ul>
<li><strong>관점</strong>: HBM은 “이 데이터가 어떻게 생성되었을까?”를 확률적으로 <strong>모델링</strong>하는 데 초점을 맞춥니다. 반면, 메타러닝은 “어떻게 하면 성능을 최적화할까?”라는 <strong>알고리즘적</strong> 관점에 더 가깝습니다.</li>
<li><strong>복잡성</strong>: 전통적인 HBM은 수학적으로 다루기 쉬운 간단한 모델에 주로 사용된 반면, 현대 메타러닝은 수백만 개의 파라미터를 가진 복잡한 딥러닝 모델의 학습 과정을 다룹니다.</li>
</ul></li>
<li><strong>결론</strong>: HBM은 메타러닝의 철학적, 구조적 배경을 이해하는 데 훌륭한 이론적 틀을 제공하지만, 오늘날 딥러닝에서 다루는 문제의 규모와 복잡성에는 직접 적용하기 어렵습니다.</li>
</ul>
</section>
<section id="automl" class="level3">
<h3 class="anchored" data-anchor-id="automl">AutoML</h3>
<p>AutoML[31]-[33]은 데이터 준비, 알고리즘 선택, 하이퍼파라미터 튜닝, 구조 탐색과 같이 일반적으로 수동으로 이루어지는 <strong>머신러닝 과정의 일부를 자동화하려는 접근법들을 포괄하는 다소 넓은 분야를 통칭하는 말</strong>입니다.</p>
<p>AutoML은 종종 여기서 정의한 메타러닝의 범위를 벗어나는 수많은 휴리스틱을 사용하며, 데이터 정제와 같이 메타러닝에서는 덜 중심적인 과제에 초점을 맞춥니다.</p>
<p>하지만, AutoML은 때때로 메타-목표의 종단간 최적화를 사용하기도 하므로, 메타러닝은 <strong>AutoML의 한 전문 분야(specialization)</strong>로 볼 수 있습니다.</p>
<p><strong>comments</strong></p>
<ul>
<li><strong>AutoML이란?</strong>: 머신러닝의 A부터 Z까지(데이터 정제, 모델 선택, 튜닝 등) 모든 과정을 자동화하려는 기술 분야입니다.</li>
<li><strong>메타러닝과의 관계</strong>:
<ul>
<li><strong>AutoML이 더 넓은 개념</strong>: AutoML은 ’자동화’라는 목표를 위해 메타러닝뿐만 아니라 온갖 종류의 기법(휴리스틱, 탐색 알고리즘 등)을 모두 사용합니다.</li>
<li><strong>메타러닝은 AutoML의 한 도구</strong>: AutoML이 여러 단계를 자동화할 때, 특히 ‘최적의 학습 전략을 찾는’ 부분에서 메타러닝의 아이디어(메타-목표의 종단간 최적화)를 강력한 도구로 사용할 수 있습니다.</li>
</ul></li>
<li><strong>결론</strong>: 메타러닝은 <strong>AutoML이라는 거대한 목표를 달성하기 위한, 특히 ’학습 원리’에 초점을 맞춘 정교하고 전문화된 방법론 중 하나</strong>라고 볼 수 있습니다.</li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>