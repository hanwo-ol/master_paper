<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="김한울">
<meta name="dcterms.date" content="2025-11-17">
<meta name="description" content="초록 탐구">

<title>Parameter Initialization - from survey paper – Master Thesis Literature Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e31584831b205ffbb2d98406f31c2a5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Master Thesis Literature Review</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.qmd"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Posts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="../posts/index.html">
 <span class="dropdown-text">All posts</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Parameter Initialization - from survey paper</h1>
                  <div>
        <div class="description">
          초록 탐구
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">MetaLearning</div>
                <div class="quarto-category">Survey</div>
                <div class="quarto-category">Review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>김한울 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 17, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#parameter-initialization-paper" id="toc-parameter-initialization-paper" class="nav-link active" data-scroll-target="#parameter-initialization-paper">Parameter Initialization Paper</a></li>
  <li><a href="#model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks" id="toc-model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks" class="nav-link" data-scroll-target="#model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks">Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks</a>
  <ul class="collapse">
  <li><a href="#초록" id="toc-초록" class="nav-link" data-scroll-target="#초록">초록</a></li>
  <li><a href="#main-equations" id="toc-main-equations" class="nav-link" data-scroll-target="#main-equations">Main Equations</a>
  <ul class="collapse">
  <li><a href="#meta-learning-problem-set-up" id="toc-meta-learning-problem-set-up" class="nav-link" data-scroll-target="#meta-learning-problem-set-up">Meta-Learning Problem Set-Up</a></li>
  <li><a href="#a-model-agnostic-meta-learning-algorithm" id="toc-a-model-agnostic-meta-learning-algorithm" class="nav-link" data-scroll-target="#a-model-agnostic-meta-learning-algorithm">A Model-Agnostic Meta-Learning Algorithm</a></li>
  </ul></li>
  <li><a href="#what-is-new-in-the-work" id="toc-what-is-new-in-the-work" class="nav-link" data-scroll-target="#what-is-new-in-the-work">(1) What is new in the work</a></li>
  <li><a href="#why-is-the-work-important" id="toc-why-is-the-work-important" class="nav-link" data-scroll-target="#why-is-the-work-important">(2) Why is the work important</a></li>
  <li><a href="#what-is-the-literature-gap" id="toc-what-is-the-literature-gap" class="nav-link" data-scroll-target="#what-is-the-literature-gap">(3) What is the literature gap</a></li>
  <li><a href="#how-is-the-gap-filled" id="toc-how-is-the-gap-filled" class="nav-link" data-scroll-target="#how-is-the-gap-filled">(4) How is the gap filled</a></li>
  <li><a href="#what-is-achieved-with-the-new-method" id="toc-what-is-achieved-with-the-new-method" class="nav-link" data-scroll-target="#what-is-achieved-with-the-new-method">(5) What is achieved with the new method</a></li>
  <li><a href="#what-data-are-used" id="toc-what-data-are-used" class="nav-link" data-scroll-target="#what-data-are-used">(6) What data are used</a></li>
  <li><a href="#what-are-the-limitations" id="toc-what-are-the-limitations" class="nav-link" data-scroll-target="#what-are-the-limitations">(7) What are the limitations</a></li>
  <li><a href="#maml-한계점의-해소-방안" id="toc-maml-한계점의-해소-방안" class="nav-link" data-scroll-target="#maml-한계점의-해소-방안">(8) MAML 한계점의 해소 방안</a>
  <ul class="collapse">
  <li><a href="#계산-비용-문제-second-order-gradient-computation" id="toc-계산-비용-문제-second-order-gradient-computation" class="nav-link" data-scroll-target="#계산-비용-문제-second-order-gradient-computation">1. 계산 비용 문제 (Second-Order Gradient Computation)</a></li>
  <li><a href="#차-근사의-성능-개선" id="toc-차-근사의-성능-개선" class="nav-link" data-scroll-target="#차-근사의-성능-개선">2. 1차 근사의 성능 개선</a></li>
  <li><a href="#강화학습에서의-샘플-효율성-문제" id="toc-강화학습에서의-샘플-효율성-문제" class="nav-link" data-scroll-target="#강화학습에서의-샘플-효율성-문제">3. 강화학습에서의 샘플 효율성 문제</a></li>
  <li><a href="#메모리-효율성-개선" id="toc-메모리-효율성-개선" class="nav-link" data-scroll-target="#메모리-효율성-개선">4. 메모리 효율성 개선</a></li>
  <li><a href="#메타-연속-학습에서의-분산-감소" id="toc-메타-연속-학습에서의-분산-감소" class="nav-link" data-scroll-target="#메타-연속-학습에서의-분산-감소">5. 메타-연속 학습에서의 분산 감소</a></li>
  <li><a href="#automatic-differentiation-최적화" id="toc-automatic-differentiation-최적화" class="nav-link" data-scroll-target="#automatic-differentiation-최적화">6. Automatic Differentiation 최적화</a></li>
  <li><a href="#대규모-병렬화-지원" id="toc-대규모-병렬화-지원" class="nav-link" data-scroll-target="#대규모-병렬화-지원">7. 대규모 병렬화 지원</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#probabilistic-model-agnostic-meta-learning" id="toc-probabilistic-model-agnostic-meta-learning" class="nav-link" data-scroll-target="#probabilistic-model-agnostic-meta-learning">Probabilistic Model-agnostic Meta-learning</a>
  <ul class="collapse">
  <li><a href="#초록-1" id="toc-초록-1" class="nav-link" data-scroll-target="#초록-1">초록</a></li>
  <li><a href="#what-is-new-in-the-work-1" id="toc-what-is-new-in-the-work-1" class="nav-link" data-scroll-target="#what-is-new-in-the-work-1">(1) What is new in the work</a></li>
  <li><a href="#why-is-the-work-important-1" id="toc-why-is-the-work-important-1" class="nav-link" data-scroll-target="#why-is-the-work-important-1">(2) Why is the work important</a></li>
  <li><a href="#what-is-the-literature-gap-1" id="toc-what-is-the-literature-gap-1" class="nav-link" data-scroll-target="#what-is-the-literature-gap-1">(3) What is the literature gap</a></li>
  <li><a href="#how-is-the-gap-filled-1" id="toc-how-is-the-gap-filled-1" class="nav-link" data-scroll-target="#how-is-the-gap-filled-1">(4) How is the gap filled</a></li>
  <li><a href="#what-is-achieved-with-the-new-method-1" id="toc-what-is-achieved-with-the-new-method-1" class="nav-link" data-scroll-target="#what-is-achieved-with-the-new-method-1">(5) What is achieved with the new method</a></li>
  <li><a href="#what-data-are-used-1" id="toc-what-data-are-used-1" class="nav-link" data-scroll-target="#what-data-are-used-1">(6) What data are used</a></li>
  <li><a href="#what-are-the-limitations-1" id="toc-what-are-the-limitations-1" class="nav-link" data-scroll-target="#what-are-the-limitations-1">(7) What are the limitations</a></li>
  </ul></li>
  <li><a href="#online-meta-learning" id="toc-online-meta-learning" class="nav-link" data-scroll-target="#online-meta-learning">Online Meta learning</a>
  <ul class="collapse">
  <li><a href="#초록-2" id="toc-초록-2" class="nav-link" data-scroll-target="#초록-2">초록</a></li>
  <li><a href="#what-is-new-in-the-work-2" id="toc-what-is-new-in-the-work-2" class="nav-link" data-scroll-target="#what-is-new-in-the-work-2">(1) What is new in the work</a></li>
  <li><a href="#why-is-the-work-important-2" id="toc-why-is-the-work-important-2" class="nav-link" data-scroll-target="#why-is-the-work-important-2">(2) Why is the work important</a></li>
  <li><a href="#what-is-the-literature-gap-2" id="toc-what-is-the-literature-gap-2" class="nav-link" data-scroll-target="#what-is-the-literature-gap-2">(3) What is the literature gap</a></li>
  <li><a href="#how-is-the-gap-filled-2" id="toc-how-is-the-gap-filled-2" class="nav-link" data-scroll-target="#how-is-the-gap-filled-2">(4) How is the gap filled</a></li>
  <li><a href="#what-is-achieved-with-the-new-method-2" id="toc-what-is-achieved-with-the-new-method-2" class="nav-link" data-scroll-target="#what-is-achieved-with-the-new-method-2">(5) What is achieved with the new method</a></li>
  <li><a href="#what-data-are-used-2" id="toc-what-data-are-used-2" class="nav-link" data-scroll-target="#what-data-are-used-2">(6) What data are used</a></li>
  <li><a href="#what-are-the-limitations-2" id="toc-what-are-the-limitations-2" class="nav-link" data-scroll-target="#what-are-the-limitations-2">(7) What are the limitations</a></li>
  </ul></li>
  <li><a href="#gradient-based-meta-learning-with-learned-layerwise-metric-and-subspace" id="toc-gradient-based-meta-learning-with-learned-layerwise-metric-and-subspace" class="nav-link" data-scroll-target="#gradient-based-meta-learning-with-learned-layerwise-metric-and-subspace">Gradient-Based Meta-Learning With Learned Layerwise Metric And Subspace</a>
  <ul class="collapse">
  <li><a href="#초록-3" id="toc-초록-3" class="nav-link" data-scroll-target="#초록-3">초록</a></li>
  <li><a href="#what-is-new-in-the-work-3" id="toc-what-is-new-in-the-work-3" class="nav-link" data-scroll-target="#what-is-new-in-the-work-3">(1) What is new in the work</a></li>
  <li><a href="#why-is-the-work-important-3" id="toc-why-is-the-work-important-3" class="nav-link" data-scroll-target="#why-is-the-work-important-3">(2) Why is the work important</a></li>
  <li><a href="#what-is-the-literature-gap-3" id="toc-what-is-the-literature-gap-3" class="nav-link" data-scroll-target="#what-is-the-literature-gap-3">(3) What is the literature gap</a></li>
  <li><a href="#how-is-the-gap-filled-3" id="toc-how-is-the-gap-filled-3" class="nav-link" data-scroll-target="#how-is-the-gap-filled-3">(4) How is the gap filled</a></li>
  <li><a href="#what-is-achieved-with-the-new-method-3" id="toc-what-is-achieved-with-the-new-method-3" class="nav-link" data-scroll-target="#what-is-achieved-with-the-new-method-3">(5) What is achieved with the new method</a></li>
  <li><a href="#what-data-are-used-3" id="toc-what-data-are-used-3" class="nav-link" data-scroll-target="#what-data-are-used-3">(6) What data are used</a></li>
  <li><a href="#what-are-the-limitations-3" id="toc-what-are-the-limitations-3" class="nav-link" data-scroll-target="#what-are-the-limitations-3">(7) What are the limitations</a></li>
  </ul></li>
  <li><a href="#meta-learning-with-latent-embedding-optimization" id="toc-meta-learning-with-latent-embedding-optimization" class="nav-link" data-scroll-target="#meta-learning-with-latent-embedding-optimization">Meta-Learning with Latent Embedding Optimization</a>
  <ul class="collapse">
  <li><a href="#초록-4" id="toc-초록-4" class="nav-link" data-scroll-target="#초록-4">초록</a></li>
  <li><a href="#what-is-new-in-the-work-4" id="toc-what-is-new-in-the-work-4" class="nav-link" data-scroll-target="#what-is-new-in-the-work-4">(1) What is new in the work</a></li>
  <li><a href="#why-is-the-work-important-4" id="toc-why-is-the-work-important-4" class="nav-link" data-scroll-target="#why-is-the-work-important-4">(2) Why is the work important</a>
  <ul class="collapse">
  <li><a href="#what-is-the-literature-gap-4" id="toc-what-is-the-literature-gap-4" class="nav-link" data-scroll-target="#what-is-the-literature-gap-4">(3) What is the literature gap</a></li>
  <li><a href="#how-is-the-gap-filled-4" id="toc-how-is-the-gap-filled-4" class="nav-link" data-scroll-target="#how-is-the-gap-filled-4">(4) How is the gap filled</a></li>
  <li><a href="#what-is-achieved-with-the-new-method-4" id="toc-what-is-achieved-with-the-new-method-4" class="nav-link" data-scroll-target="#what-is-achieved-with-the-new-method-4">(5) What is achieved with the new method</a></li>
  <li><a href="#what-data-are-used-4" id="toc-what-data-are-used-4" class="nav-link" data-scroll-target="#what-data-are-used-4">(6) What data are used</a></li>
  <li><a href="#what-are-the-limitations-4" id="toc-what-are-the-limitations-4" class="nav-link" data-scroll-target="#what-are-the-limitations-4">(7) What are the limitations</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="parameter-initialization-paper" class="level1">
<h1>Parameter Initialization Paper</h1>
<p>In this Page, I will Read these papers’ Abstracts</p>
<blockquote class="blockquote">
<ol type="1">
<li>C.Finn,P. Abbeel, and S. Levine, “Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks,” in ICML, 2017.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="2" type="1">
<li>C. Finn, K. Xu, and S. Levine, “Probabilistic Model-agnostic Meta-learning,” in NeurIPS, 2018.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="3" type="1">
<li>C. Finn, A. Rajeswaran, S. Kakade, and S. Levine, “Online Meta learning,” ICML, 2019.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="4" type="1">
<li>S. C. Yoonho Lee, “Gradient-Based Meta-Learning With Learned Layerwise Metric And Subspace,” in ICML, 2018.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="5" type="1">
<li>A. A. Rusu, D. Rao, J. Sygnowski, O. Vinyals, R. Pascanu, S. Osindero, and R. Hadsell, “Meta-Learning With Latent Embedding Optimization,” ICLR, 2019.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="6" type="1">
<li>S. Qiao, C. Liu, W. Shen, and A. L. Yuille, “Few-Shot Image Recognition By Predicting Parameters From Activations,” CVPR, 2018.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="7" type="1">
<li>A. Antoniou and A. Storkey, “Learning To Learn By Self Critique,” NeurIPS, 2019.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="8" type="1">
<li>Q. Sun, Y. Liu, T.-S. Chua, and B. Schiele, “Meta-Transfer Learning For Few-Shot Learning,” in CVPR, 2018.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="9" type="1">
<li>R. Vuorio, S.-H. Sun, H. Hu, and J. J. Lim, “Multimodal Model-Agnostic Meta-Learning Via Task-Aware Modulation,” in NeurIPS, 2019.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="10" type="1">
<li>H. Yao, Y. Wei, J. Huang, and Z. Li, “Hierarchically Structured Meta-learning,” ICML, 2019.</li>
</ol>
</blockquote>
</section>
<section id="model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks" class="level1">
<h1>Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks</h1>
<section id="초록" class="level2">
<h2 class="anchored" data-anchor-id="초록">초록</h2>
<p>메타학습을 위한 알고리즘을 제안하며, 이는 모델에 구애받지 않는다는 점에서 경사하강법으로 학습되는 모든 모델과 호환되고 분류, 회귀, 강화학습을 포함한 다양한 학습 문제에 적용 가능합니다. 메타학습의 목표는 다양한 학습 과제에 대해 모델을 학습시켜, 소수의 학습 샘플만으로 새로운 학습 과제를 해결할 수 있도록 하는 것입니다. 본 접근법에서는 모델의 파라미터가 명시적으로 학습되어, 새로운 과제로부터 소량의 학습 데이터로 소수의 경사 단계만으로 해당 과제에 대한 좋은 일반화 성능을 생성하도록 합니다. 사실상, 본 방법은 모델이 미세조정하기 쉽도록 학습시킵니다. 두 개의 few-shot 이미지 분류 벤치마크에서 최첨단 성능을 달성하고, few-shot 회귀에서 좋은 결과를 생성하며, 신경망 정책을 사용한 정책 경사 강화학습의 미세조정을 가속화함을 보여줍니다.</p>
</section>
<section id="main-equations" class="level2">
<h2 class="anchored" data-anchor-id="main-equations">Main Equations</h2>
<section id="meta-learning-problem-set-up" class="level3">
<h3 class="anchored" data-anchor-id="meta-learning-problem-set-up">Meta-Learning Problem Set-Up</h3>
<p><strong>목표</strong>: Few-shot 메타학습의 목표는 소수의 데이터 포인트와 학습 반복만으로 새로운 과제에 빠르게 적응할 수 있는 모델을 학습시키는 것입니다.</p>
<p><strong>메타학습의 기본 구조</strong>: 모델(또는 학습자)은 메타학습 단계에서 과제들의 집합에 대해 학습되며, 이를 통해 학습된 모델은 소수의 예시나 시행만으로 새로운 과제에 빠르게 적응할 수 있습니다. 사실상, 메타학습 문제는 전체 과제를 학습 예시로 취급합니다.</p>
<p><strong>모델 정의</strong>: 모델 <span class="math inline">\(f\)</span>는 관측값 <span class="math inline">\(x\)</span>를 출력 <span class="math inline">\(a\)</span>로 매핑합니다.</p>
<p><strong>과제(Task) 정의</strong>: 각 과제 <span class="math inline">\(T\)</span>는 다음으로 구성됩니다:</p>
<p><span class="math display">\[
T = \{\mathcal{L}(\mathbf{x}_1, \mathbf{a}_1, \ldots, \mathbf{x}_H, \mathbf{a}_H), q(\mathbf{x}_1), q(\mathbf{x}_{t+1}|\mathbf{x}_t, \mathbf{a}_t), H\}
\]</span></p>
<p>여기서:</p>
<ul>
<li><span class="math inline">\(\mathcal{L}\)</span>: 손실 함수</li>
<li><span class="math inline">\(q(\mathbf{x}_1)\)</span>: 초기 관측값에 대한 분포</li>
<li><span class="math inline">\(q(\mathbf{x}_{t+1}|\mathbf{x}_t, \mathbf{a}_t)\)</span>: 전이 분포</li>
<li><span class="math inline">\(H\)</span>: 에피소드 길이</li>
</ul>
<p>i.i.d.가정하에 지도학습 문제에서는 <span class="math inline">\(H=1\)</span>로 설정합니다. 모델은 각 시간 <span class="math inline">\(t\)</span>에서 출력 <span class="math inline">\(\mathbf{a}_t\)</span>를 선택하여 길이 <span class="math inline">\(H\)</span>의 샘플을 생성할 수 있습니다. 손실 <span class="math inline">\(\mathcal{L}(\mathbf{x}_1, \mathbf{a}_1, \ldots, \mathbf{x}_H, \mathbf{a}_H) \in \mathbb{R}\)</span>은 과제별 피드백을 제공하며, 이는 오분류 손실 형태이거나 Markov 결정 과정의 비용 함수일 수 있습니다.</p>
<p><strong>메타학습 시나리오</strong>: 과제에 대한 분포 <span class="math inline">\(p(\mathcal{T})\)</span>를 고려하며, 모델이 이에 적응할 수 있기를 원합니다. <span class="math inline">\(K\)</span>-shot 학습 설정에서, 모델은 <span class="math inline">\(p(\mathcal{T})\)</span>로부터 추출된 새로운 과제 <span class="math inline">\(\mathcal{T}_i\)</span>를 <span class="math inline">\(q_i\)</span>로부터 추출된 <span class="math inline">\(K\)</span>개의 샘플과 <span class="math inline">\(\mathcal{T}_i\)</span>에 의해 생성된 피드백 <span class="math inline">\(\mathcal{L}_{\mathcal{T}_i}\)</span>만으로 학습하도록 훈련됩니다.</p>
<p><strong>메타-훈련 과정</strong>:</p>
<ol type="1">
<li>과제 <span class="math inline">\(\mathcal{T}_i\)</span>가 <span class="math inline">\(p(\mathcal{T})\)</span>로부터 샘플링됨</li>
<li>모델이 <span class="math inline">\(K\)</span>개의 샘플과 <span class="math inline">\(\mathcal{T}_i\)</span>로부터의 손실 <span class="math inline">\(\mathcal{L}_{\mathcal{T}_i}\)</span>를 사용하여 학습됨</li>
<li>그 후 <span class="math inline">\(\mathcal{T}_i\)</span>로부터의 새로운 샘플에 대해 테스트됨</li>
<li>모델 <span class="math inline">\(f\)</span>는 <span class="math inline">\(q_i\)</span>로부터의 새로운 데이터에 대한 테스트 오차가 파라미터에 대해 어떻게 변화하는지를 고려하여 개선됨</li>
</ol>
<p><strong>메타-테스팅</strong>: 메타-훈련이 끝나면, 새로운 과제들이 <span class="math inline">\(p(\mathcal{T})\)</span>로부터 샘플링되고, 메타-성능은 <span class="math inline">\(K\)</span>개의 샘플로부터 학습한 후 모델의 성능으로 측정됩니다. 일반적으로 메타-테스팅에 사용되는 과제들은 메타-훈련 중에는 제외됩니다.</p>
</section>
<section id="a-model-agnostic-meta-learning-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="a-model-agnostic-meta-learning-algorithm">A Model-Agnostic Meta-Learning Algorithm</h3>
<p><strong>기본 아이디어</strong>: 모델이 경사 기반 학습 규칙을 사용하여 미세조정될 것이므로, <span class="math inline">\(p(\mathcal{T})\)</span>에서 추출한 새로운 과제에서 과적합 없이 빠른 진전을 이룰 수 있도록 모델을 학습시킵니다. 일부 내부 표현이 다른 것들보다 더 전이 가능하다는 직관에 기반합니다.</p>
<p><strong>핵심 접근법</strong>: 모델 파라미터가 과제의 변화에 민감하도록 찾는 것을 목표로 합니다. 즉, <span class="math inline">\(p(\mathcal{T})\)</span>에서 추출한 모든 과제의 손실 함수에서, 해당 손실의 경사 방향으로 변경될 때 파라미터의 작은 변경이 큰 개선을 이끌어낼 수 있도록 합니다.</p>
<p><strong>노테이션</strong>:</p>
<ul>
<li><span class="math inline">\(\theta\)</span>: 모델의 파라미터</li>
<li><span class="math inline">\(f_{\theta}\)</span>: 파라미터 <span class="math inline">\(\theta\)</span>로 표현된 모델</li>
<li><span class="math inline">\(\theta_i\)</span>: 새로운 과제 <span class="math inline">\(\mathcal{T}_i\)</span>에 적응할 때의 파라미터</li>
<li><span class="math inline">\(\alpha\)</span>: 단계 크기 (스텝 사이즈), 하이퍼파라미터로 고정되거나 메타-학습될 수 있음</li>
</ul>
<p><strong>파라미터 업데이트</strong>: 하나의 경사 업데이트를 사용할 때, 업데이트된 파라미터는 다음과 같이 계산됩니다:</p>
<p><span class="math display">\[
\theta_i' = \theta - \alpha \nabla_{\theta}\mathcal{L}_{\mathcal{T}_i}(f_{\theta})
\]</span></p>
<p><strong>메타-목적 함수</strong>: 모델 파라미터는 <span class="math inline">\(p(\mathcal{T})\)</span>로부터 샘플링된 과제들에 대해 <span class="math inline">\(f_{\theta'_i}\)</span>의 성능을 <span class="math inline">\(\theta\)</span>에 대해 최적화함으로써 학습됩니다. 더 구체적으로, 메타-목적 함수는 다음과 같습니다:</p>
<p><span class="math display">\[
\min_{\theta} \sum_{\mathcal{T}_i \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_i}(f_{\theta'_i}) = \sum_{\mathcal{T}_i \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_i}(f_{\theta - \alpha \nabla_{\theta}\mathcal{L}_{\mathcal{T}_i}(f_{\theta})})
\]</span></p>
<p><strong>핵심 특징</strong>: 메타-최적화는 모델 파라미터 <span class="math inline">\(\theta\)</span>에 대해 수행되지만, 목적 함수는 업데이트된 모델 파라미터 <span class="math inline">\(\theta'\)</span>를 사용하여 계산됩니다. 사실상, 제안된 방법은 하나 또는 소수의 경사 단계가 새로운 과제에서 최대한 효과적인 행동을 생성하도록 모델 파라미터를 최적화합니다.</p>
<p><strong>메타-최적화</strong>: 과제들에 걸친 메타-최적화는 확률적 경사 하강법(SGD)을 통해 수행되며, 모델 파라미터는 다음과 같이 업데이트됩니다:</p>
<p><span class="math display">\[
\theta \leftarrow \theta - \beta \nabla_{\theta} \sum_{\mathcal{T}_i \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_i}(f_{\theta'_i})
\]</span></p>
<p>여기서 <span class="math inline">\(\beta\)</span>는 메타 단계 크기(meta step size)입니다.</p>
<p><strong>Algorithm 1: Model-Agnostic Meta-Learning</strong></p>
<p>Require: p(T): 과제에 대한 분포 Require: α, β: 단계 크기 하이퍼파라미터</p>
<pre><code>1: θ를 무작위로 초기화
2: while not done do
3:    과제 배치 {Ti}를 p(T)로부터 샘플링
4:    for all Ti do
5:       K개의 예시를 사용하여 L_Ti(f_θ)를 평가
6:       경사 하강법으로 적응된 파라미터를 계산:
          θ'_i = θ - α∇_θ L_Ti(f_θ)
7:    end for
8:    메타-업데이트:
       θ ← θ - β∇_θ Σ_{Ti~p(T)} L_Ti(f_{θ'_i})
9: end while</code></pre>
<p><strong>계산적 고려사항</strong>: MAML 메타-경사 업데이트는 경사를 통한 경사(gradient through a gradient)를 포함합니다. 계산적으로 이는 Hessian-벡터 곱을 계산하기 위해 <span class="math inline">\(f\)</span>를 통한 추가 역전파 과정이 필요하며, 이는 TensorFlow와 같은 표준 딥러닝 라이브러리에서 지원됩니다.</p>
<p><strong>모델 가정</strong>: MAML은 모델의 형태에 대해 가정하지 않으며, 파라미터 벡터 <span class="math inline">\(\theta\)</span>로 파라미터화되고 손실 함수가 <span class="math inline">\(\theta\)</span>에 대해 충분히 매끄러워 경사 기반 학습 기법을 사용할 수 있다는 것만 가정합니다.</p>
<p><strong>해석</strong>:</p>
<ul>
<li><p><strong>특징 학습 관점</strong>: 모델의 파라미터를 학습시켜 소수의 경사 단계, 또는 단 하나의 경사 단계만으로 새로운 과제에서 좋은 결과를 생성할 수 있도록 하는 과정은, 많은 과제에 광범위하게 적합한 내부 표현을 구축하는 것으로 볼 수 있습니다. 내부 표현이 많은 과제에 적합하다면, 파라미터를 약간 미세조정하는 것만으로(예: feedforward 모델의 최상위 레이어 가중치를 주로 수정) 좋은 결과를 생성할 수 있습니다.</p></li>
<li><p><strong>동적 시스템 관점</strong>: 학습 과정은 새로운 과제의 손실 함수의 파라미터에 대한 민감도를 최대화하는 것으로 볼 수 있습니다. 민감도가 높을 때, 파라미터에 대한 작은 국소적 변경이 과제 손실에서 큰 개선을 이끌어낼 수 있습니다.</p></li>
</ul>
<p>이러한 메타학습 프레임워크는 분류, 회귀, 강화학습을 포함한 여러 문제 설정에 최소한의 수정만으로 쉽게 적용될 수 있으며, 완전 연결, 합성곱, 순환 신경망과 결합될 수 있습니다.</p>
</section>
</section>
<section id="what-is-new-in-the-work" class="level2">
<h2 class="anchored" data-anchor-id="what-is-new-in-the-work">(1) What is new in the work</h2>
<p>본 연구의 주요 새로운 점은 다음과 같습니다:</p>
<p><strong>모델에 구애받지 않는 메타학습 접근법</strong>: MAML은 경사하강법으로 학습되는 모든 모델에 직접 적용될 수 있는 일반적이고 모델에 구애받지 않는 메타학습 알고리즘을 제안합니다. 이전 메타학습 방법들이 업데이트 함수나 학습 규칙을 학습하는 것과 달리, MAML은 학습된 파라미터의 수를 늘리지 않으며 모델 아키텍처에 제약을 두지 않습니다.</p>
<p><strong>초기 파라미터 최적화</strong>: 모델의 초기 파라미터 <span class="math inline">\(\theta\)</span>를 학습시켜, 소수의 경사 단계 또는 단 하나의 경사 단계만으로 새로운 과제에서 좋은 결과를 생성할 수 있도록 합니다. 이는 메타-최적화가 모델 파라미터 $대해 수행되지만, 목적 함수는 업데이트된 모델 파라미터 <span class="math inline">\(\theta'_i\)</span>를 사용하여 계산됩니다.</p>
<p><strong>범용 적용성</strong>: 분류, 회귀, 강화학습을 포함한 여러 문제 설정에 최소한의 수정만으로 쉽게 적용될 수 있으며, 완전 연결, 합성곱, 순환 신경망과 결합될 수 있습니다.</p>
</section>
<section id="why-is-the-work-important" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-work-important">(2) Why is the work important</h2>
<p>본 연구는 다음과 같은 이유로 중요합니다:</p>
<p><strong>빠른 적응 능력</strong>: 인간 지능의 특징인 빠른 학습 능력을 인공 에이전트에 부여하는 것이 중요합니다. 소수의 예시만으로 객체를 인식하거나 몇 분의 경험만으로 새로운 기술을 배우는 능력을 모방합니다.</p>
<p><strong>실용적 가치</strong>: 소량의 데이터만으로 새로운 과제에 빠르게 적응할 수 있어, 데이터 수집이 어렵거나 비용이 많이 드는 실제 응용 분야에서 유용합니다. 특히 few-shot learning 문제에서 에이전트가 소량의 새로운 정보를 과거 경험과 통합하면서 새로운 데이터에 과적합을 피해야 하는 도전적인 문제를 해결합니다.</p>
<p><strong>범용성</strong>: 과제와 모델에 구애받지 않는 특성으로 인해 다양한 도메인에 적용 가능하여, 딥러닝과 강화학습에서 다중 과제 초기화를 표준 요소로 만들 수 있는 잠재력을 가집니다.</p>
</section>
<section id="what-is-the-literature-gap" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-literature-gap">(3) What is the literature gap</h2>
<p>논문에서 식별한 문헌의 격차는 다음과 같습니다:</p>
<p><strong>기존 방법의 제한사항</strong>: 이전 메타학습 방법들은 전체 데이터셋을 수집하는 순환 신경망을 학습시키거나, 테스트 시 비모수적 방법과 결합될 수 있는 특징 임베딩을 학습했습니다. 이러한 방법들은 특정 과제(예: few-shot classification)를 염두에 두고 설계되어 강화학습과 같은 다른 도메인에 쉽게 적용할 수 없었습니다.</p>
<p><strong>아키텍처 제약</strong>: 일부 방법들은 순환 모델이나 Siamese 네트워크와 같은 특정 모델 아키텍처를 요구했습니다. 메모리 증강 신경망과 같은 순환 메타학습 모델들도 MAML처럼 여러 과제에 적용 가능하지만, MAML이 5-way Omniglot과 MiniImagenet 분류에서 이들을 크게 능가했습니다.</p>
<p><strong>추가 파라미터</strong>: 많은 방법들이 메타학습을 위해 추가 학습 파라미터를 도입했습니다. 예를 들어, 업데이트 함수나 학습 규칙을 학습하는 방법들이 있었습니다.</p>
</section>
<section id="how-is-the-gap-filled" class="level2">
<h2 class="anchored" data-anchor-id="how-is-the-gap-filled">(4) How is the gap filled</h2>
<p>MAML은 다음과 같은 방식으로 격차를 메웁니다:</p>
<p><strong>단순하고 일반적인 접근법</strong>: 모델이 경사 기반 학습 규칙을 사용하여 미세조정될 것이므로, 이 경사 기반 학습 규칙이 <span class="math inline">\(p(T)\)</span>에서 추출한 새로운 과제에서 과적합 없이 빠른 진전을 이룰 수 있도록 모델을 학습시킵니다. 실제로 <span class="math inline">\(p(T)\)</span>에서 추출한 모든 과제의 손실 함수에서, 해당 손실의 경사 방향으로 변경될 때 파라미터의 작은 변경이 큰 개선을 이끌어낼 수 있도록 과제 변화에 민감한 모델 파라미터를 찾는 것을 목표로 합니다.</p>
<p><strong>메타-목적 함수</strong>: 메타-목적 함수는 다음과 같이 정의됩니다:</p>
<p><span class="math display">\[
\min_{\theta} \sum_{T_i \sim p(T)} \mathcal{L}_{T_i}(f_{\theta'_i}) = \sum_{T_i \sim p(T)} \mathcal{L}_{T_i}(f_{\theta - \alpha \nabla_{\theta}\mathcal{L}_{T_i}(f_{\theta})})
\]</span></p>
<p>여기서 <span class="math inline">\(\theta'_i = \theta - \alpha \nabla_{\theta}\mathcal{L}_{T_i}(f_{\theta})\)</span>입니다. 이는 하나 또는 소수의 경사 단계가 새로운 과제에서 최대한 효과적인 행동을 생성하도록 모델 파라미터를 최적화합니다.</p>
<p><strong>아키텍처 독립성</strong>: MAML은 모델의 형태에 대해 가정하지 않으며, 파라미터 벡터 <span class="math inline">\(\theta\)</span>로 파라미터화되고 손실 함수가 <span class="math inline">\(\theta\)</span>에 대해 충분히 매끄러워 경사 기반 학습 기법을 사용할 수 있다는 것만 가정합니다. 완전 연결, 합성곱, 또는 순환 신경망과 쉽게 결합될 수 있습니다.</p>
</section>
<section id="what-is-achieved-with-the-new-method" class="level2">
<h2 class="anchored" data-anchor-id="what-is-achieved-with-the-new-method">(5) What is achieved with the new method</h2>
<p>새로운 방법으로 달성한 성과는 다음과 같습니다:</p>
<p><strong>Few-shot Classification 성능</strong>:</p>
<ul>
<li>Omniglot: 5-way 1-shot에서 98.7±0.4%, 5-shot에서 99.9±0.1%; 20-way 1-shot에서 95.8±0.3%, 5-shot에서 98.9±0.2%를 달성했습니다</li>
<li>MiniImagenet: 5-way 1-shot에서 48.70±1.84%, 5-shot에서 63.11±0.92%를 달성하여 matching networks와 meta-learner LSTM을 능가했습니다</li>
</ul>
<p><strong>회귀 성능</strong>: 진폭과 위상이 변하는 사인파 회귀 과제에서, MAML로 학습된 모델은 5개의 데이터 포인트만으로 빠르게 적응할 수 있었으며, K 데이터 포인트가 모두 입력 범위의 한쪽 절반에 있을 때도 다른 절반의 진폭과 위상을 추론할 수 있었습니다. 이는 모델이 사인파의 주기적 구조를 학습했음을 보여줍니다.</p>
<p><strong>강화학습 성능</strong>:</p>
<ul>
<li>2D Navigation: MAML은 단 하나의 정책 경사 업데이트로 새로운 목표 위치에 훨씬 더 빠르게 적응할 수 있었습니다</li>
<li>Locomotion (Half-cheetah와 Ant): MAML은 단 하나의 경사 업데이트만으로도 속도와 방향을 빠르게 적응시킬 수 있었으며, 더 많은 경사 단계로 계속 개선되었습니다. MAML 초기화가 무작위 초기화와 사전학습을 크게 능가했으며, 사전학습은 경우에 따라 무작위 초기화보다 나쁜 경우도 있었습니다</li>
</ul>
<p><strong>효율성</strong>: MAML은 matching networks와 meta-learner LSTM에 비해 더 적은 전체 파라미터를 사용하며, 알고리즘이 분류기 자체의 가중치를 넘어서는 추가 파라미터를 도입하지 않습니다.</p>
</section>
<section id="what-data-are-used" class="level2">
<h2 class="anchored" data-anchor-id="what-data-are-used">(6) What data are used</h2>
<p>논문에서 사용된 데이터는 다음과 같습니다:</p>
<p><strong>회귀 과제</strong>:</p>
<ul>
<li>사인파 함수: 진폭은 [0.1, 5.0] 범위에서, 위상은 [0, π] 범위에서 변합니다. 학습 및 테스트 중에 데이터 포인트 x는 [−5.0, 5.0]에서 균일하게 샘플링됩니다. K-shot 회귀 과제에서는 각 과제에 대해 K개의 입력/출력 쌍이 제공됩니다.</li>
</ul>
<p><strong>분류 과제</strong>:</p>
<ul>
<li><strong>Omniglot 데이터셋</strong>: 50개의 다른 알파벳에서 1623개의 문자로 구성되며, 각각 20개의 인스턴스가 있습니다. 각 인스턴스는 다른 사람이 그렸습니다. 학습을 위해 1200개의 문자를 무작위로 선택하고 나머지는 테스트에 사용했습니다. 데이터셋은 90도 배수로 회전하여 증강되었습니다.</li>
<li><strong>MiniImagenet 데이터셋</strong>: 64개의 학습 클래스, 12개의 검증 클래스, 24개의 테스트 클래스를 포함합니다. N-way 분류의 경우, N개의 클래스에서 각각 K개의 다른 인스턴스가 모델에 제공됩니다.</li>
</ul>
<p><strong>강화학습 과제</strong>:</p>
<ul>
<li><strong>2D Navigation</strong>: 포인트 에이전트가 단위 정사각형 내에서 무작위로 선택된 2D 목표 위치로 이동해야 합니다. 관측은 현재 2D 위치이고, 행동은 [−0.1, 0.1] 범위로 제한된 속도 명령에 해당합니다. 보상은 목표까지의 음의 제곱 거리이며, 에피소드는 에이전트가 목표의 0.01 이내에 있거나 H = 100의 지평에 도달하면 종료됩니다.</li>
<li><strong>Locomotion (MuJoCo 시뮬레이터)</strong>: 평면 cheetah와 3D quadruped(“ant”)가 특정 방향 또는 특정 속도로 달리도록 요구합니다. 목표 속도 실험에서 보상은 에이전트의 현재 속도와 목표 사이의 음의 절댓값이며, 목표는 cheetah의 경우 0.0과 2.0 사이에서, ant의 경우 0.0과 3.0 사이에서 균일하게 무작위로 선택됩니다. 목표 방향 실험에서 보상은 전진 또는 후진 방향의 속도 크기이며, 각 과제마다 무작위로 선택됩니다. 지평은 H = 200이고, 모든 문제에 대해 경사 단계당 20개의 rollout을 사용했습니다(ant forward/backward 과제는 단계당 40개의 rollout 사용).</li>
</ul>
</section>
<section id="what-are-the-limitations" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-limitations">(7) What are the limitations</h2>
<p>논문에서 명시적으로 언급된 제한사항은 다음과 같습니다:</p>
<p><strong>계산 비용</strong>: MAML 메타-경사 업데이트는 경사를 통한 경사를 포함합니다. 계산적으로 이는 Hessian-벡터 곱을 계산하기 위해 <span class="math inline">\(f\)</span>를 통한 추가 역전파 과정이 필요하며, 이는 TensorFlow와 같은 표준 딥러닝 라이브러리에서 지원됩니다.</p>
<p><strong>1차 근사</strong>: 이러한 2차 도함수를 생략한 1차 근사를 실험했으며, 결과 방법은 여전히 업데이트 후 파라미터 값 <span class="math inline">\(\theta'_i\)</span>에서 메타-경사를 계산합니다. MiniImagenet에서 1차 근사의 성능은 전체 2차 도함수를 사용한 것과 거의 동일했으며, 이는 MAML의 개선 대부분이 업데이트 후 파라미터 값에서 목적 함수의 경사에서 나온다는 것을 시사합니다. ReLU 신경망이 국소적으로 거의 선형이라는 과거 연구는 2차 도함수가 대부분의 경우 0에 가까울 수 있음을 시사하며, 이는 1차 근사의 좋은 성능을 부분적으로 설명합니다. 이 근사는 추가 역전파 과정에서 Hessian-벡터 곱을 계산할 필요를 제거하며, 네트워크 계산에서 약 33%의 속도 향상을 가져왔습니다.</p>
<p><strong>강화학습에서의 샘플 요구사항</strong>: 정책 경사가 on-policy 알고리즘이므로, <span class="math inline">\(f_{\theta}\)</span>의 적응 중 각 추가 경사 단계는 현재 정책 <span class="math inline">\(f_{\theta'_i}\)</span>로부터 새로운 샘플을 필요로 합니다. 이는 감독학습 과제와 달리 각 경사 단계가 환경으로부터 추가 샘플을 필요로 함을 의미합니다.</p>
<p><strong>3차 도함수 회피</strong>: 강화학습 실험에서 3차 도함수 계산을 피하기 위해 TRPO를 위한 Hessian-벡터 곱을 계산하는 데 유한 차분을 사용했습니다.</p>
</section>
<section id="maml-한계점의-해소-방안" class="level2">
<h2 class="anchored" data-anchor-id="maml-한계점의-해소-방안">(8) MAML 한계점의 해소 방안</h2>
<p>MAML 논문에서 언급된 주요 한계점들에 대해 2024-2025년 최신 연구들은 다음과 같은 해결책을 제시하고 있습니다.</p>
<section id="계산-비용-문제-second-order-gradient-computation" class="level3">
<h3 class="anchored" data-anchor-id="계산-비용-문제-second-order-gradient-computation">1. 계산 비용 문제 (Second-Order Gradient Computation)</h3>
<p><strong>Directed-MAML (2025)</strong>: <strong>Task-directed 근사 기법</strong>을 도입하여 2차 도함수 계산 전에 1차 task-directed 근사를 적용합니다. 이 방법은 대표 과제의 1차 경사만 계산하여 2차 경사의 효과를 근사하므로, 여러 과제에 대한 2차 경사 계산보다 필요한 자원이 적습니다. CartPole-v1, LunarLander-v2 실험에서 MAML 대비 1.77배의 수렴 속도 향상을 달성했으며, 에폭당 실행 시간은 약간 증가했지만(2.52초 vs 2.34초) 수렴까지의 총 시간은 0.22시간으로 MAML의 0.39시간보다 크게 단축되었습니다.</p>
<p><strong>Hessian-Free 접근법</strong>: ES-MAML(2019)은 Evolution Strategies를 활용하여 2차 도함수 추정을 완전히 피하며, 2024년 연구에서는 zeroth-order 최적화 기법을 활용한 Model-Agnostic Meta-Policy Optimization이 제안되었습니다. 이 방법은 Stein’s Gaussian smoothing 기법을 사용하여 정책 Hessian 추정을 생략하고, 안정성과 높은 계산 비용 문제를 동시에 해결합니다.[2][3]</p>
<p><strong>Implicit Gradients (2024)</strong>: Meta-learning with implicit gradients 접근법은 메타-경사 계산을 내부 루프 최적화 선택으로부터 분리합니다. 이론적으로 단일 내부 루프 경사 계산에 필요한 것 이상의 메모리 사용 없이 정확한 메타-경사를 계산할 수 있으며, 전체 계산 비용도 증가하지 않습니다.[4]</p>
</section>
<section id="차-근사의-성능-개선" class="level3">
<h3 class="anchored" data-anchor-id="차-근사의-성능-개선">2. 1차 근사의 성능 개선</h3>
<p><strong>First-Order MAML with Controllable Bias (2024)</strong>: 새로운 1차 MAML 변형은 MAML 목적 함수의 정상점으로 수렴할 것이 증명되었으며, 이는 기존 1차 변형들(FO-MAML, Reptile)과 다릅니다. 연구진은 MAML 목적 함수가 이전 연구에서 가정한 평활성(smoothness) 가정을 만족하지 않으며, 평활성 상수가 메타-경사의 norm과 함께 증가한다는 것을 보였습니다. 이는 이론적으로 일반 경사 방법보다 정규화되거나 clipped-gradient 방법의 사용을 시사합니다.[5]</p>
<p><strong>Enhancing Model Agnostic Meta-Learning (2024)</strong>: Approximate Hessian Effect 프레임워크 내에서 코사인 유사도와 제곱 오차(L2 loss)를 손실 함수로 사용하는 연구가 제안되었습니다. 연구진은 1차 메타학습 알고리즘이 계산 효율성과 확장성을 약속한다고 강조하며, Sign-MAML과 같은 방법들이 sign-based 최적화 전략을 활용하여 1차 기법으로 메타학습 과제를 다룹니다.[6]</p>
</section>
<section id="강화학습에서의-샘플-효율성-문제" class="level3">
<h3 class="anchored" data-anchor-id="강화학습에서의-샘플-효율성-문제">3. 강화학습에서의 샘플 효율성 문제</h3>
<p><strong>Model-Based Meta-RL (MAMBA, 2024)</strong>: 모델 기반 접근법을 메타-RL에 적용하여 샘플 효율성을 크게 향상시켰습니다. MAMBA는 Dreamer 아키텍처를 활용하여 기존 메타-RL 및 모델 기반 RL 베이스라인 대비 최대 15배의 샘플 효율성 향상을 달성했습니다. 전체 메타-에피소드 인코딩, 선택적 잠재 상태 최적화, 스케줄된 world model horizon을 통해 계산 부담을 줄이면서 장기 메모리 요구사항을 해결했습니다.[7][8][9]</p>
<p><strong>Coreset-Based Task Selection (2025)</strong>: 과제 선택을 통해 메타-RL의 샘플 효율성을 향상시키는 연구입니다. 경사 공간에서 과제의 다양성에 기반하여 가중치가 부여된 과제 부분집합을 선택하며, 가장 정보가 풍부하고 다양한 과제를 우선시합니다. 이는 <span class="math inline">\(\epsilon\)</span>-가까운 정상 해를 찾는 데 필요한 샘플 수를 <span class="math inline">\(O(1/\epsilon)\)</span> 배율로 감소시킵니다.[10]</p>
<p><strong>Off-Policy Meta-RL (2024)</strong>: Efficient off-policy meta-RL 알고리즘들이 과제 추론과 제어를 분리하고, 잠재 과제 변수의 온라인 확률적 필터링을 수행하여 적은 양의 경험으로 새로운 과제를 해결하는 방법을 추론합니다. Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP, 2024)는 비용 효율적인 샘플 생성을 통해 메타-테스팅의 샘플 효율성을 크게 향상시켰습니다.[11][12]</p>
</section>
<section id="메모리-효율성-개선" class="level3">
<h3 class="anchored" data-anchor-id="메모리-효율성-개선">4. 메모리 효율성 개선</h3>
<p><strong>Memory-Efficient Gradient Computation (2024-2025)</strong>: DP-GRAPE는 gradient projection을 활용하여 메모리 사용량을 크게 줄입니다. RoBERTa-Large 미세조정 시 DP-Adam 대비 70% 이상의 메모리 사용량 감소(24.4GB vs 78.1GB)를 달성했습니다. 샘플 경사 메모리를 <span class="math inline">\(B\sum_{\ell=1}^{L}m_{\ell}n_{\ell}\)</span>에서 <span class="math inline">\(Br\sum_{\ell=1}^{L}n_{\ell}\)</span>로 줄입니다.[13]</p>
<p><strong>META-LORA (2025)</strong>: 샘플 재가중치를 위한 메모리 효율적인 접근법으로, 경사 유사도를 저차원 활성화 상태와 해당 경사의 곱으로 분해하여 7,552배의 메모리 사용량 감소를 달성했습니다. 메모리 소비는 4%만 증가하면서 최대 5%의 성능 향상을 보였습니다.[14]</p>
</section>
<section id="메타-연속-학습에서의-분산-감소" class="level3">
<h3 class="anchored" data-anchor-id="메타-연속-학습에서의-분산-감소">5. 메타-연속 학습에서의 분산 감소</h3>
<p><strong>Variance Reduced Meta-CL (VR-MCL, 2024)</strong>: 메타-연속 학습이 Hessian을 온라인 방식으로 암묵적으로 근사하지만 무작위 메모리 버퍼 샘플링으로 인한 높은 분산 문제를 겪는다는 점을 발견했습니다. VR-MCL은 적시성 있고 정확한 Hessian 근사를 동시에 달성하여 지식 전이와 망각 사이의 최적화된 균형을 제공합니다.[15]</p>
</section>
<section id="automatic-differentiation-최적화" class="level3">
<h3 class="anchored" data-anchor-id="automatic-differentiation-최적화">6. Automatic Differentiation 최적화</h3>
<p><strong>Optimizing AD with Deep RL (2024)</strong>: Cross-country elimination과 심층 강화학습을 활용하여 Jacobian 계산에 필요한 곱셈 횟수를 최적화합니다. 효율적인 제거 순서를 찾아 새로운 자동 미분 알고리즘과 실질적인 실행 시간 이득을 달성했습니다.[16]</p>
</section>
<section id="대규모-병렬화-지원" class="level3">
<h3 class="anchored" data-anchor-id="대규모-병렬화-지원">7. 대규모 병렬화 지원</h3>
<p><strong>Massively Parallelized Multi-Task RL (2024)</strong>: GPU 가속 시뮬레이터를 활용한 대규모 병렬화(&gt;&gt;1000 시뮬레이션) 훈련 패러다임이 등장했습니다. 단일 GPU에서 과제당 고정된 수의 환경을 할당하여 동시에 다양한 데이터 수집과 end-to-end MTRL 훈련을 가능하게 합니다. 실험 결과, wall-clock 효율성이 샘플 효율성보다 더 중요하며, 경험 수집이 더 많은 GPU로 쉽게 확장되기 때문입니다.[17]</p>
<p>이러한 최신 연구들은 MAML의 원래 한계점들을 다양한 각도에서 해결하고 있으며, 특히 계산 효율성, 메모리 사용량, 샘플 효율성 측면에서 실질적인 개선을 제공하고 있습니다.</p>
<p><a href="https://arxiv.org/html/2510.00212v1">1</a> <a href="https://arxiv.org/html/2503.00385v1">2</a> <a href="https://arxiv.org/abs/1910.01215">3</a> <a href="https://dl.acm.org/doi/10.5555/3454287.3454298">4</a> <a href="https://arxiv.org/html/2409.03682v1">5</a> <a href="https://scholarworks.bwise.kr/cau/bitstream/2019.sw.cau/72909/1/Enhancing%20Model%20Agnostic%20Meta-Learning%20via%20Gradient%20Similarity%20Loss.pdf">6</a> <a href="https://arxiv.org/pdf/2403.09859.pdf">7</a> <a href="https://www.themoonlight.io/en/review/mamba-an-effective-world-model-approach-for-meta-reinforcement-learning">8</a> <a href="https://github.com/zoharri/mamba">9</a> <a href="https://arxiv.org/abs/2502.02332">10</a> <a href="https://arxiv.org/html/2506.04399v1">11</a> <a href="https://www.semanticscholar.org/paper/Efficient-Off-Policy-Meta-Reinforcement-Learning-Rakelly-Zhou/4625628163a2ee0e6cd320cd7a14b4ccded2a631">12</a> <a href="https://arxiv.org/html/2506.15588v1">13</a> <a href="https://aclanthology.org/2025.coling-main.568.pdf">14</a> <a href="https://openreview.net/forum?id=TpD2aG1h0D">15</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/06cbd2e81dfbd3bb4cb0abce95b32584-Paper-Conference.pdf">16</a> <a href="https://arxiv.org/html/2507.23172v2">17</a> <a href="https://www.nature.com/articles/s41598-025-22058-3">18</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0004370224001206">19</a> <a href="https://aclanthology.org/2025.uncertainlp-main.17.pdf">20</a> <a href="https://peerj.com/articles/cs-2757/">21</a> <a href="https://www.emergentmind.com/topics/model-agnostic-meta-learning-maml">22</a> <a href="https://www.ijcai.org/proceedings/2024/500">23</a> <a href="https://johnjaejunlee95.github.io/meta_learning_2/">24</a> <a href="https://proceedings.iclr.cc/paper_files/paper/2024/file/0b6df1a973b82b3cf7fadca6c387ae5a-Paper-Conference.pdf">25</a> <a href="https://rlj.cs.umass.edu/2025/papers/RLJ_RLC_2025_218.pdf">26</a> <a href="https://openreview.net/forum?id=if2vRbS8Ew">27</a> <a href="https://www.semanticscholar.org/paper/283f975e221f56974f30a3b12c7fb015c0c77377">28</a> <a href="https://www.semanticscholar.org/paper/On-First-Order-Meta-Learning-Algorithms-Nichol-Achiam/90dc22818bd2d97d8deaff168b0137b75a962767">29</a> <a href="https://www.nowpublishers.com/article/DownloadSummary/MAL-080">30</a> <a href="https://nips.cc/virtual/2024/poster/95734">31</a> <a href="https://ieeexplore.ieee.org/document/10649914/">32</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197624021250">33</a> <a href="https://ieeexplore.ieee.org/abstract/document/10839866/">34</a> <a href="https://proceedings.mlr.press/v235/huang24a.html">35</a> <a href="https://arxiv.org/html/2504.08277v2">36</a> <a href="https://dl.acm.org/doi/10.1145/3466772.3467038">37</a> <a href="http://hcisj.com/articles/issue_view.php?wr_id=577&amp;page=3">38</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/5706668422bd0d82588998ebe1067133-Paper-Conference.pdf">39</a> <a href="https://arxiv.org/pdf/2409.03682.pdf">40</a> <a href="https://openreview.net/pdf?id=5trmyvtkeo">41</a> <a href="https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p317.pdf">42</a> <a href="https://wonyeol.github.io/papers/2024-iclr.pdf">43</a> <a href="https://www.ijcai.org/proceedings/2024/0500.pdf">44</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608023001582">45</a> <a href="https://aclanthology.org/2024.naacl-long.282.pdf">46</a> <a href="https://openreview.net/forum?id=vUuUPszknz">47</a> <a href="https://ieeexplore.ieee.org/document/10667211/">48</a> <a href="https://www.sciencedirect.com/science/article/pii/S0098135425002443">49</a> <a href="https://www.ijcai.org/proceedings/2025/0711.pdf">50</a> <a href="https://ai.meta.com/research/publications/federated-multi-task-learning-for-competing-constraints/">51</a> <a href="https://ieeexplore.ieee.org/document/10643964">52</a> <a href="https://research.tue.nl/en/publications/model-based-meta-reinforcement-learning-for-hyperparameter-optimi">53</a> <a href="https://hdsr.mitpress.mit.edu/pub/lgmkutcd">54</a> <a href="https://dl.acm.org/doi/10.1145/3659947">55</a> <a href="https://www.sciencedirect.com/science/article/pii/S0950705125014820">56</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522001281">57</a> <a href="https://www.biorxiv.org/content/10.1101/2025.07.10.664201v1.full.pdf">58</a></p>
</section>
</section>
</section>
<section id="probabilistic-model-agnostic-meta-learning" class="level1">
<h1>Probabilistic Model-agnostic Meta-learning</h1>
<section id="초록-1" class="level2">
<h2 class="anchored" data-anchor-id="초록-1">초록</h2>
<p>메타러닝에서 few-shot learning이란 이전의 다양한 작업과 경험들로부터 사전(prior)을 획득하고 이를 통해 적은 데이터만으로 새로운 작업을 학습하는 것을 의미합니다. 그러나 few-shot 학습의 중요한 과제 중 하나는 작업의 모호성입니다. 강력한 사전이 다수의 작업에서 메타러닝될지라도, 새로운 작업을 위한 소량의 데이터로는 단일 모델(예를 들어 정확한 분류기)을 도출하기 어려울 수 있습니다. 본 논문에서는 새로운 작업에 대해 모델 분포로부터 샘플링할 수 있는 확률적 메타러닝 알고리즘을 제안합니다. 본 접근법은 gradient descent로 새로운 작업에 적응하는 model-agnostic meta-learning을 확장하여, 파라미터 분포를 변분 하한(variational lower bound)으로 학습하도록 설계했습니다. 메타 테스트 시에는 gradient descent에 노이즈를 주입하는 간단한 적응 절차를 사용하며, 메타 학습 시에는 이 절차가 근사 모델의 사후분포로부터 샘플을 생성하도록 최적화합니다. 실험 결과, 본 방법이 모호한 few-shot 학습 문제에서 타당한 분류기 및 회귀 모델을 샘플링할 수 있음을 보이고, 이러한 모호성 인식이 downstream active learning 문제에도 활용될 수 있음을 제시합니다.</p>
</section>
<section id="what-is-new-in-the-work-1" class="level2">
<h2 class="anchored" data-anchor-id="what-is-new-in-the-work-1">(1) What is new in the work</h2>
<ul>
<li>기존의 MAML(Model-Agnostic Meta-Learning)에 ’확률적 모형’을 결합시켜, 모호한 few-shot 문제 상황에서 여러 모델을 샘플링할 수 있는 방법(PLATIPUS)을 제안했습니다.</li>
<li>Gradient descent에 확률적 분포(노이즈)를 주입하는 간단한 적응절차와 변분추론 기반 학습 과정을 도입했습니다.</li>
</ul>
</section>
<section id="why-is-the-work-important-1" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-work-important-1">(2) Why is the work important</h2>
<ul>
<li>Few-shot 상황은 데이터가 적어 모형 설정에 불확실성이 큽니다. 여러 후보 모델을 “샘플링”하며 불확실성을 추정할 수 있어, 안전성이나 human-in-the-loop 학습(예: 의료 이미지 분류)에서 신뢰도와 데이터 선정에 중요한 의미를 가집니다.</li>
<li>능동적 학습(active learning) 등 downstream 응용에서 불확실성 기반 데이터 선택이 가능해집니다.</li>
</ul>
</section>
<section id="what-is-the-literature-gap-1" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-literature-gap-1">(3) What is the literature gap</h2>
<ul>
<li>Bayesian 모델 기반 과거 접근(예: 신경통계학자 neural statistician 등)은 네트워크가 단순할 때만 합리적으로 불확실성을 모델링했으나, 대규모 신경망에서는 수식적으로나 계산적으로 비효율적이었습니다.</li>
<li>MAML 포함 최근 메타러닝들은 높은 표현력(대규모 신경망 등)에서는 ’확률적 분포’를 무시하고 결정적(deterministic) 추정에만 집중했습니다.</li>
</ul>
</section>
<section id="how-is-the-gap-filled-1" class="level2">
<h2 class="anchored" data-anchor-id="how-is-the-gap-filled-1">(4) How is the gap filled</h2>
<ul>
<li>PLATIPUS에서는 MAML을 확률적 그래프 모델/변분추론 관점으로 재해석함으로써, 기존 deep learning 기반 모델에 확률적 분포 추정 및 샘플링을 효과적으로 도입했습니다.</li>
<li>단순 gradient descent에 노이즈를 주입하는 방식으로 확률적 추론을 실제 네트워크에 적용할 수 있도록 함—수식적으로는 변분 하한(variational lower bound)를 사용하며, 분포 모형은 Gaussian 분포로 설정합니다.</li>
<li>부족한 정보에 대해 다양한 후보 작업/모형을 샘플링함으로써 다중 모드(task ambiguity/multimodal task) 문제를 해결합니다.</li>
</ul>
</section>
<section id="what-is-achieved-with-the-new-method-1" class="level2">
<h2 class="anchored" data-anchor-id="what-is-achieved-with-the-new-method-1">(5) What is achieved with the new method</h2>
<ul>
<li>모호한 few-shot 문제에서도 다양한 분류기·회귀 모델을 효과적으로 샘플링할 수 있습니다.</li>
<li>실제 실험(1D 회귀, 2D 이진 분류, 이미지 분류)에서 PLATIPUS는 불확실성이 큰 부분에서는 다양한 함수 형태(선형, 사인 등)와 다양한 결정 경계(원 크기/위치) 샘플을 생성함을 보였습니다.</li>
<li>MAML 대비 ambiguous task에서 더 많은 모드(mode)를 커버하면서, 성능(accuracy)은 동일하거나 향상됨을 보였습니다.</li>
<li>불확실성을 활용해 능동적 데이터 선택(active learning)에서도 MAML 대비 더 빠르게 오차를 줄임을 보였습니다.</li>
</ul>
</section>
<section id="what-data-are-used-1" class="level2">
<h2 class="anchored" data-anchor-id="what-data-are-used-1">(6) What data are used</h2>
<ul>
<li>1D 회귀(선형/사인 함수 task)와 2D 분류(원이 결정 경계인 task)로 구성된 인공 데이터셋.</li>
<li>실세계 데이터로는 CelebA 얼굴 속성 이미지 분류(다중 attribute 기반 ambiguous task), MiniImagenet 5-way, 1-shot benchmark를 사용했습니다.</li>
</ul>
</section>
<section id="what-are-the-limitations-1" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-limitations-1">(7) What are the limitations</h2>
<ul>
<li>현재 방식은 posterior 분산 추정이 상대적으로 단순하여, 각 작업마다 모호성이 다를 때 최적의 불확실성 추정이 어려울 수 있습니다.</li>
<li>variance estimator를 few-shot 트레인셋에 의존하도록 개선하면 더 나을 수 있으나, 파라미터 효율적 설계가 추가 연구 과제입니다.</li>
<li>RL(강화학습) 등으로 확장시 structured exploration에서 어떻게 모델링할지 추가 연구가 필요함을 언급합니다.</li>
</ul>
</section>
</section>
<section id="online-meta-learning" class="level1">
<h1>Online Meta learning</h1>
<section id="초록-2" class="level2">
<h2 class="anchored" data-anchor-id="초록-2">초록</h2>
<p>지능형 시스템의 핵심 능력은 이전 경험을 바탕으로 새로운 과제의 학습을 가속화하고 향상시키는 것입니다. 메타러닝은 이 문제를 새로운 과제에 빠르게 적응할 수 있는 모델 파라미터의 사전확률을 학습하는 것으로 봅니다. 다만 기존 메타러닝은 과제들이 배치로 한 번에 주어진다고 가정합니다. 반면 온라인 회귀 기반 학습은 문제가 순차적으로 드러나는 설정을 고려하지만, 일반적으로 과제별 적응 없이 단일 모델만 학습합니다. 본 논문은 이 두 패러다임을 통합하여 연속적 평생학습의 실질을 더 잘 포착하는 온라인 메타러닝 설정을 제시합니다. 우리는 MAML을 이 설정으로 확장하는 “Follow-the-Meta-Leader(FTML)” 알고리즘을 제안합니다. 이론적으로 표준 온라인 설정 대비 하나의 추가 고계 평활성 가정 하에서 O(log T) 회귀 보장을 제공합니다. 세 가지 대규모 과제에 대한 실험평가 결과, 제안 알고리즘이 기존 온라인 학습 접근법을 크게 능가함을 보여줍니다.</p>
</section>
<section id="what-is-new-in-the-work-2" class="level2">
<h2 class="anchored" data-anchor-id="what-is-new-in-the-work-2">(1) What is new in the work</h2>
<p>기존 메타러닝과 온라인 학습을 통합한 <strong>온라인 메타러닝(Online Meta-Learning)</strong> 문제 설정과 알고리즘을 제시합니다. 구체적으로:</p>
<ul>
<li><strong>FTML 알고리즘</strong>: MAML을 순차적 설정으로 확장하여 <span class="math display">\[\text{Follow-the-Leader}\]</span> 원칙을 메타러닝에 적용. 업데이트는 <span class="math display">\[w_{t+1} = \arg\min_w \sum_{k=1}^{t} f_k(U_t(w))\]</span> 형태</li>
<li><strong>이론적 분석</strong>: MAML 유사 목적함수가 강볼록(strongly convex)임을 증명하고 <span class="math display">\[O(\log T)\]</span> 회귀 보장 도출</li>
<li><strong>비연속적 → 연속적 학습</strong>: 기존 메타러닝의 ‘메타트레인/메타테스트’ 두 단계 구조를 단일 연속 학습 과정으로 재구성</li>
</ul>
</section>
<section id="why-is-the-work-important-2" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-work-important-2">(2) Why is the work important</h2>
<ul>
<li><strong>현실성</strong>: 실제 환경에서는 과제가 배치로 주어지지 않고 순차적으로 나타남. 온라인 메타러닝은 이를 반영하여 <strong>평생학습(lifelong learning)</strong> 을 현실적으로 모델링</li>
<li><strong>이론적 의의</strong>: MAML 유사 목적함수의 수렴성을 처음으로 엄밀하게 분석. 안정성과 적응성의 균형을 제공</li>
<li><strong>실용성</strong>: 변화하는 환경에서 새 과제마다 빠르게 적응하면서도, 과거 경험으로부터 효과적 사전확률을 학습</li>
</ul>
</section>
<section id="what-is-the-literature-gap-2" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-literature-gap-2">(3) What is the literature gap</h2>
<ul>
<li><strong>메타러닝의 한계</strong>: 기존 MAML 등은 메타트레인 과제가 “고정 분포”에서 한꺼번에 주어진다고 가정하고, 메타테스트 시에만 순차성을 고려</li>
<li><strong>온라인 학습의 한계</strong>: 표준 온라인 학습은 과제 구조를 무시하고 ’단일 모델’로 모든 데이터를 학습. 과제 모호성(ambiguity)에 대처 불가</li>
<li><strong>평생학습의 미흡한 이론</strong>: 연속적 비정상(non-stationary) 환경에서 메타학습 기반 접근의 이론적 수렴성이 명확히 제시되지 않음</li>
</ul>
</section>
<section id="how-is-the-gap-filled-2" class="level2">
<h2 class="anchored" data-anchor-id="how-is-the-gap-filled-2">(4) How is the gap filled</h2>
<p><strong>온라인 메타러닝 문제 정의</strong>: 각 라운드 <span class="math display">\[t\]</span>에서 과제 <span class="math display">\[f_t\]</span>가 나타나고, 에이전트가 모델 <span class="math display">\[w_t\]</span>로 손실을 입은 후, 과제별 업데이트 절차 <span class="math display">\[U_t(w_t)\]</span>를 통해 적응:</p>
<p><span class="math display">\[
\text{Regret}_T = \sum_{t=1}^{T} f_t(U_t(w_t)) - \min_w \sum_{t=1}^{T} f_t(U_t(w))
\]</span></p>
<p><strong>FTML 알고리즘</strong>: 오프라인 “Follow-the-Leader”를 메타러닝 관점에서 확장: <span class="math display">\[
w_{t+1} = \arg\min_w \sum_{k=1}^{t} f_k(U_k(w))
\]</span> 이는 ’모든 이전 과제에 대해 하나의 메타학습된 초기 파라미터’를 찾는 형태</p>
<p><strong>이론적 증명</strong>: - <strong>Theorem 1</strong>: <span class="math display">\[f\]</span>와 <span class="math display">\[\nabla f\]</span>가 강볼록이면, 한 단계 gradient update 후 함수 <span class="math display">\[\bar{f}(w) = f(w - \alpha \nabla f(w))\]</span>도 강볼록 유지. 따라서 FTML은 강볼록 목적함수의 FTL과 동일한 <span class="math display">\[O(\log T)\]</span> 회귀 보장 획득</p>
<p><strong>실무 알고리즘</strong>: 신경망 적용 시, 여러 내부 gradient step과 stochastic approximation 사용: <span class="math display">\[
g_t(w) = -\nabla_w \mathbb{E}_{k \sim \pi_t}[L(D^{\text{val}}_k, U_k(w))]
\]</span></p>
</section>
<section id="what-is-achieved-with-the-new-method-2" class="level2">
<h2 class="anchored" data-anchor-id="what-is-achieved-with-the-new-method-2">(5) What is achieved with the new method</h2>
<p><strong>이론적 성과</strong>: - MAML 유사 목적함수가 처음으로 강볼록임을 증명하여, first-order 최적화 방법의 수렴성 보장 - <span class="math display">\[O(\log T)\]</span> 회귀 보장으로 FTML이 ’최적 메타러너’와의 격차를 로그적으로 좁혀감</p>
<p><strong>실험 결과</strong>:</p>
<ol type="1">
<li><p><strong>Rainbow MNIST</strong> (56개 과제, 색상/스케일/회전 변화): FTML이 다른 방법 대비 훨씬 빠르게 새 과제 습득 및 최종 성능 향상</p></li>
<li><p><strong>CIFAR-100</strong> (100개 클래스 순차 분류): FTML이 2000개 데이터포인트에서 독립 학습과 유사한 성능이나 초기 단계(50, 250개)에서 훨씬 효율적</p></li>
<li><p><strong>Object Pose Prediction</strong> (90개 과제): FTML이 불과 10개 데이터포인트로 많은 과제 습득 가능. 과제 간 높은 구조 유사성에서 기존 방법 대비 우수한 전이 학습</p></li>
</ol>
</section>
<section id="what-data-are-used-2" class="level2">
<h2 class="anchored" data-anchor-id="what-data-are-used-2">(6) What data are used</h2>
<ul>
<li><strong>Rainbow MNIST</strong>: MNIST 60,000개 이미지를 56개 과제로 분할. 각 과제 900개 이미지에 색상 배경, 스케일, 회전 적용</li>
<li><strong>CIFAR-100</strong>: 100개 클래스를 순차적 5-way 분류 과제로 구성. 각 라운드 새 클래스 도입</li>
<li><strong>PASCAL 3D 기반 Object Pose 예측</strong>: 50개 객체 모델(9개 클래스)의 합성 이미지 생성. 90개 과제, 과제당 평균 2개 카메라 뷰포인트, 1000개 데이터포인트</li>
</ul>
</section>
<section id="what-are-the-limitations-2" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-limitations-2">(7) What are the limitations</h2>
<ul>
<li><strong>메모리 제약</strong>: 모든 이전 과제 데이터를 메모리에 저장해야 함. 많은 과제에서 확장성 문제</li>
<li><strong>계산 비용</strong>: FTL 기반 설정은 계산 비용이 시간에 따라 증가. Mirror descent 등 더 효율적인 온라인 알고리즘으로의 확장 필요</li>
<li><strong>이론 제약</strong>: 강볼록 가정(Assumption 2) 및 Hessian Lipschitz 가정(Assumption 1.3)은 신경망의 비볼록 손실 함수에서는 정확하지 않으며, 이론은 convex 설정에만 엄밀</li>
<li><strong>다중 내부 단계</strong>: 이론은 single-step gradient update만 분석하나, 실무에서는 다중 내부 step 사용으로 이론과 실제 간극 존재</li>
<li><strong>재해적 망각 회피</strong>: 논문은 모든 데이터 버퍼로 망각(catastrophic forgetting)을 회피하는데, 실제 환경에서는 메모리 제한</li>
</ul>
</section>
</section>
<section id="gradient-based-meta-learning-with-learned-layerwise-metric-and-subspace" class="level1">
<h1>Gradient-Based Meta-Learning With Learned Layerwise Metric And Subspace</h1>
<section id="초록-3" class="level2">
<h2 class="anchored" data-anchor-id="초록-3">초록</h2>
<p>경사도 기반 메타러닝 방법들은 여러 과제에 걸친 공통점을 학습하기 위해 경사하강법을 활용합니다. 이전의 이러한 방법들이 메타러닝 과제에서 성공했지만, 메타 테스트 시에는 단순한 경사하강법을 사용합니다. 본 연구의 주요 기여는 MT-net으로, 메타러닝기가 각 계층의 활성화(activation) 공간에서 과제별 학습기가 경사하강법을 수행할 부분공간(subspace)을 학습할 수 있게 합니다. 추가적으로, MT-net의 과제별 학습기는 메타러닝된 거리 메트릭(distance metric)에 대해 경사하강법을 수행하며, 이 메트릭은 활성화 공간을 과제 정체성에 더 민감하도록 왜곡(warp)합니다. 우리는 이 학습된 부분공간의 차원이 과제별 학습기의 적응 작업의 복잡도를 반영함을 보이고, 또한 우리의 모델이 이전 경사도 기반 메타러닝 방법들보다 초기 학습율 선택에 덜 민감함을 보입니다. 우리의 방법은 few-shot 분류 및 회귀 과제에서 최첨단 또는 동등한 성능을 달성합니다.</p>
</section>
<section id="what-is-new-in-the-work-3" class="level2">
<h2 class="anchored" data-anchor-id="what-is-new-in-the-work-3">(1) What is new in the work</h2>
<p>메타러닝에 <strong>계층별 메트릭 학습(learned layerwise metric)</strong>과 <strong>부분공간 선택(learned subspace)</strong>을 도입한 두 가지 모델을 제안합니다:[1]</p>
<ul>
<li><p><strong>T-net (Transformation Networks)</strong>: MAML을 확장하여 각 계층에서 <strong>변환 행렬 <span class="math display">\[T\]</span></strong>를 메타러닝. 활성화 공간에 메트릭 <span class="math display">\[T^T T\]</span>를 학습하여 경사하강 방향을 왜곡[1]</p></li>
<li><p><strong>MT-net (Mask Transformation Networks)</strong>: T-net을 더 확장하여 <strong>이진 마스크 <span class="math display">\[M\]</span></strong>을 도입. 어떤 파라미터를 과제별 학습 중 업데이트할지 선택. 마스크는 Bernoulli 분포에서 샘플링: <span class="math display">\[m_j \sim \text{Bernoulli}\left(\sigma(\psi_j)\right)\]</span> (Gumbel-Softmax로 미분 가능)[1]</p></li>
<li><p><strong>핵심 다른 점</strong>: MAML은 모든 파라미터를 동일하게 학습하지만, MT-net은 ‘메타러닝된 초기값’과 ’과제별 학습 가능 파라미터’ 두 역할을 자동으로 구분[1]</p></li>
</ul>
</section>
<section id="why-is-the-work-important-3" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-work-important-3">(2) Why is the work important</h2>
<ul>
<li><p><strong>표현력과 안정성의 균형</strong>: MAML이 고정된 모델 아키텍처를 가정하는 반면, MT-net은 <strong>각 과제의 복잡도에 맞게 자동 적응</strong>. 간단한 과제는 적은 파라미터만 업데이트, 복잡한 과제는 더 많은 파라미터 업데이트[1]</p></li>
<li><p><strong>학습율 강건성</strong>: 메트릭 <span class="math display">\[T\]</span>가 경사 업데이트의 “유효 스텝 크기”를 조절하므로, 초기 학습율 선택에 덜 민감. 이는 실무에서 중요한 이점[1]</p></li>
<li><p><strong>해석 가능성</strong>: 학습된 부분공간 차원이 과제 복잡도를 반영하므로, 모델이 ‘무엇을 학습하는지’ 이해 가능[1]</p></li>
</ul>
</section>
<section id="what-is-the-literature-gap-3" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-literature-gap-3">(3) What is the literature gap</h2>
<ul>
<li><p><strong>MAML의 한계</strong>: MAML은 메타러닝 초기값 <span class="math display">\[\theta\]</span>를 고정 모델 아키텍처 내에서만 학습. 메타 공간(meta-level)과 과제별 공간(task-specific level)이 동일한 자유도를 가진다고 암묵적으로 가정[1]</p></li>
<li><p><strong>메트릭 학습의 결한</strong>: 기존 거리 메트릭 학습은 데이터포인트 간 거리만 학습하고, 신경망의 내부 활성화 공간에서의 메트릭은 고려하지 않았음[1]</p></li>
<li><p><strong>적응적 모델 선택 부재</strong>: 다양한 복잡도의 과제를 처리할 때, 각 과제에 ’얼마나 많은 파라미터가 필요한가’를 자동으로 결정하는 메카니즘이 없었음[1]</p></li>
</ul>
</section>
<section id="how-is-the-gap-filled-3" class="level2">
<h2 class="anchored" data-anchor-id="how-is-the-gap-filled-3">(4) How is the gap filled</h2>
<p><strong>T-net의 메트릭 학습</strong>: 각 계층의 업데이트를 분석하면, 활성화 <span class="math display">\[y\]</span>의 변화는:</p>
<p>표준 경사하강: <span class="math display">\[
\Delta y_{\text{std}} = -\nabla A L_T \cdot \Delta x
\]</span></p>
<p>T-net의 경우: <span class="math display">\[
\Delta y_{\text{T-net}} = -T^T A L_T \cdot \Delta x
\]</span></p>
<p>즉, <strong>메트릭 <span class="math display">\[T^T T\]</span>가 활성화 공간을 왜곡</strong>하여 경사 방향이 과제에 더 민감해짐[1]</p>
<p><strong>MT-net의 부분공간 선택</strong>: 마스크를 <span class="math display">\[M\]</span>이라 하면, 업데이트는: <span class="math display">\[
\Delta W = M \odot (-\alpha \nabla_W L_T(W, T, D_T^{\text{train}}))
\]</span> 여기서 <span class="math display">\[\odot\]</span>는 Hadamard(원소별) 곱셈. 마스크의 각 행은 활성화에 영향을 미치는 모든 가중치에 함께 작용[1]</p>
<p><strong>이론 분석</strong>: - <strong>Proposition 1</strong>: 적절한 <span class="math display">\[T, W, \psi\]</span> 조합으로 임의의 <span class="math display">\[d\]</span>차원 부분공간 <span class="math display">\[U \subset \mathbb{R}^n\]</span>에 제약 가능[1] - <strong>Proposition 2</strong>: MT-net은 부분공간 <span class="math display">\[U\]</span> 내에서 임의의 메트릭 텐서 <span class="math display">\[g\]</span>에 대한 경사하강 수행 가능[1]</p>
<p><strong>메타러닝 목적함수</strong>: <span class="math display">\[
\theta \gets \theta - \alpha' \sum_{T \sim p_T} \nabla_\theta L_T(\theta_{A}, T, \Psi, D_T^{\text{test}})
\]</span> 여기서 <span class="math display">\[\theta_{A} = W_A \odot (-\alpha \nabla_{W_A} L_T(\cdots))\]</span>는 마스크된 과제별 업데이트[1]</p>
</section>
<section id="what-is-achieved-with-the-new-method-3" class="level2">
<h2 class="anchored" data-anchor-id="what-is-achieved-with-the-new-method-3">(5) What is achieved with the new method</h2>
<p><strong>회귀 실험</strong> (사인파 함수): - MT-net: 5-shot에서 0.76 손실, 10-shot에서 0.49, 20-shot에서 0.33[1] - MAML 대비: 약 30% 오류 감소[1]</p>
<p><strong>학습율 강건성</strong> (Table 2): - MAML: <span class="math display">\[\alpha = 10\]</span>에서 171.92 손실 → <span class="math display">\[\alpha = 0.01\]</span>에서 0.71 손실 (급격한 변동) - MT-net: <span class="math display">\[\alpha = 10\]</span>에서 4.08 → <span class="math display">\[\alpha = 0.01\]</span>에서 0.49 (완만한 변동. 메트릭 <span class="math display">\[T\]</span>가 효과적 학습율 조절)[1]</p>
<p><strong>부분공간 차원 변화</strong> (다항식 회귀): - 0차 (상수): 약 20% 파라미터 업데이트 - 1차 (선형): 약 40% 파라미터 업데이트<br>
- 2차 (이차): 약 70% 파라미터 업데이트 - → 과제 복잡도가 증가하면서 MT-net이 자동으로 더 많은 ‘자유도’ 선택[1]</p>
<p><strong>분류 성능</strong> (Omniglot &amp; MiniImageNet): - Omniglot 5-way 1-shot: MT-net 99.5% ± 0.3% (MAML 98.7% ± 0.4%) - MiniImageNet 5-way 1-shot: MT-net 51.70% ± 1.84% (MAML 48.70% ± 1.84%) - → 최첨단 또는 동등 성능[1]</p>
</section>
<section id="what-data-are-used-3" class="level2">
<h2 class="anchored" data-anchor-id="what-data-are-used-3">(6) What data are used</h2>
<ul>
<li><p><strong>사인파 회귀</strong>: 각 과제마다 <span class="math display">\[A \sim U[0.1, 5.0]\]</span>, <span class="math display">\[w \sim U[0.8, 1.2]\]</span>, <span class="math display">\[b \sim U[0, 2\pi]\]</span>. K-shot (K=5, 10, 20) 설정[1]</p></li>
<li><p><strong>다항식 회귀</strong>: 0차, 1차, 2차 다항식. 계수 <span class="math display">\[c_i \sim U[-1, 1]\]</span>. 10-shot 회귀 과제[1]</p></li>
<li><p><strong>Omniglot</strong>: 50개 문자, 5-way 1-shot 및 20-way 1-shot 분류. 표준 학습/검증/테스트 분할 사용[1]</p></li>
<li><p><strong>MiniImageNet</strong>: 100개 클래스. 5-way 1-shot 및 5-way 5-shot 분류. Ravi &amp; Larochelle 2017의 분할 기준 따름[1]</p></li>
</ul>
</section>
<section id="what-are-the-limitations-3" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-limitations-3">(7) What are the limitations</h2>
<ul>
<li><p><strong>계산 비용</strong>: Gumbel-Softmax를 통한 마스크 샘플링으로 인해 MAML 대비 약 0.4배 시간 증가 (Omniglot에서 7h 19m vs 5h 14m). 완전 연결 네트워크에서는 1.1배[1]</p></li>
<li><p><strong>수렴 분석의 제약</strong>: 논문의 이론(Propositions 1, 2)은 <strong>강볼록 함수 및 Hessian Lipschitz 가정</strong>을 기반하나, 신경망의 비볼록 손실에서는 정확하지 않음[1]</p></li>
<li><p><strong>단순화된 가정</strong>: T-net/MT-net의 분석은 ‘블록 대각선 곡률 행렬’ 근사에 기반. 계층 간 상호작용은 무시[1]</p></li>
<li><p><strong>마스크 학습의 초기 불안정성</strong>: Bernoulli 샘플링이 초반에 불안정할 수 있으며, Gumbel-Softmax의 온도 파라미터 <span class="math display">\[c\]</span> 선택이 중요[1]</p></li>
<li><p><strong>메모리 저장</strong>: 메타 학습 시 모든 이전 과제의 데이터 버퍼가 필요하며, 대규모 데이터셋에서 확장성 한계 존재[1]</p></li>
<li><p><strong>아키텍처 의존성</strong>: 현재 구현은 완전 연결 및 합성곱 네트워크에 맞춤. 다른 신경망 구조(예: RNN, Transformer)로의 확장은 미흡[1]</p></li>
</ul>
</section>
</section>
<section id="meta-learning-with-latent-embedding-optimization" class="level1">
<h1>Meta-Learning with Latent Embedding Optimization</h1>
<section id="초록-4" class="level2">
<h2 class="anchored" data-anchor-id="초록-4">초록</h2>
<p>경사도 기반 메타러닝 기법은 적용 범위가 넓고 few-shot 학습 및 빠른 적응 문제에 효율적입니다. 그러나 극도로 적은 데이터 영역(extreme low-data regime)에서 고차원 파라미터 공간에 작동할 때 실질적 어려움이 있습니다. 본 논문은 데이터에 의존하는 저차원 잠재 생성 표현(latent generative representation)을 학습하고, 이 저차원 잠재 공간에서 경사도 기반 메타러닝을 수행함으로써 이러한 한계를 우회할 수 있음을 보입니다. 이 결과적 접근법인 잠재 임베딩 최적화(LEO)는 경사도 기반 적응 절차를 고차원 모델 파라미터 공간으로부터 분리합니다. 평가 결과, LEO는 경쟁력 있는 miniImageNet 및 tieredImageNet few-shot 분류 과제에서 최첨단 성능을 달성할 수 있음을 보입니다. 추가 분석은 LEO가 데이터의 불확실성을 포착할 수 있으며 잠재 공간 최적화를 통해 더 효과적으로 적응할 수 있음을 나타냅니다.</p>
</section>
<section id="what-is-new-in-the-work-4" class="level2">
<h2 class="anchored" data-anchor-id="what-is-new-in-the-work-4">(1) What is new in the work</h2>
<p><strong>잠재 임베딩 최적화 (LEO)</strong>라는 새로운 메타러닝 패러다임을 제안합니다:[1]</p>
<ul>
<li><p><strong>세 개의 핵심 네트워크</strong>:</p>
<ul>
<li><strong>Encoder <span class="math display">\[g_e\]</span></strong>: 입력 데이터 <span class="math display">\[\mathbf{x}^k_n\]</span>을 중간 특성 공간 <span class="math display">\[\mathbb{H}\]</span>로 매핑[1]</li>
<li><strong>Relation Network <span class="math display">\[g_r\]</span></strong>: 클래스 내 데이터의 쌍 관계(pairwise relationship)를 학습[1]</li>
<li><strong>Decoder <span class="math display">\[g_d\]</span></strong>: 잠재 코드 <span class="math display">\[\mathbf{z}\]</span>를 모델 파라미터 <span class="math display">\[\boldsymbol{\theta}\]</span>로 변환[1]</li>
</ul></li>
<li><p><strong>이중 공간 최적화</strong>: 메타러닝의 내부 루프를 저차원 잠재 공간에서, 외부 루프를 원본 고차원 공간에서 수행[1]</p></li>
<li><p><strong>확률적 파라미터 생성</strong>: 각 클래스마다 잠재 코드 <span class="math display">\[\mathbf{z}_n \sim \mathcal{N}(\mu^e_n, \text{diag}(\sigma^e_n)^2)\]</span>에서 샘플링[1]</p></li>
</ul>
</section>
<section id="why-is-the-work-important-4" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-work-important-4">(2) Why is the work important</h2>
<ul>
<li><p><strong>고차원 어려움 해결</strong>: MAML은 고차원 파라미터 공간에서 few-shot 데이터로 경사를 계산하면 일반화 어려움이 있으나, LEO는 저차원 병목을 통해 이를 우회[1]</p></li>
<li><p><strong>과과적합(Overfitting) 완화</strong>: 잠재 공간이 정보 병목(information bottleneck)으로 작용하여, 최소한의 정보만 인코딩하도록 강제[1]</p></li>
<li><p><strong>데이터 조건부 초기화</strong>: MAML의 고정된 초기값 대신 각 과제의 데이터로부터 맞춤형 초기 파라미터 생성. 이는 관계 네트워크를 통해 클래스 간 context를 고려[1]</p></li>
<li><p><strong>불확실성 모델링</strong>: 확률적 encoder/decoder가 few-shot 영역의 모호성을 자연스럽게 표현[1]</p></li>
</ul>
<section id="what-is-the-literature-gap-4" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-literature-gap-4">(3) What is the literature gap</h3>
<ul>
<li><p><strong>MAML의 확장성 제약</strong>: MAML은 모든 파라미터를 직접 최적화하므로, 큰 신경망(예: ResNet)에서 few-shot 학습이 불안정[1]</p></li>
<li><p><strong>고정된 초기값 가정</strong>: MAML은 모든 과제에 동일한 초기 파라미터를 사용하나, few-shot 환경에서는 과제별로 다른 시작점이 필요할 수 있음[1]</p></li>
<li><p><strong>매개변수 생성 모형의 부재</strong>: 기존 Hypernetwork(Ha et al., 2016)는 매개변수를 생성하지만, 경사도 기반 적응과 결합하지 않았음. 또한 불확실성을 모델링하지 못함[1]</p></li>
<li><p><strong>신경망 프로세스의 한계</strong>: Neural Processes는 잠재 공간 매핑을 학습하나, 내부 루프 적응을 수행하지 않음[1]</p></li>
</ul>
</section>
<section id="how-is-the-gap-filled-4" class="level3">
<h3 class="anchored" data-anchor-id="how-is-the-gap-filled-4">(4) How is the gap filled</h3>
<p><strong>초기화 단계 (인코딩)</strong>:</p>
<p>각 클래스에 대해 class-conditional Gaussian을 학습:</p>
<p><span class="math display">\[
q(\mathbf{z}_n | \mathcal{D}^{\text{tr}}_n) = \mathcal{N}\left(\mu^e_n, \text{diag}(\sigma^e_n)^2\right)
\]</span></p>
<p>여기서:</p>
<p><span class="math display">\[
\mu^e_n, \sigma^e_n = \frac{1}{NK^2 \cdot K} \sum_{k_n=1}^{K} \sum_{m=1}^{K} g_r(g_e(\mathbf{x}^{k_n}_n), g_e(\mathbf{x}^{k_m}_n))
\]</span></p>
<p>관계 네트워크가 모든 데이터 쌍을 비교하므로, 문맥(context)을 고려한 초기화[1]</p>
<p><strong>디코딩 단계</strong>:</p>
<p>잠재 코드로부터 선형 분류기의 가중치 생성:</p>
<p><span class="math display">\[
\mathbf{w}_n \sim p(\mathbf{w}_n | \mathbf{z}_n) = \mathcal{N}(g_d^{\mu}(\mathbf{z}_n), \text{diag}(g_d^{\sigma}(\mathbf{z}_n))^2)
\]</span></p>
<p><strong>내부 루프 (잠재 공간 적응)</strong>:</p>
<p>훈련 손실에 대해 잠재 코드를 업데이트:</p>
<p><span class="math display">\[
\mathbf{z}'_n \leftarrow \mathbf{z}_n - \alpha \nabla_{\mathbf{z}} \mathcal{L}_{\text{tr}}(\mathcal{T}_i, f_{\boldsymbol{\theta}_i})
\]</span></p>
<p>여기서 <span class="math display">\[\boldsymbol{\theta}_i = g_d(\mathbf{z}'_n)\]</span>. 중요: 잠재 공간에서만 경사 계산하고, 디코더를 통해 고차원 파라미터 공간에 영향[1]</p>
<p><strong>외부 루프 (메타 학습)</strong>:</p>
<p><span class="math display">\[
\min_{\theta_e, \theta_r, \theta_d} \sum_{\mathcal{T}_i \sim p_T} \left[ \mathcal{L}_{\text{val}}(\mathcal{T}_i, f_{\boldsymbol{\theta}_i}) + \beta_1 D_{KL}(q(\mathbf{z}_n | \mathcal{D}^{\text{tr}}_n) \| p(\mathbf{z}_n)) + \beta_2 \|\mathbf{z}'_n - \mathbf{z}_n\|^2_2 + \lambda R(\theta_e, \theta_r, \theta_d) \right]
\]</span></p>
<p>KL 정칙화는 잠재 공간을 <strong>분리 가능</strong>(disentangled)하게 유지[1]</p>
</section>
<section id="what-is-achieved-with-the-new-method-4" class="level3">
<h3 class="anchored" data-anchor-id="what-is-achieved-with-the-new-method-4">(5) What is achieved with the new method</h3>
<p><strong>회귀 실험</strong> (잡음 있는 선/사인 혼합):</p>
<ul>
<li>LEO는 모호한 케이스(선과 사인파 모두 데이터 적합)에서 <strong>두 가지 모드를 모두 샘플링</strong> 가능[1]</li>
<li>PLATIPUS(확률적 MAML) 대비, LEO가 더 명확한 다중 모드 분포 표현[1]</li>
</ul>
<p><strong>분류 성능</strong> (miniImageNet):</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>설정</th>
<th>성능 (이전 SOTA 대비)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1-shot</td>
<td><strong>61.76%</strong> (이전: 59.60%)</td>
</tr>
<tr class="even">
<td>5-shot</td>
<td><strong>77.59%</strong> (이전: 76.70%)</td>
</tr>
</tbody>
</table>
<p><strong>분류 성능</strong> (tieredImageNet, 더 어려운 벤치마크):</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>설정</th>
<th>성능</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1-shot</td>
<td><strong>66.33%</strong></td>
</tr>
<tr class="even">
<td>5-shot</td>
<td><strong>81.44%</strong></td>
</tr>
</tbody>
</table>
<p>이는 MAML 51.67% (1-shot) / 70.30% (5-shot)를 크게 상회[1]</p>
<p><strong>Ablation Study 분석</strong> (miniImageNet 1-shot):</p>
<ul>
<li>Meta-SGD (직접 파라미터 공간): 54.24%</li>
<li>조건부 생성만 (적응 없음): 60.33%</li>
<li>조건부 생성 + 미세조정: 60.62%</li>
<li><strong>LEO (완전 방식)</strong>: 61.76%</li>
</ul>
<p>→ 저차원 병목과 잠재 공간 적응이 둘 다 필수[1]</p>
<p><strong>곡률 분석</strong> (Figure 5):</p>
<ul>
<li>LEO 잠재 공간의 Hessian 고유값: <strong>2자리 수 더 큼</strong> (Meta-SGD 대비)</li>
<li>디코더의 특이값 확대: 선형 디코더가 잠재 공간 벡터를 <strong>최소 10배 이상 확대</strong></li>
<li>결과: 작은 잠재 공간 단계가 거대한 파라미터 공간 변화 유발[1]</li>
</ul>
</section>
<section id="what-data-are-used-4" class="level3">
<h3 class="anchored" data-anchor-id="what-data-are-used-4">(6) What data are used</h3>
<p><strong>회귀 데이터</strong>: - 선형 함수: 기울기 <span class="math display">\[\sim U[-3, 3]\]</span>, 절편 <span class="math display">\[\sim U[-3, 3]\]</span>[1] - 사인파 함수: 진폭 <span class="math display">\[\sim U[0.1, 5]\]</span>, 위상 <span class="math display">\[\sim U[0, 2\pi]\]</span>[1] - 입력: <span class="math display">\[\mathbf{x} \sim U[-5, 5]\]</span>, 5-shot, 표준편차 0.3의 가우스 노이즈 추가[1]</p>
<p><strong>miniImageNet</strong>: - ILSVRC-12의 100개 클래스 부분집합 - 클래스당 600장 이미지 (80×80 픽셀) - 분할: 64개 클래스(메타 학습) / 16개(메타 검증) / 20개(메타 테스트) - 5-way 1-shot 및 5-shot 분류[1]</p>
<p><strong>tieredImageNet</strong>: - ILSVRC-12의 608개 클래스 - 779,165개 이미지, ImageNet 계층 기반 분할 - 메타 테스트 클래스가 메타 학습과 <strong>덜 유사</strong> (더 도전적) - 분할: 20개 노드(학습) / 6개(검증) / 8개(테스트)[1]</p>
<p><strong>특성 사전 학습</strong>: - Wide ResidualNetwork (WRN-28-10)을 메타 학습 전에 64-way(miniImageNet) 또는 351-way(tieredImageNet) 분류로 사전 학습 - 21번째 계층의 활성화(640차원)를 특성으로 사용[1]</p>
</section>
<section id="what-are-the-limitations-4" class="level3">
<h3 class="anchored" data-anchor-id="what-are-the-limitations-4">(7) What are the limitations</h3>
<p><strong>계산 복잡성</strong>: - 관계 네트워크는 모든 데이터 쌍(<span class="math display">\[NK^2\]</span>)을 비교하므로, K(shot 수)에 따라 계산 비용 증가[1] - 메타 학습: miniImageNet 1-2시간, tieredImageNet 5시간 (CPU)[1] - 특성 사전 학습: 32개 GPU로 5시간~1일[1]</p>
<p><strong>선형 분류기 제약</strong>: - 현재 구현은 사전 학습된 특성 위의 <strong>선형 소프트맥스 분류기</strong>만 생성[1] - 전체 신경망 생성으로 확장 시, 디코더가 훨씬 고차원 공간을 모델링해야 하므로 병목 효과 감소[1]</p>
<p><strong>이론적 간극</strong>: - KL 정칙화 가중치(<span class="math display">\[\beta_1, \beta_2\]</span>) 및 학습율을 일일이 튜닝해야 함. 하이퍼파라미터 민감도 상당[1] - 확률적 샘플링으로 인한 초기 훈련 불안정성. 메타 그래디언트 클리핑(absolute value 0.1) 필요[1]</p>
<p><strong>특성 사전 학습 의존</strong>: - 전체 엔드투엔드(end-to-end) 학습이 아니라 <strong>두 단계 프로세스</strong>(특성 학습 → LEO 학습)이므로, 최적 특성 표현을 보장하지 못함[1] - 논문: “미래 방향: 사전 학습된 특성 추출기를 메타러닝과 함께 학습할 수 있도록 확장”[1]</p>
<p><strong>일반화 한계</strong>: - tieredImageNet에서는 확률적 샘플링의 이점이 <strong>miniImageNet보다 적음</strong>. 논문은 더 큰 데이터셋에서 stochasticity 필요성 감소를 언급[1] - 강화학습이나 순차 데이터(RNN)로의 확장은 미래 과제로 명시[1]</p>
<p><strong>메모리 및 확장성</strong>: - 관계 네트워크 연산이 <span class="math display">\[O(K^2)\]</span>이므로, 매우 큰 K에서 실질적 병목 가능[1]</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>