[
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "여기는 모든 포스트 목록입니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypernetworks\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 16, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMeta Learning in Neural Networks — A Survey\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts But VAE - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+MetaLearning\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nSuccessive model-agnostic meta-learning for few-shot fault time series prognosis\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 15, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+MetaLearning\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n이상치 탐지 with Uncertainty?\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "국문 제목\nTask 간 유사도를 반영한 계층 베이지안 메타러닝 prior의 일반적 구성과 통계적 성질\n영문 제목\nA General Prior Design Incorporating Task Similarity in Hierarchical Bayesian Meta-Learning and Its Statistical Properties\n\n\n\n\n딥러닝 기반 모델은 대규모 데이터와 연산 자원을 요구하며, 새로운 task가 등장할 때마다 학습을 처음부터 반복해야 한다는 한계를 가진다. 이를 극복하기 위해 등장한 meta-learning(learning to learn) 은 여러 task로부터 축적된 경험을 이용하여, 새로운 task에 대한 빠른 적응과 데이터 효율적 학습을 목표로 한다.\n최근 meta-learning 연구는 few-shot 이미지 분류, 강화학습, 베이지안 신경망 등 다양한 응용에서 활발히 진행되고 있으며, 특히 여러 task 간의 공통 구조를 활용하는 계층 베이지안(hierarchical Bayes) 및 Gaussian process(GP) 기반 meta-learning 이 주목받고 있다.\n그러나 기존 Bayesian/meta-learning 연구들은 다음과 같은 한계를 가진다.\n\nTask 유사도 구조의 모형화 부족\n\n많은 meta-learning 알고리즘은 암묵적으로 “task들이 유사하다”는 가정을 갖고 있으나,\n유사도를 명시적인 prior 공분산 구조로 표현하고 그 통계적 효과를 분석한 연구는 제한적이다.\n\n선형–가우시안 계층 모형에서의 이론적 분석 부족\n\nGP 기반 meta-learning은 task 간 커널을 제안하고 실험적으로 성능 향상을 보이지만,\n단순한 선형 회귀/가우시안 노이즈 환경에서\ntask similarity를 반영한 prior와 독립 prior의 Bayes risk를 비교·정량화하는 통계적 연구는 상대적으로 부족하다.\n\nMeta-learning 이론(예: PAC-Bayes bound)과 구체적 prior 구조의 연결 부족\n\nPAC-Bayesian meta-learning은 hyper-posterior의 최적 구조(PACOH)를 제시하지만,\n구체적인 task similarity 기반 prior가 이러한 이론적 틀 안에서 어떤 효과를 가지는지에 대한 정량적 논의는 제한적이다.\n\n\n본 연구는 이러한 한계를 해결하고자, task 간 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구조를 제안하고,\n선형–가우시안 계층 모형에서의 Bayes risk 및 학습 곡선(learning curve) 관점에서 그 통계적 성질을 분석하는 것을 목표로 한다.\n\n\n\n\n\n\nMeta-learning은 여러 task로부터 “학습 알고리즘 자체” 또는 “초기 파라미터/표현”을 학습하여, 새로운 task에 빠르게 적응하는 것을 목표로 한다. Hospedales et al.은 meta-learning을 정리하면서, meta-train / meta-test 분할, N-way K-shot 설정, task 분포 \\(\\mathcal{T}\\) 등의 표준 수학적 세팅을 제시하고, 다양한 방법론을 포괄하는 taxonomy를 제안하였다.\n일반적으로 meta-learning은 다음과 같이 정식화된다.\n\nTask 분포 \\(\\mathcal{T}\\) 에서 task \\(t\\)를 샘플: \\[\nt \\sim \\mathcal{T}, \\quad D_t = \\{(x_{ti}, y_{ti})\\}_{i=1}^{n_t}\n\\]\nMeta-train 단계에서 여러 \\(t=1,\\dots,T\\) 에 대해 데이터를 관측하고,\n새로운 task \\(t^\\*\\) 에 대한 적은 양의 데이터로 빠르게 적응하는 meta-learner를 학습한다.\n\nHospedales et al.의 taxonomy에 따르면, meta-learning 방법은 크게\n(1) optimization-based, (2) metric-based, (3) model-based, (4) Bayesian/probabilistic 기반 방법으로 나눌 수 있다.\n본 연구는 이 중 Bayesian/probabilistic meta-learning 축에 속한다.\n\n\n\n\nOptimization-based meta-learning의 대표적 예로 MAML(Model-Agnostic Meta-Learning) 계열이 있다. 이들은 모델 파라미터의 초기값 \\(\\phi\\) 를 meta-level에서 학습하고, 각 task별로 서버럴 스텝의 gradient descent를 통해 적응한다. 이러한 방법들은 다양한 신경망 구조에 적용이 가능하고, 구현이 상대적으로 간단하다는 장점이 있어 few-shot 학습에서 널리 사용된다.\nGrant et al.는 “Recasting Gradient-Based Meta-Learning as Hierarchical Bayes” 에서 MAML과 같은 gradient-based meta-learning이, 적당한 근사 하에서 계층 베이지안 추론의 한 형태로 해석될 수 있음을 보였다.\n즉, meta-parameter는 상위 계층의 hyperparameter, inner-loop 업데이트는 task-specific posterior mode 추정에 해당한다.\n또한, Zou & Lu는 Gradient-EM Bayesian Meta-Learning 을 통해 계층 베이지안 모형에서 empirical Bayes 추정을 수행하는 gradient-EM 기반 meta-learning 알고리즘을 제안하고, 기존 gradient-based meta-learning 알고리즘을 하나의 Bayesian 틀 안에서 통합하여 해석하였다.\n이러한 연구들은 gradient-based meta-learning과 계층 베이지안 추론 간의 연결을 보여주지만,\ntask 유사도 구조를 공분산으로 명시적으로 모델링하고 그 통계적 성질을 분석하는 데에는 초점을 두지 않는다.\n\n\n\n\nBayesian meta-learning은 여러 task의 데이터를 이용하여 prior 또는 hyperparameter를 empirical Bayes/fully Bayes 방식으로 추정하고, 새로운 task에 대해 불확실성 추정을 포함한 적응을 수행한다.\n일반적인 계층 베이지안 meta-learning 모형은 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\eta &\\sim p(\\eta), \\\\\n\\theta_t \\mid \\eta &\\sim p(\\theta_t \\mid \\eta), \\quad t = 1,\\dots,T, \\\\\nD_t \\mid \\theta_t &\\sim p(D_t \\mid \\theta_t),\n\\end{aligned}\n\\]\n여기서 \\(\\eta\\) 는 상위 계층의 hyperparameter, \\(\\theta_t\\) 는 task-specific 파라미터이다.\nGradient-EM Bayesian meta-learning과 관련 연구들은 이러한 구조에서\n\\(\\eta\\) 를 empirical Bayes 방식으로 추정하는 다양한 알고리즘과 이론적 성질을 제시하였다.\n그러나 Bayesian meta-learning 문헌의 상당수는 hyperparameter 추정 알고리즘과 실험적 성능에 집중하며,\ntask 간 유사도 구조가 prior 공분산에 어떻게 반영되며, 이로 인해 Bayes risk와 pooling 정도가 어떻게 변하는지에 대한 체계적 분석은 상대적으로 부족하다.\n\n\n\n\n\n\nGaussian process(GP)는 함수 공간의 베이지안 prior로서, 불확실성을 자연스럽게 표현할 수 있다는 장점이 있다. Nguyen et al.은 “Learning to Learn with Gaussian Processes”에서 few-shot 회귀 문제를 위해 Gaussian Process Meta-Learning(GPML) 을 제안하였으며, task 간 거리를 이용한 novel task kernel 을 도입하여 meta-learning 환경에서 task 간 유사도를 활용하였다.\n이와 유사한 GP 기반 meta-learning 연구들은, multi-task GP, deep kernel GP, variational GP 등의 구조를 활용하여 task 간 공유 정보를 모델링하고 few-shot 상황에서 성능 향상을 보였다.\n또한 Ashton & Sollich은 “Learning curves for multi-task Gaussian process regression”에서\nmulti-task GP 회귀의 평균 Bayes error(learning curve) 를 분석하여, task 간 공분산 구조가 학습 곡선에 미치는 영향을 정량적으로 연구하였다.\n이는 본 연구에서 계획하는 task similarity 기반 prior의 Bayes risk 분석과 직접적인 수학적 연관이 있다.\n\n\n\nRothfuss et al.은 “Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior (PACOH)”에서\nmeta-learning의 generalization error에 대한 PAC-Bayesian upper bound를 유도하고, 이를 최소화하는 PAC-optimal hyper-posterior (PACOH) 를 도출하였다.\nPACOH는 GP, Bayesian neural network 등 다양한 base learner에 적용 가능하며, meta-level regularization을 이론적으로 정당화한다.\nPAC-Bayesian meta-learning 이론은 meta-level에서의 최적 prior/hyper-posterior 구조에 대한 중요한 통찰을 제공하지만,\n구체적인 task similarity 기반 공분산 구조가 이러한 bound에 어떤 영향을 주는지에 대한 분석은 제한적이다.\n\n\n\n\n\nMulti-task learning 및 GP 기반 모델에서는 오래전부터 task 간 유사도를 공분산 구조로 표현해 왔다.\n예를 들어, multi-task GP에서는 입력 커널 \\(K_x\\)와 task 간 공분산 \\(\\Sigma_{\\text{task}}\\)의 곱으로 전체 공분산을 구성한다.\n\\[\nK((x,s), (x',t)) = K_x(x, x') \\cdot \\Sigma_{\\text{task}}(s,t).\n\\]\n여기서 \\(\\Sigma_{\\text{task}}\\)는 task 간 유사도/상관을 반영하는 행렬이다.\nNguyen et al.의 GPML은 task 간 거리를 활용한 task kernel 을 제안하여, meta-learning 환경에서 task similarity를 명시적으로 모델링한다.\n또한 다양한 multi-task GP, hierarchical GP 연구에서는 task feature, 그래프 구조, 군집 등을 이용한 공분산 설계를 시도하고 있다.\n하지만 이들 연구는 주로 복잡한 GP 구조 및 대규모 실험에 기반한 모델 제안에 집중하며,\n단순한 선형–가우시안 계층 모형에서\n\n\ntask similarity를 반영한 prior 공분산 구조가 어떤 조건 하에서 유효한지,\n\n\n\n독립 prior 대비 Bayes risk 및 learning curve가 어떻게 달라지는지\n\n\n를 이론적으로 분석하는 통계적 연구는 상대적으로 부족하다.\n따라서 본 연구는, 선형–가우시안 계층 베이지안 meta-learning 모형을 기반으로\ntask similarity 기반 prior 구조를 일반적으로 정의하고, Bayes risk 및 pooling 구조를 수학적으로 분석함으로써,\n기존 문헌의 공백을 메우고자 한다.\n\n\n\n\n\n\n\n\nTask 간 유사도를 반영하는 일반적인 계층 베이지안 meta-learning prior 구조 제안\n\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 Bayes risk 및 학습 곡선 비교 분석\n\n제안 prior 구조의 이론적 성질(유효성, risk 개선 조건 등)을 정리하고, 시뮬레이션 및 실증으로 검증\n\n\n\n\n\nRQ1. Task feature 또는 task 간 거리/그래프 정보를 이용하여,\n계층 베이지안 meta-learning에서 일반적으로 사용할 수 있는 task similarity 기반 prior 공분산 구조를 어떻게 정의할 수 있는가?\nRQ2. 선형 회귀 + 가우시안 노이즈 환경에서,\nsimilarity-aware prior와 독립 prior에 기반한 meta-learning의 Bayes risk는 어떻게 비교되는가?\n특히 어떤 조건(유사도 구조가 실제 task 관계를 잘 반영할 때 등) 하에서 risk 개선이 발생하는가?\nRQ3. Multi-task GP 회귀의 학습 곡선 분석 결과를 활용하여,\nsimilarity-aware prior의 평균 Bayes error(learning curve) 에 대한 해석적 표현 또는 근사/상하한을 제시할 수 있는가?\nRQ4. 제안 prior 구조와 분석 결과는\n실제 meta-learning 환경(예: few-shot 회귀/분류 데이터셋)에서 성능 향상 및 불확실성 측정 개선으로 이어지는가?\n\n\n\n\n\n\n\n\n본 연구는 다음과 같은 선형–가우시안 계층 베이지안 meta-learning 모형을 기본으로 한다.\n\nTask \\(t\\)의 회귀 모형: \\[\ny_{ti} = x_{ti}^\\top \\beta_t + \\epsilon_{ti}, \\quad\n\\epsilon_{ti} \\sim \\mathcal{N}(0, \\sigma^2),\n\\] 여기서 \\(x_{ti} \\in \\mathbb{R}^d\\), \\(\\beta_t \\in \\mathbb{R}^d\\).\n각 task의 파라미터 벡터를 쌓아 \\[\n\\beta = (\\beta_1^\\top, \\dots, \\beta_T^\\top)^\\top.\n\\]\n\n\n\n\n\n\n기존 계층 모형에서 자주 사용하는 baseline prior는 다음과 같다.\n\\[\n\\beta_t \\sim \\mathcal{N}(0, \\tau^2 I_d), \\quad t = 1,\\dots,T,\n\\]\n또는 전체 벡터에 대해\n\\[\n\\beta \\sim \\mathcal{N}(0, I_T \\otimes \\tau^2 I_d).\n\\]\n이는 task 간 독립성을 가정하며, task 간 유사도 구조를 반영하지 않는다.\n\n\n\n본 연구에서는 task feature \\(\\phi(t) \\in \\mathbb{R}^q\\) 또는 task 간 거리/그래프 정보를 이용하여\n다음과 같은 task covariance 행렬을 정의한다.\n\n커널 기반 구조: \\[\n\\Sigma_{\\text{task}}(s,t) = k(\\phi(s), \\phi(t)),\n\\] 여기서 \\(k\\)는 positive definite kernel (예: RBF, Matérn 등)이다.\n그래프 라플라시안 기반 구조: \\[\n\\Sigma_{\\text{task}} = (L + \\lambda I)^{-1},\n\\] 여기서 \\(L\\)은 task 그래프의 라플라시안, \\(\\lambda&gt;0\\)는 regularization 파라미터이다.\n\n이를 이용하여 전체 prior 공분산을\n\\[\n\\operatorname{cov}(\\beta) = \\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\n\\]\n로 정의하는 similarity-aware prior를 제안한다.\n이때 \\(k\\)의 positive definiteness, \\(L\\)의 성질 등을 이용하여\n\\(\\Sigma_{\\text{task}}\\) 및 \\(\\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\\) 가 양정치 행렬이 됨을 보이고,\n이에 따라 prior가 well-defined multivariate Gaussian이 됨을 정리 형태로 제시한다.\n\n\n\n\n\n\n선형–가우시안 모형에서 similarity-aware prior를 사용하면,\nposterior 및 posterior predictive distribution은 닫힌형으로 표현 가능하다.\n\nPosterior: \\[\np(\\beta \\mid D_{1:T}) = \\mathcal{N}(\\mu_{\\beta\\mid D}, \\Sigma_{\\beta\\mid D}),\n\\] 여기서 \\(\\mu_{\\beta\\mid D}\\), \\(\\Sigma_{\\beta\\mid D}\\)는 prior 공분산과 데이터 행렬 \\(X_{1:T}\\), 노이즈 분산 \\(\\sigma^2\\)에 의해 결정된다.\n새로운 task \\(t^\\*\\) 에 대한 예측 분포: \\[\np(y^\\* \\mid x^\\*, D_{1:T}, D_{t^\\*}) = \\mathcal{N}(m(x^\\*), v(x^\\*)),\n\\]\n\n이를 독립 prior와 similarity-aware prior 두 경우에 대해 명시적으로 도출한다.\n\n\n\n새로운 task에서의 예측 MSE를 Bayes risk로 정의한다.\n\\[\nR = \\mathbb{E}\\left[(y^\\* - \\hat{y}^\\*)^2\\right],\n\\]\n여기서 기대는 데이터 및 prior/likelihood에 대한 joint 분포에 대해 취한다.\n\n독립 prior: \\(R_{\\text{ind}}\\)\nsimilarity-aware prior: \\(R_{\\text{sim}}\\)\n\n를 각각 계산하거나 상·하한을 도출하고,\n특히 task covariance 행렬 \\(\\Sigma_{\\text{task}}\\)와 참 covariance \\(\\Sigma_{\\text{true}}\\)의 정렬 정도(예: eigen 구조, 코사인 유사도 등)에 따라\n\\[\nR_{\\text{sim}} \\le R_{\\text{ind}}\n\\]\n가 성립하는 조건을 정리 형태(정리/레마)로 제시한다.\n이 과정에서 multi-task GP learning curve 분석에서 사용된 테크닉 을 참고하여,\n평균 Bayes error를 task 수 \\(T\\), 각 task의 샘플 수 \\(n_t\\)의 함수로 표현하는 근사식을 도출하는 것을 목표로 한다.\n\n\n\nAshton & Sollich의 multi-task GP learning curve 결과를 차용하여,\n본 연구에서 정의한 선형–가우시안 모형이 multi-task GP의 특수한 경우에 해당함을 보이고,\nsimilarity-aware prior의 학습 곡선을\n\\[\n\\epsilon(n) = \\mathbb{E}\\left[ (f_{t^\\*}(x) - \\hat{f}_{t^\\*}(x))^2 \\right]\n\\]\n형태로 표현하거나 근사함으로써,\n\ntask similarity 구조가 클수록,\n\n다른 task의 데이터가 많을수록,\n\n새로운 task의 Bayes error가 더 빠르게 감소한다는 결과를 이론적으로 설명한다.\n\n\n\n\n\n시뮬레이션 환경 구성\n\nTask feature 및 참 task covariance \\(\\Sigma_{\\text{true}}\\) 를 설계하여,\n\n\nsimilarity-aware prior가 참 구조와 잘 맞는 경우,\n\n\n구조가 mismatch된 경우,\n\n\n실제로 task들이 독립인 경우, 를 비교.\n\n\n각 설정에서 \\(T\\), \\(n_t\\)를 변화시키며 독립 prior vs similarity-aware prior의\nBayes risk 및 학습 곡선을 비교.\n\n실제 데이터 기반 meta-learning 실험\n\n공개된 few-shot 회귀/분류 데이터셋(예: UCI 회귀 데이터셋을 여러 task로 나눈 환경 등)에 대해,\ntask feature(예: 입력 분포 통계량, domain index 등)를 구성하고\n제안 prior 구조를 적용.\n예측 정확도, 불확실성 calibration, 샘플 효율성 등의 지표 비교를 통해\n이론 결과와의 일관성을 확인.\n\n\n\n\n\n\n\n\n이론적 기여\n\nTask 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구성 틀을 제시하고,\n그 유효성(positive definiteness)과 Bayes risk 측면의 이점을 정리 형태로 제시한다.\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 risk/learning curve 비교 분석을 통해,\n기존 GP/meta-learning 문헌의 공백을 메운다.\n\n범용성 있는 방법론 제안\n\n제안 prior 구조는 task feature, 그래프, 클러스터 등 다양한 유사도 정보를 커널/공분산 형태로 통합할 수 있어,\n회귀, 분류, GP, BNN 등 다양한 meta-learning 환경에 적용 가능하다.\n\nMeta-learning 이론과 실용 알고리즘 간의 연결 강화\n\nMulti-task GP와 PAC-Bayesian meta-learning의 이론적 결과를\n구체적인 prior 설계 문제와 연결함으로써,\nmeta-learning 알고리즘 설계에 대한 통계적·이론적 가이드를 제공한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n기간\n내용\n\n\n\n\n1학기 전반 (3–4월)\nMeta-learning 및 Bayesian/meta-learning, GP, multi-task GP 문헌 조사\n\n\n1학기 후반 (5–7월)\n모형 설정 구체화, prior 구조 정의, 기본 정리(유효성) 도출\n\n\n여름 방학 (7–8월)\nBayes risk/learning curve 이론적 분석, 초벌 증명 정리\n\n\n2학기 전반 (9–10월)\n시뮬레이션 코드 구현, synthetic 실험 및 결과 분석\n\n\n2학기 후반 (11–1월)\n실증 데이터 실험, 결과 해석 및 이론과의 연결\n\n\n3학기 전반 (3–4월)\n논문 초고(1–4장) 작성, 정리/보완\n\n\n3학기 후반 (5–7월)\n논문 최종 수정, 심사 준비 및 발표\n\n\n\n(실제 일정은 지도교수와의 논의를 거쳐 조정 예정)\n\n\n\n\n\nHospedales, T., Antoniou, A., Micaelli, P., & Storkey, A. (2021). Meta-Learning in Neural Networks: A Survey.\n\nGrant, E., Finn, C., Levine, S., Darrell, T., & Griffiths, T. (2018). Recasting Gradient-Based Meta-Learning as Hierarchical Bayes. ICLR.\n\nZou, Y., & Lu, X. (2020). Gradient-EM Bayesian Meta-Learning. NeurIPS.\n\nNguyen, Q. P., Low, B. K. H., & Jaillet, P. (2021). Learning to Learn with Gaussian Processes. UAI.\n\nAshton, S. R. F., & Sollich, P. (2012). Learning Curves for Multi-task Gaussian Process Regression. NeurIPS.\n\nRothfuss, J., Josifoski, M., Fortuin, V., & Krause, A. (2021). Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior.\n\nChai, K. M. A. (2010). Multi-task Learning with Gaussian Processes.\n\n(최종 참고 문헌 목록은 실제 논문 작성 시 추가·수정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-주제",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-주제",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "국문 제목\nTask 간 유사도를 반영한 계층 베이지안 메타러닝 prior의 일반적 구성과 통계적 성질\n영문 제목\nA General Prior Design Incorporating Task Similarity in Hierarchical Bayesian Meta-Learning and Its Statistical Properties"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-배경-및-필요성",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-배경-및-필요성",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "딥러닝 기반 모델은 대규모 데이터와 연산 자원을 요구하며, 새로운 task가 등장할 때마다 학습을 처음부터 반복해야 한다는 한계를 가진다. 이를 극복하기 위해 등장한 meta-learning(learning to learn) 은 여러 task로부터 축적된 경험을 이용하여, 새로운 task에 대한 빠른 적응과 데이터 효율적 학습을 목표로 한다.\n최근 meta-learning 연구는 few-shot 이미지 분류, 강화학습, 베이지안 신경망 등 다양한 응용에서 활발히 진행되고 있으며, 특히 여러 task 간의 공통 구조를 활용하는 계층 베이지안(hierarchical Bayes) 및 Gaussian process(GP) 기반 meta-learning 이 주목받고 있다.\n그러나 기존 Bayesian/meta-learning 연구들은 다음과 같은 한계를 가진다.\n\nTask 유사도 구조의 모형화 부족\n\n많은 meta-learning 알고리즘은 암묵적으로 “task들이 유사하다”는 가정을 갖고 있으나,\n유사도를 명시적인 prior 공분산 구조로 표현하고 그 통계적 효과를 분석한 연구는 제한적이다.\n\n선형–가우시안 계층 모형에서의 이론적 분석 부족\n\nGP 기반 meta-learning은 task 간 커널을 제안하고 실험적으로 성능 향상을 보이지만,\n단순한 선형 회귀/가우시안 노이즈 환경에서\ntask similarity를 반영한 prior와 독립 prior의 Bayes risk를 비교·정량화하는 통계적 연구는 상대적으로 부족하다.\n\nMeta-learning 이론(예: PAC-Bayes bound)과 구체적 prior 구조의 연결 부족\n\nPAC-Bayesian meta-learning은 hyper-posterior의 최적 구조(PACOH)를 제시하지만,\n구체적인 task similarity 기반 prior가 이러한 이론적 틀 안에서 어떤 효과를 가지는지에 대한 정량적 논의는 제한적이다.\n\n\n본 연구는 이러한 한계를 해결하고자, task 간 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구조를 제안하고,\n선형–가우시안 계층 모형에서의 Bayes risk 및 학습 곡선(learning curve) 관점에서 그 통계적 성질을 분석하는 것을 목표로 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#선행-연구-및-이론적-배경",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#선행-연구-및-이론적-배경",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Meta-learning은 여러 task로부터 “학습 알고리즘 자체” 또는 “초기 파라미터/표현”을 학습하여, 새로운 task에 빠르게 적응하는 것을 목표로 한다. Hospedales et al.은 meta-learning을 정리하면서, meta-train / meta-test 분할, N-way K-shot 설정, task 분포 \\(\\mathcal{T}\\) 등의 표준 수학적 세팅을 제시하고, 다양한 방법론을 포괄하는 taxonomy를 제안하였다.\n일반적으로 meta-learning은 다음과 같이 정식화된다.\n\nTask 분포 \\(\\mathcal{T}\\) 에서 task \\(t\\)를 샘플: \\[\nt \\sim \\mathcal{T}, \\quad D_t = \\{(x_{ti}, y_{ti})\\}_{i=1}^{n_t}\n\\]\nMeta-train 단계에서 여러 \\(t=1,\\dots,T\\) 에 대해 데이터를 관측하고,\n새로운 task \\(t^\\*\\) 에 대한 적은 양의 데이터로 빠르게 적응하는 meta-learner를 학습한다.\n\nHospedales et al.의 taxonomy에 따르면, meta-learning 방법은 크게\n(1) optimization-based, (2) metric-based, (3) model-based, (4) Bayesian/probabilistic 기반 방법으로 나눌 수 있다.\n본 연구는 이 중 Bayesian/probabilistic meta-learning 축에 속한다.\n\n\n\n\nOptimization-based meta-learning의 대표적 예로 MAML(Model-Agnostic Meta-Learning) 계열이 있다. 이들은 모델 파라미터의 초기값 \\(\\phi\\) 를 meta-level에서 학습하고, 각 task별로 서버럴 스텝의 gradient descent를 통해 적응한다. 이러한 방법들은 다양한 신경망 구조에 적용이 가능하고, 구현이 상대적으로 간단하다는 장점이 있어 few-shot 학습에서 널리 사용된다.\nGrant et al.는 “Recasting Gradient-Based Meta-Learning as Hierarchical Bayes” 에서 MAML과 같은 gradient-based meta-learning이, 적당한 근사 하에서 계층 베이지안 추론의 한 형태로 해석될 수 있음을 보였다.\n즉, meta-parameter는 상위 계층의 hyperparameter, inner-loop 업데이트는 task-specific posterior mode 추정에 해당한다.\n또한, Zou & Lu는 Gradient-EM Bayesian Meta-Learning 을 통해 계층 베이지안 모형에서 empirical Bayes 추정을 수행하는 gradient-EM 기반 meta-learning 알고리즘을 제안하고, 기존 gradient-based meta-learning 알고리즘을 하나의 Bayesian 틀 안에서 통합하여 해석하였다.\n이러한 연구들은 gradient-based meta-learning과 계층 베이지안 추론 간의 연결을 보여주지만,\ntask 유사도 구조를 공분산으로 명시적으로 모델링하고 그 통계적 성질을 분석하는 데에는 초점을 두지 않는다.\n\n\n\n\nBayesian meta-learning은 여러 task의 데이터를 이용하여 prior 또는 hyperparameter를 empirical Bayes/fully Bayes 방식으로 추정하고, 새로운 task에 대해 불확실성 추정을 포함한 적응을 수행한다.\n일반적인 계층 베이지안 meta-learning 모형은 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\eta &\\sim p(\\eta), \\\\\n\\theta_t \\mid \\eta &\\sim p(\\theta_t \\mid \\eta), \\quad t = 1,\\dots,T, \\\\\nD_t \\mid \\theta_t &\\sim p(D_t \\mid \\theta_t),\n\\end{aligned}\n\\]\n여기서 \\(\\eta\\) 는 상위 계층의 hyperparameter, \\(\\theta_t\\) 는 task-specific 파라미터이다.\nGradient-EM Bayesian meta-learning과 관련 연구들은 이러한 구조에서\n\\(\\eta\\) 를 empirical Bayes 방식으로 추정하는 다양한 알고리즘과 이론적 성질을 제시하였다.\n그러나 Bayesian meta-learning 문헌의 상당수는 hyperparameter 추정 알고리즘과 실험적 성능에 집중하며,\ntask 간 유사도 구조가 prior 공분산에 어떻게 반영되며, 이로 인해 Bayes risk와 pooling 정도가 어떻게 변하는지에 대한 체계적 분석은 상대적으로 부족하다.\n\n\n\n\n\n\nGaussian process(GP)는 함수 공간의 베이지안 prior로서, 불확실성을 자연스럽게 표현할 수 있다는 장점이 있다. Nguyen et al.은 “Learning to Learn with Gaussian Processes”에서 few-shot 회귀 문제를 위해 Gaussian Process Meta-Learning(GPML) 을 제안하였으며, task 간 거리를 이용한 novel task kernel 을 도입하여 meta-learning 환경에서 task 간 유사도를 활용하였다.\n이와 유사한 GP 기반 meta-learning 연구들은, multi-task GP, deep kernel GP, variational GP 등의 구조를 활용하여 task 간 공유 정보를 모델링하고 few-shot 상황에서 성능 향상을 보였다.\n또한 Ashton & Sollich은 “Learning curves for multi-task Gaussian process regression”에서\nmulti-task GP 회귀의 평균 Bayes error(learning curve) 를 분석하여, task 간 공분산 구조가 학습 곡선에 미치는 영향을 정량적으로 연구하였다.\n이는 본 연구에서 계획하는 task similarity 기반 prior의 Bayes risk 분석과 직접적인 수학적 연관이 있다.\n\n\n\nRothfuss et al.은 “Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior (PACOH)”에서\nmeta-learning의 generalization error에 대한 PAC-Bayesian upper bound를 유도하고, 이를 최소화하는 PAC-optimal hyper-posterior (PACOH) 를 도출하였다.\nPACOH는 GP, Bayesian neural network 등 다양한 base learner에 적용 가능하며, meta-level regularization을 이론적으로 정당화한다.\nPAC-Bayesian meta-learning 이론은 meta-level에서의 최적 prior/hyper-posterior 구조에 대한 중요한 통찰을 제공하지만,\n구체적인 task similarity 기반 공분산 구조가 이러한 bound에 어떤 영향을 주는지에 대한 분석은 제한적이다.\n\n\n\n\n\nMulti-task learning 및 GP 기반 모델에서는 오래전부터 task 간 유사도를 공분산 구조로 표현해 왔다.\n예를 들어, multi-task GP에서는 입력 커널 \\(K_x\\)와 task 간 공분산 \\(\\Sigma_{\\text{task}}\\)의 곱으로 전체 공분산을 구성한다.\n\\[\nK((x,s), (x',t)) = K_x(x, x') \\cdot \\Sigma_{\\text{task}}(s,t).\n\\]\n여기서 \\(\\Sigma_{\\text{task}}\\)는 task 간 유사도/상관을 반영하는 행렬이다.\nNguyen et al.의 GPML은 task 간 거리를 활용한 task kernel 을 제안하여, meta-learning 환경에서 task similarity를 명시적으로 모델링한다.\n또한 다양한 multi-task GP, hierarchical GP 연구에서는 task feature, 그래프 구조, 군집 등을 이용한 공분산 설계를 시도하고 있다.\n하지만 이들 연구는 주로 복잡한 GP 구조 및 대규모 실험에 기반한 모델 제안에 집중하며,\n단순한 선형–가우시안 계층 모형에서\n\n\ntask similarity를 반영한 prior 공분산 구조가 어떤 조건 하에서 유효한지,\n\n\n\n독립 prior 대비 Bayes risk 및 learning curve가 어떻게 달라지는지\n\n\n를 이론적으로 분석하는 통계적 연구는 상대적으로 부족하다.\n따라서 본 연구는, 선형–가우시안 계층 베이지안 meta-learning 모형을 기반으로\ntask similarity 기반 prior 구조를 일반적으로 정의하고, Bayes risk 및 pooling 구조를 수학적으로 분석함으로써,\n기존 문헌의 공백을 메우고자 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-목적-및-연구-질문",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-목적-및-연구-질문",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Task 간 유사도를 반영하는 일반적인 계층 베이지안 meta-learning prior 구조 제안\n\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 Bayes risk 및 학습 곡선 비교 분석\n\n제안 prior 구조의 이론적 성질(유효성, risk 개선 조건 등)을 정리하고, 시뮬레이션 및 실증으로 검증\n\n\n\n\n\nRQ1. Task feature 또는 task 간 거리/그래프 정보를 이용하여,\n계층 베이지안 meta-learning에서 일반적으로 사용할 수 있는 task similarity 기반 prior 공분산 구조를 어떻게 정의할 수 있는가?\nRQ2. 선형 회귀 + 가우시안 노이즈 환경에서,\nsimilarity-aware prior와 독립 prior에 기반한 meta-learning의 Bayes risk는 어떻게 비교되는가?\n특히 어떤 조건(유사도 구조가 실제 task 관계를 잘 반영할 때 등) 하에서 risk 개선이 발생하는가?\nRQ3. Multi-task GP 회귀의 학습 곡선 분석 결과를 활용하여,\nsimilarity-aware prior의 평균 Bayes error(learning curve) 에 대한 해석적 표현 또는 근사/상하한을 제시할 수 있는가?\nRQ4. 제안 prior 구조와 분석 결과는\n실제 meta-learning 환경(예: few-shot 회귀/분류 데이터셋)에서 성능 향상 및 불확실성 측정 개선으로 이어지는가?"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-내용-및-방법",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-내용-및-방법",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "본 연구는 다음과 같은 선형–가우시안 계층 베이지안 meta-learning 모형을 기본으로 한다.\n\nTask \\(t\\)의 회귀 모형: \\[\ny_{ti} = x_{ti}^\\top \\beta_t + \\epsilon_{ti}, \\quad\n\\epsilon_{ti} \\sim \\mathcal{N}(0, \\sigma^2),\n\\] 여기서 \\(x_{ti} \\in \\mathbb{R}^d\\), \\(\\beta_t \\in \\mathbb{R}^d\\).\n각 task의 파라미터 벡터를 쌓아 \\[\n\\beta = (\\beta_1^\\top, \\dots, \\beta_T^\\top)^\\top.\n\\]\n\n\n\n\n\n\n기존 계층 모형에서 자주 사용하는 baseline prior는 다음과 같다.\n\\[\n\\beta_t \\sim \\mathcal{N}(0, \\tau^2 I_d), \\quad t = 1,\\dots,T,\n\\]\n또는 전체 벡터에 대해\n\\[\n\\beta \\sim \\mathcal{N}(0, I_T \\otimes \\tau^2 I_d).\n\\]\n이는 task 간 독립성을 가정하며, task 간 유사도 구조를 반영하지 않는다.\n\n\n\n본 연구에서는 task feature \\(\\phi(t) \\in \\mathbb{R}^q\\) 또는 task 간 거리/그래프 정보를 이용하여\n다음과 같은 task covariance 행렬을 정의한다.\n\n커널 기반 구조: \\[\n\\Sigma_{\\text{task}}(s,t) = k(\\phi(s), \\phi(t)),\n\\] 여기서 \\(k\\)는 positive definite kernel (예: RBF, Matérn 등)이다.\n그래프 라플라시안 기반 구조: \\[\n\\Sigma_{\\text{task}} = (L + \\lambda I)^{-1},\n\\] 여기서 \\(L\\)은 task 그래프의 라플라시안, \\(\\lambda&gt;0\\)는 regularization 파라미터이다.\n\n이를 이용하여 전체 prior 공분산을\n\\[\n\\operatorname{cov}(\\beta) = \\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\n\\]\n로 정의하는 similarity-aware prior를 제안한다.\n이때 \\(k\\)의 positive definiteness, \\(L\\)의 성질 등을 이용하여\n\\(\\Sigma_{\\text{task}}\\) 및 \\(\\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\\) 가 양정치 행렬이 됨을 보이고,\n이에 따라 prior가 well-defined multivariate Gaussian이 됨을 정리 형태로 제시한다.\n\n\n\n\n\n\n선형–가우시안 모형에서 similarity-aware prior를 사용하면,\nposterior 및 posterior predictive distribution은 닫힌형으로 표현 가능하다.\n\nPosterior: \\[\np(\\beta \\mid D_{1:T}) = \\mathcal{N}(\\mu_{\\beta\\mid D}, \\Sigma_{\\beta\\mid D}),\n\\] 여기서 \\(\\mu_{\\beta\\mid D}\\), \\(\\Sigma_{\\beta\\mid D}\\)는 prior 공분산과 데이터 행렬 \\(X_{1:T}\\), 노이즈 분산 \\(\\sigma^2\\)에 의해 결정된다.\n새로운 task \\(t^\\*\\) 에 대한 예측 분포: \\[\np(y^\\* \\mid x^\\*, D_{1:T}, D_{t^\\*}) = \\mathcal{N}(m(x^\\*), v(x^\\*)),\n\\]\n\n이를 독립 prior와 similarity-aware prior 두 경우에 대해 명시적으로 도출한다.\n\n\n\n새로운 task에서의 예측 MSE를 Bayes risk로 정의한다.\n\\[\nR = \\mathbb{E}\\left[(y^\\* - \\hat{y}^\\*)^2\\right],\n\\]\n여기서 기대는 데이터 및 prior/likelihood에 대한 joint 분포에 대해 취한다.\n\n독립 prior: \\(R_{\\text{ind}}\\)\nsimilarity-aware prior: \\(R_{\\text{sim}}\\)\n\n를 각각 계산하거나 상·하한을 도출하고,\n특히 task covariance 행렬 \\(\\Sigma_{\\text{task}}\\)와 참 covariance \\(\\Sigma_{\\text{true}}\\)의 정렬 정도(예: eigen 구조, 코사인 유사도 등)에 따라\n\\[\nR_{\\text{sim}} \\le R_{\\text{ind}}\n\\]\n가 성립하는 조건을 정리 형태(정리/레마)로 제시한다.\n이 과정에서 multi-task GP learning curve 분석에서 사용된 테크닉 을 참고하여,\n평균 Bayes error를 task 수 \\(T\\), 각 task의 샘플 수 \\(n_t\\)의 함수로 표현하는 근사식을 도출하는 것을 목표로 한다.\n\n\n\nAshton & Sollich의 multi-task GP learning curve 결과를 차용하여,\n본 연구에서 정의한 선형–가우시안 모형이 multi-task GP의 특수한 경우에 해당함을 보이고,\nsimilarity-aware prior의 학습 곡선을\n\\[\n\\epsilon(n) = \\mathbb{E}\\left[ (f_{t^\\*}(x) - \\hat{f}_{t^\\*}(x))^2 \\right]\n\\]\n형태로 표현하거나 근사함으로써,\n\ntask similarity 구조가 클수록,\n\n다른 task의 데이터가 많을수록,\n\n새로운 task의 Bayes error가 더 빠르게 감소한다는 결과를 이론적으로 설명한다.\n\n\n\n\n\n시뮬레이션 환경 구성\n\nTask feature 및 참 task covariance \\(\\Sigma_{\\text{true}}\\) 를 설계하여,\n\n\nsimilarity-aware prior가 참 구조와 잘 맞는 경우,\n\n\n구조가 mismatch된 경우,\n\n\n실제로 task들이 독립인 경우, 를 비교.\n\n\n각 설정에서 \\(T\\), \\(n_t\\)를 변화시키며 독립 prior vs similarity-aware prior의\nBayes risk 및 학습 곡선을 비교.\n\n실제 데이터 기반 meta-learning 실험\n\n공개된 few-shot 회귀/분류 데이터셋(예: UCI 회귀 데이터셋을 여러 task로 나눈 환경 등)에 대해,\ntask feature(예: 입력 분포 통계량, domain index 등)를 구성하고\n제안 prior 구조를 적용.\n예측 정확도, 불확실성 calibration, 샘플 효율성 등의 지표 비교를 통해\n이론 결과와의 일관성을 확인."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#기대-효과-및-학문적-기여",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#기대-효과-및-학문적-기여",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "이론적 기여\n\nTask 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구성 틀을 제시하고,\n그 유효성(positive definiteness)과 Bayes risk 측면의 이점을 정리 형태로 제시한다.\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 risk/learning curve 비교 분석을 통해,\n기존 GP/meta-learning 문헌의 공백을 메운다.\n\n범용성 있는 방법론 제안\n\n제안 prior 구조는 task feature, 그래프, 클러스터 등 다양한 유사도 정보를 커널/공분산 형태로 통합할 수 있어,\n회귀, 분류, GP, BNN 등 다양한 meta-learning 환경에 적용 가능하다.\n\nMeta-learning 이론과 실용 알고리즘 간의 연결 강화\n\nMulti-task GP와 PAC-Bayesian meta-learning의 이론적 결과를\n구체적인 prior 설계 문제와 연결함으로써,\nmeta-learning 알고리즘 설계에 대한 통계적·이론적 가이드를 제공한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-일정-예시-석사-3학기-기준",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-일정-예시-석사-3학기-기준",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "기간\n내용\n\n\n\n\n1학기 전반 (3–4월)\nMeta-learning 및 Bayesian/meta-learning, GP, multi-task GP 문헌 조사\n\n\n1학기 후반 (5–7월)\n모형 설정 구체화, prior 구조 정의, 기본 정리(유효성) 도출\n\n\n여름 방학 (7–8월)\nBayes risk/learning curve 이론적 분석, 초벌 증명 정리\n\n\n2학기 전반 (9–10월)\n시뮬레이션 코드 구현, synthetic 실험 및 결과 분석\n\n\n2학기 후반 (11–1월)\n실증 데이터 실험, 결과 해석 및 이론과의 연결\n\n\n3학기 전반 (3–4월)\n논문 초고(1–4장) 작성, 정리/보완\n\n\n3학기 후반 (5–7월)\n논문 최종 수정, 심사 준비 및 발표\n\n\n\n(실제 일정은 지도교수와의 논의를 거쳐 조정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#참고-문헌-예시",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#참고-문헌-예시",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Hospedales, T., Antoniou, A., Micaelli, P., & Storkey, A. (2021). Meta-Learning in Neural Networks: A Survey.\n\nGrant, E., Finn, C., Levine, S., Darrell, T., & Griffiths, T. (2018). Recasting Gradient-Based Meta-Learning as Hierarchical Bayes. ICLR.\n\nZou, Y., & Lu, X. (2020). Gradient-EM Bayesian Meta-Learning. NeurIPS.\n\nNguyen, Q. P., Low, B. K. H., & Jaillet, P. (2021). Learning to Learn with Gaussian Processes. UAI.\n\nAshton, S. R. F., & Sollich, P. (2012). Learning Curves for Multi-task Gaussian Process Regression. NeurIPS.\n\nRothfuss, J., Josifoski, M., Fortuin, V., & Krause, A. (2021). Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior.\n\nChai, K. M. A. (2010). Multi-task Learning with Gaussian Processes.\n\n(최종 참고 문헌 목록은 실제 논문 작성 시 추가·수정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "",
    "text": "가장 교과서적인 MoE는 보통 지도학습 문맥에서 소개됨:\n\n입력: (x)\n출력: (y)\n여러 개의 expert (f_k(x))와 gating network (g(x))\n\n모양은 대충 이렇게:\n\\[\ny \\approx \\sum_{k=1}^K \\pi_k(x), f_k(x), \\qquad\n\\pi_k(x) = \\text{softmax}_k(g(x))\n\\]\n\nexpert: (f_k(x))\n\n“모드 k일 때의 예측기” (회귀, 분류, 등등)\n\ngating network: (g(x))\n\n입력 (x)를 보고 “어느 expert를 얼마나 쓸지” 가중치 (_k(x))를 냄\n\n주 용도:\n\n복잡한 함수 (x y)를 여러 지역/모드로 나눠서 각자 다른 네트워크가 담당하게 하는 구조\n예: piecewise function, 여러 작업을 나눠 맡는 모델 등\n\n\n→ 여기서 포인트는 보통 “조건부 모델링 (p(yx))”를 한다는 것."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-expertsmoe의-기본-모양",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-expertsmoe의-기본-모양",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "",
    "text": "가장 교과서적인 MoE는 보통 지도학습 문맥에서 소개됨:\n\n입력: (x)\n출력: (y)\n여러 개의 expert (f_k(x))와 gating network (g(x))\n\n모양은 대충 이렇게:\n\\[\ny \\approx \\sum_{k=1}^K \\pi_k(x), f_k(x), \\qquad\n\\pi_k(x) = \\text{softmax}_k(g(x))\n\\]\n\nexpert: (f_k(x))\n\n“모드 k일 때의 예측기” (회귀, 분류, 등등)\n\ngating network: (g(x))\n\n입력 (x)를 보고 “어느 expert를 얼마나 쓸지” 가중치 (_k(x))를 냄\n\n주 용도:\n\n복잡한 함수 (x y)를 여러 지역/모드로 나눠서 각자 다른 네트워크가 담당하게 하는 구조\n예: piecewise function, 여러 작업을 나눠 맡는 모델 등\n\n\n→ 여기서 포인트는 보통 “조건부 모델링 (p(yx))”를 한다는 것."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-vaes-기본-모양",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-vaes-기본-모양",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "2. Mixture-of-VAEs 기본 모양",
    "text": "2. Mixture-of-VAEs 기본 모양\nMixture-of-VAEs는 말 그대로 expert가 “VAE”인 mixture 모델 즉, 각 expert가 생성모델 (p_{_k}(x))을 담당한다고 보면 됨.\n구조는 대략:\n\n모드/클러스터 (k)를 latent로 도입:\n\n\\[\np(k) = \\pi_k \\quad (\\text{또는 } \\pi_k(x) = p(k\\mid x) \\text{로 gating})\n\\]\n\n모드별 VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0,I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k), \\quad q_{\\phi_k}(z_k \\mid x)\n\\]\n\n전체 분포:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k, p_{\\theta_k}(x)\n\\quad \\text{(또는 } \\sum_k \\pi_k(x), p_{\\theta_k}(x) \\text{)}\n\\]\n즉,\n\nexpert = “x를 생성하는 VAE 하나”\nmixture는 데이터 분포 (p(x)) 자체를 여러 모드로 나눠서 설명하는 구조.\n\n이건 Mixture-of-Experts의 unsupervised / generative 버전이라고 볼 수 있음."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#공통점과-차이점-정리",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#공통점과-차이점-정리",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "3. 공통점과 차이점 정리",
    "text": "3. 공통점과 차이점 정리\n\n3.1 공통점 (구조적인 측면)\n\n여러 개의 expert 존재\n\nMoE: (f_k(x)) (회귀/분류 등)\nMixture-of-VAEs: (p_{_k}(xz_k)) (생성모델)\n\ngating 개념\n\nMoE: (g(x))로부터 (_k(x)) (입력 의존적인 expert 가중치)\nMixture-of-VAEs:\n\n간단 버전: (_k) 고정 mixture weight\n조금 더 MoE 느낌: (_k(x) = p(kx))를 네트워크로 모델링 가능\n\n\n전체 출력은 “expert들의 weighted combination”\n\nMoE: (_k _k(x) f_k(x))\nMoVAE: (_k k(x) p{_k}(x)) (density 혹은 likelihood)\n\n\n→ 그래서 개념적으로는 “Mixture-of-VAEs도 MoE의 한 종류”라고 보는 게 자연스러움\n\n\n\n3.2 차이점 (보통 쓰이는 맥락 / modeling target)\n\n목표로 하는 확률분포가 다름\n\n일반적인 MoE:\n\n(p(yx)) (조건부 분포, supervised)\n예측 문제: 입력-출력 mapping\n\nMixture-of-VAEs:\n\n(p(x)) (joint / marginal 분포, unsupervised)\n생성/이상치 탐지 문제: 데이터 분포 자체를 모델링\n\n\nexpert의 내부 구조\n\nMoE:\n\nexpert는 그냥 “네트워크 함수” (f_k(x))일 때가 많음 (일반 MLP, CNN, RNN 등등)\n\nMixture-of-VAEs:\n\nexpert는 VAE 전체 (encoder + decoder + latent z)\n내부에 또 하나의 latent 구조 (z_k)가 있어서 두 단계 latent (k, z) 가 됨 → 일종의 hierarchical latent model\n\n\n학습 방식\n\nMoE (supervised):\n\n보통 backprop으로 end-to-end 학습\n혹은 EM-like 알고리즘 (예: hard gating 등)\n\nMixture-of-VAEs:\n\nmixture model + VAE라서\n\nmixture responsibility(E-step 비슷한 역할)와\n각 VAE parameter 업데이트(M-step 비슷한 역할)를 번갈아 하거나 joint training\n\n논문/구현에 따라 EM 스타일 / ELBO 최적화 스타일 등이 변주됨"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#네가-쓰려는-논문에서는-어떻게-부르면-좋을까",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#네가-쓰려는-논문에서는-어떻게-부르면-좋을까",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "4. 네가 쓰려는 논문에서는 어떻게 부르면 좋을까?",
    "text": "4. 네가 쓰려는 논문에서는 어떻게 부르면 좋을까?\n지금 우리가 이야기한 구조는:\n\n각 모드별로 VAE 하나가 있고\n모드 index (k)에 대한 mixture가 있어서\n\n\\[\np(x) = \\sum_k \\pi_k, p_{\\theta_k}(x)\n\\]\n이거라서,\n\n이론/수학 쪽에서 설명할 땐\n\n“Mixture-of-VAEs”, “mixture of latent variable models”\n\n딥러닝/엔지니어링 쪽에서 설명할 땐\n\n“각 expert가 VAE인 Mixture-of-Experts 구조” 라고 같이 언급해도 좋아.\n\n\n\nWe adopt a mixture-of-VAEs architecture, which can be interpreted as a Mixture-of-Experts model where each expert is a VAE that models a specific mode of the data distribution."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#석사-논문-스토리에서-활용-포인트",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#석사-논문-스토리에서-활용-포인트",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "5. 석사 논문 스토리에서 활용 포인트",
    "text": "5. 석사 논문 스토리에서 활용 포인트\n\n3장 – VAE 기반 이상치 + UQ\n\n단일 모드(normal 상태가 하나라고 보는) 데이터 가정\n\\(p(x)\\)를 하나의 VAE로 모델링\n\n4장 – Mixture-of-VAEs 확장\n\n“실제 현장 데이터는 여러 정상 모드(운영 상태)를 가진다”\n이를 위해 Mixture-of-Experts 관점에서, 각 모드를 담당하는 VAE expert를 두고 gating/mixture 구조를 도입\n즉, “VAE를 expert로 하는 Mixture-of-Experts = Mixture-of-VAEs”\n\n기여 포인트 강조\n\n기존 anomaly detection은 “하나의 정상 모드”만 가정하는 경우가 많다.\n우리는 모드(k) + 모드 내부 latent(z) 두 단계로 분해해\n\n모드별 이상치,\n모드 간 불확실성까지 구분해서 다룸."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#짧게-요약하면",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#짧게-요약하면",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "6. 짧게 요약하면",
    "text": "6. 짧게 요약하면\n\nMixture-of-Experts\n\n일반적으로 (p(yx))를 여러 expert + gating으로 나눠 모델링하는 조건부 모델\nexpert는 보통 “함수 네트워크”\n\nMixture-of-VAEs\n\n각 expert가 VAE 같은 확률 생성모델\n(p(x)) (데이터 분포) 자체를 mixture로 모델링하는 생성/unsupervised 모델\n구조적으로는 “expert를 VAE로 둔 generative MoE”"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "",
    "text": "이상치 탐지 등의 모형에 Uncertainty 를 출력 시키면 Decision making에 좋지 않나"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#왜-이상치-탐지에-uncertainty를-붙이면-좋냐",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#왜-이상치-탐지에-uncertainty를-붙이면-좋냐",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "1. 왜 이상치 탐지에 Uncertainty를 붙이면 좋냐?",
    "text": "1. 왜 이상치 탐지에 Uncertainty를 붙이면 좋냐?\n보통 이상치 탐지는\n\n점수 s(x)만 주고\n임계값 τ 넘으면 “이상치”라고 함.\n\n여기에 불확실성 u(x)까지 나오면:\n\n경계 케이스 구분\n\n점수는 높지만 불확실성이 엄청 크면: → 모델이 “자신 없는데 일단 이상치 같다고 해본 것” → 사람 검토 대상으로 보내기 좋음.\n점수는 애매하지만 불확실성이 작으면: → 모델이 “이건 거의 정상(또는 이상치)이야”라고 확신하는 구간.\n\n우선순위 정렬\n\n모니터링/알람 시스템에서\n\ns(x) 큰 순서 + u(x) 큰 순서를 섞어서 → “심각하고, 동시에 모델도 헷갈리는” 사례를 제일 위로 올릴 수 있음.\n\n\nActive Learning / Labeling 전략\n\n라벨링 budget이 제한된 상황에서\n\n이상치 점수도 높고, 불확실성도 높은 샘플만 골라 사람이 라벨→ 재학습.\n\n결국 데이터 효율을 올리는 용도로도 유용.\n\n운영 단계에서 신뢰도 제공\n\n산업/의료에서 “왜 이게 이상치냐?”보다 “이 판단을 얼마나 믿어도 되냐?”가 중요.\nUncertainty는 일종의 confidence interval이라, 운영자 설득에 도움이 됨."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#어떤-식-모델-구조를-생각해볼-수-있나",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#어떤-식-모델-구조를-생각해볼-수-있나",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "2. 어떤 식 모델 구조를 생각해볼 수 있나?",
    "text": "2. 어떤 식 모델 구조를 생각해볼 수 있나?\n\n(1) 베이지안 이상치 탐지\n\na. Bayesian Autoencoder / VAE 기반\n\nAutoencoder나 VAE를 베이지안화해서\n\n재구성 오류(reconstruction error) +\nlatent / decoder의 predictive uncertainty를 같이 사용.\n\n예:\n\n입력 x에 대해\n\nreconstruction error r(x)\nMC Dropout 또는 BNN 통해 여러 번 forward → 출력 분포의 분산 u(x)\n\n\n이상치 점수 예시:\n\nscore(x) = α · r(x) + β · u(x)\n또는 2D로 두 축을 따로 보고 threshold를 각각 설정.\n\n\n\n\nb. Bayesian One-Class Classifier\n\nOne-Class SVM 스타일 대신\n\nNormal data를 중심으로 하는 Bayesian density model (예: Bayesian GMM, GP, BNN density estimator)\n예측 밀도 p(x)와 함께 “밀도 추정의 불확실성”을 같이 뽑는 형태.\n\n\n\n\n\n\n(2) Deep Ensemble + 이상치 스코어\nBayesian 딥러닝이 아니어도, Deep Ensemble로 꽤 쓸만한 Uncertainty를 얻을 수 있어 보임.\n\n서로 다른 초기값/부트스트랩으로 모델 여러 개 학습:\n\n예) Autoencoder 5개, 이상치 분류기 5개.\n\n입력 x에 대해:\n\n각 모델의 이상치 점수 s_i(x)\n평균 E[s(x)] = 대표 점수\n분산 Var[s(x)] = epistemic uncertainty 근사\n\n활용:\n\nE[s(x)]가 높고 Var[s(x)]가 높다 → “위험 + 자신 없음 → 반드시 검토”\nE[s(x)] 높고 Var[s(x)] 낮다 → “위험하지만 꽤 확신 있음”\n\n\n\n\n\n(3) Normalizing Flow / Density Estimator + UQ\n이상치 탐지에서는 likelihood-based model도 많이 쓰긴 함함. 예: Flow, Autoregressive model, Energy-based model.\n여기에 UQ를 섞는 방식:\n\nBayesian Flow:\n\nFlow의 파라미터에 prior를 두고 variational inference/MC Dropout 등으로\n입력에 대한 likelihood의 분포를 추정 → 평균/분산.\n\nEnsemble Flow:\n\n서로 다르게 학습된 flow 여러 개\n각자의 log p_i(x) 평균·분산을 가지고 score + uncertainty.\n\n\n재미있는 점은,\n\n일부 연구들에서 likelihood만으로는 OOD 구분이 잘 안 된다는 문제를 지적했기 때문에\nUQ를 추가해서 “likelihood는 높은데, 모델이 이 영역을 잘 모른다” 같은 케이스를 잡아낼 수 있을 가능성이 큼.\n\n\n\n\n(4) Classification 기반 OOD + UQ\n만약 이상치 = inlier/outlier binary classification으로 보는 세팅이면:\n\ninlier만으로 학습한 classifier(예: one-class) 대신\n다중 클래스 분류 + out-of-distribution detection 세팅으로 전환하고\nMC Dropout / BNN / Ensemble로 predictive entropy, mutual information 등을 이용:\n\np(y | x)의 entropy → aleatoric + epistemic 섞인 overall uncertainty\nBALD(MI) 등 → epistemic 쪽 강조.\n\n\n이때 이상치 점수는:\n\nlogits 기반 (max-softmax, energy 등) + uncertainty 지표 같이 제공."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#평가실험-관점에서-고려할-점",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#평가실험-관점에서-고려할-점",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "3. 평가/실험 관점에서 고려할 점",
    "text": "3. 평가/실험 관점에서 고려할 점\nUncertainty를 같이 제공하면, 평가도 더 rich해지는 장점이 있음.\n\n기존 이상치 탐지 metric\n\nAUROC, AUPR, FPR@95TPR 등은 계속 사용.\n\nUncertainty 관련 metric\n\nCalibration (ECE, NLL)\nUncertainty vs. Error correlation:\n\n이상치 탐지 decision이 틀린 샘플에서 u(x)가 큰지 확인.\n\n\nRisk-aware metric\n\n예: threshold를 바꿔가며\n\n“불확실성이 높은 샘플은 사람에게 보내고, 나머지는 자동 처리”라는 정책에서의 전체 error / human load / missed anomaly 등 trade-off 분석."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#아이디어-구체화",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#아이디어-구체화",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "4. 아이디어 구체화",
    "text": "4. 아이디어 구체화\n예를 들어 시계열 이상치 탐지라고 가정하면:\n\n기본 구조\n\nLSTM/Transformer 기반 예측 모델 또는 Autoencoder.\n\nBayesian화\n\nDropout을 training + inference에서 모두 켬(MC Dropout).\n같은 입력 구간 x에 대해 T번 forward →\n\nreconstruction/prediction error의 평균 μ_r, 분산 σ_r^2.\n\n\n점수 정의\n\n이상치 점수: A(x) = μ_r\n불확실성: U(x) = σ_r^2\n최종 의사결정:\n\nA(x) &gt; τ₁ 이고 U(x) &gt; τ₂ → “Critical (사람 검토 필수)”\nA(x) &gt; τ₁ 이고 U(x) ≤ τ₂ → “자동 알람”\n나머지 → “정상 또는 low-priority”\n\n\n훈련 시\n\nreconstruction loss 최소화\n\n필요하다면 calibration을 위한 auxiliary loss(예: temperature scaling은 사후에 적용)."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#연구-아이디어로서의-포지셔닝",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#연구-아이디어로서의-포지셔닝",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "5. 연구 아이디어로서의 포지셔닝",
    "text": "5. 연구 아이디어로서의 포지셔닝\n\n문제 정의\n\n기존 이상치 탐지 모델은 score만 제공 → “얼마나 믿을 수 있는가?”에 대한 정보 부재.\n\n기여\n\n(모델 측면)\n\n베이지안/Ensemble 기반 이상치 탐지 모델 설계\n이상치 점수와 함께 calibrated uncertainty 제공.\n\n(평가 측면)\n\n“Risk-aware anomaly detection benchmark”를 제안\n예: 사람-in-the-loop 세팅에서\n\n일정 human budget 하에서 최대한 많은 true anomaly를 잡는 문제로 정식화.\n\n\n(실험 측면)\n\n시계열 / 이미지 / 의료 데이터 셋에서\n\n기존 deterministic anomaly detector vs. 제안한 UQ-aware detector 비교."
  },
  {
    "objectID": "posts/20251115_1.html",
    "href": "posts/20251115_1.html",
    "title": "Successive model-agnostic meta-learning for few-shot fault time series prognosis",
    "section": "",
    "text": "초록\n메타러닝은 few-shot 결함 예측 문제를 해결하는 유망한 기술로, 최근 몇 년간 많은 연구자들의 주목을 받아왔습니다. 주로 무작위 및 유사성 매칭 기반의 task 분할에 의존하는 기존의 시계열 예측 메타러닝 방법들은 세 가지 주요 한계에 직면합니다:\n\nFeature exploitation inefficiency(특징 활용의 비효율성)\n\nSuboptimal task data allocation\nLimited Robustness with small samples(적은 샘플에서의 제한된 견고성)\n\n이러한 한계를 극복하기 위해,\n\n본 연구는 시계열의 연속적인 기간을 다수의 연속된 짧은 기간으로 구성된 메타-task로 간주하는 새로운 ‘의사 메타-task(pseudo meta-task)’ 분할 기법을 제안합니다. 연속 시계열을 의사 메타-task로 사용함으로써, 제안하는 방법은 데이터로부터 더 포괄적인 특징과 관계를 추출하여 더 정확한 예측을 할 수 있습니다.\n\n또한, 여러 데이터셋에 걸쳐 제안 방법의 견고성을 향상시키기 위해 차분(differential) 알고리즘을 도입합니다.\n\n여러 결함 및 시계열 예측 데이터셋에 대한 광범위한 실험을 통해, 제안하는 접근법이 few-shot 조건과 일반 조건 모두에서 예측 성능과 일반화 능력을 상당히 향상시킨다는 것을 입증합니다.\n\n\nIntroduction\nFault Prediction in Time series Data\n시계열 데이터의 결함 예측은 광범위한 산업적 응용 분야를 가진 매우 중요한 머신러닝 task이지만, 데이터 부족 및 주파수 불일치와 같은 문제점에 직면합니다.\n\n문제점: Data Scarcity, Frequency Mismatch\n\n메타러닝은 이러한 문제들을 해결하기 위한 유망한 접근법으로 부상했으며, task 간 유사점과 차이점을 활용하여 새로운 시계열 결함 예측 task에 효과적으로 적응합니다.\n이는 딥러닝 모델이 단 몇 개의 샘플 또는 심지어 샘플이 없는 경우에도 새로운 시계열 데이터에 빠르게 적응할 수 있게 하며, 다양한 도메인과 시나리오에서 비롯된 시계열 데이터 간의 유사점과 차이점을 활용하여 일반화 능력을 향상시킵니다([35], [2]).\n\n메타러닝: cross-task similarities와 differences 활용해 fualt prediction에 적용\n\n메타러닝은 머신러닝 알고리즘이 ’learning to learn’을 가능하게 하여, 지식의 보편성과 적응성을 향상시킵니다. 시계열 결함 예측 분야에서 메타러닝의 효과는 task-distribution에 의존하는 몇 가지 요인들의 미묘한 보정에 달려 있으며, 연구자들은\n\nData representation (데이터 표현),\n\nMeta-learner design (메타-러너 설계),\n\nMeta-learning algorithms (메타러닝 알고리즘),\n\nPeuso meta-task division (의사 메타-task 분할)\n\n이라는 네 가지 핵심 측면을 꼽습니다.\n주목할 점은, 첫 세 가지 측면은 특정 task distribution에 따라 다른 조정이 필요한 반면, 의사 메타-task의 분할은 task distribution에 의존하지 않는다는 것입니다 [24]. 따라서, 본 논문은 결함 예측에서 메타러닝의 적응성을 향상시키기 위해 주로 의사 메타-task의 분할 방법을 개선합니다.\n\n시계열 예측에서 메타러닝을 위한 task 분할 알고리즘은 크게 두 가지 유형으로 분류할 수 있습니다.\n무작위 task 분할 방법: 이 범주에서 가장 대표적인 방법은 Model-Agnostic Meta-Learning (MAML) [6]으로, 무작위로 시간 구간을 선택하여 의사 메타-task로 사용하는 전략을 사용합니다. MAML++ [1], MetaL [3], Bootstrapped Meta-learning (BMG) [7]과 같은 방법들이 다양한 측면에서 MAML에 대한 훌륭한 발전과 개선을 이루었지만, MAML의 의사 메타-task 분할 접근법을 특별히 개선하지는 않았습니다. 시계열을 무작위로 task로 분할하는 특성상, 이 접근법은 시간적 상관관계를 완전히 포착하지 못할 수 있으며, 시계열의 일관성을 잠재적으로 훼손할 수 있습니다.\n유사성 매칭 기반 task 분할 방법: 이 범주의 대표적인 방법은 Mo 등이 제안한 것으로[23], 본 논의에서는 이를 ’MAML (DTW)’라고 지칭하겠습니다. 이 방법은 MAML 프레임워크 내에서 동적 시간 워핑(Dynamic Time Warping, DTW)을 사용하여 현재 시간 구간과 가장 유사한 시간 구간들을 의사 메타-task로 선택합니다. 이를 통해 모델의 예측 성능과 견고성을 향상시킵니다. 그러나 이 접근법은 특히 데이터가 부족한 환경에서 어려움을 겪습니다. 데이터 품질이 낮을 때 적절한 데이터 샘플을 찾는 데 어려움을 겪을 수 있습니다. 더 나아가, 시계열에서 충분한 상관관계를 추출하지 못할 수 있습니다.\n\n기존 Meta-Learning의 Task Paritioning Algorithms의 단점?\n\n무작위 방식은 시간적 상관관계를 파괴한다.\n\n유사성 매칭 방식인 DTW방식은 시간적 상관관계를 포착하려고 시도하지만, 데이터 부족이나 방법론적 한계 때문에 충분하지 않다.\n\n\n메타러닝이 상당한 발전을 이루었지만, 이 분야 내에서의 task 분할은 비교적 적은 주목을 받아왔습니다.\n\n이는 기존 메타러닝 알고리즘의 효과를 제한하고 있을 수 있는 잠재적 약점을 시사합니다.\n\n이를 더 잘 이해하기 위해서는, 현재 task 분할 방법들의 작동 방식의 세부 사항을 면밀히 살펴보고 어떤 부분에서 부족한 지 파악해야 합니다.\n\n현재 방법들은 연속 시계열에 내재된 특징과 의존성을 효과적으로 활용하는 데 어려움을 겪습니다.\n\n\n심층 분석에 따르면, 널리 사용되는 Model-Agnostic Meta-Learning(MAML)을 포함한 이러한 방법들의 대다수가 무작위 task 분할을 사용한다는 점이 드러났습니다. 이러한 task 분할 접근법은 적용 범위가 넓다는 장점이 있긴 하지만, 본질적으로 연속 시계열을 분리된 세그먼트로 나누어 버린다는 단점이 있습니다. 이러한 단절은 정확한 시계열 예측에 필수적인 중요한 시간적 의존성의 손실을 초래하는 경우가 많습니다 [31].\nMAML과 DTW에서 영감을 받아 유사성 매칭 기반 방법론을 사용하는 대안적인 task 분할 패러다임이 [23]에서 소개되었습니다. 이 패러다임은 복잡한 시계열 특징과 의존성을 어느 정도 포착하는 데 장점이 있습니다. 그러나, 데이터셋에 유사성 매칭 샘플이 충분하지 않은 시나리오에서는 이 전략의 성능이 무작위 task 분할의 성능으로 수렴하는 경향이 있다는 점에 주목할 필요가 있습니다. 결정적으로, 이 방법은 메타-훈련에 사용되는 시계열을 본질적으로 분리된 세그먼트로 분해하여 장기 의존성을 포착하는 데 한계를 야기합니다.\n\n\n\n현재 의사 메타-task의 분할은 종종 차선책에 머물러, 일반화 능력이 제한되고 환경에 따라 성능 편차가 크게 나타납니다. 대표적인 예는 MAML(DTW) [23]의 유사성 매칭 기반 접근법입니다.\n\n\n이 방법은 유사한 시간 구간을 task로 묶어 모델 성능을 향상시키는 것을 목표로 합니다. 그럼에도 불구하고, 데이터셋에 조건을 충족하는 샘플이 충분하지 않을 때 그 효과는 약화됩니다. 이러한 경우, 이 방법의 성능은 무작위 task 분할 접근법의 성능에 가까워지는 경향이 있어, 적응성에 한계가 있음을 보여줍니다.\n\n\n이전의 task 분할 메타-러너들은 제한된(limited) 샘플 크기를 다룰 때 견고성이 떨어집니다. 이 문제는 데이터가 부족하거나 드문드문 나타날 수 있는 산업 환경에서 특히 두드러집니다.\n\n\nMAML과 그 변형들을 포함한 전통적인 메타러닝 알고리즘들은 이러한 제약 조건 하에서 성능이 현저히 저하됩니다. 이는 최근 연구들에서도 확인된 바(corroborated by recent studies)로, 제한된 샘플이 예외보다는 일반적인 규칙인 실제 시나리오에서는 이러한 알고리즘들이 덜 효과적임을 나타냅니다 [8]. 따라서, task 분할이 받아온 제한된 관심과 희소하거나 누락된 샘플을 처리하는 데 있어서의 현재의 부적절함을 고려할 때, 제한된 샘플 조건 하에서도 높은 성능을 유지하는 견고한 메타러닝 접근법에 대한 명백한 필요성이 있습니다. 이러한 고려 사항은 저희가 이후에 제안할 방법을 설계하는 데 있어 핵심적인 요소입니다.\n\nIn response to the aforementioned limitations…\nfew-shot 결함 예측에 특화된 모델 독립적인 메타러닝 접근법인 Successive Model-Agnostic Meta-Learning (SMAML)을 소개합니다.\n\nSMAML의 핵심은 차분 자기회귀(differential autoregression)에 기반하여 의사 메타-task를 구성하는 방법입니다. 이 방법은 MAML [6]이 제시한 방법에 깊이 영감을 받았으며 그 원리를 한 단계 발전시키고자 합니다.\nSMAML의 중심에는 소스 도메인에서 메타러닝을 위해 시간 세그먼트를 연속적으로 추출하는 샘플 선택 방법이 있습니다. 이는 2022년 Mo 등이 제안한 의사 메타-RUL task라는 혁신적인 개념을 기반으로 합니다 [23].\nSMAML의 결정적인 특징은 장기 시계열의 미묘한 차이를 통합하여, 더 조밀한 시간적 의존성을 형성하는 능력에 있습니다. 이러한 의존성은 저희 실험에서 few-shot 조건이라고 알려진 어려운 학습 시나리오에서 특히 중추적인 역할을 합니다.\n주목할 점은, 이러한 조건들은 소스 도메인과 타겟 도메인이 서로 다른 작동 조건이나 고장 모드(failure modes)를 가지며, 타겟 도메인의 훈련 데이터는 오직 테스트에만 사용되는 시나리오를 의미합니다.\n저희가 제안하는 방법을 사용하면 소스 도메인에서 훈련된 모델이 타겟 도메인에서의 예측 정확도를 향상시킬 수 있습니다.\n\nSMAML의 다재다능함을 강조하기 위해, 이러한 few-shot 조건과 일반 조건(소스 도메인과 타겟 도메인이 동일한 작동 조건과 고장 모드를 공유하며 훈련 데이터 양이 충분한 경우) 모두에서 비교 테스트를 수행했습니다.\n\n제안 방법은 두 조건 모두에서 지속적으로 현저하게 좋은 성능 향상을 기록했습니다. task 분할 방법과 그것이 어떻게 서로 다른 학습 환경에서 작동하는지에 대한 자세한 설명은 4장에서 제공됩니다. 일반 조건에서는 저희 방법이 예측 성능을 더욱 향상시킬 수 있습니다. 이 연구에서 제안된 task 분할 방법의 장점을 검증하기 위해, 저희는 의사 메타-task 분할 접근법만 변경하고 실험 조건은 일정하게 유지했습니다.\n\n본 논문의 주요 기여 본 논문의 주요 기여는 다음과 같이 요약됩니다.\n\n연속 시계열에서의 Task 분할 문제 해결:\n\n저희는 의사 메타-task 구성을 위해 차분 자기회귀에 기반한 획기적인 접근법을 소개합니다. 이 방법은 무작위 task 분할과 관련된 내재적인 문제들을 해결하기 위해 세심하게 설계되었습니다. 연속 시계열의 고유한 특징과 의존성을 보존하고 능숙하게 활용함으로써, 저희 접근법은 시계열을 분리된 세그먼트로 단편화하는 방법들이 가진 한계를 극복합니다.\n\n제한된 샘플 조건 하에서의 견고한 메타러닝:\n\n이전 task 분할 메타-러너들의 단점, 특히 제한된 샘플 크기에 직면했을 때의 취약성을 인식하고, 저희가 제안하는 접근법은 견고하게 맞섭니다. 데이터 부족이 시급한 문제인 산업 환경에서, 저희 방법은 견고성과 우수한 성능을 보여줍니다.\n\nSMAML의 다재다능함에 대한 경험적 입증:\n\n벤치마크 데이터셋인 Electricity Transformer Dataset(ETT)을 포함한 여러 산업 결함 데이터셋에 대한 광범위한 평가를 통해, 저희 접근법은 few-shot 학습 시나리오와 전통적인 설정 모두에서 그 우수성을 입증할 뿐만 아니라, 다양한 시계열 데이터셋에 걸쳐 다른 메타러닝 기법들을 일관되게 능가합니다.\n본 논문의 구성\n본 논문의 나머지 부분은 다음과 같이 구성됩니다.\n\n2장에서는 해당 분야의 관련 연구들을 검토합니다.\n3장에서는 결함 예측 task를 위한 Successive Model-Agnostic Meta-Learning(SMAML)의 방법론을 상세히 설명합니다.\n실험 설정과 결과는 각각 4장과 5장에서 제시되며, 제안된 방법의 효용성을 보여줍니다.\n마지막으로 6장에서는 논문을 마무리하며, 기여한 바를 요약하고 향후 연구 방향을 제안합니다."
  },
  {
    "objectID": "posts/20251113_1.html",
    "href": "posts/20251113_1.html",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "@article{hospedales2021meta,\n  title={Meta-learning in neural networks: A survey},\n  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={44},\n  number={9},\n  pages={5149--5169},\n  year={2021},\n  publisher={IEEE}\n}\n업데이트 내역\n\n\n\n2025-11-14\n태스크 분포 관점 업데이트\n\n\n\n2025-11-15\nBilevel optimization View 업데이트\n\n\n\n\n\n\nLearning-to-learn이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 학습 알고리즘 자체를 개선하는 것을 목표로 합니다. 이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다. 본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다. 먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다. 다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다. 또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다. 마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다.\n\n\n\n메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음\n\nMeta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.\n\n\nprovides an alternative paradigm?\n\n\n기존 방식?\n기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.\n\n대안(메타러닝):\n기계에게 숙제 하나만 주는 게 아니라, “스스로 공부하는 법”을 터득하게 만들자!\n\n\na machine learning model gains experience over multiple learning episodes\n\n\n비유를 해보자면\n사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 여러 과목의 문제(관련된 과제들)를 풀게 하는 행위랑 비슷함.\n이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 ‘요령(패턴)’을 깨닫게 됨. 이것이 바로 “경험”이라고 할 수 있음.\nlearning episodes: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.\n\n보통의 경우에, 그리고 역사적으로 보면,\n\n머신러닝\n\n\n\n기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.\n\nhand-engineered features\n\n\n그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.\n\n이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.\n\n\n즉, 머신러닝에서 특징 추출 단계와 모델 학습 단계는 분리 되어 있음.\n\n\n딥러닝\n\n\n\n위 머신러닝의 두 단계인 특징 추출 단계와 모델 학습 단계를 하나의 단계로 통합해버림.\n\n특징과 모델의 공동 학습 (Joint feature and model learning)\n\n\n예전 처럼 특징을 정성스럽게 추출할 필요가 없음.\n\n원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,\n\n모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.\n\n\n고양이 사진 분류하는 모델을 예로 들어보면…\n\n초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.\n\n중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.\n\n후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.\n\n어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.\n\n사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.\n이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.\n\n\n신경망에서의 메타러닝?\n\n\n특징 추출 단계, 모델 학습 단계, 그리고 알고리즘을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.\n\nThrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.\n\nThrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.\n해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 \n\n\n학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,\n즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.\n\n\ntask family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.\n\n예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 “동물 분류”라는 하나의 task family에 속합니다.\n\nAI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.\n즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.\n\n\n\nconventional machine learning performance improves as more data from a single task is seen\n\n\n기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.\n\n공짜 점심은 없다(no free lunch) Theorem 에 대항하는 알고리즘 ㅋㅋ\n\nThis perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.\n\n\n이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.\n\n\nHowever, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.\n\n\n하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.\n\n\n“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.\n\n이 논문이 Review하려고 하는 대상 논문?\n\n본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.\n\n참고문헌 [27], [28]에 따라 ‘알고리즘 학습’으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.\n이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.\n\n본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.\n\n먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다\n그런 다음, 메타-표현(meta-representation), 메타-목적(meta-objective), 메타-최적화기(meta-optimizer)라는 관점에서 새로운 분류 체계를 제공할 것입니다.\n이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 설계 공간(design-space)을 제시합니다.\n우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.\n마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다.\n\n\n\n\n\n메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.\n\n이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.\n\n\n\n‘학습하는 방법을 학습하는 것(learning to learn)’\n\n이는 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미함.\n기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.\n기반 학습(base learning) 중에는 내부(inner) (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임\n\n메타러닝 중에는 외부(outer)(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.\n\n예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.\n(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.\n\n\ninner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.\n\n\n\n메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?\n\n위에 정의된 대로라면, Cross Validtion을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.\n\n\n\n\n명시적으로 정의된 메타 수준의 목적 함수이 있고,\n\n이 목적 함수에 대한 내부 알고리즘의 end-to-end 최적화가 이루어짐.\n\n\n\n\n\n\n\n기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 \\(D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}\\)이 주어짐.\n\\(\\theta\\)로 매개변수화된 예측 모델 \\(\\hat{y} = f_{\\theta}(x)\\)를 다음 식을 풀어 훈련시키게 됨:\n\\[\n\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(D; \\theta, \\omega) \\quad (1)\n\\]\n\n\\(\\mathcal{L}\\)은 실제 레이블과 \\(f_{\\theta}(\\cdot)\\)가 예측한 값 사이의 오차를 측정하는 손실 함수.\n\\(\\omega\\)라는 조건이 걸려 있음.\n\n이는 학습하는 방법 \\(\\omega\\)에 따라 이 식(1)의 해인 \\(\\theta\\)가 달라질 수 있다는 의미임.\n\n\\(\\omega\\) 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.\n\n일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.\n\n\n\n\n최적화 과정이 모든 문제 \\(D\\)에 대해 매번 처음부터 수행됨(from scratch)\n\n학습 방법 \\(\\omega\\)는 사전에 지정됨.\n\n이때, \\(\\omega\\)의 specification, 즉 학습 방법을 어떻게 정하느냐는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.\n\n메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 사전에 지정하고 고정하는 대신 학습 알고리즘 자체를 학습하게 됨.\nSpecification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음\n\n최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?\n학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?\n모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?\n정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?\n\n\n\n\n\n\n\n메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,\n이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 범용 학습 알고리즘을 학습하자.\n\nNotation\n\n\\(p(\\mathcal{T})\\): 과제들의 분포\n\\(\\omega\\): 어떤 학습 방법\n\\(\\mathcal{T} = \\{D, L\\}\\): 어떤 과제(\\(\\mathcal{T}\\))는 데이터셋(\\(D\\))과 손실 함수(\\(L\\))의 조합이다.\n\\(D\\): 데이터 셋\n\\(\\mathcal{L}(D, \\omega)\\): 데이터 셋 \\(D\\)에서 학습 방법 \\(\\omega\\)를 사용해 훈련했을 때의 loss 값\n\n위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.\n\\[\n\\min_{\\omega} \\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})} \\mathcal{L}(D; \\omega) \\quad (2)\n\\]\n‘학습 방법’, 즉 \\(\\omega\\)는 과제 전반의 지식(across-task knowledge) 또는 메타 지식(meta-knowledge) 이라고 할 수 있음.\n식 (2)를 실제로 해결하려면?\n\n목표: 세상의 모든 과제 분포 \\(p(\\mathcal{T})\\)에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 \\(\\omega\\)를 찾자!\n\n현실: 모든 과제 분포의 모든 문제인 \\(p(\\mathcal{T})\\)를 다룰 수는 없음.\n타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 \\(p(\\mathcal{T})\\)를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)\n\nNotation 2\n\\(\\mathcal{D}_{\\text{source}} = \\{(D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})^{(i)}\\}_{i=1}^M\\)\n\n메타-훈련(meta-training)에 사용할 전체 데이터셋을 나타내는 기호.\n\n하나씩 뜯어보면\n\n\\(\\mathcal{D}_{\\text{source}}\\) : ‘소스 데이터셋(Source Dataset)’이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 원천(Source)이 된다는 의미. 즉, “훈련용”이라는 뜻.\n\\(M\\): 우리가 가지고 있는 훈련용 과제(task)의 총 개수. (예: 50개의 다른 종류의 동물 분류 문제)\n\\(\\{ \\dots \\}_{i=1}^M\\): 괄호 안의 내용이 1번부터 M번까지 M개가 있다는 뜻.\n\\(( \\dots )^{(i)}\\): 그중에서 i번째 과제를 의미. (예: 50개 중 17번째 과제)\n\\((D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})\\): 하나의 과제(\\(i\\))가 두 종류의 데이터로 구성되어 있다는 뜻.\n\n\\(D_{\\text{train}}^{\\text{source}}\\): ‘훈련용’ 데이터(train data). 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 서포트셋(support set)이라고 함.\n\\(D_{\\text{val}}^{\\text{source}}\\): ‘검증용’ 데이터(validation data). 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 쿼리셋(query set)이라고 함.\n\n\n\n“\\(\\mathcal{D}_{\\text{source}}\\)란, 총 M개의 훈련용 과제 묶음인데, 각 과제\\(i\\)는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”\n\n아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n또, 식을 하나씩 요소별로 뜯어보자.\n\n\\(\\omega\\) (오메가): 우리가 찾고 싶은 ‘학습 방법’ 또는 ‘공부법’\n\\(\\omega^{\\ast}\\) (오메가 스타): 수많은 가능한 공부법(\\(\\omega\\)) 중에서 우리가 찾아낸 최고의(optimal) 공부법을 의미함.\n\\(\\arg\\max_{\\omega}\\): “괄호 안의 값을 최대(max)로 만드는 \\(\\omega\\)를 찾아라(arg)”라는 명령어.\n\\(p(\\omega|\\mathcal{D}_{\\text{source}})\\): 사후 확률(posterior probability).\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 관찰했을 때, 어떤 공부법(\\(\\omega\\))이 가장 그럴듯한가(정답일 확률이 높은가)?”.\n\n\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(\\(\\omega\\))을 찾아서, 그것을 우리의 최종 학습법(\\(\\omega^{\\ast}\\))으로 삼아라!“\n\n이제 메타-테스트 단계에서 사용되는 \\(Q\\)개의 타겟 과제(target tasks) 집합을 \\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{target}}^{\\text{train}}, D_{\\text{target}}^{\\text{test}})^{(i)}\\}_{i=1}^Q\\) 로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 \\(\\omega^*\\)를 사용하여 이전에 보지 못한 각 타겟 과제 \\(i\\)에 대한 기반 모델을 훈련합니다:\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{target}}^{\\text{train }(i)}) \\quad (4)\n\\]\n식 (1)의 기존 학습과 대조적으로, 타겟 과제 \\(i\\)의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 \\(\\omega^*\\)의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 \\(D_{\\text{test}}^{\\text{target}}(i)\\)에 대한 \\(\\theta^{*(i)}\\)의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.\n이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 메타-과소적합(meta-underfitting) 과 메타-과적합(meta-overfitting) 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 \\(\\theta\\)를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 \\(\\omega\\)를 학습하는 것으로 볼 수 있습니다.\n다음 섹션 넘어가기 전 수식 해설:\n\\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{target}}^{\\text{train}}, D_{\\text{target}}^{\\text{test}})^{(i)}\\}_{i=1}^Q\\)\n이 수식은 메타-테스팅(Meta-Testing) 단계, 즉 최종 실력을 평가하는 데 사용되는 “실전 시험 문제지 묶음” 전체를 정의합니다.\n이 구조를 세 단계로 나누어 이해하면 가장 쉽습니다.\n\n\n\n이름: 타겟 데이터셋 (The Target Dataset)\n역할: 메타-훈련을 통해 학습된 ’만능 공부법(\\(\\omega^*\\))’이 얼마나 효과적인지 최종적으로 평가하기 위한 전체 시험 문제들의 집합입니다.\n표기 규칙: target이 아래 첨자(subscript)로 붙어, 이 데이터셋 묶음의 소속(Group)이 ’소스(훈련용)’가 아닌 ’타겟(시험용)’임을 나타냅니다.\n\n\n\n\n\n이름: i번째 타겟 과제 (The i-th Target Task)\n역할: 전체 시험지 묶음(\\(\\mathcal{D}_{\\text{target}}\\))은 총 Q개의 개별 시험 문제(과제)로 이루어져 있습니다. 이 표기는 그중 i번째 시험 문제 하나를 가리킵니다.\n비유: ‘수능 시험’이라는 전체 묶음 속의 ’수학 시험지’ 하나에 해당합니다.\n\n\n\n\n이것이 가장 중요한 부분입니다. ‘수학 시험지’ 한 장은 두 부분으로 구성됩니다.\n\n\n\n정확한 표기: target은 아래 첨자, train은 윗 첨자.\n역할:\n\n이 데이터는 이미 학습이 끝난 ’만능 공부법(\\(\\omega^*\\))’을 개선하는 데 사용되지 않습니다.\n대신, \\(i\\)번째 새로운 문제를 만난 모델이 이 데이터를 딱 몇 번만 보고 “아, 이 문제는 이런 유형이구나!”하고 빠르게 적응(adaptation)하는 데 사용됩니다.\n이 적응 과정을 통해 \\(i\\)번째 문제에만 특화된 모델(\\(\\theta^{*(i)}\\))이 만들어집니다.\n\n비유: 시험 문제에 나오는 &lt;보기&gt; 자료와 같습니다. &lt;보기&gt;를 읽고 문제의 의도를 파악하고 적응하는 것이지, &lt;보기&gt;를 읽는다고 해서 근본적인 국어 실력(\\(\\omega\\))이 오르는 것은 아닙니다.\n\n\n\n\n\n정확한 표기: target은 아래 첨자, test은 윗 첨자.\n역할:\n\n위에서 &lt;보기&gt;(\\(D_{\\text{target}}^{\\text{train}}\\))를 보고 적응을 마친 모델(\\(\\theta^{*(i)}\\))에게 이 문제를 풀게 합니다.\n모델의 답과 정답을 비교하여 최종 성능(정확도)을 채점합니다. 이 점수가 바로 메타 학습기의 \\(i\\)번째 과제에 대한 최종 실력입니다.\n\n비유: &lt;보기&gt;를 참고하여 풀어야 하는 실제 문제 1번, 2번, 3번에 해당합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표기법\n소속 (아래 첨자)\n역할 (윗 첨자)\n비유\n\n\n\n\n\\(\\mathcal{D}_{\\text{target}}\\)\n타겟(Target)\n(없음)\n수능 시험 전체 (최종 평가 목적)\n\n\n\\(D_{\\text{target}}^{\\text{train}}\\)\n타겟(Target)\n훈련(Train)\n시험지 속 &lt;보기&gt; (새로운 유형에 적응)\n\n\n\\(D_{\\text{target}}^{\\text{test}}\\)\n타겟(Target)\n테스트(Test)\n시험지 속 채점 문제 (최종 성능 평가)\n\n\n\n\n\n\n\n이전 섹션의 논의는 다중 과제 시나리오에서 메타러닝의 일반적인 흐름을 설명했지만, 식 (3)의 메타-훈련 단계를 어떻게 풀어야 하는지는 명시하지 않았습니다. 이는 보통 메타-훈련 단계를 이중 최적화(bilevel optimization) 문제로 구성함으로써 수행됩니다. 이 그림은 최적화기 기반(optimizer-based) 방법론(섹션 3.1 참조)에만 정확하게 들어맞는다고 할 수 있지만, 메타러닝의 작동 방식을 더 보편적으로 시각화하는 데 도움이 됩니다. 이중 최적화[40]는 계층적 최적화 문제로, 하나의 최적화가 다른 최적화를 제약 조건으로 포함하는 구조를 의미합니다[17], [41].\n이 표기법을 사용하면, 메타-훈련은 다음과 같이 정형화될 수 있습니다:\n\\[\n\\omega^* = \\arg\\min_{\\omega} \\sum_{i=1}^{M} \\mathcal{L}^{\\text{meta}}(\\theta^{*(i)}(\\omega), \\omega, D_{\\text{source}}^{\\text{val }(i)}) \\quad (5)\n\\]\n\\[\n\\text{s.t. } \\theta^{*(i)}(\\omega) = \\arg\\min_{\\theta} \\mathcal{L}^{\\text{task}}(\\theta, \\omega, D^{\\text{train }(i)}_{\\text{source}}) \\quad (6)\n\\]\n여기서 \\(\\mathcal{L}^{\\text{meta}}\\) 와 \\(\\mathcal{L}^{\\text{task}}\\) 는 각각 외부(outer) 및 내부(inner) 목적 함수를 의미하며, 퓨샷 분류의 경우 교차 엔트로피와 같은 것입니다. 외부와 내부 수준 사이의 리더-팔로워(leader-follower) 비대칭성에 주목하십시오: 내부 수준 최적화인 식 (6)은 외부 수준에서 정의된 학습 전략 \\(\\omega\\)에 따라 조건부로 결정되지만, 자신의 훈련 중에는 \\(\\omega\\)를 변경할 수 없습니다.\n여기서 \\(\\omega\\)는 비볼록(non-convex) 최적화에서의 초기 조건[16], 정규화 강도와 같은 하이퍼파라미터[17], 또는 최적화할 손실 함수 \\(\\mathcal{L}^{\\text{task}}\\)의 매개변수화[42]까지도 나타낼 수 있습니다.\n\n섹션 4.1에서 \\(\\omega\\)에 대한 선택의 공간을 자세히 논의합니다.\n\n외부 수준 최적화는 훈련 후 검증 세트에서 좋은 성능을 보이는 모델 \\(\\theta^{*(i)}(\\omega)\\)를 생성하도록 \\(\\omega\\)를 학습합니다.\n\n섹션 4.2에서는 \\(\\omega\\)를 최적화하는 방법을 자세히 논의합니다.\n섹션 4.3에서는 \\(\\mathcal{L}^{\\text{meta}}\\)가 검증 성능, 학습 속도, 모델 강건성 등 무엇을 측정할 수 있는지 고려합니다.\n\n마지막으로, 위의 정형화는 과제 분포라는 개념을 사용한다는 점에 주목합니다.\n\n이는 메타러닝 문헌에서 일반적이지만, 메타러닝의 필수 조건은 아닙니다.\n\n더 공식적으로, 만약 단일 훈련 및 테스트 데이터셋(\\(M=Q=1\\))이 주어진다면, 우리는 훈련 세트를 분할하여 메타-훈련을 위한 \\(\\mathcal{D}_{\\text{source}} = (D^{\\text{train}}_{\\text{source}},\nD^{\\text{val}}_{\\text{source}})\\) 와 메타-테스트를 위한 \\(\\mathcal{D}_{\\text{target}} = (D^{\\text{train}}_{\\text{source}} \\cup D^{\\text{val}}_{\\text{source}}, D^{\\text{test}}_{\\text{target}})\\)를 얻을 수 있습니다. 우리는 여전히 여러 에피소드에 걸쳐 \\(\\omega\\)를 학습하며, 메타-훈련 중에는 보통 다른 훈련-검증 분할이 사용됩니다.\ncomment\n메타러닝의 작동 방식을 “두 단계로 이루어진 최적화”라는 틀로 설명합니다. 마치 회사에서 팀장(외부 루프)과 팀원(내부 루프)이 협업하는 것과 같습니다.\n\n\n\n내부 최적화 (식 6) - 팀원의 임무:\n\n팀장은 업무 가이드라인(\\(\\omega\\))을 줍니다. (예: “이런 방식으로 초기 모델을 설정해봐”, “학습률은 0.01로 해”)\n팀원은 주어진 가이드라인(\\(\\omega\\))과 훈련 데이터(\\(D^{\\text{train}}\\))를 가지고, 자신의 과제(\\(\\theta\\))를 가장 잘 해결하기 위해 최선을 다합니다.\n중요한 점: 팀원은 팀장이 준 가이드라인(\\(\\omega\\))을 바꿀 수 없습니다. 그냥 따라야 합니다. 그 결과물이 바로 최적의 모델(\\(\\theta^*\\))입니다.\n\n외부 최적화 (식 5) - 팀장의 임무:\n\n팀장은 팀원이 과제를 수행한 결과물(\\(\\theta^*\\))을 가져와서 실전 테스트(\\(D^{\\text{val}}\\))를 해봅니다.\n테스트 결과(성능)를 보고, “내가 처음에 줬던 가이드라인(\\(\\omega\\))이 과연 최선이었을까?”를 고민합니다.\n목표: 팀원의 최종 성과(\\(\\mathcal{L}^{\\text{meta}}\\))가 가장 좋아지도록, 최초의 가이드라인(\\(\\omega\\)) 자체를 수정하고 개선합니다. 이것이 바로 팀장의 최적화, 즉 메타러닝입니다.\n\n\n\n\n\n팀장이 주는 가이드라인(\\(\\omega\\))은 여러 형태일 수 있습니다. * 초기 조건: “업무를 이 지점(\\(\\theta_0\\))에서 시작하면 가장 빨리 끝낼 수 있을 거야.” (MAML 방식) * 하이퍼파라미터: “이 업무는 꼼꼼함(정규화)이 중요하니, 정규화 강도를 0.5로 설정해.” * 손실 함수: “이 업무의 목표는 단순히 정확도를 높이는 게 아니라, 안정성도 고려해야 해.” 라며 목표 자체를 재정의해 줌.\n\n\n\n\n보통 메타러닝은 여러 팀(과제)의 성과를 보고 최고의 가이드라인을 찾지만, 꼭 그럴 필요는 없습니다.\n단 하나의 매우 중요한 프로젝트(single task)가 있다면, 프로젝트를 여러 단계로 나누고 각 단계마다 팀원이 업무를 수행하게 한 뒤, 그 결과를 보고 팀장이 계속해서 가이드라인을 수정해주는 방식도 가능합니다. 이것이 ‘단일 과제 메타러닝’입니다.\n\n\n\n\n\n앞서 살펴본 바와 같이, 식 (5)-(6)과 같은 명시적인 반복 최적화를 통하지 않고, 피드-포워드 방식으로 모델을 합성하는 여러 메타러닝 접근법이 있습니다. 이들은 복잡도에 차이가 있지만, 이 접근법 계열을 이해하기 위해서는 식 (2)의 추상적인 목표를 구체화하여 선형 회귀 메타-훈련을 위한 간단한 예시[43]를 정의하는 것이 도움이 될 수 있습니다.\n\\[\\min_{\\omega} \\underset{(\\mathcal{D}^{tr}, \\mathcal{D}^{val}) \\in \\mathcal{T}}{\\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})}} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}^{val}} \\left[ (\\mathbf{x}^T \\mathbf{g}_{\\omega}(\\mathcal{D}^{tr}) - y)^2 \\right] \\quad (7)\\]\n여기서 우리는 과제 분포에 대해 메타-훈련을 수행합니다. 각 과제에 대해 훈련 세트와 검증 세트가 주어집니다.\n\n훈련 세트 \\(D^{\\text{tr}}\\)은 벡터 \\(g_\\omega\\)로 임베딩[44]되며, 이 벡터는 검증 세트의 예시 \\(x\\)를 예측하기 위한 선형 회귀 가중치를 정의합니다.\n식 (7)을 최적화하는 것은 함수 \\(g_\\omega\\)가 훈련 세트를 가중치 벡터로 매핑하도록 훈련함으로써 ’학습하는 법을 배우는 것’입니다.\n따라서 \\(g_\\omega\\)는 \\(p(\\mathcal{T})\\)에서 추출된 새로운 메타-테스트 과제 \\(^{\\text{te}}\\)에 대해서도 좋은 해법을 제공해야 합니다. 이 계열의 방법들은 사용되는 예측 모델 \\(g\\)의 복잡성과 서포트셋이 어떻게 임베딩되는지(예: 풀링, CNN, RNN 사용)[44]에 따라 다양합니다.\n\n이러한 모델들은 상각(amortized)[45] 모델로도 알려져 있는데, 이는 새로운 과제를 학습하는 비용이 \\(g_\\omega(\\cdot)\\)를 통한 피드-포워드 연산 한 번으로 줄어들기 때문입니다. 반복 최적화에 드는 비용은 이미 \\(\\omega\\)의 메타-훈련 중에 지불되었습니다.\ncomments\n이 섹션은 이전의 ‘이중 최적화’ 방식과는 완전히 다른, 매우 빠르고 효율적인 메타러닝 방식을 설명합니다.\n\n\n\n새로운 문제가 주어질 때마다, 내부 루프에서 느린 최적화 과정(경사 하강법 등)을 여러 번 반복해야 합니다.\n비유: 학생이 새로운 수학 문제를 만날 때마다, 공책에 여러 번 계산을 반복하며 풀어야 합니다.\n\n\n\n\n\n“느린 반복 계산 과정을 없애버리고, 그냥 문제를 척 보면 바로 답이 나오는 ‘만능 공식 생성기’(\\(g_\\omega\\))를 만들자!”\n비유: 학생이 문제 유형과 주어진 숫자들을 ’만능 공식 생성기’에 넣으면, 계산 과정 없이 바로 그 문제에 맞는 ’최적의 공식’이 튀어나오고, 그 공식으로 답을 구합니다.\n\n\n\n\n\\[\\min_{\\omega} \\underset{(\\mathcal{D}^{tr}, \\mathcal{D}^{val}) \\in \\mathcal{T}}{\\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})}} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}^{val}} \\left[ (\\mathbf{x}^T \\mathbf{g}_{\\omega}(\\mathcal{D}^{tr}) - y)^2 \\right] \\quad (7)\\]\n\n\\(D^{\\text{tr}}\\) (훈련 세트): 학생에게 주어진 ‘참고 예제’ 데이터입니다.\n\\(g_{\\omega}(D^{\\text{tr}})\\): 이것이 바로 ‘만능 공식 생성기’입니다. 이 함수(\\(g\\))는 참고 예제 데이터(\\(D^{\\text{tr}}\\))를 입력으로 받아서, 이 문제를 푸는 데 필요한 최적의 모델 파라미터(가중치)를 한 방에(피드-포워드 연산으로) 출력합니다.\n\\(x^T g_{\\omega}(D^{\\text{tr}})\\): ’만능 공식 생성기’가 만들어준 공식(\\(g_{\\omega}(D^{\\text{tr}})\\))을 가지고 실제 문제(\\(x\\))를 푸는 과정입니다.\n\\(( \\dots - y)^2\\): 예측값과 실제 정답(\\(y\\)) 사이의 오차입니다.\n전체 의미: 여러 종류의 과제에 대해, “주어진 참고 예제(\\(D^{\\text{tr}}\\))를 보고 최적의 공식(\\(g_{\\omega}(D^{\\text{tr}})\\))을 한 번에 만들어내는 생성기(\\(g_\\omega\\))를 훈련시켜라! 이 생성기는 어떤 문제가 주어져도 항상 좋은 공식을 만들어내야 한다.”\n\n\n\n\n\n‘상각(Amortize)’은 회계 용어로, 큰 비용을 여러 기간에 걸쳐 나누어 처리한다는 의미입니다.\n메타러닝에서 이 용어는, 가장 비용이 많이 드는 ‘느린 반복 최적화’ 과정을 메타-훈련 때 미리 다 해치워버리고(\\(\\omega\\)를 학습), 정작 새로운 문제를 풀 때는 그 비용을 거의 치르지 않는다는 의미에서 사용됩니다.\n메타-훈련 (비용이 비쌈): 수많은 과제를 풀어보며 ‘만능 공식 생성기’(\\(g_\\omega\\))를 만드는 데는 엄청난 시간과 계산이 필요합니다. (비용을 미리 지불)\n메타-테스트 (비용이 거의 0): 일단 생성기만 만들어지면, 새로운 문제는 그냥 함수에 데이터 한 번 넣는 것으로 끝나므로 거의 즉시 해결됩니다. (미리 지불한 비용의 혜택을 봄)\n\n이 피드-포워드 방식은 특히 새로운 문제에 대한 반응 속도가 매우 빨라야 하는 응용 분야에 매우 유용합니다."
  },
  {
    "objectID": "posts/20251113_1.html#초록",
    "href": "posts/20251113_1.html#초록",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "Learning-to-learn이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 학습 알고리즘 자체를 개선하는 것을 목표로 합니다. 이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다. 본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다. 먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다. 다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다. 또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다. 마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다."
  },
  {
    "objectID": "posts/20251113_1.html#introduction",
    "href": "posts/20251113_1.html#introduction",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음\n\nMeta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.\n\n\nprovides an alternative paradigm?\n\n\n기존 방식?\n기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.\n\n대안(메타러닝):\n기계에게 숙제 하나만 주는 게 아니라, “스스로 공부하는 법”을 터득하게 만들자!\n\n\na machine learning model gains experience over multiple learning episodes\n\n\n비유를 해보자면\n사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 여러 과목의 문제(관련된 과제들)를 풀게 하는 행위랑 비슷함.\n이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 ‘요령(패턴)’을 깨닫게 됨. 이것이 바로 “경험”이라고 할 수 있음.\nlearning episodes: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.\n\n보통의 경우에, 그리고 역사적으로 보면,\n\n머신러닝\n\n\n\n기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.\n\nhand-engineered features\n\n\n그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.\n\n이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.\n\n\n즉, 머신러닝에서 특징 추출 단계와 모델 학습 단계는 분리 되어 있음.\n\n\n딥러닝\n\n\n\n위 머신러닝의 두 단계인 특징 추출 단계와 모델 학습 단계를 하나의 단계로 통합해버림.\n\n특징과 모델의 공동 학습 (Joint feature and model learning)\n\n\n예전 처럼 특징을 정성스럽게 추출할 필요가 없음.\n\n원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,\n\n모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.\n\n\n고양이 사진 분류하는 모델을 예로 들어보면…\n\n초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.\n\n중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.\n\n후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.\n\n어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.\n\n사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.\n이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.\n\n\n신경망에서의 메타러닝?\n\n\n특징 추출 단계, 모델 학습 단계, 그리고 알고리즘을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.\n\nThrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.\n\nThrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.\n해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 \n\n\n학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,\n즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.\n\n\ntask family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.\n\n예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 “동물 분류”라는 하나의 task family에 속합니다.\n\nAI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.\n즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.\n\n\n\nconventional machine learning performance improves as more data from a single task is seen\n\n\n기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.\n\n공짜 점심은 없다(no free lunch) Theorem 에 대항하는 알고리즘 ㅋㅋ\n\nThis perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.\n\n\n이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.\n\n\nHowever, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.\n\n\n하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.\n\n\n“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.\n\n이 논문이 Review하려고 하는 대상 논문?\n\n본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.\n\n참고문헌 [27], [28]에 따라 ‘알고리즘 학습’으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.\n이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.\n\n본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.\n\n먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다\n그런 다음, 메타-표현(meta-representation), 메타-목적(meta-objective), 메타-최적화기(meta-optimizer)라는 관점에서 새로운 분류 체계를 제공할 것입니다.\n이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 설계 공간(design-space)을 제시합니다.\n우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.\n마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다."
  },
  {
    "objectID": "posts/20251113_1.html#배경",
    "href": "posts/20251113_1.html#배경",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.\n\n이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.\n\n\n\n‘학습하는 방법을 학습하는 것(learning to learn)’\n\n이는 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미함.\n기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.\n기반 학습(base learning) 중에는 내부(inner) (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임\n\n메타러닝 중에는 외부(outer)(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.\n\n예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.\n(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.\n\n\ninner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.\n\n\n\n메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?\n\n위에 정의된 대로라면, Cross Validtion을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.\n\n\n\n\n명시적으로 정의된 메타 수준의 목적 함수이 있고,\n\n이 목적 함수에 대한 내부 알고리즘의 end-to-end 최적화가 이루어짐.\n\n\n\n\n\n\n\n기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 \\(D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}\\)이 주어짐.\n\\(\\theta\\)로 매개변수화된 예측 모델 \\(\\hat{y} = f_{\\theta}(x)\\)를 다음 식을 풀어 훈련시키게 됨:\n\\[\n\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(D; \\theta, \\omega) \\quad (1)\n\\]\n\n\\(\\mathcal{L}\\)은 실제 레이블과 \\(f_{\\theta}(\\cdot)\\)가 예측한 값 사이의 오차를 측정하는 손실 함수.\n\\(\\omega\\)라는 조건이 걸려 있음.\n\n이는 학습하는 방법 \\(\\omega\\)에 따라 이 식(1)의 해인 \\(\\theta\\)가 달라질 수 있다는 의미임.\n\n\\(\\omega\\) 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.\n\n일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.\n\n\n\n\n최적화 과정이 모든 문제 \\(D\\)에 대해 매번 처음부터 수행됨(from scratch)\n\n학습 방법 \\(\\omega\\)는 사전에 지정됨.\n\n이때, \\(\\omega\\)의 specification, 즉 학습 방법을 어떻게 정하느냐는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.\n\n메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 사전에 지정하고 고정하는 대신 학습 알고리즘 자체를 학습하게 됨.\nSpecification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음\n\n최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?\n학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?\n모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?\n정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?\n\n\n\n\n\n\n\n메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,\n이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 범용 학습 알고리즘을 학습하자.\n\nNotation\n\n\\(p(\\mathcal{T})\\): 과제들의 분포\n\\(\\omega\\): 어떤 학습 방법\n\\(\\mathcal{T} = \\{D, L\\}\\): 어떤 과제(\\(\\mathcal{T}\\))는 데이터셋(\\(D\\))과 손실 함수(\\(L\\))의 조합이다.\n\\(D\\): 데이터 셋\n\\(\\mathcal{L}(D, \\omega)\\): 데이터 셋 \\(D\\)에서 학습 방법 \\(\\omega\\)를 사용해 훈련했을 때의 loss 값\n\n위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.\n\\[\n\\min_{\\omega} \\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})} \\mathcal{L}(D; \\omega) \\quad (2)\n\\]\n‘학습 방법’, 즉 \\(\\omega\\)는 과제 전반의 지식(across-task knowledge) 또는 메타 지식(meta-knowledge) 이라고 할 수 있음.\n식 (2)를 실제로 해결하려면?\n\n목표: 세상의 모든 과제 분포 \\(p(\\mathcal{T})\\)에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 \\(\\omega\\)를 찾자!\n\n현실: 모든 과제 분포의 모든 문제인 \\(p(\\mathcal{T})\\)를 다룰 수는 없음.\n타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 \\(p(\\mathcal{T})\\)를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)\n\nNotation 2\n\\(\\mathcal{D}_{\\text{source}} = \\{(D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})^{(i)}\\}_{i=1}^M\\)\n\n메타-훈련(meta-training)에 사용할 전체 데이터셋을 나타내는 기호.\n\n하나씩 뜯어보면\n\n\\(\\mathcal{D}_{\\text{source}}\\) : ‘소스 데이터셋(Source Dataset)’이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 원천(Source)이 된다는 의미. 즉, “훈련용”이라는 뜻.\n\\(M\\): 우리가 가지고 있는 훈련용 과제(task)의 총 개수. (예: 50개의 다른 종류의 동물 분류 문제)\n\\(\\{ \\dots \\}_{i=1}^M\\): 괄호 안의 내용이 1번부터 M번까지 M개가 있다는 뜻.\n\\(( \\dots )^{(i)}\\): 그중에서 i번째 과제를 의미. (예: 50개 중 17번째 과제)\n\\((D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})\\): 하나의 과제(\\(i\\))가 두 종류의 데이터로 구성되어 있다는 뜻.\n\n\\(D_{\\text{train}}^{\\text{source}}\\): ‘훈련용’ 데이터(train data). 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 서포트셋(support set)이라고 함.\n\\(D_{\\text{val}}^{\\text{source}}\\): ‘검증용’ 데이터(validation data). 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 쿼리셋(query set)이라고 함.\n\n\n\n“\\(\\mathcal{D}_{\\text{source}}\\)란, 총 M개의 훈련용 과제 묶음인데, 각 과제\\(i\\)는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”\n\n아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n또, 식을 하나씩 요소별로 뜯어보자.\n\n\\(\\omega\\) (오메가): 우리가 찾고 싶은 ‘학습 방법’ 또는 ‘공부법’\n\\(\\omega^{\\ast}\\) (오메가 스타): 수많은 가능한 공부법(\\(\\omega\\)) 중에서 우리가 찾아낸 최고의(optimal) 공부법을 의미함.\n\\(\\arg\\max_{\\omega}\\): “괄호 안의 값을 최대(max)로 만드는 \\(\\omega\\)를 찾아라(arg)”라는 명령어.\n\\(p(\\omega|\\mathcal{D}_{\\text{source}})\\): 사후 확률(posterior probability).\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 관찰했을 때, 어떤 공부법(\\(\\omega\\))이 가장 그럴듯한가(정답일 확률이 높은가)?”.\n\n\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(\\(\\omega\\))을 찾아서, 그것을 우리의 최종 학습법(\\(\\omega^{\\ast}\\))으로 삼아라!“\n\n이제 메타-테스트 단계에서 사용되는 \\(Q\\)개의 타겟 과제(target tasks) 집합을 \\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{target}}^{\\text{train}}, D_{\\text{target}}^{\\text{test}})^{(i)}\\}_{i=1}^Q\\) 로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 \\(\\omega^*\\)를 사용하여 이전에 보지 못한 각 타겟 과제 \\(i\\)에 대한 기반 모델을 훈련합니다:\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{target}}^{\\text{train }(i)}) \\quad (4)\n\\]\n식 (1)의 기존 학습과 대조적으로, 타겟 과제 \\(i\\)의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 \\(\\omega^*\\)의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 \\(D_{\\text{test}}^{\\text{target}}(i)\\)에 대한 \\(\\theta^{*(i)}\\)의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.\n이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 메타-과소적합(meta-underfitting) 과 메타-과적합(meta-overfitting) 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 \\(\\theta\\)를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 \\(\\omega\\)를 학습하는 것으로 볼 수 있습니다.\n다음 섹션 넘어가기 전 수식 해설:\n\\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{target}}^{\\text{train}}, D_{\\text{target}}^{\\text{test}})^{(i)}\\}_{i=1}^Q\\)\n이 수식은 메타-테스팅(Meta-Testing) 단계, 즉 최종 실력을 평가하는 데 사용되는 “실전 시험 문제지 묶음” 전체를 정의합니다.\n이 구조를 세 단계로 나누어 이해하면 가장 쉽습니다.\n\n\n\n이름: 타겟 데이터셋 (The Target Dataset)\n역할: 메타-훈련을 통해 학습된 ’만능 공부법(\\(\\omega^*\\))’이 얼마나 효과적인지 최종적으로 평가하기 위한 전체 시험 문제들의 집합입니다.\n표기 규칙: target이 아래 첨자(subscript)로 붙어, 이 데이터셋 묶음의 소속(Group)이 ’소스(훈련용)’가 아닌 ’타겟(시험용)’임을 나타냅니다.\n\n\n\n\n\n이름: i번째 타겟 과제 (The i-th Target Task)\n역할: 전체 시험지 묶음(\\(\\mathcal{D}_{\\text{target}}\\))은 총 Q개의 개별 시험 문제(과제)로 이루어져 있습니다. 이 표기는 그중 i번째 시험 문제 하나를 가리킵니다.\n비유: ‘수능 시험’이라는 전체 묶음 속의 ’수학 시험지’ 하나에 해당합니다.\n\n\n\n\n이것이 가장 중요한 부분입니다. ‘수학 시험지’ 한 장은 두 부분으로 구성됩니다.\n\n\n\n정확한 표기: target은 아래 첨자, train은 윗 첨자.\n역할:\n\n이 데이터는 이미 학습이 끝난 ’만능 공부법(\\(\\omega^*\\))’을 개선하는 데 사용되지 않습니다.\n대신, \\(i\\)번째 새로운 문제를 만난 모델이 이 데이터를 딱 몇 번만 보고 “아, 이 문제는 이런 유형이구나!”하고 빠르게 적응(adaptation)하는 데 사용됩니다.\n이 적응 과정을 통해 \\(i\\)번째 문제에만 특화된 모델(\\(\\theta^{*(i)}\\))이 만들어집니다.\n\n비유: 시험 문제에 나오는 &lt;보기&gt; 자료와 같습니다. &lt;보기&gt;를 읽고 문제의 의도를 파악하고 적응하는 것이지, &lt;보기&gt;를 읽는다고 해서 근본적인 국어 실력(\\(\\omega\\))이 오르는 것은 아닙니다.\n\n\n\n\n\n정확한 표기: target은 아래 첨자, test은 윗 첨자.\n역할:\n\n위에서 &lt;보기&gt;(\\(D_{\\text{target}}^{\\text{train}}\\))를 보고 적응을 마친 모델(\\(\\theta^{*(i)}\\))에게 이 문제를 풀게 합니다.\n모델의 답과 정답을 비교하여 최종 성능(정확도)을 채점합니다. 이 점수가 바로 메타 학습기의 \\(i\\)번째 과제에 대한 최종 실력입니다.\n\n비유: &lt;보기&gt;를 참고하여 풀어야 하는 실제 문제 1번, 2번, 3번에 해당합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표기법\n소속 (아래 첨자)\n역할 (윗 첨자)\n비유\n\n\n\n\n\\(\\mathcal{D}_{\\text{target}}\\)\n타겟(Target)\n(없음)\n수능 시험 전체 (최종 평가 목적)\n\n\n\\(D_{\\text{target}}^{\\text{train}}\\)\n타겟(Target)\n훈련(Train)\n시험지 속 &lt;보기&gt; (새로운 유형에 적응)\n\n\n\\(D_{\\text{target}}^{\\text{test}}\\)\n타겟(Target)\n테스트(Test)\n시험지 속 채점 문제 (최종 성능 평가)\n\n\n\n\n\n\n\n이전 섹션의 논의는 다중 과제 시나리오에서 메타러닝의 일반적인 흐름을 설명했지만, 식 (3)의 메타-훈련 단계를 어떻게 풀어야 하는지는 명시하지 않았습니다. 이는 보통 메타-훈련 단계를 이중 최적화(bilevel optimization) 문제로 구성함으로써 수행됩니다. 이 그림은 최적화기 기반(optimizer-based) 방법론(섹션 3.1 참조)에만 정확하게 들어맞는다고 할 수 있지만, 메타러닝의 작동 방식을 더 보편적으로 시각화하는 데 도움이 됩니다. 이중 최적화[40]는 계층적 최적화 문제로, 하나의 최적화가 다른 최적화를 제약 조건으로 포함하는 구조를 의미합니다[17], [41].\n이 표기법을 사용하면, 메타-훈련은 다음과 같이 정형화될 수 있습니다:\n\\[\n\\omega^* = \\arg\\min_{\\omega} \\sum_{i=1}^{M} \\mathcal{L}^{\\text{meta}}(\\theta^{*(i)}(\\omega), \\omega, D_{\\text{source}}^{\\text{val }(i)}) \\quad (5)\n\\]\n\\[\n\\text{s.t. } \\theta^{*(i)}(\\omega) = \\arg\\min_{\\theta} \\mathcal{L}^{\\text{task}}(\\theta, \\omega, D^{\\text{train }(i)}_{\\text{source}}) \\quad (6)\n\\]\n여기서 \\(\\mathcal{L}^{\\text{meta}}\\) 와 \\(\\mathcal{L}^{\\text{task}}\\) 는 각각 외부(outer) 및 내부(inner) 목적 함수를 의미하며, 퓨샷 분류의 경우 교차 엔트로피와 같은 것입니다. 외부와 내부 수준 사이의 리더-팔로워(leader-follower) 비대칭성에 주목하십시오: 내부 수준 최적화인 식 (6)은 외부 수준에서 정의된 학습 전략 \\(\\omega\\)에 따라 조건부로 결정되지만, 자신의 훈련 중에는 \\(\\omega\\)를 변경할 수 없습니다.\n여기서 \\(\\omega\\)는 비볼록(non-convex) 최적화에서의 초기 조건[16], 정규화 강도와 같은 하이퍼파라미터[17], 또는 최적화할 손실 함수 \\(\\mathcal{L}^{\\text{task}}\\)의 매개변수화[42]까지도 나타낼 수 있습니다.\n\n섹션 4.1에서 \\(\\omega\\)에 대한 선택의 공간을 자세히 논의합니다.\n\n외부 수준 최적화는 훈련 후 검증 세트에서 좋은 성능을 보이는 모델 \\(\\theta^{*(i)}(\\omega)\\)를 생성하도록 \\(\\omega\\)를 학습합니다.\n\n섹션 4.2에서는 \\(\\omega\\)를 최적화하는 방법을 자세히 논의합니다.\n섹션 4.3에서는 \\(\\mathcal{L}^{\\text{meta}}\\)가 검증 성능, 학습 속도, 모델 강건성 등 무엇을 측정할 수 있는지 고려합니다.\n\n마지막으로, 위의 정형화는 과제 분포라는 개념을 사용한다는 점에 주목합니다.\n\n이는 메타러닝 문헌에서 일반적이지만, 메타러닝의 필수 조건은 아닙니다.\n\n더 공식적으로, 만약 단일 훈련 및 테스트 데이터셋(\\(M=Q=1\\))이 주어진다면, 우리는 훈련 세트를 분할하여 메타-훈련을 위한 \\(\\mathcal{D}_{\\text{source}} = (D^{\\text{train}}_{\\text{source}},\nD^{\\text{val}}_{\\text{source}})\\) 와 메타-테스트를 위한 \\(\\mathcal{D}_{\\text{target}} = (D^{\\text{train}}_{\\text{source}} \\cup D^{\\text{val}}_{\\text{source}}, D^{\\text{test}}_{\\text{target}})\\)를 얻을 수 있습니다. 우리는 여전히 여러 에피소드에 걸쳐 \\(\\omega\\)를 학습하며, 메타-훈련 중에는 보통 다른 훈련-검증 분할이 사용됩니다.\ncomment\n메타러닝의 작동 방식을 “두 단계로 이루어진 최적화”라는 틀로 설명합니다. 마치 회사에서 팀장(외부 루프)과 팀원(내부 루프)이 협업하는 것과 같습니다.\n\n\n\n내부 최적화 (식 6) - 팀원의 임무:\n\n팀장은 업무 가이드라인(\\(\\omega\\))을 줍니다. (예: “이런 방식으로 초기 모델을 설정해봐”, “학습률은 0.01로 해”)\n팀원은 주어진 가이드라인(\\(\\omega\\))과 훈련 데이터(\\(D^{\\text{train}}\\))를 가지고, 자신의 과제(\\(\\theta\\))를 가장 잘 해결하기 위해 최선을 다합니다.\n중요한 점: 팀원은 팀장이 준 가이드라인(\\(\\omega\\))을 바꿀 수 없습니다. 그냥 따라야 합니다. 그 결과물이 바로 최적의 모델(\\(\\theta^*\\))입니다.\n\n외부 최적화 (식 5) - 팀장의 임무:\n\n팀장은 팀원이 과제를 수행한 결과물(\\(\\theta^*\\))을 가져와서 실전 테스트(\\(D^{\\text{val}}\\))를 해봅니다.\n테스트 결과(성능)를 보고, “내가 처음에 줬던 가이드라인(\\(\\omega\\))이 과연 최선이었을까?”를 고민합니다.\n목표: 팀원의 최종 성과(\\(\\mathcal{L}^{\\text{meta}}\\))가 가장 좋아지도록, 최초의 가이드라인(\\(\\omega\\)) 자체를 수정하고 개선합니다. 이것이 바로 팀장의 최적화, 즉 메타러닝입니다.\n\n\n\n\n\n팀장이 주는 가이드라인(\\(\\omega\\))은 여러 형태일 수 있습니다. * 초기 조건: “업무를 이 지점(\\(\\theta_0\\))에서 시작하면 가장 빨리 끝낼 수 있을 거야.” (MAML 방식) * 하이퍼파라미터: “이 업무는 꼼꼼함(정규화)이 중요하니, 정규화 강도를 0.5로 설정해.” * 손실 함수: “이 업무의 목표는 단순히 정확도를 높이는 게 아니라, 안정성도 고려해야 해.” 라며 목표 자체를 재정의해 줌.\n\n\n\n\n보통 메타러닝은 여러 팀(과제)의 성과를 보고 최고의 가이드라인을 찾지만, 꼭 그럴 필요는 없습니다.\n단 하나의 매우 중요한 프로젝트(single task)가 있다면, 프로젝트를 여러 단계로 나누고 각 단계마다 팀원이 업무를 수행하게 한 뒤, 그 결과를 보고 팀장이 계속해서 가이드라인을 수정해주는 방식도 가능합니다. 이것이 ‘단일 과제 메타러닝’입니다.\n\n\n\n\n\n앞서 살펴본 바와 같이, 식 (5)-(6)과 같은 명시적인 반복 최적화를 통하지 않고, 피드-포워드 방식으로 모델을 합성하는 여러 메타러닝 접근법이 있습니다. 이들은 복잡도에 차이가 있지만, 이 접근법 계열을 이해하기 위해서는 식 (2)의 추상적인 목표를 구체화하여 선형 회귀 메타-훈련을 위한 간단한 예시[43]를 정의하는 것이 도움이 될 수 있습니다.\n\\[\\min_{\\omega} \\underset{(\\mathcal{D}^{tr}, \\mathcal{D}^{val}) \\in \\mathcal{T}}{\\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})}} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}^{val}} \\left[ (\\mathbf{x}^T \\mathbf{g}_{\\omega}(\\mathcal{D}^{tr}) - y)^2 \\right] \\quad (7)\\]\n여기서 우리는 과제 분포에 대해 메타-훈련을 수행합니다. 각 과제에 대해 훈련 세트와 검증 세트가 주어집니다.\n\n훈련 세트 \\(D^{\\text{tr}}\\)은 벡터 \\(g_\\omega\\)로 임베딩[44]되며, 이 벡터는 검증 세트의 예시 \\(x\\)를 예측하기 위한 선형 회귀 가중치를 정의합니다.\n식 (7)을 최적화하는 것은 함수 \\(g_\\omega\\)가 훈련 세트를 가중치 벡터로 매핑하도록 훈련함으로써 ’학습하는 법을 배우는 것’입니다.\n따라서 \\(g_\\omega\\)는 \\(p(\\mathcal{T})\\)에서 추출된 새로운 메타-테스트 과제 \\(^{\\text{te}}\\)에 대해서도 좋은 해법을 제공해야 합니다. 이 계열의 방법들은 사용되는 예측 모델 \\(g\\)의 복잡성과 서포트셋이 어떻게 임베딩되는지(예: 풀링, CNN, RNN 사용)[44]에 따라 다양합니다.\n\n이러한 모델들은 상각(amortized)[45] 모델로도 알려져 있는데, 이는 새로운 과제를 학습하는 비용이 \\(g_\\omega(\\cdot)\\)를 통한 피드-포워드 연산 한 번으로 줄어들기 때문입니다. 반복 최적화에 드는 비용은 이미 \\(\\omega\\)의 메타-훈련 중에 지불되었습니다.\ncomments\n이 섹션은 이전의 ‘이중 최적화’ 방식과는 완전히 다른, 매우 빠르고 효율적인 메타러닝 방식을 설명합니다.\n\n\n\n새로운 문제가 주어질 때마다, 내부 루프에서 느린 최적화 과정(경사 하강법 등)을 여러 번 반복해야 합니다.\n비유: 학생이 새로운 수학 문제를 만날 때마다, 공책에 여러 번 계산을 반복하며 풀어야 합니다.\n\n\n\n\n\n“느린 반복 계산 과정을 없애버리고, 그냥 문제를 척 보면 바로 답이 나오는 ‘만능 공식 생성기’(\\(g_\\omega\\))를 만들자!”\n비유: 학생이 문제 유형과 주어진 숫자들을 ’만능 공식 생성기’에 넣으면, 계산 과정 없이 바로 그 문제에 맞는 ’최적의 공식’이 튀어나오고, 그 공식으로 답을 구합니다.\n\n\n\n\n\\[\\min_{\\omega} \\underset{(\\mathcal{D}^{tr}, \\mathcal{D}^{val}) \\in \\mathcal{T}}{\\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})}} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}^{val}} \\left[ (\\mathbf{x}^T \\mathbf{g}_{\\omega}(\\mathcal{D}^{tr}) - y)^2 \\right] \\quad (7)\\]\n\n\\(D^{\\text{tr}}\\) (훈련 세트): 학생에게 주어진 ‘참고 예제’ 데이터입니다.\n\\(g_{\\omega}(D^{\\text{tr}})\\): 이것이 바로 ‘만능 공식 생성기’입니다. 이 함수(\\(g\\))는 참고 예제 데이터(\\(D^{\\text{tr}}\\))를 입력으로 받아서, 이 문제를 푸는 데 필요한 최적의 모델 파라미터(가중치)를 한 방에(피드-포워드 연산으로) 출력합니다.\n\\(x^T g_{\\omega}(D^{\\text{tr}})\\): ’만능 공식 생성기’가 만들어준 공식(\\(g_{\\omega}(D^{\\text{tr}})\\))을 가지고 실제 문제(\\(x\\))를 푸는 과정입니다.\n\\(( \\dots - y)^2\\): 예측값과 실제 정답(\\(y\\)) 사이의 오차입니다.\n전체 의미: 여러 종류의 과제에 대해, “주어진 참고 예제(\\(D^{\\text{tr}}\\))를 보고 최적의 공식(\\(g_{\\omega}(D^{\\text{tr}})\\))을 한 번에 만들어내는 생성기(\\(g_\\omega\\))를 훈련시켜라! 이 생성기는 어떤 문제가 주어져도 항상 좋은 공식을 만들어내야 한다.”\n\n\n\n\n\n‘상각(Amortize)’은 회계 용어로, 큰 비용을 여러 기간에 걸쳐 나누어 처리한다는 의미입니다.\n메타러닝에서 이 용어는, 가장 비용이 많이 드는 ‘느린 반복 최적화’ 과정을 메타-훈련 때 미리 다 해치워버리고(\\(\\omega\\)를 학습), 정작 새로운 문제를 풀 때는 그 비용을 거의 치르지 않는다는 의미에서 사용됩니다.\n메타-훈련 (비용이 비쌈): 수많은 과제를 풀어보며 ‘만능 공식 생성기’(\\(g_\\omega\\))를 만드는 데는 엄청난 시간과 계산이 필요합니다. (비용을 미리 지불)\n메타-테스트 (비용이 거의 0): 일단 생성기만 만들어지면, 새로운 문제는 그냥 함수에 데이터 한 번 넣는 것으로 끝나므로 거의 즉시 해결됩니다. (미리 지불한 비용의 혜택을 봄)\n\n이 피드-포워드 방식은 특히 새로운 문제에 대한 반응 속도가 매우 빨라야 하는 응용 분야에 매우 유용합니다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kim Hanwool",
    "section": "",
    "text": "졸업하고 싶은 대학원생의 몸부림 기록 일지"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "master_paper",
    "section": "",
    "text": "Posts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypernetworks\n\n\n\nMetaLearning\n\nReview\n\nHypernetworks\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 16, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nSuccessive model-agnostic meta-learning for few-shot fault time series prognosis\n\n\n\nMetaLearning\n\nSurvey\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 15, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n\n\n\nMetaLearning\n\nMAML\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMeta Learning in Neural Networks — A Survey\n\n\n\nMetaLearning\n\nSurvey\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n이상치 탐지 with Uncertainty?\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\nMoE\n\nVAE\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts But VAE - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\nMoE\n\nVAE\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nPaper\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+MetaLearning\n\n\n\nBayesian\n\nMetaLearning\n\nIdea\n\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+MetaLearning\n\n\n\nBayesian\n\nMetaLearning\n\nIdea\n\nPaper\n\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20251114_1.html",
    "href": "posts/20251114_1.html",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "",
    "text": "@inproceedings{finn2017model,\n  title={Model-agnostic meta-learning for fast adaptation of deep networks},\n  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},\n  booktitle={International conference on machine learning},\n  pages={1126--1135},\n  year={2017},\n  organization={PMLR}\n}"
  },
  {
    "objectID": "posts/20251114_1.html#인간-지능의-핵심적인-특징과-ai-agent에게-바라는-것",
    "href": "posts/20251114_1.html#인간-지능의-핵심적인-특징과-ai-agent에게-바라는-것",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "인간 지능의 핵심적인 특징과 AI agent에게 바라는 것",
    "text": "인간 지능의 핵심적인 특징과 AI agent에게 바라는 것\n\n적은 수의 예시만으로 사물을 인식하거나, 단 몇 분의 경험만으로 새로운 기술을 습득하는 등, 빠르게 학습하는 능력\n우리가 만드는 인공 에이전트 역시 인간의 지능과 같은 특징을 가지면 좋다.\n\n즉, 소수의 예시만으로도 신속하게 학습하고 적응하며, 더 많은 데이터가 주어짐에 따라 지속적으로 적응해 나가야 함."
  },
  {
    "objectID": "posts/20251114_1.html#빠르고-유연한-학습은-어려운-과제",
    "href": "posts/20251114_1.html#빠르고-유연한-학습은-어려운-과제",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "빠르고 유연한 학습은 어려운 과제",
    "text": "빠르고 유연한 학습은 어려운 과제\n\n에이전트는 새로운 데이터에 과적합(overfitting)되는 것을 피해야 하고,\n기존의 경험을 소량의 새로운 정보와 통합해야 한다.\n더욱이, 사전 경험(prior experiments)과 새로운 데이터의 형태는 과제(task)에 따라 달라진다.\n\n따라서 최대한의 적용 가능성을 확보하기 위해서는, ’학습하는 방법을 학습’하는 메커니즘(즉, 메타 러닝)이 특정 과제나 연산 형태에 국한되지 않고 범용적(general)이어야 합니다."
  },
  {
    "objectID": "posts/20251114_1.html#제안-모델에-구애받지-않는model-agnostic-메타-러닝-알고리즘",
    "href": "posts/20251114_1.html#제안-모델에-구애받지-않는model-agnostic-메타-러닝-알고리즘",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "제안: 모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘",
    "text": "제안: 모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘\n\n경사 하강법(gradient descent)으로 훈련되는 어떠한 학습 문제와 모델에도 직접 적용될 수 있다는 의미.\n심층 신경망 모델(deep neural network models)에 초점을 맞추고 있긴 하지만, 본 논문이 제안하는 접근법(MAML)은 최소한의 수정만으로도 분류, 회귀, 정책 경사(policy gradient) 강화학습 등 다양한 아키텍처와 문제 설정에 얼마나 쉽게 적용될 수 있는지를 보여줌.\n\n메타 러닝에서 훈련된 모델의 목표는 적은 양의 새로운 데이터만으로 새로운 과제를 신속하게 학습하는 것이며, 모델은 메타 학습기에 의해 수많은 다른 과제에 대해 학습할 수 있도록 훈련됩니다."
  },
  {
    "objectID": "posts/20251114_1.html#핵심-아이디어-of-maml",
    "href": "posts/20251114_1.html#핵심-아이디어-of-maml",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "핵심 아이디어 of MAML",
    "text": "핵심 아이디어 of MAML\n새로운 과제에서 얻은 소량의 데이터로 계산된 한 번 이상의 경사 하강 단계를 거쳐 파라미터가 업데이트되었을 때, 해당 과제에서 모델의 성능이 극대화되도록 모델의 초기 파라미터를 훈련하는 것입니다.\n\n업데이트 함수나 학습 규칙을 학습하는 기존의 메타 러닝 방법들[1]과 달리, MAML 알고리즘은 학습해야 할 파라미터의 수를 늘리지 않으며, 순환 모델(recurrent model) [2]이나 샴 네트워크(Siamese network)[3]를 요구하는 것처럼 모델 아키텍처에 제약을 가하지도 않습니다.\n\n[1] (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017)\n\n[2] (Santoro et al., 2016)\n\n[3] (Koch, 2015)\n\n\n또한, 완전 연결(fully connected), 컨볼루션(convolutional), 순환(recurrent) 신경망 등과 쉽게 결합할 수 있습니다.\n미분 가능한 지도 학습 손실 함수는 물론, 미분 불가능한 강화학습 목표 함수를 포함한 다양한 종류의 손실 함수와도 함께 사용할 수 있습니다.\n\n단 몇 번의 경사 하강 단계만으로, 혹은 단 한 번의 단계만으로도 새로운 과제에서 좋은 결과를 낼 수 있도록 모델의 파라미터를 훈련하는 과정은, 특징 학습(feature learning)의 관점에서 볼 때 여러 과제에 폭넓게 적용 가능한 내부 표현(internal representation)을 구축하는 것으로 해석할 수 있습니다.\n\n만약 내부 표현이 여러 과제에 적합하다면, 파라미터를 약간만 미세조정하는 것(예: 피드포워드 모델의 마지막 레이어 가중치를 주로 수정하는 것)만으로도 좋은 결과를 얻을 수 있습니다.\n\n결과적으로, 우리 절차는 쉽고 빠르게 미세조정될 수 있는 모델을 최적화하여, 신속한 학습에 적합한 공간에서 적응이 일어나도록 만듭니다.\n\n동적 시스템(dynamical systems) 관점에서 보면, 우리의 학습 과정은 파라미터에 대한 새로운 과제들의 손실 함수의 민감도(sensitivity)를 극대화하는 것으로 볼 수 있습니다.\n\n민감도가 높을 때, 파라미터의 작은 국소적 변화가 과제 손실(task loss)을 크게 개선할 수 있기 때문입니다.\n\n\nmaximizing the sensitivity of the loss functions of new tasks with respect to the parameters?"
  },
  {
    "objectID": "posts/20251114_1.html#이-연구의-주된-기여",
    "href": "posts/20251114_1.html#이-연구의-주된-기여",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "이 연구의 주된 기여",
    "text": "이 연구의 주된 기여\n\n적은 횟수의 경사 하강 업데이트만으로 새로운 과제에 대한 빠른 학습이 가능하도록 모델의 파라미터를 훈련하는, 단순하면서도 모델과 과제에 구애받지 않는 메타 러닝 알고리즘.\n이 알고리즘을 완전 연결 신경망과 컨볼루션 신경망을 포함한 다양한 모델 유형과, 퓨샷(few-shot) 회귀, 이미지 분류, 강화학습 등 여러 영역에서 시연.\n\n평가는 제안된 메타 러닝 알고리즘이 지도 분류를 위해 특별히 설계된 최신 원샷(one-shot) 학습 방법들과 비교하여 더 적은 파라미터를 사용하면서도 우수한 성능을 보이며, 회귀 문제에도 쉽게 적용될 수 있고, 과제 가변성이 존재하는 상황에서 강화학습을 가속화하여 초기화 방식으로서의 직접적인 사전 훈련(pretraining)보다 월등히 뛰어난 성능을 보인다는 것을 보여줍니다."
  },
  {
    "objectID": "posts/20251114_1.html#핵심-개념-민감도sensitivity-기울기gradient의-크기",
    "href": "posts/20251114_1.html#핵심-개념-민감도sensitivity-기울기gradient의-크기",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "핵심 개념: 민감도(Sensitivity) = 기울기(Gradient)의 크기",
    "text": "핵심 개념: 민감도(Sensitivity) = 기울기(Gradient)의 크기\n수학, 특히 최적화 문제에서 어떤 함수의 “파라미터에 대한 민감도”는 기울기(gradient)로 표현됩니다. 기울기는 파라미터를 아주 약간 변경했을 때 함수 값이 얼마나, 그리고 어느 방향으로 변하는지를 나타냅니다.\n\n기울기의 방향: 함수 값이 가장 가파르게 증가하는 방향\n기울기의 크기(magnitude): 그 가파른 정도. 즉, 민감도\n\n따라서 “파라미터(θ)에 대한 새로운 과제의 손실 함수(L)의 민감도를 극대화한다”는 것은, 손실 함수의 기울기 벡터 \\(\\nabla_{\\theta} \\mathcal{L}\\)의 크기(norm), 즉 \\(\\Vert \\nabla_{\\theta} \\mathcal{L} \\Vert\\) 를 크게 만드는 것을 의미합니다."
  },
  {
    "objectID": "posts/20251114_1.html#수식을-통한-설명",
    "href": "posts/20251114_1.html#수식을-통한-설명",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "수식을 통한 설명",
    "text": "수식을 통한 설명\n\n기본 설정\n\n\n모델 파라미터: \\(\\theta\\)\n새로운 (임의의) 과제 \\(\\mathcal{T}_i\\)에 대한 손실 함수: \\(\\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\)\n\n\n민감도(Sensitivity)의 수학적 표현\n\n파라미터 \\(\\theta\\)에 대한 손실 함수 \\(\\mathcal{L}_{\\mathcal{T}_i}\\)의 민감도는 기울기(gradient)의 크기(norm)로 나타낼 수 있습니다.\n\\[ \\text{Sensitivity} = \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\| \\]\n\n이 값이 크다는 것은 손실 함수의 “경사면”이 매우 가파르다는 것을 의미합니다.\n\n\n파라미터의 작은 변화와 손실의 큰 개선\n\n경사 하강법에서는 파라미터를 다음과 같이 업데이트합니다.\n\\[ \\theta' = \\theta - \\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n여기서 \\(\\alpha\\)는 학습률(learning rate)입니다.\n\n이때, 업데이트 후의 손실 값 \\(\\mathcal{L}_{\\mathcal{T}_i}(\\theta')\\)는 1차 테일러 근사(first-order Taylor approximation)를 통해 다음과 같이 예측할 수 있습니다.\n\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (\\theta' - \\theta)^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n위 식에 \\(\\theta' - \\theta = -\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\)를 대입하면,\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (-\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)) \\]\n벡터와 자신의 내적(dot product)은 크기의 제곱이므로,\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 \\]\n\n결론: 손실 개선량\n\n위 식을 정리하여 한 번의 업데이트로 인한 손실 개선량을 살펴보면 다음과 같습니다.\n\\[ \\text{Loss Improvement} = \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 \\]\n이 수식은 매우 중요한 점을 시사합니다.\n\n손실 개선량은 민감도(기울기의 크기)의 제곱에 비례합니다.\n\n따라서 MAML의 학습 과정은 어떤 새로운 과제 \\(\\mathcal{T}_i\\)가 주어지더라도, 현재 파라미터 \\(\\theta\\) 위치에서 손실 함수의 기울기 크기 \\(\\vert \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\vert\\)가 크도록 만드는 것입니다.\n\n이렇게 되면 단 한 번의 경사 하강 단계만으로도 손실 값을 크게 줄일 수 있어, 빠르고 효율적인 적응(adaptation)이 가능해집니다."
  },
  {
    "objectID": "posts/20251114_1.html#비유를-통한-이해",
    "href": "posts/20251114_1.html#비유를-통한-이해",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "비유를 통한 이해",
    "text": "비유를 통한 이해\n\n나쁜 초기 파라미터 (낮은 민감도): 넓은 고원이나 평지에 서 있는 것과 같습니다. 어느 방향으로 한 걸음 내딛어도 고도(손실)는 거의 변하지 않습니다. 최저점(최적해)에 도달하려면 수많은 걸음을 옮겨야 합니다.\n좋은 초기 파라미터 (높은 민감도, MAML의 목표): 여러 계곡(각 과제의 최적해)으로 내려가는 길이 시작되는 산등성이의 중앙에 서 있는 것과 같습니다. 어떤 계곡으로 내려가야 할지 목표가 주어지면, 그 방향은 매우 가파르기 때문에 단 몇 걸음만으로도 고도(손실)를 크게 낮출 수 있습니다.\n\nMAML은 바로 이 “산등성이의 중앙”과 같은 초기 파라미터 \\(\\theta\\)를 찾는 알고리즘이라고 할 수 있습니다."
  },
  {
    "objectID": "posts/20251116_1.html",
    "href": "posts/20251116_1.html",
    "title": "Hypernetworks",
    "section": "",
    "text": "이 연구는 하이퍼네트워크를 탐구합니다. 하이퍼네트워크는 한 네트워크를 사용하여 다른 네트워크의 가중치를 생성하는 방식입니다.\n하이퍼네트워크는 자연에서 발견되는 것과 유사한 추상화를 제공합니다: 유전형질(하이퍼네트워크)과 표현형(주 네트워크) 간의 관계입니다.\n진화 알고리즘의 HyperNEAT과 유사하지만, 본 연구의 하이퍼네트워크는 역전파(backpropagation)로 End-to-End 학습되므로 일반적으로 더 빠릅니다.\n본 연구의 초점은 하이퍼네트워크를 심층 합성곱 신경망과 장기 순환 신경망에 유용하게 만드는 것입니다. 여기서 하이퍼네트워크는 계층 간 가중치 공유의 완화된 형태로 볼 수 있습니다. 주요 결과는 하이퍼네트워크가 LSTM의 비공유 가중치를 생성할 수 있으며, 문자 수준의 언어 모델링, 필기 생성, 신경 기계 번역을 포함한 다양한 시퀀스 모델링 작업에서 최첨단에 가까운 성능을 달성할 수 있다는 것입니다.\n이는 순환 신경망의 가중치 공유 패러다임에 도전합니다. 또한 결과는 합성곱 신경망에 적용된 하이퍼네트워크가 최첨단 기준 모델과 비교하여 이미지 인식 작업에서 뛰어난 결과를 달성하면서도 학습 가능한 매개변수가 더 적음을 보여줍니다."
  },
  {
    "objectID": "posts/20251116_1.html#hyperneat-framework",
    "href": "posts/20251116_1.html#hyperneat-framework",
    "title": "Hypernetworks",
    "section": "HyperNEAT Framework",
    "text": "HyperNEAT Framework\nHyperNEAT 프레임워크에서는 구성 패턴 생성 네트워크(Compositional Pattern-Producing Networks, CPPNs)가 진화하여 훨씬 더 큰 주 네트워크의 가중치 구조를 정의합니다.\n\n본 연구의 접근법과 밀접하게 관련된 것은 HyperNEAT의 단순화된 변형으로, 구조는 고정되고 가중치는 이산 코사인 변환(Discrete Cosine Transform, DCT)을 통해 진화하는 압축 가중치 탐색(Compressed Weight Search)입니다.\n본 연구의 접근법과 더욱 밀접하게 관련된 것은 구조는 진화하지만 가중치는 학습되는 미분 가능한 패턴 생성 네트워크(Differentiable Pattern Producing Networks, DPPNs)와 선형 계층이 DCT로 압축되고 매개변수가 학습되는 ACDC-Networks입니다.\n\n그러나 이러한 방법을 사용한 대부분의 보고된 결과는 소규모 수준에 그쳤는데, 아마도 학습이 느리고 효율적이기 위해 휴리스틱이 필요하기 때문일 것입니다."
  },
  {
    "objectID": "posts/20251116_1.html#this-paper-vs.-hyperneat",
    "href": "posts/20251116_1.html#this-paper-vs.-hyperneat",
    "title": "Hypernetworks",
    "section": "This Paper vs. HyperNEAT",
    "text": "This Paper vs. HyperNEAT\n본 연구의 접근법과 HyperNEAT의 주요 차이점은 본 연구의 하이퍼네트워크가 주 네트워크와 함께 그래디언트 하강법을 사용하여 End-to-End 학습되므로 더 효율적이라는 것입니다.\n그래디언트 하강법을 사용한 End-to-End 학습 외에도, 본 연구의 접근법은 모델 유연성과 학습 단순성 측면에서 압축 가중치 탐색과 HyperNEAT 사이에서 좋은 균형을 이룹니다.\n\n첫째, 압축 가중치 탐색에 사용되는 이산 코사인 변환이 너무 단순할 수 있으며 DCT 사전 지식이 많은 문제에 적합하지 않을 수 있다고 주장할 수 있습니다.\n둘째, HyperNEAT가 더 유연하지만, HyperNEAT에서 아키텍처와 가중치를 모두 진화시키는 것은 대부분의 실용적인 문제에 대해 과도한 방법입니다.\n\nHyperNEAT와 DCT에 관한 연구 이전에도, Schmidhuber(1992, 1993)는 빠른 가중치(fast weights) 개념을 제안했습니다. 이 개념에서는 한 네트워크가 두 번째 네트워크에 대한 문맥 의존적 가중치 변경을 생성할 수 있습니다. 당시 피드포워드 네트워크를 위한 빠른 가중치를 입증하기 위해 소규모 실험이 수행되었지만, 아마도 현대적인 계산 도구가 부족했기 때문에 순환 네트워크 버전은 주로 사고 실험(thought experiment)으로 언급되었습니다. 후속 연구에서는 빠른 가중치의 실용적 응용을 입증했으며, 생성기 네트워크가 진화를 통해 학습되어 인공 제어 문제를 해결했습니다."
  },
  {
    "objectID": "posts/20251116_1.html#the-key-point",
    "href": "posts/20251116_1.html#the-key-point",
    "title": "Hypernetworks",
    "section": "The Key Point",
    "text": "The Key Point\n한 네트워크가 다른 네트워크와 상호 작용하는 개념은 여러 연구의 핵심이며, 특히 합성곱 네트워크의 특정 매개변수가 다른 네트워크에 의해 예측되는 연구들이 있습니다. 그러나 이러한 연구들은 순환 네트워크에 이 접근법을 사용하는 것을 탐구하지 않았으며, 이것이 본 연구의 주요 기여입니다.\n본 연구의 초점은 계층 임베딩 벡터를 입력으로 받아 합성곱 네트워크 및 순환 네트워크와 같은 실용적인 아키텍처를 위한 가중치를 생성하는 것입니다.\n\n그러나 본 연구의 하이퍼네트워크는 DPPNs와 유사하게 좌표 정보를 입력으로 받아 완전 연결 네트워크의 가중치를 생성하는 데도 활용될 수 있습니다. 이 설정을 사용하면, 하이퍼네트워크는 명시적으로 지시받지 않고도 합성곱 아키텍처를 근사적으로 복원할 수 있으며, 이는 진화에 의한 합성곱(Convolution by Evolution)에서 얻은 것과 유사한 결과입니다. 이 결과는 부록 A.1에 설명되어 있습니다."
  },
  {
    "objectID": "posts/20251116_1.html#what-is-evolutionary-computing",
    "href": "posts/20251116_1.html#what-is-evolutionary-computing",
    "title": "Hypernetworks",
    "section": "What is Evolutionary Computing?",
    "text": "What is Evolutionary Computing?\nEvolutionary Computing은 생물학적 진화 과정에서 영감을 받은 최적화 알고리즘의 한 분야입니다. 자연 선택, 유전, 돌연변이 같은 자연의 진화 메커니즘을 컴퓨터 상에서 모방하여 복잡한 문제를 해결하는 인공지능 및 소프트 컴퓨팅의 하위 분야입니다.\n\n핵심 개념과 작동 원리\n진화 연산은 개체군 기반(population-based) 탐색 방식을 사용합니다. 후보 솔루션들(개체)을 모집단으로 구성하고, 각 개체의 적합도(fitness)를 평가한 후, 우수한 개체를 선택하여 교배(crossover)와 돌연변이(mutation)를 통해 새로운 세대를 생성합니다. 이 과정을 반복하면서 점진적으로 더 나은 솔루션으로 진화해 나갑니다.\n주요 구성 요소는 다음과 같습니다:\n\n선택(Selection): 적합도가 높은 개체를 우선적으로 선택\n교배(Crossover/Recombination): 부모 개체의 정보를 결합하여 자손 생성\n돌연변이(Mutation): 무작위 변화를 도입하여 다양성 확보\n적합도 함수(Fitness Function): 솔루션의 품질을 평가하는 기준\n\n\n\n주요 알고리즘 종류\n진화 연산은 여러 알고리즘 계열을 포함합니다:\n\n유전 알고리즘(Genetic Algorithms, GA): 가장 널리 사용되는 방법\n진화 전략(Evolution Strategies, ES): 실수형 최적화에 특화\n진화 프로그래밍(Evolutionary Programming, EP): 유한 상태 기계 진화\n유전 프로그래밍(Genetic Programming, GP): 프로그램 구조 자체를 진화\n군집 지능(Swarm Intelligence): 개미 군집 최적화(ACO), 입자 군집 최적화(PSO) 등\n\n\n\n연구 분야로서의 특징\n진화 연산은 다음과 같은 특징으로 인해 광범위하게 활용됩니다:\n\n전역 최적화: 지역 최적점(local optima)에 덜 빠지고 전역 해를 찾을 수 있음\n문제 독립성: 문제에 대한 사전 가정이 거의 필요 없음\n병렬화 가능성: 개체군 기반 특성으로 대규모 병렬 처리에 적합\n복잡한 문제 해결: 방대한 해공간과 비선형성을 가진 문제에 효과적\n\n\n\n기계학습과의 결합\n진화 연산은 기계학습, 특히 신경망 분야와 깊이 결합되고 있습니다:\n\n신경망 구조 탐색(Neural Architecture Search, NAS): 최적의 신경망 구조를 자동으로 설계\n뉴로진화(Neuroevolution): 신경망의 가중치, 구조, 하이퍼파라미터를 진화\nAutoML: 기계학습 모델과 파이프라인을 자동으로 최적화"
  },
  {
    "objectID": "posts/20251116_1.html#최신-연구-동향-2024-2025",
    "href": "posts/20251116_1.html#최신-연구-동향-2024-2025",
    "title": "Hypernetworks",
    "section": "최신 연구 동향 (2024-2025)",
    "text": "최신 연구 동향 (2024-2025)\n\n1. 뉴로진화와 신경망 최적화\n대규모 심층 신경망 최적화가 주요 연구 주제입니다. 2024-2025년 연구들은 진화 알고리즘을 사용하여 심층 신경망의 구조와 하이퍼파라미터를 최적화하는 방법을 탐구하고 있습니다.\n\n“Evolving Neural Architectures: A Genetic Algorithm Approach to Deep Learning Optimization” (2024): 유전 알고리즘을 사용한 신경망 구조 최적화 연구로, 적응적 개체군 제어, 다양성 보존 돌연변이, 하이브리드 강화학습 전략을 제안했습니다. 병렬 처리와 가중치 공유를 통해 계산 부담을 줄이는 생물학적 영감 접근법을 도입했습니다.\nGECCO 2025 - Neuroevolution at Work Workshop: 2025년 주요 학회에서는 뉴로진화와 NAS의 통합이 핵심 주제입니다. 파라미터 공간 다양성 부족 문제와 계산 효율성 향상이 주요 도전 과제로 제기되고 있습니다.\n\n\n\n2. GPU 가속 진화 알고리즘\n텐서화(Tensorization)를 활용한 GPU 가속이 중요한 트렌드입니다:\n\n“GPU-accelerated Evolutionary Multiobjective Optimization Using Tensorized RVEA” (GECCO 2024): GPU를 활용한 대규모 다목적 최적화\n“Tensorized NeuroEvolution of Augmenting Topologies for GPU Acceleration” (GECCO 2024): NEAT 알고리즘의 GPU 가속 버전\n“Tensorized Ant Colony Optimization for GPU Acceleration” (GECCO 2024): 개미 군집 최적화의 GPU 병렬화\n\n\n\n3. 협력적 공진화(Cooperative Co-evolution)\n고차원 문제 해결을 위한 협력적 공진화 연구가 활발합니다:[8]\n\n“PyCCEA: A Python package of cooperative co-evolutionary algorithms for feature selection” (2025): 고차원 특징 선택 문제를 위한 협력적 공진화 프레임워크를 제공합니다. 문제를 여러 하위 구성요소로 분할하여 각각 독립적으로 진화시키는 방식입니다.\n\n\n\n4. 진화와 학습의 시너지\n진화와 학습의 결합이 주목받고 있습니다:\n\n“Neuroevolution insights into biological neural computation” (Science, 2025년 2월): 진화가 신경 회로 구조를 어떻게 형성하는지, 그리고 진화와 학습이 어떻게 협력하는지에 대한 종합적 리뷰. 진화는 신경망 구조를 최적화하고, 학습은 개체가 생애 동안 적응할 수 있게 합니다.\n연구 결과에 따르면, 진화된 신경망은 모듈성(modularity), 전문화된 제어 메커니즘(command neurons), 효율적 학습을 위한 구조적 특성을 자연스럽게 발달시킵니다.\n\n\n\n5. 분산 진화 신경망\n빅데이터를 위한 분산 처리 프레임워크가 발전하고 있습니다:\n\n“A novel neural network model with distributed evolutionary algorithm” (Nature, 2023): Apache Spark 프레임워크를 사용한 분산 유전 알고리즘 기반 신경망 학습. 대용량 데이터에서 전통적 방법 대비 80% 이상의 계산 시간 개선을 달성했습니다.\n\n\n\n6. 최신 응용 분야\n2024-2025년 연구들은 다양한 실제 응용에 진화 연산을 적용하고 있습니다:\n\n재료 과학: Neuroevolution Potential (NEP) 접근법이 분자 동역학 시뮬레이션에서 탁월한 정확도와 계산 효율성을 보이고 있습니다.\n음악 분류: 차등 진화 알고리즘을 사용한 CNN 파라미터 최적화\n의료 진단: 암 스크리닝을 위한 앙상블 자연 영감 알고리즘\n로봇공학: 자가 조직화 입자 시스템의 집단 행동 진화\n공기역학: 심층학습과 유전 알고리즘을 결합한 공기역학적 설계\n\n\n\n7. 주요 학술 컨퍼런스 및 저널\n진화 연산 분야의 최신 연구는 다음 학술 장소에서 발표됩니다:\n\nGECCO (Genetic and Evolutionary Computation Conference): 가장 권위 있는 학회\nEvolutionary Computation (MIT Press): 최고 수준의 저널\nSwarm and Evolutionary Computation: 전문 저널\nNature, Science: 최근 뉴로진화 관련 리뷰 논문 게재\n\n진화 연산은 생물학적 원리를 컴퓨터 과학에 적용하여 복잡한 최적화 문제를 해결하는 강력한 도구로, 현재 인공지능, 특히 신경망 설계와 최적화 분야에서 혁신적인 돌파구를 제공하고 있습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39"
  },
  {
    "objectID": "posts/20251116_1.html#hypernetworks와-bayesian-meta-learning-uncertainty의-결합",
    "href": "posts/20251116_1.html#hypernetworks와-bayesian-meta-learning-uncertainty의-결합",
    "title": "Hypernetworks",
    "section": "HyperNetworks와 Bayesian Meta-Learning, Uncertainty의 결합",
    "text": "HyperNetworks와 Bayesian Meta-Learning, Uncertainty의 결합\n\n1. HyperNetworks의 Bayesian 결합 가능 요소\n\n1.1 가중치 생성 메커니즘의 확률적 해석\nHyperNetworks의 핵심 구조가 Bayesian 프레임워크와 자연스럽게 결합됩니다:[1][2]\n논문에서 하이퍼네트워크는 임베딩 벡터 \\[z\\]를 받아 가중치 \\[W\\]를 생성합니다. 이를 Bayesian 관점에서 재해석하면:[3]\n\nPoint estimate (원논문): \\[W = f_{\\theta}(z)\\]\nBayesian 확장: \\[W \\sim p(W|z, \\theta)\\]로 가중치의 사후 분포(posterior distribution)를 모델링[2][1][4]\n\n장점: - 태스크별 가중치의 불확실성을 명시적으로 모델링 - 데이터가 적은 few-shot 상황에서 epistemic uncertainty 포착[2][1]\n\n\n1.2 동적 임베딩의 불확실성\n논문의 동적 하이퍼네트워크는 입력에 따라 임베딩이 변하는데, 이는 Bayesian 관점에서 매우 풍부한 연구 주제입니다:[5][3]\n\n임베딩 자체에 불확실성 부여: \\[z \\sim p(z|\\text{task})\\][6][5]\nBayesian meta-prompt 개념과 연결[5]\n태스크 표현의 불확실성이 가중치 불확실성으로 전파[4][7]\n\n\n\n1.3 계층별 가중치 스케일링\n논문의 weight scaling vectors 접근법:[3]\nW(d(z)) = W ⊙ d(z)\n이는 Bayesian 관점에서: - \\[d(z)\\]를 확률 변수로 확장 가능 - 전체 가중치 행렬보다 낮은 차원에서 불확실성 모델링 - 계산 효율적인 Variational Inference 가능[1][2]\n\n\n\n2. 최신 연구: BayesianHMAML (2022)\nHypernetwork approach to Bayesian MAML이 대표적인 사례입니다.[2][1]\n\n2.1 핵심 아이디어\n기존 MAML의 한계: - 그래디언트 기반 업데이트만 사용 - 불확실성 정량화 불가 - Few-shot 상황에서 과적합 위험[1][2]\nBayesianHMAML의 해결책:[2][1]\n(μ(Si), σ(Si)) = Hφ(Si, fθ(Si))\nθ'i ~ N(θ + μ(Si), σ(Si))\n하이퍼네트워크 \\[H_{\\phi}\\]가: - 서포트 세트 \\[S_i\\]로부터 정보 집계 - 태스크별 가중치의 평균(μ)과 분산(σ) 생성[1][2] - 가중치를 분포에서 샘플링하여 불확실성 포착[2][1]\nDecision Making 관점의 장점:[8][2] - Epistemic uncertainty 정량화: 모델이 얼마나 확신하는지 측정 - Rejection diagnosis: 불확실성이 높은 예측은 거부 가능[7] - Risk-aware decision: 불확실성을 고려한 안전한 의사결정[9]\n\n\n2.2 실험 결과\nBayesianHMAML은 다음에서 우수한 성능을 보였습니다:[8][2] - miniImageNet 5-way 1-shot: 기존 MAML 대비 정확도 향상 - Uncertainty calibration: 예측 불확실성이 실제 오류와 높은 상관관계 - Out-of-distribution detection: OOD 샘플 탐지 능력 향상[8]\n\n\n\n3. 최신 연구 트렌드 (2024-2025)\n\n3.1 Meta-Mol: 약물 발견을 위한 Bayesian Meta-Learning\n“Pushing the boundaries of few-shot learning for low-data drug discovery” (Nature Communications, 2025):[4]\n문제 상황: - 약물 특성 예측은 데이터 부족 문제 심각 - 잘못된 예측은 임상 시험 실패로 이어짐 - Uncertainty 정량화 필수[4]\nMeta-Mol의 접근법:[4] 1. Bayesian MAML 변형: 범용 가중치(universal weights)는 point estimate, 태스크별 가중치는 사후 분포로 학습 2. HyperNetwork 활용: 서포트 세트에서 사후 분포의 파라미터(평균, 분산) 직접 생성[4] 3. 복잡한 사후 분포 학습: 충분히 표현력 있는 하이퍼네트워크로 임의의 사후 분포 근사[4]\nDecision Making에의 기여:[4] - 불확실성 기반 샘플 필터링: 신뢰도 낮은 예측 제거 - 리스크 인지 약물 설계: 부작용 가능성이 높은 화합물 사전 제외 - 능동 학습(Active Learning): 불확실성이 높은 영역에 실험 자원 집중\n\n\n3.2 UBMF: 결함 진단을 위한 Uncertainty-aware Bayesian Meta-Learning\n“UBMF: Uncertainty-aware bayesian meta-learning framework” (2025):[7]\n산업 응용에서의 Uncertainty:[7] - 3가지 불확실성 원천: 미지의 조건, 적은 샘플, 도메인 외 데이터 - 잘못된 진단은 장비 파손이나 안전 사고로 이어질 수 있음[7]\n핵심 기여:[7] 1. 통합 불확실성 모델링: Aleatoric과 epistemic uncertainty를 체계적으로 구분하고 정량화[7] 2. 불확실성 기반 샘플 필터링: OOD 샘플을 자동으로 감지하고 제거[7] 3. Bayesian 메타 지식 추출: 사후 확률 보정으로 분류기 정밀도 향상[7]\nDecision Making 프레임워크:[7] - 신뢰도 임계값 설정: 불확실성이 높으면 인간 전문가에게 판단 위임 - 리스크 기반 우선순위: 고위험 결함을 우선 처리 - 적응적 진단: 새로운 조건에서 메타 지식을 활용하여 빠르게 적응\n\n\n3.3 Trust-Bayes: 신뢰할 수 있는 Uncertainty Quantification\n“Bayesian meta learning for trustworthy uncertainty quantification” (2024):[10][11]\n문제 정의:[10] - 기존 Bayesian 방법들은 모델 불확실성과 데이터 불확실성을 혼동 - 부정확한 불확실성 추정은 잘못된 의사결정으로 이어짐[10]\nTrust-Bayes 프레임워크:[10] - Trustworthy uncertainty: 보정된(calibrated) 불확실성 제공 - Meta-learning과 결합: 다양한 태스크에서 학습하여 일반화 가능한 불확실성 추정 - 최적화 프레임워크: 불확실성 품질을 명시적으로 최적화[10]\n\n\n3.4 SurvUnc: 생존 분석을 위한 Meta-Model 기반 Uncertainty\n“SurvUnc: A Meta-Model Based Uncertainty Quantification Framework” (2024):[12][13]\n의료 의사결정에서의 중요성:[12] - 생존 예측의 불확실성은 치료 결정에 직접적 영향 - 높은 불확실성 → 추가 검사 필요 - 낮은 불확실성 → 적극적 치료 가능[12]\n메타 모델 접근법:[13][12] - Base survival model 위에 경량 메타 모델 구축 - Anchor-based learning: Concordance 개념을 활용한 불확실성 학습[12] - Post-hoc uncertainty: 기존 모델 수정 없이 불확실성 추가[12]\n평가 프로토콜:[12] - Selective prediction: 확신도 높은 예측만 사용 - Misprediction detection: 오류 가능성 사전 파악 - OOD detection: 분포 외 환자 식별[12]\n\n\n\n4. Decision Making에서 Uncertainty의 역할\n\n4.1 Exploration-Exploitation Trade-off\nMeta-RL에서의 불확실성 활용:[14][15][9]\nRisk-aware Meta-level Decision Making (2022):[9] - 로봇 탐사에서 epistemic uncertainty로 탐사 전략 결정 - 불확실성 높은 영역 → 탐사 가치 높음 - 불확실성 낮은 영역 → 활용(exploitation) 전략[9]\nMeta-reinforcement learning for quantum control (Nature, 2025):[14] - 양자 시스템의 불확실성 존재 하 제어 - 메타 학습으로 환경 변화에 강건한 제어 - 내부 루프(specific task)와 외부 루프(meta-learning) 이중 구조[14]\nGrasp Learning with Uncertainty (2018):[15] - Epistemic uncertainty: 지식 부족으로 인한 불확실성 → 탐사로 감소 가능 - Aleatoric uncertainty: 데이터 노이즈 → 탐사로 감소 불가 - Epistemic만 활용한 탐사가 훨씬 효과적[15]\n\n\n4.2 Uncertainty의 두 가지 유형과 의사결정\nEpistemic Uncertainty (인식론적 불확실성):[16][15][12][7] - 원인: 모델의 지식 부족, 학습 데이터 부족 - 특징: 추가 데이터로 감소 가능 - Decision making: - 높은 epistemic uncertainty → 더 많은 데이터 수집 필요[15] - Active learning의 샘플 선택 기준[15] - 탐사(exploration) 전략에 활용[16][9]\nAleatoric Uncertainty (우연적 불확실성):[15][12][7] - 원인: 데이터 자체의 노이즈, 측정 오류 - 특징: 더 많은 데이터로도 감소 불가 - Decision making: - 높은 aleatoric uncertainty → 본질적으로 예측 어려운 케이스 - 리스크 관리: 보수적 결정 필요[7] - 예측 거부(rejection) 고려[7]\n\n\n4.3 Uncertainty-guided Meta-Learning\nUAPML: Uncertainty-Aware Prompted Meta-Learning (2024):[5]\n핵심 아이디어:[5] - Bayesian meta-prompt: 메타 프롬프트 자체에 불확실성 부여 - 사후 불확실성이 태스크별 프롬프트 불확실성과 일치함을 이론적으로 증명[5] - Hard vs Soft 방식: 불확실성에 따라 자동으로 프롬프트 구성 방식 선택[5]\n계산 효율성:[5] - 모델 백본 고정, 프롬프트만 조정 - 전체 가중치 업데이트 대비 80% 이상 계산 비용 감소 - 성능 저하 없이 빠른 적응[5]\n\n\n\n5. HyperNetworks 논문에 Bayesian을 적용할 구체적 방법\n\n5.1 정적 하이퍼네트워크의 Bayesian 확장\n원논문의 접근:[3]\nz_i: fixed layer embedding (learnable parameter)\nW_i = f_θ(z_i)\nBayesian 확장 방안:\nz_i ~ N(μ_z, Σ_z): 임베딩의 사후 분포\nW_i = f_θ(z_i): 가중치 생성\np(W_i | data) = ∫ p(W_i | z_i) p(z_i | data) dz_i\n구현 방법:[1][2] - Variational Inference로 \\[q(z_i)\\] 학습 - Reparameterization trick: \\[z_i = \\mu_z + \\sigma_z \\odot \\epsilon\\], where \\[\\epsilon \\sim N(0,1)\\] - 여러 샘플로 앙상블 예측[2]\n\n\n5.2 동적 하이퍼네트워크의 Bayesian 확장\n원논문의 동적 임베딩:[3] - LSTM의 hidden state가 시간에 따라 변하며 가중치 생성 - 입력 시퀀스에 적응적\nBayesian 해석:[2][4]\nh_t: LSTM hidden state at time t\nz_t = g(h_t): dynamic embedding\n(μ_W(t), σ_W(t)) = Hypernetwork(z_t)\nW_t ~ N(μ_W(t), diag(σ_W(t)^2))\nUncertainty 전파: - 시간에 따른 epistemic uncertainty 변화 추적 - 초반에는 높은 불확실성, 더 많은 정보 관찰 시 감소 - Decision making: 불확실성 임계값 이하일 때만 예측 출력[12][7]\n\n\n5.3 Layer Normalization과 Bayesian의 결합\n논문에서 Layer Norm + HyperLSTM이 효과적임을 보였습니다.[3]\nBayesian 관점의 해석:[17] - Layer Normalization은 암묵적 정규화 효과 - Bayesian 프레임워크와 결합 시 사후 분포의 분산 안정화[17] - 불확실성 추정의 품질 향상[17]\n\n\n\n6. 실용적 구현 전략\n\n6.1 경량 Bayesian HyperNetworks\n문제: Full Bayesian inference는 계산 비용이 높음[2][4]\n해결책:[2][4] 1. Universal weights는 point estimate: 공통 지식은 deterministic 2. Task-specific weights만 Bayesian: 불확실성이 중요한 부분만 3. Low-rank approximation: \\[\\Sigma = LL^T\\]로 분산 행렬 저차원화[2]\n\n\n6.2 Ensemble 기반 접근\nDeep Ensemble과 HyperNetworks 결합:[18][15]\n# Multiple hypernetworks\nhypernetworks = [HyperNet() for _ in range(N)]\n\n# Generate ensemble predictions\npredictions = []\nfor hyper in hypernetworks:\n    W = hyper.generate_weights(task_embedding)\n    pred = main_network(input, W)\n    predictions.append(pred)\n\n# Uncertainty estimation\nmean_pred = mean(predictions)\nepistemic_unc = variance(predictions)\n장점:[18] - 구현 간단 - 병렬화 용이 - Gradient 기반 학습 가능\n\n\n6.3 MC Dropout with HyperNetworks\nVariational inference의 근사:[17]\n# Enable dropout during inference\nhypernetwork.train()  # Keep dropout active\n\npredictions = []\nfor _ in range(K):  # K samples\n    W = hypernetwork(task_embedding)\n    pred = main_network(input, W)\n    predictions.append(pred)\n\nuncertainty = std(predictions)\n계산 효율성:[17] - 단일 모델만 필요 - Inference 시 multiple forward pass - 추가 학습 비용 없음\n\n\n\n7. 향후 연구 방향과 제안\n\n7.1 HyperNetworks + Bayesian + Meta-Learning 통합\n제안하는 프레임워크:\n\nOuter loop (Meta-learning):\n\n다양한 태스크에서 하이퍼네트워크 파라미터 학습\n태스크 분포 \\[p(T)\\]에서 샘플링[19][2]\n\nMiddle loop (HyperNetwork):\n\n태스크 임베딩에서 가중치 분포 생성[1][2]\n\\[(μ_W, σ_W) = H_φ(z_{\\text{task}})\\]\n\nInner loop (Bayesian Inference):\n\n소수의 샘플로 빠른 적응[1][2]\nUncertainty 정량화로 예측 신뢰도 제공[12][7]\n\n\n\n\n7.2 Decision Making 응용 시나리오\n금융 의사결정: - 시장 변화 → 새로운 태스크 - HyperNetwork로 빠르게 새 전략 생성 - Uncertainty로 리스크 관리 - 불확실성 높은 시기 → 보수적 포트폴리오\n자율주행: - 다양한 날씨/도로 조건 → 태스크 - Meta-learning으로 새 조건 빠른 적응 - Epistemic uncertainty로 탐사 영역 결정 - 높은 불확실성 → 인간에게 제어 이양[9]\n의료 진단:[4] - 환자 특성 → 태스크 - Few-shot으로 희귀 질환 진단 - Uncertainty로 추가 검사 필요성 판단 - Aleatoric uncertainty 높음 → 예측 불가능, 경과 관찰\n\n\n\n결론\nHyperNetworks 논문은 Bayesian 프레임워크와 결합할 수 있는 풍부한 요소들을 가지고 있습니다:\n주요 결합 요소: - 가중치 생성 메커니즘 → 확률 분포로 확장 - 임베딩 벡터 → 불확실성 부여 - 동적 가중치 → 시간에 따른 불확실성 변화\n최신 연구 현황: - BayesianHMAML (2022): Few-shot learning + uncertainty[1][2] - Meta-Mol (2025): 약물 발견 + Bayesian hypernetwork[4] - UBMF (2025): 결함 진단 + uncertainty-aware meta-learning[7] - SurvUnc (2024): 생존 분석 + meta-model uncertainty[12]\nDecision Making에의 기여: - Epistemic uncertainty: 탐사 전략, active learning[16][9][15] - Aleatoric uncertainty: 리스크 관리, 예측 거부[7] - Calibrated uncertainty: 신뢰할 수 있는 의사결정[11][10]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "다변량 딥러닝 기반 이상치 탐지에서의 불확실성 추정과\nMixture-of-VAEs를 활용한 위험 민감 의사결정 프레임워크\n(영문 예시)\nRisk-Aware Decision Framework with Uncertainty-Aware Deep Multivariate Anomaly Detection using Variational and Mixture-of-VAEs\n\n\n\n\n제조 공정, 네트워크 트래픽, 금융 거래, 의료 모니터링 등 다양한 응용 분야에서 다변량(multivariate) 시계열·표형 데이터에 대한 이상치 탐지(anomaly / outlier detection) 는 안전성, 비용 절감, 서비스 안정성 측면에서 매우 중요한 과제이다.\n그러나 기존 딥러닝 기반 이상치 탐지 기법들(예: Autoencoder, LSTM-AE, CNN 기반 모델 등)은 다음과 같은 한계를 가진다.\n\n이상치 점수만 제공\n\n단일 스칼라 점수 \\(A(x)\\)만 제공하는 경우가 많아,\n“얼마나 이상한가?”는 알 수 있어도\n“이 판단을 얼마나 믿을 수 있는가?”(불확실성)는 알기 어렵다.\n\n불확실성(uncertainty) 정보 부재\n\n모델이 자신 없는 영역에서 내린 이상치 판단을\n동일한 신뢰도로 사용하게 되며,\n이는 실제 운영 환경에서 위험한 결정으로 이어질 수 있다.\n\n비용 구조가 반영되지 않은 결정\n\n실제 시스템에서는\n\n정상인데 이상치로 판단할 때의 비용(공장 정지, 서비스 중단 등)\n\n이상치인데 정상으로 넘기는 비용(고장, 사고, 손실 등)\n\n사람/전문가에게 “검토를 요청할 때” 드는 비용\n이 서로 다름에도 불구하고,\n단일 threshold 기반 이진 결정으로만 처리되는 경우가 많다.\n\n\n\n이에 본 연구는, 딥러닝 기반 베이지안 VAE와 Mixture-of-VAEs를 활용하여\n\n다변량 데이터에서 이상치 점수와 불확실성을 동시에 추정하고,\n이를 바탕으로 STOP / CHECK / IGNORE 형태의\n위험 민감(risk-aware) 의사결정 규칙을 설계하고자 한다.\n\n\n\n\n\n\n\n\nBase Model:\nVariational Autoencoder(VAE)를 기반으로 한 다변량 딥러닝 이상치 탐지 모델을 설계하여,\n전역(global) 및 변수별(feature-wise) 이상치 점수와 불확실성을 동시에 추정한다.\nExtended Model:\n데이터가 여러 정상 모드(운영 상태)를 가진다고 가정하고,\nMixture-of-VAEs (MoVAE) 구조를 설계하여\n모드별 이상치·불확실성과 모드 자체에 대한 불확실성(mode uncertainty) 를 함께 추정한다.\nRisk-aware Decision:\n이상치 점수와 불확실성 정보를 활용해\n비용 구조를 반영한 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 정식화하고,\n기존 threshold 기반 기법보다 더 낮은 위험도(risk)를 달성하는지 평가한다.\n범용성 검증:\n공정/센서 시계열, 네트워크/트래픽, 공개 multivariate anomaly dataset 등\n서로 다른 도메인에서 제안 프레임워크의 일관된 효과를 검증한다.\n\n\n\n\n\nRQ1. Variational Autoencoder 기반 다변량 딥러닝 모델을 통해\n전역 및 변수별 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 동시에 추정할 수 있는가?\nRQ2. 데이터가 여러 정상 모드를 가질 때, 단일 VAE보다\nMixture-of-VAEs가 이상치 탐지 및 불확실성 추정 측면에서\n더 나은 표현력과 의사결정 성능을 제공하는가?\nRQ3. 추정된 \\((A(x), U(x))\\) (및 모드 불확실성)를 이용하여\nSTOP / CHECK / IGNORE 형태의 위험 민감 의사결정 규칙을 설계할 때,\n기존 단일 threshold 기반 이진 의사결정보다\n실제 비용(risk)을 유의하게 감소시킬 수 있는가?\n\n\n\n\n\n\n\n\n\n이상치 탐지 / 다변량\n\nmultivariate anomaly detection\n\nmultivariate time series anomaly detection\n\ndeep anomaly detection, deep autoencoder, VAE anomaly detection\n\nreconstruction-based anomaly detection\n\n딥러닝 & 베이지안 / 불확실성\n\ndeep learning, representation learning (PyTorch / fastai)\n\nBayesian deep learning, variational inference\n\nMonte Carlo Dropout, deep ensemble\n\nuncertainty quantification, aleatoric / epistemic uncertainty\n\nVariational Autoencoder, Bayesian VAE, probabilistic autoencoder\n\nmixture of VAEs, mixture density networks, mixture-of-experts\n\n의사결정 / 위험\n\nselective prediction, abstention, reject option\n\nrisk-aware decision making, cost-sensitive learning\n\nrisk–coverage trade-off, calibration\n\n\n\n\n\n\n1–2개월차에 집중적으로 논문 수집 및 정리\n각 논문에 대해 다음 항목으로 구조화:\n\n데이터 타입 (시계열, 이미지, 센서, 트래픽 등)\n\n딥러닝 사용 여부, VAE/flow/AE 등 모델 유형\n\n이상치 점수 정의 방식 (reconstruction, likelihood, distance 등)\n\n불확실성 추정 여부 및 방법\n\nrisk-aware / selective decision 관점 고려 여부\n\n본 연구와의 차별점 / 한 줄 평가\n\n\n\n\n\n\n\n본 연구는 Base Model(VAE)와 Extended Model(Mixture-of-VAEs)으로 구성되며,\n두 모델에서 공통적으로 이상치 점수 + 불확실성 추정 + risk-aware decision layer를 설계한다.\n\n\n\n\n다변량 입력 \\(x \\in \\mathbb{R}^d\\)에 대해, VAE 구조는 다음과 같이 정의한다.\n\nPrior:\n\n\\[\nz \\sim p(z) = \\mathcal{N}(0, I)\n\\]\n\nDecoder:\n\n\\[\np_\\theta(x \\mid z) = \\mathcal{N}\\big(\\mu_\\theta(z), \\text{diag}(\\sigma^2_\\theta(z))\\big)\n\\]\n\nEncoder (approximate posterior):\n\n\\[\nq_\\phi(z \\mid x) = \\mathcal{N}\\big(\\mu_\\phi(x), \\text{diag}(\\sigma^2_\\phi(x))\\big)\n\\]\n학습은 ELBO 최적화를 통해 수행한다.\n\nELBO:\n\n\\[\n\\mathcal{L}_{\\text{ELBO}}(x;\\theta,\\phi) = \\mathbb{E}_{q_\\phi(z\\mid x)}[\\log p_\\theta(x \\mid z)] - \\mathrm{KL}\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big)\n\\]\nPyTorch/fastai로는 encoder/decoder를 MLP, 1D-CNN, LSTM 등으로 구현하고,\n출력층에서 mean 및 log-variance를 예측하도록 구성한다.\n\n\n\n관측 \\(x\\)에 대해, 다음과 같이 Monte Carlo 샘플링을 수행한다.\n\n\\(z^{(t)} \\sim q_\\phi(z \\mid x), \\quad t = 1,\\dots,T\\)\n\\(\\hat x^{(t)} \\sim p_\\theta(x \\mid z^{(t)})\\)\n\n각 변수 \\(j = 1,\\dots,d\\)에 대해:\n\n변수별 이상치 점수 (재구성 오차)\n\n\\[\nr_j(x) = \\frac{1}{T} \\sum_{t=1}^T \\big(x_j - \\hat x^{(t)}_j\\big)^2\n\\]\n\n변수별 불확실성 (예측 분산)\n평균 재구성을\n\n\\[\n\\bar x_j = \\frac{1}{T} \\sum_{t=1}^T \\hat x^{(t)}_j\n\\]\n로 정의할 때,\n\\[\nu_j(x) = \\frac{1}{T-1} \\sum_{t=1}^T \\big(\\hat x^{(t)}_j - \\bar x_j\\big)^2\n\\]\n전역(global) 이상치 점수와 불확실성은 가중합으로 정의한다.\n\n전역 이상치 점수:\n\n\\[\nA_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j r_j(x)\n\\]\n\n전역 불확실성:\n\n\\[\nU_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j u_j(x)\n\\]\n여기서 \\(w_j\\)는 각 변수의 중요도를 반영하는 가중치(동일 가중치 또는 도메인 지식 기반)를 의미한다.\n필요 시, encoder/decoder 네트워크에 Dropout을 적용하여\nepistemic uncertainty를 추가로 반영할 수 있다.\n\n\n\n\n\n\n\n다변량 데이터가 여러 정상 모드(운영 상태)를 가진다고 가정한다.\n이를 위해 \\(K\\)개의 VAE expert와 gating network로 구성된 Mixture-of-VAEs 구조를 정의한다.\n\nGating network:\n\n\\[\n\\pi_k(x) = p_\\psi(k \\mid x), \\quad k = 1,\\dots,K\n\\]\n여기서 \\(\\pi_k(x)\\)는 입력 \\(x\\)가 모드 \\(k\\)에 속할 확률을 나타내며,\n\\(\\sum_{k=1}^K \\pi_k(x) = 1\\)을 만족한다.\n\n각 expert VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0, I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k) = \\mathcal{N}\\big(\\mu_{\\theta_k}(z_k), \\text{diag}(\\sigma^2_{\\theta_k}(z_k))\\big)\n\\]\n\\[\nq_{\\phi_k}(z_k \\mid x) = \\mathcal{N}\\big(\\mu_{\\phi_k}(x), \\text{diag}(\\sigma^2_{\\phi_k}(x))\\big)\n\\]\n\n전체 likelihood:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x)\n\\]\n학습은 mixture 형태의 ELBO 또는 EM-유사 전략,\n혹은 end-to-end joint training으로 수행할 수 있으며,\n실험 단계에서 구현 난이도와 성능을 고려하여 선택한다.\n\n\n\n각 expert에 대해, VAE와 동일하게 재구성 기반 점수 \\(A_k(x)\\)를 정의한다.\n\nexpert \\(k\\)의 이상치 점수(예시):\n\n\\[\nA_k(x) = \\sum_{j=1}^d w_j r_{j,k}(x)\n\\]\nMixture 전체의 이상치 점수는 다음과 같이 정의할 수 있다.\n\nlikelihood 기반:\n\n\\[\nA_{\\text{MoVAE}}(x) = -\\log \\left( \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x) \\right)\n\\]\n\nreconstruction 기반 가중합:\n\n\\[\nA_{\\text{MoVAE}}(x) = \\sum_{k=1}^K \\pi_k(x)\\, A_k(x)\n\\]\n두 정의는 실험에서 비교 가능하며,\n도메인 특성에 따라 더 좋은 score 정의를 선택할 수 있다.\n\n\n\nMixture-of-VAEs에서는 불확실성이 두 층으로 나뉜다.\n\nexpert 내부 불확실성 (in-expert uncertainty)\n\n각 expert \\(k\\)의 VAE에서 variance, MC 샘플 분산 등을 이용해\n\\(U_k(x)\\)를 정의 (Base VAE와 동일 방식).\n\n모드 불확실성 (between-expert / mode uncertainty)\n\ngating 확률 벡터 \\(\\pi(x) = (\\pi_1(x),\\dots,\\pi_K(x))\\)의 엔트로피:\n\n\n\\[\nH_\\pi(x) = -\\sum_{k=1}^K \\pi_k(x)\\log \\pi_k(x)\n\\]\n\n\\(\\pi_k(x)\\)가 한 모드에 집중되면 \\(H_\\pi(x)\\)가 작고,\n여러 모드에 고르게 분산되면 \\(H_\\pi(x)\\)가 커진다.\n→ “이 샘플이 어느 모드에 속하는지 모델이 헷갈리는 정도”로 해석 가능.\n\n\n종합 불확실성 정의 예시\n\n\\[\nU_{\\text{MoVAE}}(x) = \\alpha \\sum_{k=1}^K \\pi_k(x)\\, U_k(x) + \\beta H_\\pi(x)\n\\]\n여기서 \\(\\alpha, \\beta\\)는 모드 내부 불확실성과 모드 불확실성의 상대적 중요도를 조절하는 하이퍼파라미터이다.\n\n\n\n\n\n\n\n각 샘플 \\(x\\)에 대하여, 세 가지 행동 중 하나를 선택한다고 가정한다.\n\n\\(\\delta(x) \\in \\{\\text{IGNORE}, \\text{CHECK}, \\text{STOP}\\}\\)\n\n실제 상태 \\(y \\in \\{\\text{normal}, \\text{anomaly}\\}\\)에 대해,\n각 행동에 대한 비용을 \\(C(\\delta(x), y)\\)로 정의한다.\n예시:\n\n정상인데 STOP → 불필요한 정지, false positive 비용\n\n이상치인데 IGNORE → 사고/고장, false negative 비용 (가장 큼)\n\nCHECK → 사람/추가 검사 비용 (중간 수준)\n\n전체 기대 위험도(risk)는 다음과 같이 정의할 수 있다.\n\\[\nR(\\delta) = \\mathbb{E}_{(x,y)}\\big[\\,C(\\delta(x), y)\\,\\big]\n\\]\n실제 구현에서는 validation set 상에서의 경험적 위험 \\(\\hat R(\\delta)\\)를 최소화하는 규칙을 찾는다.\n\n\n\nBase VAE 및 MoVAE 모두, 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 기반으로 다음과 같은 규칙을 정의할 수 있다.\n예시 규칙:\n\\[\n\\delta(x) =\n\\begin{cases}\n\\text{STOP} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) \\le \\tau_U \\\\\n\\text{CHECK} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) &gt; \\tau_U \\\\\n\\text{IGNORE} & \\text{if } A(x) &lt; \\tau_A\n\\end{cases}\n\\]\n여기서 \\((\\tau_A, \\tau_U)\\)는 validation set에서\n경험적 위험 \\(\\hat R(\\tau_A,\\tau_U)\\)를 최소화하도록 탐색한다.\nMixture-of-VAEs의 경우,\n\\(U(x)\\)를 \\(U_{\\text{MoVAE}}(x)\\)로 두거나,\n모드 엔트로피 \\(H_\\pi(x)\\)를 추가 입력으로 사용하는 변형도 고려할 수 있다.\n\n\n\n\n\n\n프레임워크: PyTorch (필수), 필요 시 fastai로 학습/실험 루프 관리\n구성 요소\n\nmodels/ : VAE, Mixture-of-VAEs, gating network 모듈\n\ndatasets/ : 시계열/탭형 multivariate anomaly dataset 로더\n\ntraining/ : 학습 루프, ELBO 계산, threshold search, risk 계산\n\nanalysis/ : ROC, PR, risk–coverage, 의사결정 시뮬레이션, 시각화\n\n\n\n\n\n\n\n\n\n\nSynthetic multivariate 데이터\n\n다변량 Gaussian, mixture, non-linear manifold 데이터 생성\n\n단일 모드 vs 다중 모드 환경에서 VAE와 MoVAE 비교\n\n공개 multivariate anomaly dataset\n\n예: 서버/센서/시계열 관련 공개 데이터셋 (SMD, MSL, SWaT 등)\n\n도메인에 따라 tabular/multivariate time series 데이터 추가 검토\n\n\n\n\n\n\nBaseline 모델\n\n단순 Autoencoder 기반 이상치 탐지\n\nVAE (불확실성 고려하지 않는 score-only 버전)\n\n필요시 다른 딥러닝 기반 anomaly detection 방법\n\n성능 지표\n\n이상치 탐지:\n\nAUROC, AUPR, F1-score, FPR@95TPR 등\n\n의사결정 / risk 관점:\n\nrisk–coverage curve\n\nfalse alarm 수, missed anomaly 수\n\nCHECK(사람 검토) 비율 대비 risk 감소 정도\n\n\n\n\n\n\n\n\n\n1–2개월차: 문헌 조사 및 문제 정의\n\n키워드 기반 선행 연구 수집 및 정리\n\n관련 연구 요약 및 연구 질문(RQ) 확정\n\n3–4개월차: 수식 정식화 및 모델 설계\n\nVAE / Mixture-of-VAEs 수식 정리 및 손실 함수 정의\n\n이상치 점수, 불확실성, decision rule 공식화\n\n간단한 이론적 성질(정의, lemma, risk–coverage 개념) 초안 작성\n\n5–7개월차: PyTorch 구현 및 초기 실험\n\nBase VAE 및 MoVAE 구현\n\nsynthetic 데이터 및 1개 공개 데이터셋에서 1차 검증\n\n코드 구조 안정화 및 hyperparameter 기본 설정\n\n8–9개월차: 본 실험 및 분석\n\n추가 데이터셋에 대한 본격 실험\n\nSingle VAE vs Mixture-of-VAEs 비교\n\nrisk-aware decision 관점에서의 성능 분석 및 ablation study\n\n10–11개월차: 논문 집필\n\n방법론(3–4장), 실험(5장)부터 집필\n\n서론·관련연구(1–2장), 결론(6장) 작성 및 통합\n\n지도교수 피드백 반영 및 수정\n\n12개월차: 최종 정리 및 제출\n\n논문 형식, 참고문헌, 그림/표 정리\n\n발표 자료 준비 및 최종 점검\n\n\n\n\n\n\n\n모델링 기여\n\n다변량 데이터를 위한 딥러닝 기반 Bayesian VAE + Mixture-of-VAEs 구조를 설계하여,\n전역 및 변수별 이상치 점수와 계층적 불확실성(internal + mode uncertainty)을 동시에 제공한다.\n\n의사결정 기여\n\n이상치 점수와 불확실성을 활용한 risk-aware 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 제안하고,\n비용 구조를 반영한 위험도 관점에서 기존 방법보다 더 나은 성능을 보임을 보인다.\n\n범용성 기여\n\n공정/센서, 네트워크/트래픽, 일반 multivariate dataset 등\n서로 다른 도메인에 동일 프레임워크를 적용함으로써,\n범용적인 “이상치 + 불확실성 + 의사결정” 프레임워크로서의 가능성을 제시한다.\n\n실무 적용 가능성\n\n실제 시스템에서\n\n언제 자동으로 STOP할지,\n\n언제 사람에게 CHECK를 요청할지,\n\n언제 IGNORE해도 되는지\n를 정량적으로 판단하는 기준을 제공하여,\n신뢰 가능한 이상치 탐지 기반 의사결정 시스템 설계에 기여할 수 있다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-주제-가제",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-주제-가제",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "다변량 딥러닝 기반 이상치 탐지에서의 불확실성 추정과\nMixture-of-VAEs를 활용한 위험 민감 의사결정 프레임워크\n(영문 예시)\nRisk-Aware Decision Framework with Uncertainty-Aware Deep Multivariate Anomaly Detection using Variational and Mixture-of-VAEs"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-배경-및-필요성",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-배경-및-필요성",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "제조 공정, 네트워크 트래픽, 금융 거래, 의료 모니터링 등 다양한 응용 분야에서 다변량(multivariate) 시계열·표형 데이터에 대한 이상치 탐지(anomaly / outlier detection) 는 안전성, 비용 절감, 서비스 안정성 측면에서 매우 중요한 과제이다.\n그러나 기존 딥러닝 기반 이상치 탐지 기법들(예: Autoencoder, LSTM-AE, CNN 기반 모델 등)은 다음과 같은 한계를 가진다.\n\n이상치 점수만 제공\n\n단일 스칼라 점수 \\(A(x)\\)만 제공하는 경우가 많아,\n“얼마나 이상한가?”는 알 수 있어도\n“이 판단을 얼마나 믿을 수 있는가?”(불확실성)는 알기 어렵다.\n\n불확실성(uncertainty) 정보 부재\n\n모델이 자신 없는 영역에서 내린 이상치 판단을\n동일한 신뢰도로 사용하게 되며,\n이는 실제 운영 환경에서 위험한 결정으로 이어질 수 있다.\n\n비용 구조가 반영되지 않은 결정\n\n실제 시스템에서는\n\n정상인데 이상치로 판단할 때의 비용(공장 정지, 서비스 중단 등)\n\n이상치인데 정상으로 넘기는 비용(고장, 사고, 손실 등)\n\n사람/전문가에게 “검토를 요청할 때” 드는 비용\n이 서로 다름에도 불구하고,\n단일 threshold 기반 이진 결정으로만 처리되는 경우가 많다.\n\n\n\n이에 본 연구는, 딥러닝 기반 베이지안 VAE와 Mixture-of-VAEs를 활용하여\n\n다변량 데이터에서 이상치 점수와 불확실성을 동시에 추정하고,\n이를 바탕으로 STOP / CHECK / IGNORE 형태의\n위험 민감(risk-aware) 의사결정 규칙을 설계하고자 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-목표-및-연구-질문",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-목표-및-연구-질문",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "Base Model:\nVariational Autoencoder(VAE)를 기반으로 한 다변량 딥러닝 이상치 탐지 모델을 설계하여,\n전역(global) 및 변수별(feature-wise) 이상치 점수와 불확실성을 동시에 추정한다.\nExtended Model:\n데이터가 여러 정상 모드(운영 상태)를 가진다고 가정하고,\nMixture-of-VAEs (MoVAE) 구조를 설계하여\n모드별 이상치·불확실성과 모드 자체에 대한 불확실성(mode uncertainty) 를 함께 추정한다.\nRisk-aware Decision:\n이상치 점수와 불확실성 정보를 활용해\n비용 구조를 반영한 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 정식화하고,\n기존 threshold 기반 기법보다 더 낮은 위험도(risk)를 달성하는지 평가한다.\n범용성 검증:\n공정/센서 시계열, 네트워크/트래픽, 공개 multivariate anomaly dataset 등\n서로 다른 도메인에서 제안 프레임워크의 일관된 효과를 검증한다.\n\n\n\n\n\nRQ1. Variational Autoencoder 기반 다변량 딥러닝 모델을 통해\n전역 및 변수별 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 동시에 추정할 수 있는가?\nRQ2. 데이터가 여러 정상 모드를 가질 때, 단일 VAE보다\nMixture-of-VAEs가 이상치 탐지 및 불확실성 추정 측면에서\n더 나은 표현력과 의사결정 성능을 제공하는가?\nRQ3. 추정된 \\((A(x), U(x))\\) (및 모드 불확실성)를 이용하여\nSTOP / CHECK / IGNORE 형태의 위험 민감 의사결정 규칙을 설계할 때,\n기존 단일 threshold 기반 이진 의사결정보다\n실제 비용(risk)을 유의하게 감소시킬 수 있는가?"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#선행-연구-및-키워드-세트",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#선행-연구-및-키워드-세트",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "이상치 탐지 / 다변량\n\nmultivariate anomaly detection\n\nmultivariate time series anomaly detection\n\ndeep anomaly detection, deep autoencoder, VAE anomaly detection\n\nreconstruction-based anomaly detection\n\n딥러닝 & 베이지안 / 불확실성\n\ndeep learning, representation learning (PyTorch / fastai)\n\nBayesian deep learning, variational inference\n\nMonte Carlo Dropout, deep ensemble\n\nuncertainty quantification, aleatoric / epistemic uncertainty\n\nVariational Autoencoder, Bayesian VAE, probabilistic autoencoder\n\nmixture of VAEs, mixture density networks, mixture-of-experts\n\n의사결정 / 위험\n\nselective prediction, abstention, reject option\n\nrisk-aware decision making, cost-sensitive learning\n\nrisk–coverage trade-off, calibration\n\n\n\n\n\n\n1–2개월차에 집중적으로 논문 수집 및 정리\n각 논문에 대해 다음 항목으로 구조화:\n\n데이터 타입 (시계열, 이미지, 센서, 트래픽 등)\n\n딥러닝 사용 여부, VAE/flow/AE 등 모델 유형\n\n이상치 점수 정의 방식 (reconstruction, likelihood, distance 등)\n\n불확실성 추정 여부 및 방법\n\nrisk-aware / selective decision 관점 고려 여부\n\n본 연구와의 차별점 / 한 줄 평가"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-내용-및-방법",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-내용-및-방법",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "본 연구는 Base Model(VAE)와 Extended Model(Mixture-of-VAEs)으로 구성되며,\n두 모델에서 공통적으로 이상치 점수 + 불확실성 추정 + risk-aware decision layer를 설계한다.\n\n\n\n\n다변량 입력 \\(x \\in \\mathbb{R}^d\\)에 대해, VAE 구조는 다음과 같이 정의한다.\n\nPrior:\n\n\\[\nz \\sim p(z) = \\mathcal{N}(0, I)\n\\]\n\nDecoder:\n\n\\[\np_\\theta(x \\mid z) = \\mathcal{N}\\big(\\mu_\\theta(z), \\text{diag}(\\sigma^2_\\theta(z))\\big)\n\\]\n\nEncoder (approximate posterior):\n\n\\[\nq_\\phi(z \\mid x) = \\mathcal{N}\\big(\\mu_\\phi(x), \\text{diag}(\\sigma^2_\\phi(x))\\big)\n\\]\n학습은 ELBO 최적화를 통해 수행한다.\n\nELBO:\n\n\\[\n\\mathcal{L}_{\\text{ELBO}}(x;\\theta,\\phi) = \\mathbb{E}_{q_\\phi(z\\mid x)}[\\log p_\\theta(x \\mid z)] - \\mathrm{KL}\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big)\n\\]\nPyTorch/fastai로는 encoder/decoder를 MLP, 1D-CNN, LSTM 등으로 구현하고,\n출력층에서 mean 및 log-variance를 예측하도록 구성한다.\n\n\n\n관측 \\(x\\)에 대해, 다음과 같이 Monte Carlo 샘플링을 수행한다.\n\n\\(z^{(t)} \\sim q_\\phi(z \\mid x), \\quad t = 1,\\dots,T\\)\n\\(\\hat x^{(t)} \\sim p_\\theta(x \\mid z^{(t)})\\)\n\n각 변수 \\(j = 1,\\dots,d\\)에 대해:\n\n변수별 이상치 점수 (재구성 오차)\n\n\\[\nr_j(x) = \\frac{1}{T} \\sum_{t=1}^T \\big(x_j - \\hat x^{(t)}_j\\big)^2\n\\]\n\n변수별 불확실성 (예측 분산)\n평균 재구성을\n\n\\[\n\\bar x_j = \\frac{1}{T} \\sum_{t=1}^T \\hat x^{(t)}_j\n\\]\n로 정의할 때,\n\\[\nu_j(x) = \\frac{1}{T-1} \\sum_{t=1}^T \\big(\\hat x^{(t)}_j - \\bar x_j\\big)^2\n\\]\n전역(global) 이상치 점수와 불확실성은 가중합으로 정의한다.\n\n전역 이상치 점수:\n\n\\[\nA_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j r_j(x)\n\\]\n\n전역 불확실성:\n\n\\[\nU_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j u_j(x)\n\\]\n여기서 \\(w_j\\)는 각 변수의 중요도를 반영하는 가중치(동일 가중치 또는 도메인 지식 기반)를 의미한다.\n필요 시, encoder/decoder 네트워크에 Dropout을 적용하여\nepistemic uncertainty를 추가로 반영할 수 있다.\n\n\n\n\n\n\n\n다변량 데이터가 여러 정상 모드(운영 상태)를 가진다고 가정한다.\n이를 위해 \\(K\\)개의 VAE expert와 gating network로 구성된 Mixture-of-VAEs 구조를 정의한다.\n\nGating network:\n\n\\[\n\\pi_k(x) = p_\\psi(k \\mid x), \\quad k = 1,\\dots,K\n\\]\n여기서 \\(\\pi_k(x)\\)는 입력 \\(x\\)가 모드 \\(k\\)에 속할 확률을 나타내며,\n\\(\\sum_{k=1}^K \\pi_k(x) = 1\\)을 만족한다.\n\n각 expert VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0, I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k) = \\mathcal{N}\\big(\\mu_{\\theta_k}(z_k), \\text{diag}(\\sigma^2_{\\theta_k}(z_k))\\big)\n\\]\n\\[\nq_{\\phi_k}(z_k \\mid x) = \\mathcal{N}\\big(\\mu_{\\phi_k}(x), \\text{diag}(\\sigma^2_{\\phi_k}(x))\\big)\n\\]\n\n전체 likelihood:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x)\n\\]\n학습은 mixture 형태의 ELBO 또는 EM-유사 전략,\n혹은 end-to-end joint training으로 수행할 수 있으며,\n실험 단계에서 구현 난이도와 성능을 고려하여 선택한다.\n\n\n\n각 expert에 대해, VAE와 동일하게 재구성 기반 점수 \\(A_k(x)\\)를 정의한다.\n\nexpert \\(k\\)의 이상치 점수(예시):\n\n\\[\nA_k(x) = \\sum_{j=1}^d w_j r_{j,k}(x)\n\\]\nMixture 전체의 이상치 점수는 다음과 같이 정의할 수 있다.\n\nlikelihood 기반:\n\n\\[\nA_{\\text{MoVAE}}(x) = -\\log \\left( \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x) \\right)\n\\]\n\nreconstruction 기반 가중합:\n\n\\[\nA_{\\text{MoVAE}}(x) = \\sum_{k=1}^K \\pi_k(x)\\, A_k(x)\n\\]\n두 정의는 실험에서 비교 가능하며,\n도메인 특성에 따라 더 좋은 score 정의를 선택할 수 있다.\n\n\n\nMixture-of-VAEs에서는 불확실성이 두 층으로 나뉜다.\n\nexpert 내부 불확실성 (in-expert uncertainty)\n\n각 expert \\(k\\)의 VAE에서 variance, MC 샘플 분산 등을 이용해\n\\(U_k(x)\\)를 정의 (Base VAE와 동일 방식).\n\n모드 불확실성 (between-expert / mode uncertainty)\n\ngating 확률 벡터 \\(\\pi(x) = (\\pi_1(x),\\dots,\\pi_K(x))\\)의 엔트로피:\n\n\n\\[\nH_\\pi(x) = -\\sum_{k=1}^K \\pi_k(x)\\log \\pi_k(x)\n\\]\n\n\\(\\pi_k(x)\\)가 한 모드에 집중되면 \\(H_\\pi(x)\\)가 작고,\n여러 모드에 고르게 분산되면 \\(H_\\pi(x)\\)가 커진다.\n→ “이 샘플이 어느 모드에 속하는지 모델이 헷갈리는 정도”로 해석 가능.\n\n\n종합 불확실성 정의 예시\n\n\\[\nU_{\\text{MoVAE}}(x) = \\alpha \\sum_{k=1}^K \\pi_k(x)\\, U_k(x) + \\beta H_\\pi(x)\n\\]\n여기서 \\(\\alpha, \\beta\\)는 모드 내부 불확실성과 모드 불확실성의 상대적 중요도를 조절하는 하이퍼파라미터이다.\n\n\n\n\n\n\n\n각 샘플 \\(x\\)에 대하여, 세 가지 행동 중 하나를 선택한다고 가정한다.\n\n\\(\\delta(x) \\in \\{\\text{IGNORE}, \\text{CHECK}, \\text{STOP}\\}\\)\n\n실제 상태 \\(y \\in \\{\\text{normal}, \\text{anomaly}\\}\\)에 대해,\n각 행동에 대한 비용을 \\(C(\\delta(x), y)\\)로 정의한다.\n예시:\n\n정상인데 STOP → 불필요한 정지, false positive 비용\n\n이상치인데 IGNORE → 사고/고장, false negative 비용 (가장 큼)\n\nCHECK → 사람/추가 검사 비용 (중간 수준)\n\n전체 기대 위험도(risk)는 다음과 같이 정의할 수 있다.\n\\[\nR(\\delta) = \\mathbb{E}_{(x,y)}\\big[\\,C(\\delta(x), y)\\,\\big]\n\\]\n실제 구현에서는 validation set 상에서의 경험적 위험 \\(\\hat R(\\delta)\\)를 최소화하는 규칙을 찾는다.\n\n\n\nBase VAE 및 MoVAE 모두, 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 기반으로 다음과 같은 규칙을 정의할 수 있다.\n예시 규칙:\n\\[\n\\delta(x) =\n\\begin{cases}\n\\text{STOP} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) \\le \\tau_U \\\\\n\\text{CHECK} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) &gt; \\tau_U \\\\\n\\text{IGNORE} & \\text{if } A(x) &lt; \\tau_A\n\\end{cases}\n\\]\n여기서 \\((\\tau_A, \\tau_U)\\)는 validation set에서\n경험적 위험 \\(\\hat R(\\tau_A,\\tau_U)\\)를 최소화하도록 탐색한다.\nMixture-of-VAEs의 경우,\n\\(U(x)\\)를 \\(U_{\\text{MoVAE}}(x)\\)로 두거나,\n모드 엔트로피 \\(H_\\pi(x)\\)를 추가 입력으로 사용하는 변형도 고려할 수 있다.\n\n\n\n\n\n\n프레임워크: PyTorch (필수), 필요 시 fastai로 학습/실험 루프 관리\n구성 요소\n\nmodels/ : VAE, Mixture-of-VAEs, gating network 모듈\n\ndatasets/ : 시계열/탭형 multivariate anomaly dataset 로더\n\ntraining/ : 학습 루프, ELBO 계산, threshold search, risk 계산\n\nanalysis/ : ROC, PR, risk–coverage, 의사결정 시뮬레이션, 시각화"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#실험-계획",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#실험-계획",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "Synthetic multivariate 데이터\n\n다변량 Gaussian, mixture, non-linear manifold 데이터 생성\n\n단일 모드 vs 다중 모드 환경에서 VAE와 MoVAE 비교\n\n공개 multivariate anomaly dataset\n\n예: 서버/센서/시계열 관련 공개 데이터셋 (SMD, MSL, SWaT 등)\n\n도메인에 따라 tabular/multivariate time series 데이터 추가 검토\n\n\n\n\n\n\nBaseline 모델\n\n단순 Autoencoder 기반 이상치 탐지\n\nVAE (불확실성 고려하지 않는 score-only 버전)\n\n필요시 다른 딥러닝 기반 anomaly detection 방법\n\n성능 지표\n\n이상치 탐지:\n\nAUROC, AUPR, F1-score, FPR@95TPR 등\n\n의사결정 / risk 관점:\n\nrisk–coverage curve\n\nfalse alarm 수, missed anomaly 수\n\nCHECK(사람 검토) 비율 대비 risk 감소 정도"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-일정-12개월-기준-예시",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-일정-12개월-기준-예시",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "1–2개월차: 문헌 조사 및 문제 정의\n\n키워드 기반 선행 연구 수집 및 정리\n\n관련 연구 요약 및 연구 질문(RQ) 확정\n\n3–4개월차: 수식 정식화 및 모델 설계\n\nVAE / Mixture-of-VAEs 수식 정리 및 손실 함수 정의\n\n이상치 점수, 불확실성, decision rule 공식화\n\n간단한 이론적 성질(정의, lemma, risk–coverage 개념) 초안 작성\n\n5–7개월차: PyTorch 구현 및 초기 실험\n\nBase VAE 및 MoVAE 구현\n\nsynthetic 데이터 및 1개 공개 데이터셋에서 1차 검증\n\n코드 구조 안정화 및 hyperparameter 기본 설정\n\n8–9개월차: 본 실험 및 분석\n\n추가 데이터셋에 대한 본격 실험\n\nSingle VAE vs Mixture-of-VAEs 비교\n\nrisk-aware decision 관점에서의 성능 분석 및 ablation study\n\n10–11개월차: 논문 집필\n\n방법론(3–4장), 실험(5장)부터 집필\n\n서론·관련연구(1–2장), 결론(6장) 작성 및 통합\n\n지도교수 피드백 반영 및 수정\n\n12개월차: 최종 정리 및 제출\n\n논문 형식, 참고문헌, 그림/표 정리\n\n발표 자료 준비 및 최종 점검"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#기대-효과-및-기여",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#기대-효과-및-기여",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "모델링 기여\n\n다변량 데이터를 위한 딥러닝 기반 Bayesian VAE + Mixture-of-VAEs 구조를 설계하여,\n전역 및 변수별 이상치 점수와 계층적 불확실성(internal + mode uncertainty)을 동시에 제공한다.\n\n의사결정 기여\n\n이상치 점수와 불확실성을 활용한 risk-aware 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 제안하고,\n비용 구조를 반영한 위험도 관점에서 기존 방법보다 더 나은 성능을 보임을 보인다.\n\n범용성 기여\n\n공정/센서, 네트워크/트래픽, 일반 multivariate dataset 등\n서로 다른 도메인에 동일 프레임워크를 적용함으로써,\n범용적인 “이상치 + 불확실성 + 의사결정” 프레임워크로서의 가능성을 제시한다.\n\n실무 적용 가능성\n\n실제 시스템에서\n\n언제 자동으로 STOP할지,\n\n언제 사람에게 CHECK를 요청할지,\n\n언제 IGNORE해도 되는지\n를 정량적으로 판단하는 기준을 제공하여,\n신뢰 가능한 이상치 탐지 기반 의사결정 시스템 설계에 기여할 수 있다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_4_papers.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_4_papers.html",
    "title": "Paper Lists - Bayesian+AnomalyDetection",
    "section": "",
    "text": "No.\nCategory\nReference (Authors, Title)\nWhy Relevant / Notes\n\n\n\n\n1\nAnomaly detection – classic survey\nChandola et al., “Anomaly Detection: A Survey” (ACM Computing Surveys)\n고전적인 이상치 탐지 전반 개요. 전통 기법들과 용어 정리용.\n\n\n2\nDeep anomaly detection – survey\nPang et al., “Deep Learning for Anomaly Detection: A Review”\n딥러닝 기반 AD를 종합적으로 정리. 딥 모델 분류·비교 구조 잡을 때 중요.\n\n\n3\nImage/video anomaly – survey\nMohammadi et al., “Deep Learning for Video Anomaly Detection – A Survey”\n영상 도메인 위주지만, 딥 AD 패턴과 실험 관행 참고용.\n\n\n4\nGraph anomaly – survey\nXu et al., “A Comprehensive Survey on Graph Anomaly Detection with Deep Learning”\n그래프 도메인이지만, deep AD 설계 아이디어·평가 지표 참고 가능.\n\n\n5\nGeneral anomaly – survey\nSalehi et al., “A Comprehensive Survey of Anomaly Detection Algorithms”\n통계·머신러닝·딥러닝 AD 기법을 넓게 개관.\n\n\n6\nMultivariate time series AD\nMalhotra et al., “LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection”\n다변량 시계열 + LSTM AE 구조. baseline 및 시계열 세팅 참고.\n\n\n7\nMultivariate time series AD\nHundman et al., “Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding”\nNASA/spacecraft 시계열 AD. thresholding 전략까지 포함해 실전 감각 참고.\n\n\n8\nMultivariate time series AD (deep)\nAudibert et al., “USAD: UnSupervised Anomaly Detection on Multivariate Time Series”\nUSAD 구조. 다변량 시계열 AD 대표적인 딥 모델 중 하나.\n\n\n9\nDeep generative AD (AE+GMM)\nZong et al., “Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection”\nAE + GMM 조합. latent mixture 아이디어 참고 (Mixture-of-VAEs와 연결).\n\n\n10\nTime-series anomaly – survey\nBraei & Wagner, “Anomaly Detection in Univariate Time Series: A Survey on the State-of-the-Art”\n시계열 AD 전반 survey. 데이터셋·지표·평가 관행 정리용.\n\n\n11\nTime-series anomaly – survey\nBlázquez-García et al., “A Review on Outlier/Anomaly Detection in Time Series Data”\n시계열 이상치 탐지 종합 리뷰. 논문 인용·관련연구 작성에 유용.\n\n\n12\nVAE – 기본 이론\nKingma & Welling, “Auto-Encoding Variational Bayes”\nVAE 이론의 원 논문. ELBO, reparameterization 등 수식의 기반.\n\n\n13\nVAE for anomaly detection (초기)\nAn & Cho, “Variational Autoencoder based Anomaly Detection using Reconstruction Probability”\nVAE를 AD에 직접 적용한 초창기 아이디어. reconstruction probability 개념.\n\n\n14\nVAE AD – 비교 연구\nNguyen et al., “Variational Autoencoder for Anomaly Detection: A Comparative Study”\n여러 VAE 기반 AD 변형을 비교. 어떤 변형을 baseline으로 잡을지 참고 가능.\n\n\n15\nClassification-based AD\nBergman & Hoshen, “Classification-Based Anomaly Detection for General Data”\n분류 기반 AD 접근. VAE/모델링과는 다른 관점의 비교 대상으로 참고.\n\n\n16\nDeep one-class AD\nXu et al., “Deep One-Class Classification”\nDeep SVDD류. one-class 관점의 AD 이론·구조 참고.\n\n\n17\nDeep semi-supervised AD\nRuff et al., “Deep Semi-Supervised Anomaly Detection”\n일부 라벨이 있는 경우 AD 설계. 비지도/반지도 경계 정리하는 데 도움.\n\n\n18\nGM-VAE / mixture latent\nDilokthanakul et al., “Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders”\nlatent space에 GMM을 둔 VAE. Mixture-of-VAEs/클러스터링 설계에 기초.\n\n\n19\nEntangled Mixture-of-VAEs\nCaciularu & Goldberger, “An Entangled Mixture of Variational Autoencoders Approach to Deep Clustering”\n여러 VAE의 mixture로 클러스터링. 우리가 말한 Mixture-of-VAEs와 매우 직접적으로 연결.\n\n\n20\nMixture-of-VAEs for clustering\n(OpenReview) “A Mixture of Variational Autoencoders for Deep Clustering”\nMoVAE 구조를 직접 다루는 논문. 모드별 VAE·게이팅 설계 참고.\n\n\n21\nVAE + Gamma mixture latent\nLi et al., “Deep Clustering Analysis via VAE with Gamma Mixture Latent Model (GamMM-VAE)”\nlatent mixture를 변형한 모델. 모드 표현/클러스터링 관점에서 아이디어 참고.\n\n\n22\nMoE + (C)VAE for AD\nMoradi et al., “Mixture of Experts with Convolutional and Variational Autoencoders for Anomaly Detection”\nCNN+VAE 기반 expert mixture로 AD 수행. MoE와 AD를 직접 연결한 사례.\n\n\n23\nBayesian DL – MC Dropout\nGal & Ghahramani, “Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning”\nMC Dropout으로 epistemic UQ 추정. VAE/encoder/decoder에 바로 적용 가능.\n\n\n24\nUQ (aleatoric/epistemic) in DL\nKendall & Gal, “What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?”\naleatoric vs epistemic 구분 + loss에 UQ 넣는 방법. 이상치 + UQ 해석에 핵심.\n\n\n25\nDeep ensembles for UQ\nLakshminarayanan et al., “Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles”\nEnsemble 기반 UQ. VAE/decoder ensemble 설계 시 참고 가능.\n\n\n26\nUQ under dataset shift\nOvadia et al., “Can You Trust Your Model’s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift”\nUQ의 신뢰성 평가. 제안 모델 UQ를 어떻게 검증할지 아이디어 제공.\n\n\n27\nBayesian DL – thesis\nGal, “Uncertainty in Deep Learning” (PhD thesis)\nBayesian DL 전반 정리. 이론 챕터(정의·정리) 쓸 때 구조 참고.\n\n\n28\nSelective prediction – theory\nGeifman & El-Yaniv, “Selective Classification for Deep Neural Networks”\nrisk–coverage, abstention 개념의 정석 논문. STOP/CHECK/IGNORE 이론 기반.\n\n\n29\nSelective prediction in NLP\nXin et al., “The Art of Abstention: Selective Prediction and Error Regularization for NLP”\nselective prediction을 딥 모델에 적용한 실전 예. loss 설계·실험 세팅 참고.\n\n\n30\nSelective classification + AUC\nPugnana et al., “AUC-based Selective Classification”\n선택적 분류에서 AUC 기반 기준 제안. selective rule 평가 지표 설계에 참고 가능."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning_2_papers.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning_2_papers.html",
    "title": "Paper Lists - Bayesian+MetaLearning",
    "section": "",
    "text": "No.\n카테고리\n제목 / 정보\n저자 / 연도\n메모(간단)\n\n\n\n\n1\nMeta-learning 개관\nMeta-Learning in Neural Networks: A Survey\nHospedales et al., 2020\n메타러닝 전반 서베이, taxonomy·응용 정리\n\n\n2\nMeta-learning (gradient)\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (MAML)\nFinn et al., 2017\n대표 gradient-based meta-learning\n\n\n3\nMeta-learning (metric)\nMatching Networks for One Shot Learning\nVinyals et al., 2016\n초기 few-shot metric 기반 모델\n\n\n4\nMeta-learning (metric)\nPrototypical Networks for Few-shot Learning\nSnell et al., 2017\n간단·강력한 metric-based baseline\n\n\n5\nMeta-learning (model-based)\nNeural Processes\nGarnelo et al., 2018\n함수 분포 기반, GP+NN 아이디어\n\n\n6\nMeta-learning (model-based)\nAttentive Neural Processes\nKim et al., 2019\nNP에 attention 도입, 성능·안정성 개선\n\n\n7\nGradient↔︎Bayes 연결\nRecasting Gradient-Based Meta-Learning as Hierarchical Bayes\nGrant et al., 2018\nMAML을 계층 베이지안으로 재해석\n\n\n8\nBayesian meta-learning\nGradient-EM Bayesian Meta-Learning\nZou & Lu, 2020\ngradient-EM 기반 베이지안 메타러닝\n\n\n9\nBayesian meta-learning\nA Hierarchical Bayesian Model for Few-Shot Meta Learning\nKim & Hospedales, ICLR 2024\n계층 베이지안 few-shot 모형 제안\n\n\n10\nBayesian meta-learning\nBayesian Meta-Learning Through Variational Gaussian Processes (VMGP)\nFortuin et al., 2021\n변분 GP 기반 베이지안 메타러닝\n\n\n11\nBayesian meta-learning (응용)\nLearning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks\n(AITRICS), 약 2021–2022\n불균형·OOD task에서 pooling 비율 조절\n\n\n12\nMulti-task GP 토대\nLearning Gaussian Processes from Multiple Tasks\nBonilla et al., ICML 2005\nmulti-task GP의 초기 계층 Bayes 정식화\n\n\n13\nMulti-task GP 토대\nMulti-task Gaussian Process Prediction\nBonilla et al., NIPS 2007\nICM/코리저널라이제이션 구조 대표 논문\n\n\n14\nMulti-task GP 토대\nMulti-task Learning with Gaussian Processes\nK. M. A. Chai, 2010\nmulti-task GP 전반 비교·분석\n\n\n15\nMulti-task GP (딥 커널)\nMultitask Gaussian Processes (deep BNN kernels)\n(여러 저자), 2019\ndeep BNN에서 유도된 multitask GP 커널\n\n\n16\nMulti-task GP 이론\nLearning Curves for Multi-task Gaussian Process Regression\nAshton & Sollich, NIPS 2012\nmulti-task GP 학습 곡선(Bayes error) 분석\n\n\n17\nMulti-task GP 이론\nGeneralization Errors and Learning Curves for Regression with Multi-task Gaussian Processes\n(Ashton 등), 2008\ntask 상관구조 vs 일반화오차\n\n\n18\nMulti-task GP 구조\nMulti-output Gaussian Processes: Coregionalization Models Using Hadamard Product (ICM/LCM)\nBonilla 계열 / 관련 저자\n코리저널라이제이션 구조 기술\n\n\n19\nMulti-task GP (scalable)\nScalable Multi-task Gaussian Processes with Neural Embedding of Coregionalization\n(예: Nguyen 등), 2022\n신경 임베딩으로 풍부한 task 공분산 학습\n\n\n20\nGP 기반 meta-learning\nLearning to Learn with Gaussian Processes (GPML)\nNguyen, Low, Jaillet, UAI 2021\n대표 GP 기반 meta-learning, task kernel\n\n\n21\nGP 기반 meta-learning\nLearning to Learn Dense Gaussian Processes for Few-Shot Learning\n(NeurIPS), 2021\ndense inducing points 활용 GP meta-learning\n\n\n22\nGP + uncertainty calibration\nMeta-learning to Calibrate Gaussian Processes with Deep Kernels for Regression Uncertainty Estimation\n(2024)\ndeep kernel GP 불확실성 calibration\n\n\n23\nGP + meta-learning (응용)\nMeta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction (ADKF-IFT)\nChen et al., ICLR 2023\n분자 property 예측용 deep kernel GP meta\n\n\n24\nPAC-Bayes meta-learning 이론\nScalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior\nRothfuss et al., JMLR 2023\nPACOH, PAC-Bayes 기반 meta-generalization\n\n\n25\nPAC-Bayes meta-learning 이론\nPACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees\nRothfuss et al., 2021\nPACOH 초기 버전, GP base learner\n\n\n26\nPAC-Bayes + BNN prior\nMeta-Learning Bayesian Neural Network Priors Based on PAC-Bayesian Theory\n(예: Rothfuss/관련 저자), 2020\nPAC-Bayes bound로 BNN prior meta-learning\n\n\n27\nPAC-Bayes + 함수공간 prior\nMeta-Learning Reliable Priors in the Function Space (F-PACOH)\nFortuin et al., NeurIPS 2021\n함수공간 stochastic process prior 학습\n\n\n28\nTask similarity + meta-learning\nTask-Similarity Aware Meta-learning through Nonparametric Kernel Regression\nVenkitaraman, Hansson, Wahlberg, 2020\ntask를 RKHS에 두고 커널로 similarity 모델\n\n\n29\nTask similarity + Bayesian meta\nBayesian Meta-Learning for Task Adaptation Using Expert-Inferred Task Similarities\nAalto Univ. MSc Thesis, 2024\n전문가가 준 similarity를 prior에 반영\n\n\n30\nTask similarity + 계층 Bayes\nCausal Similarity-Based Hierarchical Bayesian Models (Meta-Learning with Similarity of Causal Mechanisms)\nWharrie & Kaski, 2023\n인과 메커니즘 유사도로 pooling 결정"
  }
]