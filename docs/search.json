[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "어케 쓰는거냐",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "여기는 모든 포스트 목록입니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeta Learning in Neural Networks — A Survey\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts But VAE - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+MetaLearning\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nSuccessive model-agnostic meta-learning for few-shot fault time series prognosis\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 15, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+MetaLearning\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n어케 쓰는거냐\n\n\n\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n이상치 탐지 with Uncertainty?\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "국문 제목\nTask 간 유사도를 반영한 계층 베이지안 메타러닝 prior의 일반적 구성과 통계적 성질\n영문 제목\nA General Prior Design Incorporating Task Similarity in Hierarchical Bayesian Meta-Learning and Its Statistical Properties\n\n\n\n\n딥러닝 기반 모델은 대규모 데이터와 연산 자원을 요구하며, 새로운 task가 등장할 때마다 학습을 처음부터 반복해야 한다는 한계를 가진다. 이를 극복하기 위해 등장한 meta-learning(learning to learn) 은 여러 task로부터 축적된 경험을 이용하여, 새로운 task에 대한 빠른 적응과 데이터 효율적 학습을 목표로 한다.\n최근 meta-learning 연구는 few-shot 이미지 분류, 강화학습, 베이지안 신경망 등 다양한 응용에서 활발히 진행되고 있으며, 특히 여러 task 간의 공통 구조를 활용하는 계층 베이지안(hierarchical Bayes) 및 Gaussian process(GP) 기반 meta-learning 이 주목받고 있다.\n그러나 기존 Bayesian/meta-learning 연구들은 다음과 같은 한계를 가진다.\n\nTask 유사도 구조의 모형화 부족\n\n많은 meta-learning 알고리즘은 암묵적으로 “task들이 유사하다”는 가정을 갖고 있으나,\n유사도를 명시적인 prior 공분산 구조로 표현하고 그 통계적 효과를 분석한 연구는 제한적이다.\n\n선형–가우시안 계층 모형에서의 이론적 분석 부족\n\nGP 기반 meta-learning은 task 간 커널을 제안하고 실험적으로 성능 향상을 보이지만,\n단순한 선형 회귀/가우시안 노이즈 환경에서\ntask similarity를 반영한 prior와 독립 prior의 Bayes risk를 비교·정량화하는 통계적 연구는 상대적으로 부족하다.\n\nMeta-learning 이론(예: PAC-Bayes bound)과 구체적 prior 구조의 연결 부족\n\nPAC-Bayesian meta-learning은 hyper-posterior의 최적 구조(PACOH)를 제시하지만,\n구체적인 task similarity 기반 prior가 이러한 이론적 틀 안에서 어떤 효과를 가지는지에 대한 정량적 논의는 제한적이다.\n\n\n본 연구는 이러한 한계를 해결하고자, task 간 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구조를 제안하고,\n선형–가우시안 계층 모형에서의 Bayes risk 및 학습 곡선(learning curve) 관점에서 그 통계적 성질을 분석하는 것을 목표로 한다.\n\n\n\n\n\n\nMeta-learning은 여러 task로부터 “학습 알고리즘 자체” 또는 “초기 파라미터/표현”을 학습하여, 새로운 task에 빠르게 적응하는 것을 목표로 한다. Hospedales et al.은 meta-learning을 정리하면서, meta-train / meta-test 분할, N-way K-shot 설정, task 분포 \\(\\mathcal{T}\\) 등의 표준 수학적 세팅을 제시하고, 다양한 방법론을 포괄하는 taxonomy를 제안하였다.\n일반적으로 meta-learning은 다음과 같이 정식화된다.\n\nTask 분포 \\(\\mathcal{T}\\) 에서 task \\(t\\)를 샘플: \\[\nt \\sim \\mathcal{T}, \\quad D_t = \\{(x_{ti}, y_{ti})\\}_{i=1}^{n_t}\n\\]\nMeta-train 단계에서 여러 \\(t=1,\\dots,T\\) 에 대해 데이터를 관측하고,\n새로운 task \\(t^\\*\\) 에 대한 적은 양의 데이터로 빠르게 적응하는 meta-learner를 학습한다.\n\nHospedales et al.의 taxonomy에 따르면, meta-learning 방법은 크게\n(1) optimization-based, (2) metric-based, (3) model-based, (4) Bayesian/probabilistic 기반 방법으로 나눌 수 있다.\n본 연구는 이 중 Bayesian/probabilistic meta-learning 축에 속한다.\n\n\n\n\nOptimization-based meta-learning의 대표적 예로 MAML(Model-Agnostic Meta-Learning) 계열이 있다. 이들은 모델 파라미터의 초기값 \\(\\phi\\) 를 meta-level에서 학습하고, 각 task별로 서버럴 스텝의 gradient descent를 통해 적응한다. 이러한 방법들은 다양한 신경망 구조에 적용이 가능하고, 구현이 상대적으로 간단하다는 장점이 있어 few-shot 학습에서 널리 사용된다.\nGrant et al.는 “Recasting Gradient-Based Meta-Learning as Hierarchical Bayes” 에서 MAML과 같은 gradient-based meta-learning이, 적당한 근사 하에서 계층 베이지안 추론의 한 형태로 해석될 수 있음을 보였다.\n즉, meta-parameter는 상위 계층의 hyperparameter, inner-loop 업데이트는 task-specific posterior mode 추정에 해당한다.\n또한, Zou & Lu는 Gradient-EM Bayesian Meta-Learning 을 통해 계층 베이지안 모형에서 empirical Bayes 추정을 수행하는 gradient-EM 기반 meta-learning 알고리즘을 제안하고, 기존 gradient-based meta-learning 알고리즘을 하나의 Bayesian 틀 안에서 통합하여 해석하였다.\n이러한 연구들은 gradient-based meta-learning과 계층 베이지안 추론 간의 연결을 보여주지만,\ntask 유사도 구조를 공분산으로 명시적으로 모델링하고 그 통계적 성질을 분석하는 데에는 초점을 두지 않는다.\n\n\n\n\nBayesian meta-learning은 여러 task의 데이터를 이용하여 prior 또는 hyperparameter를 empirical Bayes/fully Bayes 방식으로 추정하고, 새로운 task에 대해 불확실성 추정을 포함한 적응을 수행한다.\n일반적인 계층 베이지안 meta-learning 모형은 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\eta &\\sim p(\\eta), \\\\\n\\theta_t \\mid \\eta &\\sim p(\\theta_t \\mid \\eta), \\quad t = 1,\\dots,T, \\\\\nD_t \\mid \\theta_t &\\sim p(D_t \\mid \\theta_t),\n\\end{aligned}\n\\]\n여기서 \\(\\eta\\) 는 상위 계층의 hyperparameter, \\(\\theta_t\\) 는 task-specific 파라미터이다.\nGradient-EM Bayesian meta-learning과 관련 연구들은 이러한 구조에서\n\\(\\eta\\) 를 empirical Bayes 방식으로 추정하는 다양한 알고리즘과 이론적 성질을 제시하였다.\n그러나 Bayesian meta-learning 문헌의 상당수는 hyperparameter 추정 알고리즘과 실험적 성능에 집중하며,\ntask 간 유사도 구조가 prior 공분산에 어떻게 반영되며, 이로 인해 Bayes risk와 pooling 정도가 어떻게 변하는지에 대한 체계적 분석은 상대적으로 부족하다.\n\n\n\n\n\n\nGaussian process(GP)는 함수 공간의 베이지안 prior로서, 불확실성을 자연스럽게 표현할 수 있다는 장점이 있다. Nguyen et al.은 “Learning to Learn with Gaussian Processes”에서 few-shot 회귀 문제를 위해 Gaussian Process Meta-Learning(GPML) 을 제안하였으며, task 간 거리를 이용한 novel task kernel 을 도입하여 meta-learning 환경에서 task 간 유사도를 활용하였다.\n이와 유사한 GP 기반 meta-learning 연구들은, multi-task GP, deep kernel GP, variational GP 등의 구조를 활용하여 task 간 공유 정보를 모델링하고 few-shot 상황에서 성능 향상을 보였다.\n또한 Ashton & Sollich은 “Learning curves for multi-task Gaussian process regression”에서\nmulti-task GP 회귀의 평균 Bayes error(learning curve) 를 분석하여, task 간 공분산 구조가 학습 곡선에 미치는 영향을 정량적으로 연구하였다.\n이는 본 연구에서 계획하는 task similarity 기반 prior의 Bayes risk 분석과 직접적인 수학적 연관이 있다.\n\n\n\nRothfuss et al.은 “Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior (PACOH)”에서\nmeta-learning의 generalization error에 대한 PAC-Bayesian upper bound를 유도하고, 이를 최소화하는 PAC-optimal hyper-posterior (PACOH) 를 도출하였다.\nPACOH는 GP, Bayesian neural network 등 다양한 base learner에 적용 가능하며, meta-level regularization을 이론적으로 정당화한다.\nPAC-Bayesian meta-learning 이론은 meta-level에서의 최적 prior/hyper-posterior 구조에 대한 중요한 통찰을 제공하지만,\n구체적인 task similarity 기반 공분산 구조가 이러한 bound에 어떤 영향을 주는지에 대한 분석은 제한적이다.\n\n\n\n\n\nMulti-task learning 및 GP 기반 모델에서는 오래전부터 task 간 유사도를 공분산 구조로 표현해 왔다.\n예를 들어, multi-task GP에서는 입력 커널 \\(K_x\\)와 task 간 공분산 \\(\\Sigma_{\\text{task}}\\)의 곱으로 전체 공분산을 구성한다.\n\\[\nK((x,s), (x',t)) = K_x(x, x') \\cdot \\Sigma_{\\text{task}}(s,t).\n\\]\n여기서 \\(\\Sigma_{\\text{task}}\\)는 task 간 유사도/상관을 반영하는 행렬이다.\nNguyen et al.의 GPML은 task 간 거리를 활용한 task kernel 을 제안하여, meta-learning 환경에서 task similarity를 명시적으로 모델링한다.\n또한 다양한 multi-task GP, hierarchical GP 연구에서는 task feature, 그래프 구조, 군집 등을 이용한 공분산 설계를 시도하고 있다.\n하지만 이들 연구는 주로 복잡한 GP 구조 및 대규모 실험에 기반한 모델 제안에 집중하며,\n단순한 선형–가우시안 계층 모형에서\n\n\ntask similarity를 반영한 prior 공분산 구조가 어떤 조건 하에서 유효한지,\n\n\n\n독립 prior 대비 Bayes risk 및 learning curve가 어떻게 달라지는지\n\n\n를 이론적으로 분석하는 통계적 연구는 상대적으로 부족하다.\n따라서 본 연구는, 선형–가우시안 계층 베이지안 meta-learning 모형을 기반으로\ntask similarity 기반 prior 구조를 일반적으로 정의하고, Bayes risk 및 pooling 구조를 수학적으로 분석함으로써,\n기존 문헌의 공백을 메우고자 한다.\n\n\n\n\n\n\n\n\nTask 간 유사도를 반영하는 일반적인 계층 베이지안 meta-learning prior 구조 제안\n\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 Bayes risk 및 학습 곡선 비교 분석\n\n제안 prior 구조의 이론적 성질(유효성, risk 개선 조건 등)을 정리하고, 시뮬레이션 및 실증으로 검증\n\n\n\n\n\nRQ1. Task feature 또는 task 간 거리/그래프 정보를 이용하여,\n계층 베이지안 meta-learning에서 일반적으로 사용할 수 있는 task similarity 기반 prior 공분산 구조를 어떻게 정의할 수 있는가?\nRQ2. 선형 회귀 + 가우시안 노이즈 환경에서,\nsimilarity-aware prior와 독립 prior에 기반한 meta-learning의 Bayes risk는 어떻게 비교되는가?\n특히 어떤 조건(유사도 구조가 실제 task 관계를 잘 반영할 때 등) 하에서 risk 개선이 발생하는가?\nRQ3. Multi-task GP 회귀의 학습 곡선 분석 결과를 활용하여,\nsimilarity-aware prior의 평균 Bayes error(learning curve) 에 대한 해석적 표현 또는 근사/상하한을 제시할 수 있는가?\nRQ4. 제안 prior 구조와 분석 결과는\n실제 meta-learning 환경(예: few-shot 회귀/분류 데이터셋)에서 성능 향상 및 불확실성 측정 개선으로 이어지는가?\n\n\n\n\n\n\n\n\n본 연구는 다음과 같은 선형–가우시안 계층 베이지안 meta-learning 모형을 기본으로 한다.\n\nTask \\(t\\)의 회귀 모형: \\[\ny_{ti} = x_{ti}^\\top \\beta_t + \\epsilon_{ti}, \\quad\n\\epsilon_{ti} \\sim \\mathcal{N}(0, \\sigma^2),\n\\] 여기서 \\(x_{ti} \\in \\mathbb{R}^d\\), \\(\\beta_t \\in \\mathbb{R}^d\\).\n각 task의 파라미터 벡터를 쌓아 \\[\n\\beta = (\\beta_1^\\top, \\dots, \\beta_T^\\top)^\\top.\n\\]\n\n\n\n\n\n\n기존 계층 모형에서 자주 사용하는 baseline prior는 다음과 같다.\n\\[\n\\beta_t \\sim \\mathcal{N}(0, \\tau^2 I_d), \\quad t = 1,\\dots,T,\n\\]\n또는 전체 벡터에 대해\n\\[\n\\beta \\sim \\mathcal{N}(0, I_T \\otimes \\tau^2 I_d).\n\\]\n이는 task 간 독립성을 가정하며, task 간 유사도 구조를 반영하지 않는다.\n\n\n\n본 연구에서는 task feature \\(\\phi(t) \\in \\mathbb{R}^q\\) 또는 task 간 거리/그래프 정보를 이용하여\n다음과 같은 task covariance 행렬을 정의한다.\n\n커널 기반 구조: \\[\n\\Sigma_{\\text{task}}(s,t) = k(\\phi(s), \\phi(t)),\n\\] 여기서 \\(k\\)는 positive definite kernel (예: RBF, Matérn 등)이다.\n그래프 라플라시안 기반 구조: \\[\n\\Sigma_{\\text{task}} = (L + \\lambda I)^{-1},\n\\] 여기서 \\(L\\)은 task 그래프의 라플라시안, \\(\\lambda&gt;0\\)는 regularization 파라미터이다.\n\n이를 이용하여 전체 prior 공분산을\n\\[\n\\operatorname{cov}(\\beta) = \\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\n\\]\n로 정의하는 similarity-aware prior를 제안한다.\n이때 \\(k\\)의 positive definiteness, \\(L\\)의 성질 등을 이용하여\n\\(\\Sigma_{\\text{task}}\\) 및 \\(\\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\\) 가 양정치 행렬이 됨을 보이고,\n이에 따라 prior가 well-defined multivariate Gaussian이 됨을 정리 형태로 제시한다.\n\n\n\n\n\n\n선형–가우시안 모형에서 similarity-aware prior를 사용하면,\nposterior 및 posterior predictive distribution은 닫힌형으로 표현 가능하다.\n\nPosterior: \\[\np(\\beta \\mid D_{1:T}) = \\mathcal{N}(\\mu_{\\beta\\mid D}, \\Sigma_{\\beta\\mid D}),\n\\] 여기서 \\(\\mu_{\\beta\\mid D}\\), \\(\\Sigma_{\\beta\\mid D}\\)는 prior 공분산과 데이터 행렬 \\(X_{1:T}\\), 노이즈 분산 \\(\\sigma^2\\)에 의해 결정된다.\n새로운 task \\(t^\\*\\) 에 대한 예측 분포: \\[\np(y^\\* \\mid x^\\*, D_{1:T}, D_{t^\\*}) = \\mathcal{N}(m(x^\\*), v(x^\\*)),\n\\]\n\n이를 독립 prior와 similarity-aware prior 두 경우에 대해 명시적으로 도출한다.\n\n\n\n새로운 task에서의 예측 MSE를 Bayes risk로 정의한다.\n\\[\nR = \\mathbb{E}\\left[(y^\\* - \\hat{y}^\\*)^2\\right],\n\\]\n여기서 기대는 데이터 및 prior/likelihood에 대한 joint 분포에 대해 취한다.\n\n독립 prior: \\(R_{\\text{ind}}\\)\nsimilarity-aware prior: \\(R_{\\text{sim}}\\)\n\n를 각각 계산하거나 상·하한을 도출하고,\n특히 task covariance 행렬 \\(\\Sigma_{\\text{task}}\\)와 참 covariance \\(\\Sigma_{\\text{true}}\\)의 정렬 정도(예: eigen 구조, 코사인 유사도 등)에 따라\n\\[\nR_{\\text{sim}} \\le R_{\\text{ind}}\n\\]\n가 성립하는 조건을 정리 형태(정리/레마)로 제시한다.\n이 과정에서 multi-task GP learning curve 분석에서 사용된 테크닉 을 참고하여,\n평균 Bayes error를 task 수 \\(T\\), 각 task의 샘플 수 \\(n_t\\)의 함수로 표현하는 근사식을 도출하는 것을 목표로 한다.\n\n\n\nAshton & Sollich의 multi-task GP learning curve 결과를 차용하여,\n본 연구에서 정의한 선형–가우시안 모형이 multi-task GP의 특수한 경우에 해당함을 보이고,\nsimilarity-aware prior의 학습 곡선을\n\\[\n\\epsilon(n) = \\mathbb{E}\\left[ (f_{t^\\*}(x) - \\hat{f}_{t^\\*}(x))^2 \\right]\n\\]\n형태로 표현하거나 근사함으로써,\n\ntask similarity 구조가 클수록,\n\n다른 task의 데이터가 많을수록,\n\n새로운 task의 Bayes error가 더 빠르게 감소한다는 결과를 이론적으로 설명한다.\n\n\n\n\n\n시뮬레이션 환경 구성\n\nTask feature 및 참 task covariance \\(\\Sigma_{\\text{true}}\\) 를 설계하여,\n\n\nsimilarity-aware prior가 참 구조와 잘 맞는 경우,\n\n\n구조가 mismatch된 경우,\n\n\n실제로 task들이 독립인 경우, 를 비교.\n\n\n각 설정에서 \\(T\\), \\(n_t\\)를 변화시키며 독립 prior vs similarity-aware prior의\nBayes risk 및 학습 곡선을 비교.\n\n실제 데이터 기반 meta-learning 실험\n\n공개된 few-shot 회귀/분류 데이터셋(예: UCI 회귀 데이터셋을 여러 task로 나눈 환경 등)에 대해,\ntask feature(예: 입력 분포 통계량, domain index 등)를 구성하고\n제안 prior 구조를 적용.\n예측 정확도, 불확실성 calibration, 샘플 효율성 등의 지표 비교를 통해\n이론 결과와의 일관성을 확인.\n\n\n\n\n\n\n\n\n이론적 기여\n\nTask 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구성 틀을 제시하고,\n그 유효성(positive definiteness)과 Bayes risk 측면의 이점을 정리 형태로 제시한다.\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 risk/learning curve 비교 분석을 통해,\n기존 GP/meta-learning 문헌의 공백을 메운다.\n\n범용성 있는 방법론 제안\n\n제안 prior 구조는 task feature, 그래프, 클러스터 등 다양한 유사도 정보를 커널/공분산 형태로 통합할 수 있어,\n회귀, 분류, GP, BNN 등 다양한 meta-learning 환경에 적용 가능하다.\n\nMeta-learning 이론과 실용 알고리즘 간의 연결 강화\n\nMulti-task GP와 PAC-Bayesian meta-learning의 이론적 결과를\n구체적인 prior 설계 문제와 연결함으로써,\nmeta-learning 알고리즘 설계에 대한 통계적·이론적 가이드를 제공한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n기간\n내용\n\n\n\n\n1학기 전반 (3–4월)\nMeta-learning 및 Bayesian/meta-learning, GP, multi-task GP 문헌 조사\n\n\n1학기 후반 (5–7월)\n모형 설정 구체화, prior 구조 정의, 기본 정리(유효성) 도출\n\n\n여름 방학 (7–8월)\nBayes risk/learning curve 이론적 분석, 초벌 증명 정리\n\n\n2학기 전반 (9–10월)\n시뮬레이션 코드 구현, synthetic 실험 및 결과 분석\n\n\n2학기 후반 (11–1월)\n실증 데이터 실험, 결과 해석 및 이론과의 연결\n\n\n3학기 전반 (3–4월)\n논문 초고(1–4장) 작성, 정리/보완\n\n\n3학기 후반 (5–7월)\n논문 최종 수정, 심사 준비 및 발표\n\n\n\n(실제 일정은 지도교수와의 논의를 거쳐 조정 예정)\n\n\n\n\n\nHospedales, T., Antoniou, A., Micaelli, P., & Storkey, A. (2021). Meta-Learning in Neural Networks: A Survey.\n\nGrant, E., Finn, C., Levine, S., Darrell, T., & Griffiths, T. (2018). Recasting Gradient-Based Meta-Learning as Hierarchical Bayes. ICLR.\n\nZou, Y., & Lu, X. (2020). Gradient-EM Bayesian Meta-Learning. NeurIPS.\n\nNguyen, Q. P., Low, B. K. H., & Jaillet, P. (2021). Learning to Learn with Gaussian Processes. UAI.\n\nAshton, S. R. F., & Sollich, P. (2012). Learning Curves for Multi-task Gaussian Process Regression. NeurIPS.\n\nRothfuss, J., Josifoski, M., Fortuin, V., & Krause, A. (2021). Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior.\n\nChai, K. M. A. (2010). Multi-task Learning with Gaussian Processes.\n\n(최종 참고 문헌 목록은 실제 논문 작성 시 추가·수정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-주제",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-주제",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "국문 제목\nTask 간 유사도를 반영한 계층 베이지안 메타러닝 prior의 일반적 구성과 통계적 성질\n영문 제목\nA General Prior Design Incorporating Task Similarity in Hierarchical Bayesian Meta-Learning and Its Statistical Properties"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-배경-및-필요성",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-배경-및-필요성",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "딥러닝 기반 모델은 대규모 데이터와 연산 자원을 요구하며, 새로운 task가 등장할 때마다 학습을 처음부터 반복해야 한다는 한계를 가진다. 이를 극복하기 위해 등장한 meta-learning(learning to learn) 은 여러 task로부터 축적된 경험을 이용하여, 새로운 task에 대한 빠른 적응과 데이터 효율적 학습을 목표로 한다.\n최근 meta-learning 연구는 few-shot 이미지 분류, 강화학습, 베이지안 신경망 등 다양한 응용에서 활발히 진행되고 있으며, 특히 여러 task 간의 공통 구조를 활용하는 계층 베이지안(hierarchical Bayes) 및 Gaussian process(GP) 기반 meta-learning 이 주목받고 있다.\n그러나 기존 Bayesian/meta-learning 연구들은 다음과 같은 한계를 가진다.\n\nTask 유사도 구조의 모형화 부족\n\n많은 meta-learning 알고리즘은 암묵적으로 “task들이 유사하다”는 가정을 갖고 있으나,\n유사도를 명시적인 prior 공분산 구조로 표현하고 그 통계적 효과를 분석한 연구는 제한적이다.\n\n선형–가우시안 계층 모형에서의 이론적 분석 부족\n\nGP 기반 meta-learning은 task 간 커널을 제안하고 실험적으로 성능 향상을 보이지만,\n단순한 선형 회귀/가우시안 노이즈 환경에서\ntask similarity를 반영한 prior와 독립 prior의 Bayes risk를 비교·정량화하는 통계적 연구는 상대적으로 부족하다.\n\nMeta-learning 이론(예: PAC-Bayes bound)과 구체적 prior 구조의 연결 부족\n\nPAC-Bayesian meta-learning은 hyper-posterior의 최적 구조(PACOH)를 제시하지만,\n구체적인 task similarity 기반 prior가 이러한 이론적 틀 안에서 어떤 효과를 가지는지에 대한 정량적 논의는 제한적이다.\n\n\n본 연구는 이러한 한계를 해결하고자, task 간 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구조를 제안하고,\n선형–가우시안 계층 모형에서의 Bayes risk 및 학습 곡선(learning curve) 관점에서 그 통계적 성질을 분석하는 것을 목표로 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#선행-연구-및-이론적-배경",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#선행-연구-및-이론적-배경",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Meta-learning은 여러 task로부터 “학습 알고리즘 자체” 또는 “초기 파라미터/표현”을 학습하여, 새로운 task에 빠르게 적응하는 것을 목표로 한다. Hospedales et al.은 meta-learning을 정리하면서, meta-train / meta-test 분할, N-way K-shot 설정, task 분포 \\(\\mathcal{T}\\) 등의 표준 수학적 세팅을 제시하고, 다양한 방법론을 포괄하는 taxonomy를 제안하였다.\n일반적으로 meta-learning은 다음과 같이 정식화된다.\n\nTask 분포 \\(\\mathcal{T}\\) 에서 task \\(t\\)를 샘플: \\[\nt \\sim \\mathcal{T}, \\quad D_t = \\{(x_{ti}, y_{ti})\\}_{i=1}^{n_t}\n\\]\nMeta-train 단계에서 여러 \\(t=1,\\dots,T\\) 에 대해 데이터를 관측하고,\n새로운 task \\(t^\\*\\) 에 대한 적은 양의 데이터로 빠르게 적응하는 meta-learner를 학습한다.\n\nHospedales et al.의 taxonomy에 따르면, meta-learning 방법은 크게\n(1) optimization-based, (2) metric-based, (3) model-based, (4) Bayesian/probabilistic 기반 방법으로 나눌 수 있다.\n본 연구는 이 중 Bayesian/probabilistic meta-learning 축에 속한다.\n\n\n\n\nOptimization-based meta-learning의 대표적 예로 MAML(Model-Agnostic Meta-Learning) 계열이 있다. 이들은 모델 파라미터의 초기값 \\(\\phi\\) 를 meta-level에서 학습하고, 각 task별로 서버럴 스텝의 gradient descent를 통해 적응한다. 이러한 방법들은 다양한 신경망 구조에 적용이 가능하고, 구현이 상대적으로 간단하다는 장점이 있어 few-shot 학습에서 널리 사용된다.\nGrant et al.는 “Recasting Gradient-Based Meta-Learning as Hierarchical Bayes” 에서 MAML과 같은 gradient-based meta-learning이, 적당한 근사 하에서 계층 베이지안 추론의 한 형태로 해석될 수 있음을 보였다.\n즉, meta-parameter는 상위 계층의 hyperparameter, inner-loop 업데이트는 task-specific posterior mode 추정에 해당한다.\n또한, Zou & Lu는 Gradient-EM Bayesian Meta-Learning 을 통해 계층 베이지안 모형에서 empirical Bayes 추정을 수행하는 gradient-EM 기반 meta-learning 알고리즘을 제안하고, 기존 gradient-based meta-learning 알고리즘을 하나의 Bayesian 틀 안에서 통합하여 해석하였다.\n이러한 연구들은 gradient-based meta-learning과 계층 베이지안 추론 간의 연결을 보여주지만,\ntask 유사도 구조를 공분산으로 명시적으로 모델링하고 그 통계적 성질을 분석하는 데에는 초점을 두지 않는다.\n\n\n\n\nBayesian meta-learning은 여러 task의 데이터를 이용하여 prior 또는 hyperparameter를 empirical Bayes/fully Bayes 방식으로 추정하고, 새로운 task에 대해 불확실성 추정을 포함한 적응을 수행한다.\n일반적인 계층 베이지안 meta-learning 모형은 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\eta &\\sim p(\\eta), \\\\\n\\theta_t \\mid \\eta &\\sim p(\\theta_t \\mid \\eta), \\quad t = 1,\\dots,T, \\\\\nD_t \\mid \\theta_t &\\sim p(D_t \\mid \\theta_t),\n\\end{aligned}\n\\]\n여기서 \\(\\eta\\) 는 상위 계층의 hyperparameter, \\(\\theta_t\\) 는 task-specific 파라미터이다.\nGradient-EM Bayesian meta-learning과 관련 연구들은 이러한 구조에서\n\\(\\eta\\) 를 empirical Bayes 방식으로 추정하는 다양한 알고리즘과 이론적 성질을 제시하였다.\n그러나 Bayesian meta-learning 문헌의 상당수는 hyperparameter 추정 알고리즘과 실험적 성능에 집중하며,\ntask 간 유사도 구조가 prior 공분산에 어떻게 반영되며, 이로 인해 Bayes risk와 pooling 정도가 어떻게 변하는지에 대한 체계적 분석은 상대적으로 부족하다.\n\n\n\n\n\n\nGaussian process(GP)는 함수 공간의 베이지안 prior로서, 불확실성을 자연스럽게 표현할 수 있다는 장점이 있다. Nguyen et al.은 “Learning to Learn with Gaussian Processes”에서 few-shot 회귀 문제를 위해 Gaussian Process Meta-Learning(GPML) 을 제안하였으며, task 간 거리를 이용한 novel task kernel 을 도입하여 meta-learning 환경에서 task 간 유사도를 활용하였다.\n이와 유사한 GP 기반 meta-learning 연구들은, multi-task GP, deep kernel GP, variational GP 등의 구조를 활용하여 task 간 공유 정보를 모델링하고 few-shot 상황에서 성능 향상을 보였다.\n또한 Ashton & Sollich은 “Learning curves for multi-task Gaussian process regression”에서\nmulti-task GP 회귀의 평균 Bayes error(learning curve) 를 분석하여, task 간 공분산 구조가 학습 곡선에 미치는 영향을 정량적으로 연구하였다.\n이는 본 연구에서 계획하는 task similarity 기반 prior의 Bayes risk 분석과 직접적인 수학적 연관이 있다.\n\n\n\nRothfuss et al.은 “Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior (PACOH)”에서\nmeta-learning의 generalization error에 대한 PAC-Bayesian upper bound를 유도하고, 이를 최소화하는 PAC-optimal hyper-posterior (PACOH) 를 도출하였다.\nPACOH는 GP, Bayesian neural network 등 다양한 base learner에 적용 가능하며, meta-level regularization을 이론적으로 정당화한다.\nPAC-Bayesian meta-learning 이론은 meta-level에서의 최적 prior/hyper-posterior 구조에 대한 중요한 통찰을 제공하지만,\n구체적인 task similarity 기반 공분산 구조가 이러한 bound에 어떤 영향을 주는지에 대한 분석은 제한적이다.\n\n\n\n\n\nMulti-task learning 및 GP 기반 모델에서는 오래전부터 task 간 유사도를 공분산 구조로 표현해 왔다.\n예를 들어, multi-task GP에서는 입력 커널 \\(K_x\\)와 task 간 공분산 \\(\\Sigma_{\\text{task}}\\)의 곱으로 전체 공분산을 구성한다.\n\\[\nK((x,s), (x',t)) = K_x(x, x') \\cdot \\Sigma_{\\text{task}}(s,t).\n\\]\n여기서 \\(\\Sigma_{\\text{task}}\\)는 task 간 유사도/상관을 반영하는 행렬이다.\nNguyen et al.의 GPML은 task 간 거리를 활용한 task kernel 을 제안하여, meta-learning 환경에서 task similarity를 명시적으로 모델링한다.\n또한 다양한 multi-task GP, hierarchical GP 연구에서는 task feature, 그래프 구조, 군집 등을 이용한 공분산 설계를 시도하고 있다.\n하지만 이들 연구는 주로 복잡한 GP 구조 및 대규모 실험에 기반한 모델 제안에 집중하며,\n단순한 선형–가우시안 계층 모형에서\n\n\ntask similarity를 반영한 prior 공분산 구조가 어떤 조건 하에서 유효한지,\n\n\n\n독립 prior 대비 Bayes risk 및 learning curve가 어떻게 달라지는지\n\n\n를 이론적으로 분석하는 통계적 연구는 상대적으로 부족하다.\n따라서 본 연구는, 선형–가우시안 계층 베이지안 meta-learning 모형을 기반으로\ntask similarity 기반 prior 구조를 일반적으로 정의하고, Bayes risk 및 pooling 구조를 수학적으로 분석함으로써,\n기존 문헌의 공백을 메우고자 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-목적-및-연구-질문",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-목적-및-연구-질문",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Task 간 유사도를 반영하는 일반적인 계층 베이지안 meta-learning prior 구조 제안\n\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 Bayes risk 및 학습 곡선 비교 분석\n\n제안 prior 구조의 이론적 성질(유효성, risk 개선 조건 등)을 정리하고, 시뮬레이션 및 실증으로 검증\n\n\n\n\n\nRQ1. Task feature 또는 task 간 거리/그래프 정보를 이용하여,\n계층 베이지안 meta-learning에서 일반적으로 사용할 수 있는 task similarity 기반 prior 공분산 구조를 어떻게 정의할 수 있는가?\nRQ2. 선형 회귀 + 가우시안 노이즈 환경에서,\nsimilarity-aware prior와 독립 prior에 기반한 meta-learning의 Bayes risk는 어떻게 비교되는가?\n특히 어떤 조건(유사도 구조가 실제 task 관계를 잘 반영할 때 등) 하에서 risk 개선이 발생하는가?\nRQ3. Multi-task GP 회귀의 학습 곡선 분석 결과를 활용하여,\nsimilarity-aware prior의 평균 Bayes error(learning curve) 에 대한 해석적 표현 또는 근사/상하한을 제시할 수 있는가?\nRQ4. 제안 prior 구조와 분석 결과는\n실제 meta-learning 환경(예: few-shot 회귀/분류 데이터셋)에서 성능 향상 및 불확실성 측정 개선으로 이어지는가?"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-내용-및-방법",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-내용-및-방법",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "본 연구는 다음과 같은 선형–가우시안 계층 베이지안 meta-learning 모형을 기본으로 한다.\n\nTask \\(t\\)의 회귀 모형: \\[\ny_{ti} = x_{ti}^\\top \\beta_t + \\epsilon_{ti}, \\quad\n\\epsilon_{ti} \\sim \\mathcal{N}(0, \\sigma^2),\n\\] 여기서 \\(x_{ti} \\in \\mathbb{R}^d\\), \\(\\beta_t \\in \\mathbb{R}^d\\).\n각 task의 파라미터 벡터를 쌓아 \\[\n\\beta = (\\beta_1^\\top, \\dots, \\beta_T^\\top)^\\top.\n\\]\n\n\n\n\n\n\n기존 계층 모형에서 자주 사용하는 baseline prior는 다음과 같다.\n\\[\n\\beta_t \\sim \\mathcal{N}(0, \\tau^2 I_d), \\quad t = 1,\\dots,T,\n\\]\n또는 전체 벡터에 대해\n\\[\n\\beta \\sim \\mathcal{N}(0, I_T \\otimes \\tau^2 I_d).\n\\]\n이는 task 간 독립성을 가정하며, task 간 유사도 구조를 반영하지 않는다.\n\n\n\n본 연구에서는 task feature \\(\\phi(t) \\in \\mathbb{R}^q\\) 또는 task 간 거리/그래프 정보를 이용하여\n다음과 같은 task covariance 행렬을 정의한다.\n\n커널 기반 구조: \\[\n\\Sigma_{\\text{task}}(s,t) = k(\\phi(s), \\phi(t)),\n\\] 여기서 \\(k\\)는 positive definite kernel (예: RBF, Matérn 등)이다.\n그래프 라플라시안 기반 구조: \\[\n\\Sigma_{\\text{task}} = (L + \\lambda I)^{-1},\n\\] 여기서 \\(L\\)은 task 그래프의 라플라시안, \\(\\lambda&gt;0\\)는 regularization 파라미터이다.\n\n이를 이용하여 전체 prior 공분산을\n\\[\n\\operatorname{cov}(\\beta) = \\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\n\\]\n로 정의하는 similarity-aware prior를 제안한다.\n이때 \\(k\\)의 positive definiteness, \\(L\\)의 성질 등을 이용하여\n\\(\\Sigma_{\\text{task}}\\) 및 \\(\\Sigma_{\\text{task}} \\otimes \\tau^2 I_d\\) 가 양정치 행렬이 됨을 보이고,\n이에 따라 prior가 well-defined multivariate Gaussian이 됨을 정리 형태로 제시한다.\n\n\n\n\n\n\n선형–가우시안 모형에서 similarity-aware prior를 사용하면,\nposterior 및 posterior predictive distribution은 닫힌형으로 표현 가능하다.\n\nPosterior: \\[\np(\\beta \\mid D_{1:T}) = \\mathcal{N}(\\mu_{\\beta\\mid D}, \\Sigma_{\\beta\\mid D}),\n\\] 여기서 \\(\\mu_{\\beta\\mid D}\\), \\(\\Sigma_{\\beta\\mid D}\\)는 prior 공분산과 데이터 행렬 \\(X_{1:T}\\), 노이즈 분산 \\(\\sigma^2\\)에 의해 결정된다.\n새로운 task \\(t^\\*\\) 에 대한 예측 분포: \\[\np(y^\\* \\mid x^\\*, D_{1:T}, D_{t^\\*}) = \\mathcal{N}(m(x^\\*), v(x^\\*)),\n\\]\n\n이를 독립 prior와 similarity-aware prior 두 경우에 대해 명시적으로 도출한다.\n\n\n\n새로운 task에서의 예측 MSE를 Bayes risk로 정의한다.\n\\[\nR = \\mathbb{E}\\left[(y^\\* - \\hat{y}^\\*)^2\\right],\n\\]\n여기서 기대는 데이터 및 prior/likelihood에 대한 joint 분포에 대해 취한다.\n\n독립 prior: \\(R_{\\text{ind}}\\)\nsimilarity-aware prior: \\(R_{\\text{sim}}\\)\n\n를 각각 계산하거나 상·하한을 도출하고,\n특히 task covariance 행렬 \\(\\Sigma_{\\text{task}}\\)와 참 covariance \\(\\Sigma_{\\text{true}}\\)의 정렬 정도(예: eigen 구조, 코사인 유사도 등)에 따라\n\\[\nR_{\\text{sim}} \\le R_{\\text{ind}}\n\\]\n가 성립하는 조건을 정리 형태(정리/레마)로 제시한다.\n이 과정에서 multi-task GP learning curve 분석에서 사용된 테크닉 을 참고하여,\n평균 Bayes error를 task 수 \\(T\\), 각 task의 샘플 수 \\(n_t\\)의 함수로 표현하는 근사식을 도출하는 것을 목표로 한다.\n\n\n\nAshton & Sollich의 multi-task GP learning curve 결과를 차용하여,\n본 연구에서 정의한 선형–가우시안 모형이 multi-task GP의 특수한 경우에 해당함을 보이고,\nsimilarity-aware prior의 학습 곡선을\n\\[\n\\epsilon(n) = \\mathbb{E}\\left[ (f_{t^\\*}(x) - \\hat{f}_{t^\\*}(x))^2 \\right]\n\\]\n형태로 표현하거나 근사함으로써,\n\ntask similarity 구조가 클수록,\n\n다른 task의 데이터가 많을수록,\n\n새로운 task의 Bayes error가 더 빠르게 감소한다는 결과를 이론적으로 설명한다.\n\n\n\n\n\n시뮬레이션 환경 구성\n\nTask feature 및 참 task covariance \\(\\Sigma_{\\text{true}}\\) 를 설계하여,\n\n\nsimilarity-aware prior가 참 구조와 잘 맞는 경우,\n\n\n구조가 mismatch된 경우,\n\n\n실제로 task들이 독립인 경우, 를 비교.\n\n\n각 설정에서 \\(T\\), \\(n_t\\)를 변화시키며 독립 prior vs similarity-aware prior의\nBayes risk 및 학습 곡선을 비교.\n\n실제 데이터 기반 meta-learning 실험\n\n공개된 few-shot 회귀/분류 데이터셋(예: UCI 회귀 데이터셋을 여러 task로 나눈 환경 등)에 대해,\ntask feature(예: 입력 분포 통계량, domain index 등)를 구성하고\n제안 prior 구조를 적용.\n예측 정확도, 불확실성 calibration, 샘플 효율성 등의 지표 비교를 통해\n이론 결과와의 일관성을 확인."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#기대-효과-및-학문적-기여",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#기대-효과-및-학문적-기여",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "이론적 기여\n\nTask 유사도를 반영한 계층 베이지안 meta-learning prior의 일반적 구성 틀을 제시하고,\n그 유효성(positive definiteness)과 Bayes risk 측면의 이점을 정리 형태로 제시한다.\n선형–가우시안 계층 모형에서 similarity-aware prior와 독립 prior의 risk/learning curve 비교 분석을 통해,\n기존 GP/meta-learning 문헌의 공백을 메운다.\n\n범용성 있는 방법론 제안\n\n제안 prior 구조는 task feature, 그래프, 클러스터 등 다양한 유사도 정보를 커널/공분산 형태로 통합할 수 있어,\n회귀, 분류, GP, BNN 등 다양한 meta-learning 환경에 적용 가능하다.\n\nMeta-learning 이론과 실용 알고리즘 간의 연결 강화\n\nMulti-task GP와 PAC-Bayesian meta-learning의 이론적 결과를\n구체적인 prior 설계 문제와 연결함으로써,\nmeta-learning 알고리즘 설계에 대한 통계적·이론적 가이드를 제공한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-일정-예시-석사-3학기-기준",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#연구-일정-예시-석사-3학기-기준",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "기간\n내용\n\n\n\n\n1학기 전반 (3–4월)\nMeta-learning 및 Bayesian/meta-learning, GP, multi-task GP 문헌 조사\n\n\n1학기 후반 (5–7월)\n모형 설정 구체화, prior 구조 정의, 기본 정리(유효성) 도출\n\n\n여름 방학 (7–8월)\nBayes risk/learning curve 이론적 분석, 초벌 증명 정리\n\n\n2학기 전반 (9–10월)\n시뮬레이션 코드 구현, synthetic 실험 및 결과 분석\n\n\n2학기 후반 (11–1월)\n실증 데이터 실험, 결과 해석 및 이론과의 연결\n\n\n3학기 전반 (3–4월)\n논문 초고(1–4장) 작성, 정리/보완\n\n\n3학기 후반 (5–7월)\n논문 최종 수정, 심사 준비 및 발표\n\n\n\n(실제 일정은 지도교수와의 논의를 거쳐 조정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#참고-문헌-예시",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning.html#참고-문헌-예시",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+MetaLearning",
    "section": "",
    "text": "Hospedales, T., Antoniou, A., Micaelli, P., & Storkey, A. (2021). Meta-Learning in Neural Networks: A Survey.\n\nGrant, E., Finn, C., Levine, S., Darrell, T., & Griffiths, T. (2018). Recasting Gradient-Based Meta-Learning as Hierarchical Bayes. ICLR.\n\nZou, Y., & Lu, X. (2020). Gradient-EM Bayesian Meta-Learning. NeurIPS.\n\nNguyen, Q. P., Low, B. K. H., & Jaillet, P. (2021). Learning to Learn with Gaussian Processes. UAI.\n\nAshton, S. R. F., & Sollich, P. (2012). Learning Curves for Multi-task Gaussian Process Regression. NeurIPS.\n\nRothfuss, J., Josifoski, M., Fortuin, V., & Krause, A. (2021). Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior.\n\nChai, K. M. A. (2010). Multi-task Learning with Gaussian Processes.\n\n(최종 참고 문헌 목록은 실제 논문 작성 시 추가·수정 예정)"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "",
    "text": "가장 교과서적인 MoE는 보통 지도학습 문맥에서 소개됨:\n\n입력: (x)\n출력: (y)\n여러 개의 expert (f_k(x))와 gating network (g(x))\n\n모양은 대충 이렇게:\n\\[\ny \\approx \\sum_{k=1}^K \\pi_k(x), f_k(x), \\qquad\n\\pi_k(x) = \\text{softmax}_k(g(x))\n\\]\n\nexpert: (f_k(x))\n\n“모드 k일 때의 예측기” (회귀, 분류, 등등)\n\ngating network: (g(x))\n\n입력 (x)를 보고 “어느 expert를 얼마나 쓸지” 가중치 (_k(x))를 냄\n\n주 용도:\n\n복잡한 함수 (x y)를 여러 지역/모드로 나눠서 각자 다른 네트워크가 담당하게 하는 구조\n예: piecewise function, 여러 작업을 나눠 맡는 모델 등\n\n\n→ 여기서 포인트는 보통 “조건부 모델링 (p(yx))”를 한다는 것."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-expertsmoe의-기본-모양",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-expertsmoe의-기본-모양",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "",
    "text": "가장 교과서적인 MoE는 보통 지도학습 문맥에서 소개됨:\n\n입력: (x)\n출력: (y)\n여러 개의 expert (f_k(x))와 gating network (g(x))\n\n모양은 대충 이렇게:\n\\[\ny \\approx \\sum_{k=1}^K \\pi_k(x), f_k(x), \\qquad\n\\pi_k(x) = \\text{softmax}_k(g(x))\n\\]\n\nexpert: (f_k(x))\n\n“모드 k일 때의 예측기” (회귀, 분류, 등등)\n\ngating network: (g(x))\n\n입력 (x)를 보고 “어느 expert를 얼마나 쓸지” 가중치 (_k(x))를 냄\n\n주 용도:\n\n복잡한 함수 (x y)를 여러 지역/모드로 나눠서 각자 다른 네트워크가 담당하게 하는 구조\n예: piecewise function, 여러 작업을 나눠 맡는 모델 등\n\n\n→ 여기서 포인트는 보통 “조건부 모델링 (p(yx))”를 한다는 것."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-vaes-기본-모양",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#mixture-of-vaes-기본-모양",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "2. Mixture-of-VAEs 기본 모양",
    "text": "2. Mixture-of-VAEs 기본 모양\nMixture-of-VAEs는 말 그대로 expert가 “VAE”인 mixture 모델 즉, 각 expert가 생성모델 (p_{_k}(x))을 담당한다고 보면 됨.\n구조는 대략:\n\n모드/클러스터 (k)를 latent로 도입:\n\n\\[\np(k) = \\pi_k \\quad (\\text{또는 } \\pi_k(x) = p(k\\mid x) \\text{로 gating})\n\\]\n\n모드별 VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0,I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k), \\quad q_{\\phi_k}(z_k \\mid x)\n\\]\n\n전체 분포:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k, p_{\\theta_k}(x)\n\\quad \\text{(또는 } \\sum_k \\pi_k(x), p_{\\theta_k}(x) \\text{)}\n\\]\n즉,\n\nexpert = “x를 생성하는 VAE 하나”\nmixture는 데이터 분포 (p(x)) 자체를 여러 모드로 나눠서 설명하는 구조.\n\n이건 Mixture-of-Experts의 unsupervised / generative 버전이라고 볼 수 있음."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#공통점과-차이점-정리",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#공통점과-차이점-정리",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "3. 공통점과 차이점 정리",
    "text": "3. 공통점과 차이점 정리\n\n3.1 공통점 (구조적인 측면)\n\n여러 개의 expert 존재\n\nMoE: (f_k(x)) (회귀/분류 등)\nMixture-of-VAEs: (p_{_k}(xz_k)) (생성모델)\n\ngating 개념\n\nMoE: (g(x))로부터 (_k(x)) (입력 의존적인 expert 가중치)\nMixture-of-VAEs:\n\n간단 버전: (_k) 고정 mixture weight\n조금 더 MoE 느낌: (_k(x) = p(kx))를 네트워크로 모델링 가능\n\n\n전체 출력은 “expert들의 weighted combination”\n\nMoE: (_k _k(x) f_k(x))\nMoVAE: (_k k(x) p{_k}(x)) (density 혹은 likelihood)\n\n\n→ 그래서 개념적으로는 “Mixture-of-VAEs도 MoE의 한 종류”라고 보는 게 자연스러움\n\n\n\n3.2 차이점 (보통 쓰이는 맥락 / modeling target)\n\n목표로 하는 확률분포가 다름\n\n일반적인 MoE:\n\n(p(yx)) (조건부 분포, supervised)\n예측 문제: 입력-출력 mapping\n\nMixture-of-VAEs:\n\n(p(x)) (joint / marginal 분포, unsupervised)\n생성/이상치 탐지 문제: 데이터 분포 자체를 모델링\n\n\nexpert의 내부 구조\n\nMoE:\n\nexpert는 그냥 “네트워크 함수” (f_k(x))일 때가 많음 (일반 MLP, CNN, RNN 등등)\n\nMixture-of-VAEs:\n\nexpert는 VAE 전체 (encoder + decoder + latent z)\n내부에 또 하나의 latent 구조 (z_k)가 있어서 두 단계 latent (k, z) 가 됨 → 일종의 hierarchical latent model\n\n\n학습 방식\n\nMoE (supervised):\n\n보통 backprop으로 end-to-end 학습\n혹은 EM-like 알고리즘 (예: hard gating 등)\n\nMixture-of-VAEs:\n\nmixture model + VAE라서\n\nmixture responsibility(E-step 비슷한 역할)와\n각 VAE parameter 업데이트(M-step 비슷한 역할)를 번갈아 하거나 joint training\n\n논문/구현에 따라 EM 스타일 / ELBO 최적화 스타일 등이 변주됨"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#네가-쓰려는-논문에서는-어떻게-부르면-좋을까",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#네가-쓰려는-논문에서는-어떻게-부르면-좋을까",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "4. 네가 쓰려는 논문에서는 어떻게 부르면 좋을까?",
    "text": "4. 네가 쓰려는 논문에서는 어떻게 부르면 좋을까?\n지금 우리가 이야기한 구조는:\n\n각 모드별로 VAE 하나가 있고\n모드 index (k)에 대한 mixture가 있어서\n\n\\[\np(x) = \\sum_k \\pi_k, p_{\\theta_k}(x)\n\\]\n이거라서,\n\n이론/수학 쪽에서 설명할 땐\n\n“Mixture-of-VAEs”, “mixture of latent variable models”\n\n딥러닝/엔지니어링 쪽에서 설명할 땐\n\n“각 expert가 VAE인 Mixture-of-Experts 구조” 라고 같이 언급해도 좋아.\n\n\n\nWe adopt a mixture-of-VAEs architecture, which can be interpreted as a Mixture-of-Experts model where each expert is a VAE that models a specific mode of the data distribution."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#석사-논문-스토리에서-활용-포인트",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#석사-논문-스토리에서-활용-포인트",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "5. 석사 논문 스토리에서 활용 포인트",
    "text": "5. 석사 논문 스토리에서 활용 포인트\n\n3장 – VAE 기반 이상치 + UQ\n\n단일 모드(normal 상태가 하나라고 보는) 데이터 가정\n\\(p(x)\\)를 하나의 VAE로 모델링\n\n4장 – Mixture-of-VAEs 확장\n\n“실제 현장 데이터는 여러 정상 모드(운영 상태)를 가진다”\n이를 위해 Mixture-of-Experts 관점에서, 각 모드를 담당하는 VAE expert를 두고 gating/mixture 구조를 도입\n즉, “VAE를 expert로 하는 Mixture-of-Experts = Mixture-of-VAEs”\n\n기여 포인트 강조\n\n기존 anomaly detection은 “하나의 정상 모드”만 가정하는 경우가 많다.\n우리는 모드(k) + 모드 내부 latent(z) 두 단계로 분해해\n\n모드별 이상치,\n모드 간 불확실성까지 구분해서 다룸."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#짧게-요약하면",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_3_MoVAEs.html#짧게-요약하면",
    "title": "Mixture of Experts But VAE - Bayesian+AnomalyDetection",
    "section": "6. 짧게 요약하면",
    "text": "6. 짧게 요약하면\n\nMixture-of-Experts\n\n일반적으로 (p(yx))를 여러 expert + gating으로 나눠 모델링하는 조건부 모델\nexpert는 보통 “함수 네트워크”\n\nMixture-of-VAEs\n\n각 expert가 VAE 같은 확률 생성모델\n(p(x)) (데이터 분포) 자체를 mixture로 모델링하는 생성/unsupervised 모델\n구조적으로는 “expert를 VAE로 둔 generative MoE”"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "",
    "text": "이상치 탐지 등의 모형에 Uncertainty 를 출력 시키면 Decision making에 좋지 않나"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#왜-이상치-탐지에-uncertainty를-붙이면-좋냐",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#왜-이상치-탐지에-uncertainty를-붙이면-좋냐",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "1. 왜 이상치 탐지에 Uncertainty를 붙이면 좋냐?",
    "text": "1. 왜 이상치 탐지에 Uncertainty를 붙이면 좋냐?\n보통 이상치 탐지는\n\n점수 s(x)만 주고\n임계값 τ 넘으면 “이상치”라고 함.\n\n여기에 불확실성 u(x)까지 나오면:\n\n경계 케이스 구분\n\n점수는 높지만 불확실성이 엄청 크면: → 모델이 “자신 없는데 일단 이상치 같다고 해본 것” → 사람 검토 대상으로 보내기 좋음.\n점수는 애매하지만 불확실성이 작으면: → 모델이 “이건 거의 정상(또는 이상치)이야”라고 확신하는 구간.\n\n우선순위 정렬\n\n모니터링/알람 시스템에서\n\ns(x) 큰 순서 + u(x) 큰 순서를 섞어서 → “심각하고, 동시에 모델도 헷갈리는” 사례를 제일 위로 올릴 수 있음.\n\n\nActive Learning / Labeling 전략\n\n라벨링 budget이 제한된 상황에서\n\n이상치 점수도 높고, 불확실성도 높은 샘플만 골라 사람이 라벨→ 재학습.\n\n결국 데이터 효율을 올리는 용도로도 유용.\n\n운영 단계에서 신뢰도 제공\n\n산업/의료에서 “왜 이게 이상치냐?”보다 “이 판단을 얼마나 믿어도 되냐?”가 중요.\nUncertainty는 일종의 confidence interval이라, 운영자 설득에 도움이 됨."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#어떤-식-모델-구조를-생각해볼-수-있나",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#어떤-식-모델-구조를-생각해볼-수-있나",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "2. 어떤 식 모델 구조를 생각해볼 수 있나?",
    "text": "2. 어떤 식 모델 구조를 생각해볼 수 있나?\n\n(1) 베이지안 이상치 탐지\n\na. Bayesian Autoencoder / VAE 기반\n\nAutoencoder나 VAE를 베이지안화해서\n\n재구성 오류(reconstruction error) +\nlatent / decoder의 predictive uncertainty를 같이 사용.\n\n예:\n\n입력 x에 대해\n\nreconstruction error r(x)\nMC Dropout 또는 BNN 통해 여러 번 forward → 출력 분포의 분산 u(x)\n\n\n이상치 점수 예시:\n\nscore(x) = α · r(x) + β · u(x)\n또는 2D로 두 축을 따로 보고 threshold를 각각 설정.\n\n\n\n\nb. Bayesian One-Class Classifier\n\nOne-Class SVM 스타일 대신\n\nNormal data를 중심으로 하는 Bayesian density model (예: Bayesian GMM, GP, BNN density estimator)\n예측 밀도 p(x)와 함께 “밀도 추정의 불확실성”을 같이 뽑는 형태.\n\n\n\n\n\n\n(2) Deep Ensemble + 이상치 스코어\nBayesian 딥러닝이 아니어도, Deep Ensemble로 꽤 쓸만한 Uncertainty를 얻을 수 있어 보임.\n\n서로 다른 초기값/부트스트랩으로 모델 여러 개 학습:\n\n예) Autoencoder 5개, 이상치 분류기 5개.\n\n입력 x에 대해:\n\n각 모델의 이상치 점수 s_i(x)\n평균 E[s(x)] = 대표 점수\n분산 Var[s(x)] = epistemic uncertainty 근사\n\n활용:\n\nE[s(x)]가 높고 Var[s(x)]가 높다 → “위험 + 자신 없음 → 반드시 검토”\nE[s(x)] 높고 Var[s(x)] 낮다 → “위험하지만 꽤 확신 있음”\n\n\n\n\n\n(3) Normalizing Flow / Density Estimator + UQ\n이상치 탐지에서는 likelihood-based model도 많이 쓰긴 함함. 예: Flow, Autoregressive model, Energy-based model.\n여기에 UQ를 섞는 방식:\n\nBayesian Flow:\n\nFlow의 파라미터에 prior를 두고 variational inference/MC Dropout 등으로\n입력에 대한 likelihood의 분포를 추정 → 평균/분산.\n\nEnsemble Flow:\n\n서로 다르게 학습된 flow 여러 개\n각자의 log p_i(x) 평균·분산을 가지고 score + uncertainty.\n\n\n재미있는 점은,\n\n일부 연구들에서 likelihood만으로는 OOD 구분이 잘 안 된다는 문제를 지적했기 때문에\nUQ를 추가해서 “likelihood는 높은데, 모델이 이 영역을 잘 모른다” 같은 케이스를 잡아낼 수 있을 가능성이 큼.\n\n\n\n\n(4) Classification 기반 OOD + UQ\n만약 이상치 = inlier/outlier binary classification으로 보는 세팅이면:\n\ninlier만으로 학습한 classifier(예: one-class) 대신\n다중 클래스 분류 + out-of-distribution detection 세팅으로 전환하고\nMC Dropout / BNN / Ensemble로 predictive entropy, mutual information 등을 이용:\n\np(y | x)의 entropy → aleatoric + epistemic 섞인 overall uncertainty\nBALD(MI) 등 → epistemic 쪽 강조.\n\n\n이때 이상치 점수는:\n\nlogits 기반 (max-softmax, energy 등) + uncertainty 지표 같이 제공."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#평가실험-관점에서-고려할-점",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#평가실험-관점에서-고려할-점",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "3. 평가/실험 관점에서 고려할 점",
    "text": "3. 평가/실험 관점에서 고려할 점\nUncertainty를 같이 제공하면, 평가도 더 rich해지는 장점이 있음.\n\n기존 이상치 탐지 metric\n\nAUROC, AUPR, FPR@95TPR 등은 계속 사용.\n\nUncertainty 관련 metric\n\nCalibration (ECE, NLL)\nUncertainty vs. Error correlation:\n\n이상치 탐지 decision이 틀린 샘플에서 u(x)가 큰지 확인.\n\n\nRisk-aware metric\n\n예: threshold를 바꿔가며\n\n“불확실성이 높은 샘플은 사람에게 보내고, 나머지는 자동 처리”라는 정책에서의 전체 error / human load / missed anomaly 등 trade-off 분석."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#아이디어-구체화",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#아이디어-구체화",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "4. 아이디어 구체화",
    "text": "4. 아이디어 구체화\n예를 들어 시계열 이상치 탐지라고 가정하면:\n\n기본 구조\n\nLSTM/Transformer 기반 예측 모델 또는 Autoencoder.\n\nBayesian화\n\nDropout을 training + inference에서 모두 켬(MC Dropout).\n같은 입력 구간 x에 대해 T번 forward →\n\nreconstruction/prediction error의 평균 μ_r, 분산 σ_r^2.\n\n\n점수 정의\n\n이상치 점수: A(x) = μ_r\n불확실성: U(x) = σ_r^2\n최종 의사결정:\n\nA(x) &gt; τ₁ 이고 U(x) &gt; τ₂ → “Critical (사람 검토 필수)”\nA(x) &gt; τ₁ 이고 U(x) ≤ τ₂ → “자동 알람”\n나머지 → “정상 또는 low-priority”\n\n\n훈련 시\n\nreconstruction loss 최소화\n\n필요하다면 calibration을 위한 auxiliary loss(예: temperature scaling은 사후에 적용)."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD.html#연구-아이디어로서의-포지셔닝",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD.html#연구-아이디어로서의-포지셔닝",
    "title": "이상치 탐지 with Uncertainty?",
    "section": "5. 연구 아이디어로서의 포지셔닝",
    "text": "5. 연구 아이디어로서의 포지셔닝\n\n문제 정의\n\n기존 이상치 탐지 모델은 score만 제공 → “얼마나 믿을 수 있는가?”에 대한 정보 부재.\n\n기여\n\n(모델 측면)\n\n베이지안/Ensemble 기반 이상치 탐지 모델 설계\n이상치 점수와 함께 calibrated uncertainty 제공.\n\n(평가 측면)\n\n“Risk-aware anomaly detection benchmark”를 제안\n예: 사람-in-the-loop 세팅에서\n\n일정 human budget 하에서 최대한 많은 true anomaly를 잡는 문제로 정식화.\n\n\n(실험 측면)\n\n시계열 / 이미지 / 의료 데이터 셋에서\n\n기존 deterministic anomaly detector vs. 제안한 UQ-aware detector 비교."
  },
  {
    "objectID": "posts/20251114_1.html",
    "href": "posts/20251114_1.html",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "",
    "text": "본 논문은 경사 하강법(gradient descent)으로 훈련되는 어떠한 모델과도 호환되며 분류, 회귀, 강화학습 등 다양한 학습 문제에 적용할 수 있다는 점에서 모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘을 제안합니다. 메타 러닝의 목표는 다양한 학습 과제(task)에 대해 모델을 훈련함으로써, 적은 수의 훈련 샘플만으로도 새로운 과제를 해결할 수 있도록 하는 것입니다.\n우리가 제안하는 방식은 새로운 과제에 대한 소량의 훈련 데이터와 몇 번의 경사 하강 단계(gradient step)만으로도 해당 과제에서 우수한 일반화 성능을 달성할 수 있도록 모델의 파라미터를 명시적으로 훈련합니다. 다시 말해, 본 방법은 모델이 미세조정(fine-tuning)에 용이하도록 훈련하는 것입니다.\n본 논문은 이 접근법이 두 개의 퓨샷(few-shot) 이미지 분류 벤치마크에서 최고 수준(state-of-the-art)의 성능을 달성하고, 퓨샷 회귀 문제에서도 우수한 결과를 보이며, 신경망 정책을 사용하는 정책 경사(policy gradient) 강화학습의 미세조정 속도를 크게 향상시킨다는 것을 입증합니다."
  },
  {
    "objectID": "posts/20251114_1.html#인간-지능의-핵심적인-특징과-ai-agent에게-바라는-것",
    "href": "posts/20251114_1.html#인간-지능의-핵심적인-특징과-ai-agent에게-바라는-것",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "인간 지능의 핵심적인 특징과 AI agent에게 바라는 것",
    "text": "인간 지능의 핵심적인 특징과 AI agent에게 바라는 것\n\n적은 수의 예시만으로 사물을 인식하거나, 단 몇 분의 경험만으로 새로운 기술을 습득하는 등, 빠르게 학습하는 능력\n우리가 만드는 인공 에이전트 역시 인간의 지능과 같은 특징을 가지면 좋다.\n\n즉, 소수의 예시만으로도 신속하게 학습하고 적응하며, 더 많은 데이터가 주어짐에 따라 지속적으로 적응해 나가야 함."
  },
  {
    "objectID": "posts/20251114_1.html#빠르고-유연한-학습은-어려운-과제",
    "href": "posts/20251114_1.html#빠르고-유연한-학습은-어려운-과제",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "빠르고 유연한 학습은 어려운 과제",
    "text": "빠르고 유연한 학습은 어려운 과제\n\n에이전트는 새로운 데이터에 과적합(overfitting)되는 것을 피해야 하고,\n기존의 경험을 소량의 새로운 정보와 통합해야 한다.\n더욱이, 사전 경험(prior experiments)과 새로운 데이터의 형태는 과제(task)에 따라 달라진다.\n\n따라서 최대한의 적용 가능성을 확보하기 위해서는, ’학습하는 방법을 학습’하는 메커니즘(즉, 메타 러닝)이 특정 과제나 연산 형태에 국한되지 않고 범용적(general)이어야 합니다."
  },
  {
    "objectID": "posts/20251114_1.html#제안-모델에-구애받지-않는model-agnostic-메타-러닝-알고리즘",
    "href": "posts/20251114_1.html#제안-모델에-구애받지-않는model-agnostic-메타-러닝-알고리즘",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "제안: 모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘",
    "text": "제안: 모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘\n\n경사 하강법(gradient descent)으로 훈련되는 어떠한 학습 문제와 모델에도 직접 적용될 수 있다는 의미.\n심층 신경망 모델(deep neural network models)에 초점을 맞추고 있긴 하지만, 본 논문이 제안하는 접근법(MAML)은 최소한의 수정만으로도 분류, 회귀, 정책 경사(policy gradient) 강화학습 등 다양한 아키텍처와 문제 설정에 얼마나 쉽게 적용될 수 있는지를 보여줌.\n\n메타 러닝에서 훈련된 모델의 목표는 적은 양의 새로운 데이터만으로 새로운 과제를 신속하게 학습하는 것이며, 모델은 메타 학습기에 의해 수많은 다른 과제에 대해 학습할 수 있도록 훈련됩니다."
  },
  {
    "objectID": "posts/20251114_1.html#핵심-아이디어-of-maml",
    "href": "posts/20251114_1.html#핵심-아이디어-of-maml",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "핵심 아이디어 of MAML",
    "text": "핵심 아이디어 of MAML\n새로운 과제에서 얻은 소량의 데이터로 계산된 한 번 이상의 경사 하강 단계를 거쳐 파라미터가 업데이트되었을 때, 해당 과제에서 모델의 성능이 극대화되도록 모델의 초기 파라미터를 훈련하는 것입니다.\n\n업데이트 함수나 학습 규칙을 학습하는 기존의 메타 러닝 방법들[1]과 달리, MAML 알고리즘은 학습해야 할 파라미터의 수를 늘리지 않으며, 순환 모델(recurrent model) [2]이나 샴 네트워크(Siamese network)[3]를 요구하는 것처럼 모델 아키텍처에 제약을 가하지도 않습니다.\n\n[1] (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017)\n\n[2] (Santoro et al., 2016)\n\n[3] (Koch, 2015)\n\n\n또한, 완전 연결(fully connected), 컨볼루션(convolutional), 순환(recurrent) 신경망 등과 쉽게 결합할 수 있습니다.\n미분 가능한 지도 학습 손실 함수는 물론, 미분 불가능한 강화학습 목표 함수를 포함한 다양한 종류의 손실 함수와도 함께 사용할 수 있습니다.\n\n단 몇 번의 경사 하강 단계만으로, 혹은 단 한 번의 단계만으로도 새로운 과제에서 좋은 결과를 낼 수 있도록 모델의 파라미터를 훈련하는 과정은, 특징 학습(feature learning)의 관점에서 볼 때 여러 과제에 폭넓게 적용 가능한 내부 표현(internal representation)을 구축하는 것으로 해석할 수 있습니다.\n\n만약 내부 표현이 여러 과제에 적합하다면, 파라미터를 약간만 미세조정하는 것(예: 피드포워드 모델의 마지막 레이어 가중치를 주로 수정하는 것)만으로도 좋은 결과를 얻을 수 있습니다.\n\n결과적으로, 우리 절차는 쉽고 빠르게 미세조정될 수 있는 모델을 최적화하여, 신속한 학습에 적합한 공간에서 적응이 일어나도록 만듭니다.\n\n동적 시스템(dynamical systems) 관점에서 보면, 우리의 학습 과정은 파라미터에 대한 새로운 과제들의 손실 함수의 민감도(sensitivity)를 극대화하는 것으로 볼 수 있습니다.\n\n민감도가 높을 때, 파라미터의 작은 국소적 변화가 과제 손실(task loss)을 크게 개선할 수 있기 때문입니다.\n\n\nmaximizing the sensitivity of the loss functions of new tasks with respect to the parameters?"
  },
  {
    "objectID": "posts/20251114_1.html#이-연구의-주된-기여",
    "href": "posts/20251114_1.html#이-연구의-주된-기여",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "이 연구의 주된 기여",
    "text": "이 연구의 주된 기여\n\n적은 횟수의 경사 하강 업데이트만으로 새로운 과제에 대한 빠른 학습이 가능하도록 모델의 파라미터를 훈련하는, 단순하면서도 모델과 과제에 구애받지 않는 메타 러닝 알고리즘.\n이 알고리즘을 완전 연결 신경망과 컨볼루션 신경망을 포함한 다양한 모델 유형과, 퓨샷(few-shot) 회귀, 이미지 분류, 강화학습 등 여러 영역에서 시연.\n\n평가는 제안된 메타 러닝 알고리즘이 지도 분류를 위해 특별히 설계된 최신 원샷(one-shot) 학습 방법들과 비교하여 더 적은 파라미터를 사용하면서도 우수한 성능을 보이며, 회귀 문제에도 쉽게 적용될 수 있고, 과제 가변성이 존재하는 상황에서 강화학습을 가속화하여 초기화 방식으로서의 직접적인 사전 훈련(pretraining)보다 월등히 뛰어난 성능을 보인다는 것을 보여줍니다."
  },
  {
    "objectID": "posts/20251114_1.html#핵심-개념-민감도sensitivity-기울기gradient의-크기",
    "href": "posts/20251114_1.html#핵심-개념-민감도sensitivity-기울기gradient의-크기",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "핵심 개념: 민감도(Sensitivity) = 기울기(Gradient)의 크기",
    "text": "핵심 개념: 민감도(Sensitivity) = 기울기(Gradient)의 크기\n수학, 특히 최적화 문제에서 어떤 함수의 “파라미터에 대한 민감도”는 기울기(gradient)로 표현됩니다. 기울기는 파라미터를 아주 약간 변경했을 때 함수 값이 얼마나, 그리고 어느 방향으로 변하는지를 나타냅니다.\n\n기울기의 방향: 함수 값이 가장 가파르게 증가하는 방향\n기울기의 크기(magnitude): 그 가파른 정도. 즉, 민감도\n\n따라서 “파라미터(θ)에 대한 새로운 과제의 손실 함수(L)의 민감도를 극대화한다”는 것은, 손실 함수의 기울기 벡터 \\(\\nabla_{\\theta} \\mathcal{L}\\)의 크기(norm), 즉 \\(\\Vert \\nabla_{\\theta} \\mathcal{L} \\Vert\\) 를 크게 만드는 것을 의미합니다."
  },
  {
    "objectID": "posts/20251114_1.html#수식을-통한-설명",
    "href": "posts/20251114_1.html#수식을-통한-설명",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "수식을 통한 설명",
    "text": "수식을 통한 설명\n\n기본 설정\n\n\n모델 파라미터: \\(\\theta\\)\n새로운 (임의의) 과제 \\(\\mathcal{T}_i\\)에 대한 손실 함수: \\(\\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\)\n\n\n민감도(Sensitivity)의 수학적 표현\n\n파라미터 \\(\\theta\\)에 대한 손실 함수 \\(\\mathcal{L}_{\\mathcal{T}_i}\\)의 민감도는 기울기(gradient)의 크기(norm)로 나타낼 수 있습니다.\n\\[ \\text{Sensitivity} = \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\| \\]\n\n이 값이 크다는 것은 손실 함수의 “경사면”이 매우 가파르다는 것을 의미합니다.\n\n\n파라미터의 작은 변화와 손실의 큰 개선\n\n경사 하강법에서는 파라미터를 다음과 같이 업데이트합니다.\n\\[ \\theta' = \\theta - \\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n여기서 \\(\\alpha\\)는 학습률(learning rate)입니다.\n\n이때, 업데이트 후의 손실 값 \\(\\mathcal{L}_{\\mathcal{T}_i}(\\theta')\\)는 1차 테일러 근사(first-order Taylor approximation)를 통해 다음과 같이 예측할 수 있습니다.\n\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (\\theta' - \\theta)^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n위 식에 \\(\\theta' - \\theta = -\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\)를 대입하면,\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (-\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\]\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)) \\]\n벡터와 자신의 내적(dot product)은 크기의 제곱이므로,\n\\[ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 \\]\n\n결론: 손실 개선량\n\n위 식을 정리하여 한 번의 업데이트로 인한 손실 개선량을 살펴보면 다음과 같습니다.\n\\[ \\text{Loss Improvement} = \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 \\]\n이 수식은 매우 중요한 점을 시사합니다.\n\n손실 개선량은 민감도(기울기의 크기)의 제곱에 비례합니다.\n\n따라서 MAML의 학습 과정은 어떤 새로운 과제 \\(\\mathcal{T}_i\\)가 주어지더라도, 현재 파라미터 \\(\\theta\\) 위치에서 손실 함수의 기울기 크기 \\(\\vert \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\vert\\)가 크도록 만드는 것입니다.\n\n이렇게 되면 단 한 번의 경사 하강 단계만으로도 손실 값을 크게 줄일 수 있어, 빠르고 효율적인 적응(adaptation)이 가능해집니다."
  },
  {
    "objectID": "posts/20251114_1.html#비유를-통한-이해",
    "href": "posts/20251114_1.html#비유를-통한-이해",
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "section": "비유를 통한 이해",
    "text": "비유를 통한 이해\n\n나쁜 초기 파라미터 (낮은 민감도): 넓은 고원이나 평지에 서 있는 것과 같습니다. 어느 방향으로 한 걸음 내딛어도 고도(손실)는 거의 변하지 않습니다. 최저점(최적해)에 도달하려면 수많은 걸음을 옮겨야 합니다.\n좋은 초기 파라미터 (높은 민감도, MAML의 목표): 여러 계곡(각 과제의 최적해)으로 내려가는 길이 시작되는 산등성이의 중앙에 서 있는 것과 같습니다. 어떤 계곡으로 내려가야 할지 목표가 주어지면, 그 방향은 매우 가파르기 때문에 단 몇 걸음만으로도 고도(손실)를 크게 낮출 수 있습니다.\n\nMAML은 바로 이 “산등성이의 중앙”과 같은 초기 파라미터 \\(\\theta\\)를 찾는 알고리즘이라고 할 수 있습니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "master_paper",
    "section": "",
    "text": "Posts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuccessive model-agnostic meta-learning for few-shot fault time series prognosis\n\n\n\nMetaLearning\n\nSurvey\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 15, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMeta Learning in Neural Networks — A Survey\n\n\n\nMetaLearning\n\nSurvey\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n\n\n\nMetaLearning\n\nMAML\n\nReview\n\n\n\n메타 러닝 관련 논문 요약 및 주요 내용\n\n\n\n\n\nNov 14, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n이상치 탐지 with Uncertainty?\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\nMoE\n\nVAE\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts But VAE - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nIdea\n\nMoE\n\nVAE\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+AnomalyDetection\n\n\n\nBayesian\n\nAnomalyDetection\n\nPaper\n\n\n\n졸업 논문 주제 구체화 - Bayesian+AnomalyDetection\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n석사 학위 논문 연구 계획서 - Bayesian+MetaLearning\n\n\n\nBayesian\n\nMetaLearning\n\nIdea\n\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Lists - Bayesian+MetaLearning\n\n\n\nBayesian\n\nMetaLearning\n\nIdea\n\nPaper\n\n\n\n졸업 논문 주제 구체화 - Bayesian+MetaLearning\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nnews\n\ncode\n\nanalysis\n\n\n\n\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\n\n\n\n\n\n\n\n어케 쓰는거냐\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 13, 2025\n\n\n김한울\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/20251113_1.html",
    "href": "posts/20251113_1.html",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "@article{hospedales2021meta,\n  title={Meta-learning in neural networks: A survey},\n  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={44},\n  number={9},\n  pages={5149--5169},\n  year={2021},\n  publisher={IEEE}\n}\n\n\nLearning-to-learn이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 학습 알고리즘 자체를 개선하는 것을 목표로 합니다. 이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다. 본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다. 먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다. 다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다. 또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다. 마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다.\n\n\n\n메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음\n\nMeta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.\n\n\nprovides an alternative paradigm?\n\n\n기존 방식?\n기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.\n\n대안(메타러닝):\n기계에게 숙제 하나만 주는 게 아니라, “스스로 공부하는 법”을 터득하게 만들자!\n\n\na machine learning model gains experience over multiple learning episodes\n\n\n비유를 해보자면\n사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 여러 과목의 문제(관련된 과제들)를 풀게 하는 행위랑 비슷함.\n이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 ‘요령(패턴)’을 깨닫게 됨. 이것이 바로 “경험”이라고 할 수 있음.\nlearning episodes: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.\n\n보통의 경우에, 그리고 역사적으로 보면,\n\n머신러닝\n\n\n\n기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.\n\nhand-engineered features\n\n\n그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.\n\n이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.\n\n\n즉, 머신러닝에서 특징 추출 단계와 모델 학습 단계는 분리 되어 있음.\n\n\n딥러닝\n\n\n\n위 머신러닝의 두 단계인 특징 추출 단계와 모델 학습 단계를 하나의 단계로 통합해버림.\n\n특징과 모델의 공동 학습 (Joint feature and model learning)\n\n\n예전 처럼 특징을 정성스럽게 추출할 필요가 없음.\n\n원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,\n\n모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.\n\n\n고양이 사진 분류하는 모델을 예로 들어보면…\n\n초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.\n\n중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.\n\n후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.\n\n어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.\n\n사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.\n이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.\n\n\n신경망에서의 메타러닝?\n\n\n특징 추출 단계, 모델 학습 단계, 그리고 알고리즘을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.\n\nThrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.\n\nThrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.\n해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 \n\n\n학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,\n즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.\n\n\ntask family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.\n\n예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 “동물 분류”라는 하나의 task family에 속합니다.\n\nAI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.\n즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.\n\n\n\nconventional machine learning performance improves as more data from a single task is seen\n\n\n기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.\n\n공짜 점심은 없다(no free lunch) Theorem 에 대항하는 알고리즘 ㅋㅋ\n\nThis perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.\n\n\n이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.\n\n\nHowever, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.\n\n\n하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.\n\n\n“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.\n\n이 논문이 Review하려고 하는 대상 논문?\n\n본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.\n\n참고문헌 [27], [28]에 따라 ‘알고리즘 학습’으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.\n이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.\n\n본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.\n\n먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다\n그런 다음, 메타-표현(meta-representation), 메타-목적(meta-objective), 메타-최적화기(meta-optimizer)라는 관점에서 새로운 분류 체계를 제공할 것입니다.\n이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 설계 공간(design-space)을 제시합니다.\n우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.\n마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다.\n\n\n\n\n\n메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.\n\n이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.\n\n\n\n‘학습하는 방법을 학습하는 것(learning to learn)’\n\n이는 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미함.\n기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.\n기반 학습(base learning) 중에는 내부(inner) (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임\n\n메타러닝 중에는 외부(outer)(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.\n\n예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.\n(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.\n\n\ninner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.\n\n\n\n메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?\n\n위에 정의된 대로라면, Cross Validtion을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.\n\n\n\n\n명시적으로 정의된 메타 수준의 목적 함수이 있고,\n\n이 목적 함수에 대한 내부 알고리즘의 end-to-end 최적화가 이루어짐.\n\n\n\n\n\n\n\n기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 \\(D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}\\)이 주어짐.\n\\(\\theta\\)로 매개변수화된 예측 모델 \\(\\hat{y} = f_{\\theta}(x)\\)를 다음 식을 풀어 훈련시키게 됨:\n\\[\n\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(D; \\theta, \\omega) \\quad (1)\n\\]\n\n\\(\\mathcal{L}\\)은 실제 레이블과 \\(f_{\\theta}(\\cdot)\\)가 예측한 값 사이의 오차를 측정하는 손실 함수.\n\\(\\omega\\)라는 조건이 걸려 있음.\n\n이는 학습하는 방법 \\(\\omega\\)에 따라 이 식(1)의 해인 \\(\\theta\\)가 달라질 수 있다는 의미임.\n\n\\(\\omega\\) 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.\n\n일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.\n\n\n\n\n최적화 과정이 모든 문제 \\(D\\)에 대해 매번 처음부터 수행됨(from scratch)\n\n학습 방법 \\(\\omega\\)는 사전에 지정됨.\n\n이때, \\(\\omega\\)의 specification, 즉 학습 방법을 어떻게 정하느냐는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.\n\n메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 사전에 지정하고 고정하는 대신 학습 알고리즘 자체를 학습하게 됨.\nSpecification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음\n\n최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?\n학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?\n모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?\n정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?\n\n\n\n\n\n\n\n메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,\n이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 범용 학습 알고리즘을 학습하자.\n\nNotation\n\n\\(p(\\mathcal{T})\\): 과제들의 분포\n\\(\\omega\\): 어떤 학습 방법\n\\(\\mathcal{T} = \\{D, L\\}\\): 어떤 과제(\\(\\mathcal{T}\\))는 데이터셋(\\(D\\))과 손실 함수(\\(L\\))의 조합이다.\n\\(D\\): 데이터 셋\n\\(\\mathcal{L}(D, \\omega)\\): 데이터 셋 \\(D\\)에서 학습 방법 \\(\\omega\\)를 사용해 훈련했을 때의 loss 값\n\n위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.\n\\[\n\\min_{\\omega} \\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})} \\mathcal{L}(D; \\omega) \\quad (2)\n\\]\n‘학습 방법’, 즉 \\(\\omega\\)는 과제 전반의 지식(across-task knowledge) 또는 메타 지식(meta-knowledge) 이라고 할 수 있음.\n식 (2)를 실제로 해결하려면?\n\n목표: 세상의 모든 과제 분포 \\(p(\\mathcal{T})\\)에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 \\(\\omega\\)를 찾자!\n\n현실: 모든 과제 분포의 모든 문제인 \\(p(\\mathcal{T})\\)를 다룰 수는 없음.\n타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 \\(p(\\mathcal{T})\\)를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)\n\nNotation 2\n\\(\\mathcal{D}_{\\text{source}} = \\{(D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})^{(i)}\\}_{i=1}^M\\)\n\n메타-훈련(meta-training)에 사용할 전체 데이터셋을 나타내는 기호.\n\n하나씩 뜯어보면\n\n\\(\\mathcal{D}_{\\text{source}}\\) : ‘소스 데이터셋(Source Dataset)’이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 원천(Source)이 된다는 의미. 즉, “훈련용”이라는 뜻.\n\\(M\\): 우리가 가지고 있는 훈련용 과제(task)의 총 개수. (예: 50개의 다른 종류의 동물 분류 문제)\n\\(\\{ \\dots \\}_{i=1}^M\\): 괄호 안의 내용이 1번부터 M번까지 M개가 있다는 뜻.\n\\(( \\dots )^{(i)}\\): 그중에서 i번째 과제를 의미. (예: 50개 중 17번째 과제)\n\\((D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})\\): 하나의 과제(\\(i\\))가 두 종류의 데이터로 구성되어 있다는 뜻.\n\n\\(D_{\\text{train}}^{\\text{source}}\\): ‘훈련용’ 데이터(train data). 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 서포트셋(support set)이라고 함.\n\\(D_{\\text{val}}^{\\text{source}}\\): ‘검증용’ 데이터(validation data). 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 쿼리셋(query set)이라고 함.\n\n\n\n“\\(\\mathcal{D}_{\\text{source}}\\)란, 총 M개의 훈련용 과제 묶음인데, 각 과제\\(i\\)는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”\n\n아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n또, 식을 하나씩 요소별로 뜯어보자.\n\n\\(\\omega\\) (오메가): 우리가 찾고 싶은 ‘학습 방법’ 또는 ‘공부법’\n\\(\\omega^{\\ast}\\) (오메가 스타): 수많은 가능한 공부법(\\(\\omega\\)) 중에서 우리가 찾아낸 최고의(optimal) 공부법을 의미함.\n\\(\\arg\\max_{\\omega}\\): “괄호 안의 값을 최대(max)로 만드는 \\(\\omega\\)를 찾아라(arg)”라는 명령어.\n\\(p(\\omega|\\mathcal{D}_{\\text{source}})\\): 사후 확률(posterior probability).\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 관찰했을 때, 어떤 공부법(\\(\\omega\\))이 가장 그럴듯한가(정답일 확률이 높은가)?”.\n\n\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(\\(\\omega\\))을 찾아서, 그것을 우리의 최종 학습법(\\(\\omega^{\\ast}\\))으로 삼아라!“\n\n이제 메타-테스트 단계에서 사용되는 \\(Q\\)개의 타겟 과제(target tasks) 집합을 \\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{train}}^{\\text{target}}, D_{\\text{test}}^{\\text{target}})^{(i)}\\}_{i=1}^Q\\)로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 \\(\\omega^*\\)를 사용하여 이전에 보지 못한 각 타겟 과제 \\(i\\)에 대한 기반 모델을 훈련합니다:\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{train}}^{\\text{target}}(i)) \\quad (4)\n\\]\n식 (1)의 기존 학습과 대조적으로, 타겟 과제 \\(i\\)의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 \\(\\omega^*\\)의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 \\(D_{\\text{test}}^{\\text{target}}(i)\\)에 대한 \\(\\theta^{*(i)}\\)의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.\n이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 메타-과소적합(meta-underfitting) 과 메타-과적합(meta-overfitting) 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 \\(\\theta\\)를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 \\(\\omega\\)를 학습하는 것으로 볼 수 있습니다.\n\n\n먼저, ’훈련용’으로 사용할 M개의 샘플 과제 묶음 \\(\\mathcal{D}_{\\text{source}}\\)를 준비합니다. 각 과제는 두 종류의 데이터로 나뉩니다.\n\n훈련용 데이터 (\\(D_{\\text{train}}\\)): 이 과제를 ’학습’하는 데 사용됩니다. 메타러닝에서는 이를 서포트셋(support set) 이라고 부릅니다.\n검증용 데이터 (\\(D_{\\text{val}}\\)): 위에서 학습이 얼마나 잘 되었는지 ’평가’하는 데 사용됩니다. 메타러닝에서는 이를 쿼리셋(query set) 이라고 부릅니다.\n\n이 훈련용 과제 묶음을 가지고 “학습 노하우를 배우는” 메타-훈련 단계는 다음과 같이 표현됩니다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n\n[수식 (3) 해설]\n이 단계의 목표는 “주어진 훈련용 과제들(\\(\\mathcal{D}_{\\text{source}}\\))을 가장 잘 해결할 수 있게 해주는 최고의 학습 전략(\\(\\omega^*\\))을 찾는 것”입니다. 비유하자면, 여러 학교의 기출문제들을 풀어보면서 어떤 시험에도 통할 ’만능 공부법’을 터득하는 과정입니다.\n\n\n\n\n\n이제 학습이 끝났으니, 한 번도 본 적 없는 ‘실전용’ 타겟 과제 묶음 \\(\\mathcal{D}_{\\text{target}}\\)으로 테스트를 합니다. 각 타겟 과제(\\(i\\))에 대해, 우리는 1단계에서 배운 최고의 학습 전략(\\(\\omega^*\\))을 사용하여 모델을 훈련시킵니다.\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{train}}^{\\text{target}}(i)) \\quad (4)\n\\]\n\n[수식 (4) 해설] 기존의 학습(수식 1)과 가장 큰 차이점은 \\(\\omega^*\\)가 추가되었다는 점입니다.\n\n기존 학습: 백지상태에서 특정 과제(\\(D_{\\text{train}}\\))를 열심히 풀어 모델 파라미터(\\(\\theta\\))를 찾습니다.\n메타 학습 후: 우리가 미리 터득한 ‘만능 공부법’(\\(\\omega^*\\))을 바탕으로 새로운 과제(\\(D_{\\text{train}}^{\\text{target}}\\))를 훨씬 효율적으로 풀어 모델 파라미터(\\(\\theta^*\\))를 찾습니다.\n\n이 \\(\\omega^*\\)는 좋은 출발점(초기 파라미터)이 될 수도 있고, 아예 새로운 모델 자체나 최적화 방법이 될 수도 있습니다.\n\n최종적으로 메타러닝이 얼마나 성공적이었는지는, 이렇게 훈련된 모델(\\(\\theta^{*(i)}\\))이 실전 문제의 테스트 데이터(\\(D_{\\text{test}}^{\\text{target}}(i)\\))에서 얼마나 높은 점수를 받는지로 평가합니다.\n\n\n\n\n일반적인 머신러닝에 과소적합/과적합이 있듯이, 메타러닝에도 메타-과소적합과 메타-과적합이 있습니다. 특히 메타-과적합은 중요한 문제입니다.\n메타-과적합이란? 훈련용 과제들(source tasks)에서 배운 학습 전략(\\(\\omega\\))이 너무 그 훈련용 과제들에만 특화되어서, 막상 새로운 실전 과제들(target tasks)에는 전혀 통하지 않는 현상입니다.\n\n[쉬운 예시] 수학 공부를 할 때 ‘대수학’ 기출문제만 잔뜩 풀어서 “모든 문제는 인수분해로 풀면 된다!”는 식의 편협한 공부법(\\(\\omega\\))을 터득했다고 상상해보세요. 이 학생은 대수학 문제에서는 최고의 성적을 낼 것입니다. 하지만 갑자기 ‘기하학’ 시험을 보게 되면, 인수분해 전략이 통하지 않아 완전히 망치게 됩니다. 이것이 바로 메타-과적합입니다. 너무 좁은 범위의 문제에만 통하는 ’학습 전략’을 배운 탓입니다."
  },
  {
    "objectID": "posts/20251113_1.html#초록",
    "href": "posts/20251113_1.html#초록",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "Learning-to-learn이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. 고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, 메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 학습 알고리즘 자체를 개선하는 것을 목표로 합니다. 이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다. 본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다. 먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다. 다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다. 또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다. 마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다."
  },
  {
    "objectID": "posts/20251113_1.html#introduction",
    "href": "posts/20251113_1.html#introduction",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "메타러닝이란, “머신러닝 모델”이 “공부하는 법”자체를 배우게 하는 새로운 패러다임이라고 할 수 있음\n\nMeta-learning provides an alternative paradigm where a machine learning model gains experience over multiple learning episodes – often covering a distribution of related tasks – and uses this experience to improve its future learning performance.\n\n\nprovides an alternative paradigm?\n\n\n기존 방식?\n기계에게 ‘고양이 사진 분류’라는 숙제 하나를 주고, 그 숙제만 잘 풀도록 처음부터 끝까지 가르침. 다른 숙제(예: ’개 사진 분류’)를 주면 또 처음부터 새로 배워야 함.\n\n대안(메타러닝):\n기계에게 숙제 하나만 주는 게 아니라, “스스로 공부하는 법”을 터득하게 만들자!\n\n\na machine learning model gains experience over multiple learning episodes\n\n\n비유를 해보자면\n사람에게 수학만 가르치는 게 아니라, 수학, 과학, 국어 등 여러 과목의 문제(관련된 과제들)를 풀게 하는 행위랑 비슷함.\n이 과정에서 모델은 단순히 개별 문제를 푸는 법을 배우는 게 아니라, 문제들 사이의 공통점이나 문제 해결의 ‘요령(패턴)’을 깨닫게 됨. 이것이 바로 “경험”이라고 할 수 있음.\nlearning episodes: 문제 하나하나를 풀어보는 경험 한 번 한 번을 의미.\n\n보통의 경우에, 그리고 역사적으로 보면,\n\n머신러닝\n\n\n\n기계가 데이터를 잘 이해할 수 있도록 데이터의 핵심적인 특징(feature)을 사람 전문가(human-expert)가 직접 추출함.\n\nhand-engineered features\n\n\n그 후, 사람이 뽑아낸 특징 데이터를 입력으로 받아서, 기계가 정답을 맞히는 패턴을 학습.\n\n이미지 문제를 예로 들었을 때, 기계는 원본 이미지를 보고 있는 것이 아니라, 사람이 가공해서 준 특징 값들만 보게 됨.\n\n\n즉, 머신러닝에서 특징 추출 단계와 모델 학습 단계는 분리 되어 있음.\n\n\n딥러닝\n\n\n\n위 머신러닝의 두 단계인 특징 추출 단계와 모델 학습 단계를 하나의 단계로 통합해버림.\n\n특징과 모델의 공동 학습 (Joint feature and model learning)\n\n\n예전 처럼 특징을 정성스럽게 추출할 필요가 없음.\n\n원본 데이터(이미지 형태 그대로!) 모델에 그대로 입력하면,\n\n모델이 내부의 여러 계층(layer)을 거치면서 자동으로 특징을 찾아내고, 동시에 그 특징을 이용해 분류하는 방법까지 한꺼번에 학습함.\n\n\n고양이 사진 분류하는 모델을 예로 들어보면…\n\n초반 계층: 이미지의 가장 기본적인 특징(선, 색상, 명암 대비 등)을 스스로 학습.\n\n중간 계층: 초반 계층에서 학습한 기본 특징들을 조합하여 더 복잡한 특징(눈, 코, 귀의 형태 등)을 학습.\n\n후반 계층: 중간 계층의 복잡한 특징들을 다시 조합하여 최종적으로 “이것이 고양이다”라고 판단하는 방법을 학습.\n\n어떤 특징이 중요한지를 기계가 데이터로부터 직접 배우는 것.\n\n사람이 “귀가 중요해, 수염이 중요해”라고 알려줄 필요가 없게 됨.\n이처럼 딥러닝에서는 특징을 배우는 과정과 그 특징으로 정답을 맞히는 과정이 ‘공동으로(jointly)’, 즉 ‘동시에’ 최적화 됨.\n\n\n신경망에서의 메타러닝?\n\n\n특징 추출 단계, 모델 학습 단계, 그리고 알고리즘을 하나의 단계로 통합하고자 하는 학습 방식이라고 할 수 있음.\n\nThrun은 ’러닝-투-런’을 다음과 같이 측정 가능하게(operationally) 정의하고 있습니다.\n\nThrun [7] operationally defines learning-to-learn as occurring when a learner’s performance at solving tasks drawn from a given task family improves with respect to the number of tasks seen.\n해당 책은 한 권에 40만원이라 읽어보지는 못할 것 같다. S. Thrun and L. Pratt, “Learning To Learn: Introduction And Overview,” in Learning To Learn, 1998 \n\n\n학습자(AI)가 관련된 과제 그룹(task family)에서 여러 과제를 풀어볼수록,\n즉 더 많은 종류의 과제를 경험할수록 새로운 과제를 푸는 성능이 향상되는 현상.\n\n\ntask family (과제 그룹): 서로 다르지만 관련이 있는 문제들의 묶음입니다.\n\n예시: (‘고양이/개 분류’, ‘사자/호랑이 분류’, ‘새/물고기 분류’)는 모두 “동물 분류”라는 하나의 task family에 속합니다.\n\nAI가 ‘고양이/개 분류’ 문제를 푼 다음, ‘사자/호랑이 분류’ 문제를 풀고, 또 ‘새/물고기 분류’ 문제를 푸는 등… 이렇게 다양한 종류의 과제(tasks)를 더 많이 경험할수록, 나중에 처음 보는 ‘코끼리/기린 분류’ 문제도 더 잘 풀게 된다는 것입니다.\n즉, 경험하는 과제의 ’종류’가 늘어날수록 똑똑해집니다.\n\n\n\nconventional machine learning performance improves as more data from a single task is seen\n\n\n기존 머신러닝은 하나의 과제(a single task)에 대한 데이터가 많아질수록 성능이 향상됩니다.\n\n공짜 점심은 없다(no free lunch) Theorem 에 대항하는 알고리즘 ㅋㅋ\n\nThis perspective [27]–[29] views meta-learning as a tool to manage the ‘no free lunch’ theorem [30] and improve generalization by searching for the algorithm (inductive bias) that is best suited to a given problem, or problem family.\n\n\n이러한 관점은 메타러닝을 ’공짜 점심은 없다’는 정리(한계)에 대처하는 도구로 봅니다. 즉, 주어진 문제나 문제 그룹에 가장 적합한 알고리즘(귀납적 편향)을 탐색함으로써 일반화 성능을 향상시키는 도구라는 것입니다.\n\n\nHowever, this definition can include transfer, multi-task, feature-selection, and model-ensemble learning, which are not typically considered as meta-learning today.\n\n\n하지만, 이러한 정의는 전이 학습, 다중과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있는데, 이들은 오늘날 일반적으로 메타러닝으로 간주되지 않습니다.\n\n\n“문제에 맞는 해결책을 찾는다”는 정의가 너무 광범위해서, 관련은 있지만 엄연히 다른 여러 기법들까지 전부 ’메타러닝’의 범주에 포함시켜 버린다는 문제가 있다는 맥락입니다. 이 관점은 메타러닝의 철학을 이해하는 데는 도움이 되지만, 현대의 메타러닝을 다른 기법들과 구분 짓기에는 그 정의가 너무 모호하고 포괄적이라는 한계가 있습니다. 오늘날의 메타러닝은 단순히 알고리즘을 ’선택’하거나 ’재사용’하는 것을 넘어, ’학습하는 과정 자체’를 최적화하는 더 구체적인 의미로 사용되기 때문입니다.\n\n이 논문이 Review하려고 하는 대상 논문?\n\n본 논문에서는 현대의 신경망 기반 메타러닝에 집중하고 있습니다.\n\n참고문헌 [27], [28]에 따라 ‘알고리즘 학습’으로 간주하지만, 특히 이 학습이 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 초점을 맞춥니다.\n이에 더해, 우리는 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 폭넓고 다양한 (메타) 목적 함수에 대해서도 논의할 것입니다.\n\n본 논문에서는 메타러닝의 방법론과 응용 분야를 모두 다루려고 함.\n\n먼저, 이 분야의 연구들을 이해하고 그 위상을 정립하는 데 사용할 수 있는 고수준의 문제 정형화(formalization)를 통해 메타러닝을 소개합니다\n그런 다음, 메타-표현(meta-representation), 메타-목적(meta-objective), 메타-최적화기(meta-optimizer)라는 관점에서 새로운 분류 체계를 제공할 것입니다.\n이 프레임워크는 새로운 메타러닝 방법을 개발하고 다양한 응용에 맞게 맞춤화하기 위한 설계 공간(design-space)을 제시합니다.\n우리는 퓨샷 학습, 강화 학습, 구조 탐색 등 여러 인기 있고 새롭게 부상하는 응용 분야를 살펴보고, 전이 학습 및 다중과제 학습과 같은 관련 주제와 비교하여 메타러닝의 위상을 정립할 것입니다.\n마지막으로, 아직 해결되지 않은 중요한 과제들과 미래 연구를 위한 유망한 영역들을 논의하며 마무리하겠습니다."
  },
  {
    "objectID": "posts/20251113_1.html#배경",
    "href": "posts/20251113_1.html#배경",
    "title": "Meta Learning in Neural Networks — A Survey",
    "section": "",
    "text": "메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 “한 단어, 한 문장”으로 명확하게 정의하기가 어려운 상태임.\n\n이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 position을 정립하고 있음.\n\n\n\n‘학습하는 방법을 학습하는 것(learning to learn)’\n\n이는 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미함.\n기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적.\n기반 학습(base learning) 중에는 내부(inner) (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됨. 흔히 inner loop라는 표현으로도 많이 쓰임\n\n메타러닝 중에는 외부(outer)(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듦.\n\n예를 들어, 이 외부 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있음.\n(기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.\n\n\ninner loop의 결과물이라고 할 수 있는 (Base Algorithm, Trained Model, Performance)을 outer loop의 알고리즘이 “학습 데이터”로 삼아서 “기반 알고리즘 자체를 좋게 만드는 방법”을 학습하게 됨.\n\n\n\n메타 러닝은 여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정?\n\n위에 정의된 대로라면, Cross Validtion을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함되어 버림.\n\n\n\n\n명시적으로 정의된 메타 수준의 목적 함수이 있고,\n\n이 목적 함수에 대한 내부 알고리즘의 end-to-end 최적화가 이루어짐.\n\n\n\n\n\n\n\n기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 \\(D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}\\)이 주어짐.\n\\(\\theta\\)로 매개변수화된 예측 모델 \\(\\hat{y} = f_{\\theta}(x)\\)를 다음 식을 풀어 훈련시키게 됨:\n\\[\n\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(D; \\theta, \\omega) \\quad (1)\n\\]\n\n\\(\\mathcal{L}\\)은 실제 레이블과 \\(f_{\\theta}(\\cdot)\\)가 예측한 값 사이의 오차를 측정하는 손실 함수.\n\\(\\omega\\)라는 조건이 걸려 있음.\n\n이는 학습하는 방법 \\(\\omega\\)에 따라 이 식(1)의 해인 \\(\\theta\\)가 달라질 수 있다는 의미임.\n\n\\(\\omega\\) 예를 들어보자면 Optimizer의 선택, model의 선택이 될 수 있음.\n\n일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됨.\n\n\n\n\n최적화 과정이 모든 문제 \\(D\\)에 대해 매번 처음부터 수행됨(from scratch)\n\n학습 방법 \\(\\omega\\)는 사전에 지정됨.\n\n이때, \\(\\omega\\)의 specification, 즉 학습 방법을 어떻게 정하느냐는 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있음.\n\n메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 사전에 지정하고 고정하는 대신 학습 알고리즘 자체를 학습하게 됨.\nSpecification? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음\n\n최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?\n학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?\n모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?\n정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?\n\n\n\n\n\n\n\n메타러닝을 통해 여러 과제에 걸쳐 일반화할 수 있고,\n이상적으로는 새로운 과제를 접할 때마다 이전보다 더 잘 학습할 수 있게 해주는 범용 학습 알고리즘을 학습하자.\n\nNotation\n\n\\(p(\\mathcal{T})\\): 과제들의 분포\n\\(\\omega\\): 어떤 학습 방법\n\\(\\mathcal{T} = \\{D, L\\}\\): 어떤 과제(\\(\\mathcal{T}\\))는 데이터셋(\\(D\\))과 손실 함수(\\(L\\))의 조합이다.\n\\(D\\): 데이터 셋\n\\(\\mathcal{L}(D, \\omega)\\): 데이터 셋 \\(D\\)에서 학습 방법 \\(\\omega\\)를 사용해 훈련했을 때의 loss 값\n\n위와 같이 정의 했을 때, ’학습하는 법을 배우는 것’은 다음과 같이 표현할 수 있음.\n\\[\n\\min_{\\omega} \\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})} \\mathcal{L}(D; \\omega) \\quad (2)\n\\]\n‘학습 방법’, 즉 \\(\\omega\\)는 과제 전반의 지식(across-task knowledge) 또는 메타 지식(meta-knowledge) 이라고 할 수 있음.\n식 (2)를 실제로 해결하려면?\n\n목표: 세상의 모든 과제 분포 \\(p(\\mathcal{T})\\)에 대해 평균적으로 가장 좋은 성능을 내는 만능학습법 \\(\\omega\\)를 찾자!\n\n현실: 모든 과제 분포의 모든 문제인 \\(p(\\mathcal{T})\\)를 다룰 수는 없음.\n타협: 그러니까, 우리가 가진 문제는 “전체 과제들의 분포 \\(p(\\mathcal{T})\\)를 어느정도 대표할 수 있는 샘플들”이야! –&gt; source tasks(소스 과제)\n\nNotation 2\n\\(\\mathcal{D}_{\\text{source}} = \\{(D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})^{(i)}\\}_{i=1}^M\\)\n\n메타-훈련(meta-training)에 사용할 전체 데이터셋을 나타내는 기호.\n\n하나씩 뜯어보면\n\n\\(\\mathcal{D}_{\\text{source}}\\) : ‘소스 데이터셋(Source Dataset)’이라는 뜻. 여기서 ’소스(Source)’는 메타 지식(학습 노하우)을 배우는 원천(Source)이 된다는 의미. 즉, “훈련용”이라는 뜻.\n\\(M\\): 우리가 가지고 있는 훈련용 과제(task)의 총 개수. (예: 50개의 다른 종류의 동물 분류 문제)\n\\(\\{ \\dots \\}_{i=1}^M\\): 괄호 안의 내용이 1번부터 M번까지 M개가 있다는 뜻.\n\\(( \\dots )^{(i)}\\): 그중에서 i번째 과제를 의미. (예: 50개 중 17번째 과제)\n\\((D_{\\text{source}}^{\\text{train}}, D_{\\text{source}}^{\\text{val}})\\): 하나의 과제(\\(i\\))가 두 종류의 데이터로 구성되어 있다는 뜻.\n\n\\(D_{\\text{train}}^{\\text{source}}\\): ‘훈련용’ 데이터(train data). 이 과제를 풀기 위해 공부하는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 서포트셋(support set)이라고 함.\n\\(D_{\\text{val}}^{\\text{source}}\\): ‘검증용’ 데이터(validation data). 위에서 공부한 내용으로 얼마나 잘하는지 쪽지시험을 보는 데 사용되는 데이터. 메타러닝에서는 이것을 특별히 쿼리셋(query set)이라고 함.\n\n\n\n“\\(\\mathcal{D}_{\\text{source}}\\)란, 총 M개의 훈련용 과제 묶음인데, 각 과제\\(i\\)는 ’서포트셋(훈련용)’과 ’쿼리셋(검증용)’이라는 두 개의 데이터 묶음으로 이루어져 있다.”\n\n아무튼, 저런 데이터 묶음으로 뭘할거냐 하면, 식 (3)을 풀기 위함이다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n또, 식을 하나씩 요소별로 뜯어보자.\n\n\\(\\omega\\) (오메가): 우리가 찾고 싶은 ‘학습 방법’ 또는 ‘공부법’\n\\(\\omega^{\\ast}\\) (오메가 스타): 수많은 가능한 공부법(\\(\\omega\\)) 중에서 우리가 찾아낸 최고의(optimal) 공부법을 의미함.\n\\(\\arg\\max_{\\omega}\\): “괄호 안의 값을 최대(max)로 만드는 \\(\\omega\\)를 찾아라(arg)”라는 명령어.\n\\(p(\\omega|\\mathcal{D}_{\\text{source}})\\): 사후 확률(posterior probability).\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 관찰했을 때, 어떤 공부법(\\(\\omega\\))이 가장 그럴듯한가(정답일 확률이 높은가)?”.\n\n\n\n“우리가 가진 훈련용 과제 데이터(\\(\\mathcal{D}_{\\text{source}}\\))를 가장 잘 설명하고 해결할 수 있는, 가장 그럴듯한(확률이 가장 높은) 학습 방법(\\(\\omega\\))을 찾아서, 그것을 우리의 최종 학습법(\\(\\omega^{\\ast}\\))으로 삼아라!“\n\n이제 메타-테스트 단계에서 사용되는 \\(Q\\)개의 타겟 과제(target tasks) 집합을 \\(\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{train}}^{\\text{target}}, D_{\\text{test}}^{\\text{target}})^{(i)}\\}_{i=1}^Q\\)로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타-테스트 단계에서는 학습된 메타 지식 \\(\\omega^*\\)를 사용하여 이전에 보지 못한 각 타겟 과제 \\(i\\)에 대한 기반 모델을 훈련합니다:\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{train}}^{\\text{target}}(i)) \\quad (4)\n\\]\n식 (1)의 기존 학습과 대조적으로, 타겟 과제 \\(i\\)의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 \\(\\omega^*\\)의 이점을 얻습니다. 이것은 좋은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 \\(D_{\\text{test}}^{\\text{target}}(i)\\)에 대한 \\(\\theta^{*(i)}\\)의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.\n이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 메타-과소적합(meta-underfitting) 과 메타-과적합(meta-overfitting) 으로 이어집니다. 특히, 메타-과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 \\(\\theta\\)를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 \\(\\omega\\)를 학습하는 것으로 볼 수 있습니다.\n\n\n먼저, ’훈련용’으로 사용할 M개의 샘플 과제 묶음 \\(\\mathcal{D}_{\\text{source}}\\)를 준비합니다. 각 과제는 두 종류의 데이터로 나뉩니다.\n\n훈련용 데이터 (\\(D_{\\text{train}}\\)): 이 과제를 ’학습’하는 데 사용됩니다. 메타러닝에서는 이를 서포트셋(support set) 이라고 부릅니다.\n검증용 데이터 (\\(D_{\\text{val}}\\)): 위에서 학습이 얼마나 잘 되었는지 ’평가’하는 데 사용됩니다. 메타러닝에서는 이를 쿼리셋(query set) 이라고 부릅니다.\n\n이 훈련용 과제 묶음을 가지고 “학습 노하우를 배우는” 메타-훈련 단계는 다음과 같이 표현됩니다.\n\\[\n\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n\\]\n\n[수식 (3) 해설]\n이 단계의 목표는 “주어진 훈련용 과제들(\\(\\mathcal{D}_{\\text{source}}\\))을 가장 잘 해결할 수 있게 해주는 최고의 학습 전략(\\(\\omega^*\\))을 찾는 것”입니다. 비유하자면, 여러 학교의 기출문제들을 풀어보면서 어떤 시험에도 통할 ’만능 공부법’을 터득하는 과정입니다.\n\n\n\n\n\n이제 학습이 끝났으니, 한 번도 본 적 없는 ‘실전용’ 타겟 과제 묶음 \\(\\mathcal{D}_{\\text{target}}\\)으로 테스트를 합니다. 각 타겟 과제(\\(i\\))에 대해, 우리는 1단계에서 배운 최고의 학습 전략(\\(\\omega^*\\))을 사용하여 모델을 훈련시킵니다.\n\\[\n\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{train}}^{\\text{target}}(i)) \\quad (4)\n\\]\n\n[수식 (4) 해설] 기존의 학습(수식 1)과 가장 큰 차이점은 \\(\\omega^*\\)가 추가되었다는 점입니다.\n\n기존 학습: 백지상태에서 특정 과제(\\(D_{\\text{train}}\\))를 열심히 풀어 모델 파라미터(\\(\\theta\\))를 찾습니다.\n메타 학습 후: 우리가 미리 터득한 ‘만능 공부법’(\\(\\omega^*\\))을 바탕으로 새로운 과제(\\(D_{\\text{train}}^{\\text{target}}\\))를 훨씬 효율적으로 풀어 모델 파라미터(\\(\\theta^*\\))를 찾습니다.\n\n이 \\(\\omega^*\\)는 좋은 출발점(초기 파라미터)이 될 수도 있고, 아예 새로운 모델 자체나 최적화 방법이 될 수도 있습니다.\n\n최종적으로 메타러닝이 얼마나 성공적이었는지는, 이렇게 훈련된 모델(\\(\\theta^{*(i)}\\))이 실전 문제의 테스트 데이터(\\(D_{\\text{test}}^{\\text{target}}(i)\\))에서 얼마나 높은 점수를 받는지로 평가합니다.\n\n\n\n\n일반적인 머신러닝에 과소적합/과적합이 있듯이, 메타러닝에도 메타-과소적합과 메타-과적합이 있습니다. 특히 메타-과적합은 중요한 문제입니다.\n메타-과적합이란? 훈련용 과제들(source tasks)에서 배운 학습 전략(\\(\\omega\\))이 너무 그 훈련용 과제들에만 특화되어서, 막상 새로운 실전 과제들(target tasks)에는 전혀 통하지 않는 현상입니다.\n\n[쉬운 예시] 수학 공부를 할 때 ‘대수학’ 기출문제만 잔뜩 풀어서 “모든 문제는 인수분해로 풀면 된다!”는 식의 편협한 공부법(\\(\\omega\\))을 터득했다고 상상해보세요. 이 학생은 대수학 문제에서는 최고의 성적을 낼 것입니다. 하지만 갑자기 ‘기하학’ 시험을 보게 되면, 인수분해 전략이 통하지 않아 완전히 망치게 됩니다. 이것이 바로 메타-과적합입니다. 너무 좁은 범위의 문제에만 통하는 ’학습 전략’을 배운 탓입니다."
  },
  {
    "objectID": "posts/20251115_1.html",
    "href": "posts/20251115_1.html",
    "title": "Successive model-agnostic meta-learning for few-shot fault time series prognosis",
    "section": "",
    "text": "초록\n메타러닝은 few-shot 결함 예측 문제를 해결하는 유망한 기술로, 최근 몇 년간 많은 연구자들의 주목을 받아왔습니다. 주로 무작위 및 유사성 매칭 기반의 task 분할에 의존하는 기존의 시계열 예측 메타러닝 방법들은 세 가지 주요 한계에 직면합니다:\n\nFeature exploitation inefficiency(특징 활용의 비효율성)\n\nSuboptimal task data allocation\nLimited Robustness with small samples(적은 샘플에서의 제한된 견고성)\n\n이러한 한계를 극복하기 위해,\n\n본 연구는 시계열의 연속적인 기간을 다수의 연속된 짧은 기간으로 구성된 메타-task로 간주하는 새로운 ‘의사 메타-task(pseudo meta-task)’ 분할 기법을 제안합니다. 연속 시계열을 의사 메타-task로 사용함으로써, 제안하는 방법은 데이터로부터 더 포괄적인 특징과 관계를 추출하여 더 정확한 예측을 할 수 있습니다.\n\n또한, 여러 데이터셋에 걸쳐 제안 방법의 견고성을 향상시키기 위해 차분(differential) 알고리즘을 도입합니다.\n\n여러 결함 및 시계열 예측 데이터셋에 대한 광범위한 실험을 통해, 제안하는 접근법이 few-shot 조건과 일반 조건 모두에서 예측 성능과 일반화 능력을 상당히 향상시킨다는 것을 입증합니다.\n\n\nIntroduction\nFault Prediction in Time series Data\n시계열 데이터의 결함 예측은 광범위한 산업적 응용 분야를 가진 매우 중요한 머신러닝 task이지만, 데이터 부족 및 주파수 불일치와 같은 문제점에 직면합니다.\n\n문제점: Data Scarcity, Frequency Mismatch\n\n메타러닝은 이러한 문제들을 해결하기 위한 유망한 접근법으로 부상했으며, task 간 유사점과 차이점을 활용하여 새로운 시계열 결함 예측 task에 효과적으로 적응합니다.\n이는 딥러닝 모델이 단 몇 개의 샘플 또는 심지어 샘플이 없는 경우에도 새로운 시계열 데이터에 빠르게 적응할 수 있게 하며, 다양한 도메인과 시나리오에서 비롯된 시계열 데이터 간의 유사점과 차이점을 활용하여 일반화 능력을 향상시킵니다([35], [2]).\n\n메타러닝: cross-task similarities와 differences 활용해 fualt prediction에 적용\n\n메타러닝은 머신러닝 알고리즘이 ’learning to learn’을 가능하게 하여, 지식의 보편성과 적응성을 향상시킵니다. 시계열 결함 예측 분야에서 메타러닝의 효과는 task-distribution에 의존하는 몇 가지 요인들의 미묘한 보정에 달려 있으며, 연구자들은\n\nData representation (데이터 표현),\n\nMeta-learner design (메타-러너 설계),\n\nMeta-learning algorithms (메타러닝 알고리즘),\n\nPeuso meta-task division (의사 메타-task 분할)\n\n이라는 네 가지 핵심 측면을 꼽습니다.\n주목할 점은, 첫 세 가지 측면은 특정 task distribution에 따라 다른 조정이 필요한 반면, 의사 메타-task의 분할은 task distribution에 의존하지 않는다는 것입니다 [24]. 따라서, 본 논문은 결함 예측에서 메타러닝의 적응성을 향상시키기 위해 주로 의사 메타-task의 분할 방법을 개선합니다.\n\n시계열 예측에서 메타러닝을 위한 task 분할 알고리즘은 크게 두 가지 유형으로 분류할 수 있습니다.\n무작위 task 분할 방법: 이 범주에서 가장 대표적인 방법은 Model-Agnostic Meta-Learning (MAML) [6]으로, 무작위로 시간 구간을 선택하여 의사 메타-task로 사용하는 전략을 사용합니다. MAML++ [1], MetaL [3], Bootstrapped Meta-learning (BMG) [7]과 같은 방법들이 다양한 측면에서 MAML에 대한 훌륭한 발전과 개선을 이루었지만, MAML의 의사 메타-task 분할 접근법을 특별히 개선하지는 않았습니다. 시계열을 무작위로 task로 분할하는 특성상, 이 접근법은 시간적 상관관계를 완전히 포착하지 못할 수 있으며, 시계열의 일관성을 잠재적으로 훼손할 수 있습니다.\n유사성 매칭 기반 task 분할 방법: 이 범주의 대표적인 방법은 Mo 등이 제안한 것으로[23], 본 논의에서는 이를 ’MAML (DTW)’라고 지칭하겠습니다. 이 방법은 MAML 프레임워크 내에서 동적 시간 워핑(Dynamic Time Warping, DTW)을 사용하여 현재 시간 구간과 가장 유사한 시간 구간들을 의사 메타-task로 선택합니다. 이를 통해 모델의 예측 성능과 견고성을 향상시킵니다. 그러나 이 접근법은 특히 데이터가 부족한 환경에서 어려움을 겪습니다. 데이터 품질이 낮을 때 적절한 데이터 샘플을 찾는 데 어려움을 겪을 수 있습니다. 더 나아가, 시계열에서 충분한 상관관계를 추출하지 못할 수 있습니다.\n\n기존 Meta-Learning의 Task Paritioning Algorithms의 단점?\n\n무작위 방식은 시간적 상관관계를 파괴한다.\n\n유사성 매칭 방식인 DTW방식은 시간적 상관관계를 포착하려고 시도하지만, 데이터 부족이나 방법론적 한계 때문에 충분하지 않다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "다변량 딥러닝 기반 이상치 탐지에서의 불확실성 추정과\nMixture-of-VAEs를 활용한 위험 민감 의사결정 프레임워크\n(영문 예시)\nRisk-Aware Decision Framework with Uncertainty-Aware Deep Multivariate Anomaly Detection using Variational and Mixture-of-VAEs\n\n\n\n\n제조 공정, 네트워크 트래픽, 금융 거래, 의료 모니터링 등 다양한 응용 분야에서 다변량(multivariate) 시계열·표형 데이터에 대한 이상치 탐지(anomaly / outlier detection) 는 안전성, 비용 절감, 서비스 안정성 측면에서 매우 중요한 과제이다.\n그러나 기존 딥러닝 기반 이상치 탐지 기법들(예: Autoencoder, LSTM-AE, CNN 기반 모델 등)은 다음과 같은 한계를 가진다.\n\n이상치 점수만 제공\n\n단일 스칼라 점수 \\(A(x)\\)만 제공하는 경우가 많아,\n“얼마나 이상한가?”는 알 수 있어도\n“이 판단을 얼마나 믿을 수 있는가?”(불확실성)는 알기 어렵다.\n\n불확실성(uncertainty) 정보 부재\n\n모델이 자신 없는 영역에서 내린 이상치 판단을\n동일한 신뢰도로 사용하게 되며,\n이는 실제 운영 환경에서 위험한 결정으로 이어질 수 있다.\n\n비용 구조가 반영되지 않은 결정\n\n실제 시스템에서는\n\n정상인데 이상치로 판단할 때의 비용(공장 정지, 서비스 중단 등)\n\n이상치인데 정상으로 넘기는 비용(고장, 사고, 손실 등)\n\n사람/전문가에게 “검토를 요청할 때” 드는 비용\n이 서로 다름에도 불구하고,\n단일 threshold 기반 이진 결정으로만 처리되는 경우가 많다.\n\n\n\n이에 본 연구는, 딥러닝 기반 베이지안 VAE와 Mixture-of-VAEs를 활용하여\n\n다변량 데이터에서 이상치 점수와 불확실성을 동시에 추정하고,\n이를 바탕으로 STOP / CHECK / IGNORE 형태의\n위험 민감(risk-aware) 의사결정 규칙을 설계하고자 한다.\n\n\n\n\n\n\n\n\nBase Model:\nVariational Autoencoder(VAE)를 기반으로 한 다변량 딥러닝 이상치 탐지 모델을 설계하여,\n전역(global) 및 변수별(feature-wise) 이상치 점수와 불확실성을 동시에 추정한다.\nExtended Model:\n데이터가 여러 정상 모드(운영 상태)를 가진다고 가정하고,\nMixture-of-VAEs (MoVAE) 구조를 설계하여\n모드별 이상치·불확실성과 모드 자체에 대한 불확실성(mode uncertainty) 를 함께 추정한다.\nRisk-aware Decision:\n이상치 점수와 불확실성 정보를 활용해\n비용 구조를 반영한 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 정식화하고,\n기존 threshold 기반 기법보다 더 낮은 위험도(risk)를 달성하는지 평가한다.\n범용성 검증:\n공정/센서 시계열, 네트워크/트래픽, 공개 multivariate anomaly dataset 등\n서로 다른 도메인에서 제안 프레임워크의 일관된 효과를 검증한다.\n\n\n\n\n\nRQ1. Variational Autoencoder 기반 다변량 딥러닝 모델을 통해\n전역 및 변수별 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 동시에 추정할 수 있는가?\nRQ2. 데이터가 여러 정상 모드를 가질 때, 단일 VAE보다\nMixture-of-VAEs가 이상치 탐지 및 불확실성 추정 측면에서\n더 나은 표현력과 의사결정 성능을 제공하는가?\nRQ3. 추정된 \\((A(x), U(x))\\) (및 모드 불확실성)를 이용하여\nSTOP / CHECK / IGNORE 형태의 위험 민감 의사결정 규칙을 설계할 때,\n기존 단일 threshold 기반 이진 의사결정보다\n실제 비용(risk)을 유의하게 감소시킬 수 있는가?\n\n\n\n\n\n\n\n\n\n이상치 탐지 / 다변량\n\nmultivariate anomaly detection\n\nmultivariate time series anomaly detection\n\ndeep anomaly detection, deep autoencoder, VAE anomaly detection\n\nreconstruction-based anomaly detection\n\n딥러닝 & 베이지안 / 불확실성\n\ndeep learning, representation learning (PyTorch / fastai)\n\nBayesian deep learning, variational inference\n\nMonte Carlo Dropout, deep ensemble\n\nuncertainty quantification, aleatoric / epistemic uncertainty\n\nVariational Autoencoder, Bayesian VAE, probabilistic autoencoder\n\nmixture of VAEs, mixture density networks, mixture-of-experts\n\n의사결정 / 위험\n\nselective prediction, abstention, reject option\n\nrisk-aware decision making, cost-sensitive learning\n\nrisk–coverage trade-off, calibration\n\n\n\n\n\n\n1–2개월차에 집중적으로 논문 수집 및 정리\n각 논문에 대해 다음 항목으로 구조화:\n\n데이터 타입 (시계열, 이미지, 센서, 트래픽 등)\n\n딥러닝 사용 여부, VAE/flow/AE 등 모델 유형\n\n이상치 점수 정의 방식 (reconstruction, likelihood, distance 등)\n\n불확실성 추정 여부 및 방법\n\nrisk-aware / selective decision 관점 고려 여부\n\n본 연구와의 차별점 / 한 줄 평가\n\n\n\n\n\n\n\n본 연구는 Base Model(VAE)와 Extended Model(Mixture-of-VAEs)으로 구성되며,\n두 모델에서 공통적으로 이상치 점수 + 불확실성 추정 + risk-aware decision layer를 설계한다.\n\n\n\n\n다변량 입력 \\(x \\in \\mathbb{R}^d\\)에 대해, VAE 구조는 다음과 같이 정의한다.\n\nPrior:\n\n\\[\nz \\sim p(z) = \\mathcal{N}(0, I)\n\\]\n\nDecoder:\n\n\\[\np_\\theta(x \\mid z) = \\mathcal{N}\\big(\\mu_\\theta(z), \\text{diag}(\\sigma^2_\\theta(z))\\big)\n\\]\n\nEncoder (approximate posterior):\n\n\\[\nq_\\phi(z \\mid x) = \\mathcal{N}\\big(\\mu_\\phi(x), \\text{diag}(\\sigma^2_\\phi(x))\\big)\n\\]\n학습은 ELBO 최적화를 통해 수행한다.\n\nELBO:\n\n\\[\n\\mathcal{L}_{\\text{ELBO}}(x;\\theta,\\phi) = \\mathbb{E}_{q_\\phi(z\\mid x)}[\\log p_\\theta(x \\mid z)] - \\mathrm{KL}\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big)\n\\]\nPyTorch/fastai로는 encoder/decoder를 MLP, 1D-CNN, LSTM 등으로 구현하고,\n출력층에서 mean 및 log-variance를 예측하도록 구성한다.\n\n\n\n관측 \\(x\\)에 대해, 다음과 같이 Monte Carlo 샘플링을 수행한다.\n\n\\(z^{(t)} \\sim q_\\phi(z \\mid x), \\quad t = 1,\\dots,T\\)\n\\(\\hat x^{(t)} \\sim p_\\theta(x \\mid z^{(t)})\\)\n\n각 변수 \\(j = 1,\\dots,d\\)에 대해:\n\n변수별 이상치 점수 (재구성 오차)\n\n\\[\nr_j(x) = \\frac{1}{T} \\sum_{t=1}^T \\big(x_j - \\hat x^{(t)}_j\\big)^2\n\\]\n\n변수별 불확실성 (예측 분산)\n평균 재구성을\n\n\\[\n\\bar x_j = \\frac{1}{T} \\sum_{t=1}^T \\hat x^{(t)}_j\n\\]\n로 정의할 때,\n\\[\nu_j(x) = \\frac{1}{T-1} \\sum_{t=1}^T \\big(\\hat x^{(t)}_j - \\bar x_j\\big)^2\n\\]\n전역(global) 이상치 점수와 불확실성은 가중합으로 정의한다.\n\n전역 이상치 점수:\n\n\\[\nA_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j r_j(x)\n\\]\n\n전역 불확실성:\n\n\\[\nU_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j u_j(x)\n\\]\n여기서 \\(w_j\\)는 각 변수의 중요도를 반영하는 가중치(동일 가중치 또는 도메인 지식 기반)를 의미한다.\n필요 시, encoder/decoder 네트워크에 Dropout을 적용하여\nepistemic uncertainty를 추가로 반영할 수 있다.\n\n\n\n\n\n\n\n다변량 데이터가 여러 정상 모드(운영 상태)를 가진다고 가정한다.\n이를 위해 \\(K\\)개의 VAE expert와 gating network로 구성된 Mixture-of-VAEs 구조를 정의한다.\n\nGating network:\n\n\\[\n\\pi_k(x) = p_\\psi(k \\mid x), \\quad k = 1,\\dots,K\n\\]\n여기서 \\(\\pi_k(x)\\)는 입력 \\(x\\)가 모드 \\(k\\)에 속할 확률을 나타내며,\n\\(\\sum_{k=1}^K \\pi_k(x) = 1\\)을 만족한다.\n\n각 expert VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0, I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k) = \\mathcal{N}\\big(\\mu_{\\theta_k}(z_k), \\text{diag}(\\sigma^2_{\\theta_k}(z_k))\\big)\n\\]\n\\[\nq_{\\phi_k}(z_k \\mid x) = \\mathcal{N}\\big(\\mu_{\\phi_k}(x), \\text{diag}(\\sigma^2_{\\phi_k}(x))\\big)\n\\]\n\n전체 likelihood:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x)\n\\]\n학습은 mixture 형태의 ELBO 또는 EM-유사 전략,\n혹은 end-to-end joint training으로 수행할 수 있으며,\n실험 단계에서 구현 난이도와 성능을 고려하여 선택한다.\n\n\n\n각 expert에 대해, VAE와 동일하게 재구성 기반 점수 \\(A_k(x)\\)를 정의한다.\n\nexpert \\(k\\)의 이상치 점수(예시):\n\n\\[\nA_k(x) = \\sum_{j=1}^d w_j r_{j,k}(x)\n\\]\nMixture 전체의 이상치 점수는 다음과 같이 정의할 수 있다.\n\nlikelihood 기반:\n\n\\[\nA_{\\text{MoVAE}}(x) = -\\log \\left( \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x) \\right)\n\\]\n\nreconstruction 기반 가중합:\n\n\\[\nA_{\\text{MoVAE}}(x) = \\sum_{k=1}^K \\pi_k(x)\\, A_k(x)\n\\]\n두 정의는 실험에서 비교 가능하며,\n도메인 특성에 따라 더 좋은 score 정의를 선택할 수 있다.\n\n\n\nMixture-of-VAEs에서는 불확실성이 두 층으로 나뉜다.\n\nexpert 내부 불확실성 (in-expert uncertainty)\n\n각 expert \\(k\\)의 VAE에서 variance, MC 샘플 분산 등을 이용해\n\\(U_k(x)\\)를 정의 (Base VAE와 동일 방식).\n\n모드 불확실성 (between-expert / mode uncertainty)\n\ngating 확률 벡터 \\(\\pi(x) = (\\pi_1(x),\\dots,\\pi_K(x))\\)의 엔트로피:\n\n\n\\[\nH_\\pi(x) = -\\sum_{k=1}^K \\pi_k(x)\\log \\pi_k(x)\n\\]\n\n\\(\\pi_k(x)\\)가 한 모드에 집중되면 \\(H_\\pi(x)\\)가 작고,\n여러 모드에 고르게 분산되면 \\(H_\\pi(x)\\)가 커진다.\n→ “이 샘플이 어느 모드에 속하는지 모델이 헷갈리는 정도”로 해석 가능.\n\n\n종합 불확실성 정의 예시\n\n\\[\nU_{\\text{MoVAE}}(x) = \\alpha \\sum_{k=1}^K \\pi_k(x)\\, U_k(x) + \\beta H_\\pi(x)\n\\]\n여기서 \\(\\alpha, \\beta\\)는 모드 내부 불확실성과 모드 불확실성의 상대적 중요도를 조절하는 하이퍼파라미터이다.\n\n\n\n\n\n\n\n각 샘플 \\(x\\)에 대하여, 세 가지 행동 중 하나를 선택한다고 가정한다.\n\n\\(\\delta(x) \\in \\{\\text{IGNORE}, \\text{CHECK}, \\text{STOP}\\}\\)\n\n실제 상태 \\(y \\in \\{\\text{normal}, \\text{anomaly}\\}\\)에 대해,\n각 행동에 대한 비용을 \\(C(\\delta(x), y)\\)로 정의한다.\n예시:\n\n정상인데 STOP → 불필요한 정지, false positive 비용\n\n이상치인데 IGNORE → 사고/고장, false negative 비용 (가장 큼)\n\nCHECK → 사람/추가 검사 비용 (중간 수준)\n\n전체 기대 위험도(risk)는 다음과 같이 정의할 수 있다.\n\\[\nR(\\delta) = \\mathbb{E}_{(x,y)}\\big[\\,C(\\delta(x), y)\\,\\big]\n\\]\n실제 구현에서는 validation set 상에서의 경험적 위험 \\(\\hat R(\\delta)\\)를 최소화하는 규칙을 찾는다.\n\n\n\nBase VAE 및 MoVAE 모두, 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 기반으로 다음과 같은 규칙을 정의할 수 있다.\n예시 규칙:\n\\[\n\\delta(x) =\n\\begin{cases}\n\\text{STOP} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) \\le \\tau_U \\\\\n\\text{CHECK} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) &gt; \\tau_U \\\\\n\\text{IGNORE} & \\text{if } A(x) &lt; \\tau_A\n\\end{cases}\n\\]\n여기서 \\((\\tau_A, \\tau_U)\\)는 validation set에서\n경험적 위험 \\(\\hat R(\\tau_A,\\tau_U)\\)를 최소화하도록 탐색한다.\nMixture-of-VAEs의 경우,\n\\(U(x)\\)를 \\(U_{\\text{MoVAE}}(x)\\)로 두거나,\n모드 엔트로피 \\(H_\\pi(x)\\)를 추가 입력으로 사용하는 변형도 고려할 수 있다.\n\n\n\n\n\n\n프레임워크: PyTorch (필수), 필요 시 fastai로 학습/실험 루프 관리\n구성 요소\n\nmodels/ : VAE, Mixture-of-VAEs, gating network 모듈\n\ndatasets/ : 시계열/탭형 multivariate anomaly dataset 로더\n\ntraining/ : 학습 루프, ELBO 계산, threshold search, risk 계산\n\nanalysis/ : ROC, PR, risk–coverage, 의사결정 시뮬레이션, 시각화\n\n\n\n\n\n\n\n\n\n\nSynthetic multivariate 데이터\n\n다변량 Gaussian, mixture, non-linear manifold 데이터 생성\n\n단일 모드 vs 다중 모드 환경에서 VAE와 MoVAE 비교\n\n공개 multivariate anomaly dataset\n\n예: 서버/센서/시계열 관련 공개 데이터셋 (SMD, MSL, SWaT 등)\n\n도메인에 따라 tabular/multivariate time series 데이터 추가 검토\n\n\n\n\n\n\nBaseline 모델\n\n단순 Autoencoder 기반 이상치 탐지\n\nVAE (불확실성 고려하지 않는 score-only 버전)\n\n필요시 다른 딥러닝 기반 anomaly detection 방법\n\n성능 지표\n\n이상치 탐지:\n\nAUROC, AUPR, F1-score, FPR@95TPR 등\n\n의사결정 / risk 관점:\n\nrisk–coverage curve\n\nfalse alarm 수, missed anomaly 수\n\nCHECK(사람 검토) 비율 대비 risk 감소 정도\n\n\n\n\n\n\n\n\n\n1–2개월차: 문헌 조사 및 문제 정의\n\n키워드 기반 선행 연구 수집 및 정리\n\n관련 연구 요약 및 연구 질문(RQ) 확정\n\n3–4개월차: 수식 정식화 및 모델 설계\n\nVAE / Mixture-of-VAEs 수식 정리 및 손실 함수 정의\n\n이상치 점수, 불확실성, decision rule 공식화\n\n간단한 이론적 성질(정의, lemma, risk–coverage 개념) 초안 작성\n\n5–7개월차: PyTorch 구현 및 초기 실험\n\nBase VAE 및 MoVAE 구현\n\nsynthetic 데이터 및 1개 공개 데이터셋에서 1차 검증\n\n코드 구조 안정화 및 hyperparameter 기본 설정\n\n8–9개월차: 본 실험 및 분석\n\n추가 데이터셋에 대한 본격 실험\n\nSingle VAE vs Mixture-of-VAEs 비교\n\nrisk-aware decision 관점에서의 성능 분석 및 ablation study\n\n10–11개월차: 논문 집필\n\n방법론(3–4장), 실험(5장)부터 집필\n\n서론·관련연구(1–2장), 결론(6장) 작성 및 통합\n\n지도교수 피드백 반영 및 수정\n\n12개월차: 최종 정리 및 제출\n\n논문 형식, 참고문헌, 그림/표 정리\n\n발표 자료 준비 및 최종 점검\n\n\n\n\n\n\n\n모델링 기여\n\n다변량 데이터를 위한 딥러닝 기반 Bayesian VAE + Mixture-of-VAEs 구조를 설계하여,\n전역 및 변수별 이상치 점수와 계층적 불확실성(internal + mode uncertainty)을 동시에 제공한다.\n\n의사결정 기여\n\n이상치 점수와 불확실성을 활용한 risk-aware 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 제안하고,\n비용 구조를 반영한 위험도 관점에서 기존 방법보다 더 나은 성능을 보임을 보인다.\n\n범용성 기여\n\n공정/센서, 네트워크/트래픽, 일반 multivariate dataset 등\n서로 다른 도메인에 동일 프레임워크를 적용함으로써,\n범용적인 “이상치 + 불확실성 + 의사결정” 프레임워크로서의 가능성을 제시한다.\n\n실무 적용 가능성\n\n실제 시스템에서\n\n언제 자동으로 STOP할지,\n\n언제 사람에게 CHECK를 요청할지,\n\n언제 IGNORE해도 되는지\n를 정량적으로 판단하는 기준을 제공하여,\n신뢰 가능한 이상치 탐지 기반 의사결정 시스템 설계에 기여할 수 있다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-주제-가제",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-주제-가제",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "다변량 딥러닝 기반 이상치 탐지에서의 불확실성 추정과\nMixture-of-VAEs를 활용한 위험 민감 의사결정 프레임워크\n(영문 예시)\nRisk-Aware Decision Framework with Uncertainty-Aware Deep Multivariate Anomaly Detection using Variational and Mixture-of-VAEs"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-배경-및-필요성",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-배경-및-필요성",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "제조 공정, 네트워크 트래픽, 금융 거래, 의료 모니터링 등 다양한 응용 분야에서 다변량(multivariate) 시계열·표형 데이터에 대한 이상치 탐지(anomaly / outlier detection) 는 안전성, 비용 절감, 서비스 안정성 측면에서 매우 중요한 과제이다.\n그러나 기존 딥러닝 기반 이상치 탐지 기법들(예: Autoencoder, LSTM-AE, CNN 기반 모델 등)은 다음과 같은 한계를 가진다.\n\n이상치 점수만 제공\n\n단일 스칼라 점수 \\(A(x)\\)만 제공하는 경우가 많아,\n“얼마나 이상한가?”는 알 수 있어도\n“이 판단을 얼마나 믿을 수 있는가?”(불확실성)는 알기 어렵다.\n\n불확실성(uncertainty) 정보 부재\n\n모델이 자신 없는 영역에서 내린 이상치 판단을\n동일한 신뢰도로 사용하게 되며,\n이는 실제 운영 환경에서 위험한 결정으로 이어질 수 있다.\n\n비용 구조가 반영되지 않은 결정\n\n실제 시스템에서는\n\n정상인데 이상치로 판단할 때의 비용(공장 정지, 서비스 중단 등)\n\n이상치인데 정상으로 넘기는 비용(고장, 사고, 손실 등)\n\n사람/전문가에게 “검토를 요청할 때” 드는 비용\n이 서로 다름에도 불구하고,\n단일 threshold 기반 이진 결정으로만 처리되는 경우가 많다.\n\n\n\n이에 본 연구는, 딥러닝 기반 베이지안 VAE와 Mixture-of-VAEs를 활용하여\n\n다변량 데이터에서 이상치 점수와 불확실성을 동시에 추정하고,\n이를 바탕으로 STOP / CHECK / IGNORE 형태의\n위험 민감(risk-aware) 의사결정 규칙을 설계하고자 한다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-목표-및-연구-질문",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-목표-및-연구-질문",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "Base Model:\nVariational Autoencoder(VAE)를 기반으로 한 다변량 딥러닝 이상치 탐지 모델을 설계하여,\n전역(global) 및 변수별(feature-wise) 이상치 점수와 불확실성을 동시에 추정한다.\nExtended Model:\n데이터가 여러 정상 모드(운영 상태)를 가진다고 가정하고,\nMixture-of-VAEs (MoVAE) 구조를 설계하여\n모드별 이상치·불확실성과 모드 자체에 대한 불확실성(mode uncertainty) 를 함께 추정한다.\nRisk-aware Decision:\n이상치 점수와 불확실성 정보를 활용해\n비용 구조를 반영한 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 정식화하고,\n기존 threshold 기반 기법보다 더 낮은 위험도(risk)를 달성하는지 평가한다.\n범용성 검증:\n공정/센서 시계열, 네트워크/트래픽, 공개 multivariate anomaly dataset 등\n서로 다른 도메인에서 제안 프레임워크의 일관된 효과를 검증한다.\n\n\n\n\n\nRQ1. Variational Autoencoder 기반 다변량 딥러닝 모델을 통해\n전역 및 변수별 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 동시에 추정할 수 있는가?\nRQ2. 데이터가 여러 정상 모드를 가질 때, 단일 VAE보다\nMixture-of-VAEs가 이상치 탐지 및 불확실성 추정 측면에서\n더 나은 표현력과 의사결정 성능을 제공하는가?\nRQ3. 추정된 \\((A(x), U(x))\\) (및 모드 불확실성)를 이용하여\nSTOP / CHECK / IGNORE 형태의 위험 민감 의사결정 규칙을 설계할 때,\n기존 단일 threshold 기반 이진 의사결정보다\n실제 비용(risk)을 유의하게 감소시킬 수 있는가?"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#선행-연구-및-키워드-세트",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#선행-연구-및-키워드-세트",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "이상치 탐지 / 다변량\n\nmultivariate anomaly detection\n\nmultivariate time series anomaly detection\n\ndeep anomaly detection, deep autoencoder, VAE anomaly detection\n\nreconstruction-based anomaly detection\n\n딥러닝 & 베이지안 / 불확실성\n\ndeep learning, representation learning (PyTorch / fastai)\n\nBayesian deep learning, variational inference\n\nMonte Carlo Dropout, deep ensemble\n\nuncertainty quantification, aleatoric / epistemic uncertainty\n\nVariational Autoencoder, Bayesian VAE, probabilistic autoencoder\n\nmixture of VAEs, mixture density networks, mixture-of-experts\n\n의사결정 / 위험\n\nselective prediction, abstention, reject option\n\nrisk-aware decision making, cost-sensitive learning\n\nrisk–coverage trade-off, calibration\n\n\n\n\n\n\n1–2개월차에 집중적으로 논문 수집 및 정리\n각 논문에 대해 다음 항목으로 구조화:\n\n데이터 타입 (시계열, 이미지, 센서, 트래픽 등)\n\n딥러닝 사용 여부, VAE/flow/AE 등 모델 유형\n\n이상치 점수 정의 방식 (reconstruction, likelihood, distance 등)\n\n불확실성 추정 여부 및 방법\n\nrisk-aware / selective decision 관점 고려 여부\n\n본 연구와의 차별점 / 한 줄 평가"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-내용-및-방법",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-내용-및-방법",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "본 연구는 Base Model(VAE)와 Extended Model(Mixture-of-VAEs)으로 구성되며,\n두 모델에서 공통적으로 이상치 점수 + 불확실성 추정 + risk-aware decision layer를 설계한다.\n\n\n\n\n다변량 입력 \\(x \\in \\mathbb{R}^d\\)에 대해, VAE 구조는 다음과 같이 정의한다.\n\nPrior:\n\n\\[\nz \\sim p(z) = \\mathcal{N}(0, I)\n\\]\n\nDecoder:\n\n\\[\np_\\theta(x \\mid z) = \\mathcal{N}\\big(\\mu_\\theta(z), \\text{diag}(\\sigma^2_\\theta(z))\\big)\n\\]\n\nEncoder (approximate posterior):\n\n\\[\nq_\\phi(z \\mid x) = \\mathcal{N}\\big(\\mu_\\phi(x), \\text{diag}(\\sigma^2_\\phi(x))\\big)\n\\]\n학습은 ELBO 최적화를 통해 수행한다.\n\nELBO:\n\n\\[\n\\mathcal{L}_{\\text{ELBO}}(x;\\theta,\\phi) = \\mathbb{E}_{q_\\phi(z\\mid x)}[\\log p_\\theta(x \\mid z)] - \\mathrm{KL}\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big)\n\\]\nPyTorch/fastai로는 encoder/decoder를 MLP, 1D-CNN, LSTM 등으로 구현하고,\n출력층에서 mean 및 log-variance를 예측하도록 구성한다.\n\n\n\n관측 \\(x\\)에 대해, 다음과 같이 Monte Carlo 샘플링을 수행한다.\n\n\\(z^{(t)} \\sim q_\\phi(z \\mid x), \\quad t = 1,\\dots,T\\)\n\\(\\hat x^{(t)} \\sim p_\\theta(x \\mid z^{(t)})\\)\n\n각 변수 \\(j = 1,\\dots,d\\)에 대해:\n\n변수별 이상치 점수 (재구성 오차)\n\n\\[\nr_j(x) = \\frac{1}{T} \\sum_{t=1}^T \\big(x_j - \\hat x^{(t)}_j\\big)^2\n\\]\n\n변수별 불확실성 (예측 분산)\n평균 재구성을\n\n\\[\n\\bar x_j = \\frac{1}{T} \\sum_{t=1}^T \\hat x^{(t)}_j\n\\]\n로 정의할 때,\n\\[\nu_j(x) = \\frac{1}{T-1} \\sum_{t=1}^T \\big(\\hat x^{(t)}_j - \\bar x_j\\big)^2\n\\]\n전역(global) 이상치 점수와 불확실성은 가중합으로 정의한다.\n\n전역 이상치 점수:\n\n\\[\nA_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j r_j(x)\n\\]\n\n전역 불확실성:\n\n\\[\nU_{\\text{VAE}}(x) = \\sum_{j=1}^d w_j u_j(x)\n\\]\n여기서 \\(w_j\\)는 각 변수의 중요도를 반영하는 가중치(동일 가중치 또는 도메인 지식 기반)를 의미한다.\n필요 시, encoder/decoder 네트워크에 Dropout을 적용하여\nepistemic uncertainty를 추가로 반영할 수 있다.\n\n\n\n\n\n\n\n다변량 데이터가 여러 정상 모드(운영 상태)를 가진다고 가정한다.\n이를 위해 \\(K\\)개의 VAE expert와 gating network로 구성된 Mixture-of-VAEs 구조를 정의한다.\n\nGating network:\n\n\\[\n\\pi_k(x) = p_\\psi(k \\mid x), \\quad k = 1,\\dots,K\n\\]\n여기서 \\(\\pi_k(x)\\)는 입력 \\(x\\)가 모드 \\(k\\)에 속할 확률을 나타내며,\n\\(\\sum_{k=1}^K \\pi_k(x) = 1\\)을 만족한다.\n\n각 expert VAE:\n\n\\[\nz_k \\sim p(z_k) = \\mathcal{N}(0, I)\n\\]\n\\[\np_{\\theta_k}(x \\mid z_k) = \\mathcal{N}\\big(\\mu_{\\theta_k}(z_k), \\text{diag}(\\sigma^2_{\\theta_k}(z_k))\\big)\n\\]\n\\[\nq_{\\phi_k}(z_k \\mid x) = \\mathcal{N}\\big(\\mu_{\\phi_k}(x), \\text{diag}(\\sigma^2_{\\phi_k}(x))\\big)\n\\]\n\n전체 likelihood:\n\n\\[\np(x) = \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x)\n\\]\n학습은 mixture 형태의 ELBO 또는 EM-유사 전략,\n혹은 end-to-end joint training으로 수행할 수 있으며,\n실험 단계에서 구현 난이도와 성능을 고려하여 선택한다.\n\n\n\n각 expert에 대해, VAE와 동일하게 재구성 기반 점수 \\(A_k(x)\\)를 정의한다.\n\nexpert \\(k\\)의 이상치 점수(예시):\n\n\\[\nA_k(x) = \\sum_{j=1}^d w_j r_{j,k}(x)\n\\]\nMixture 전체의 이상치 점수는 다음과 같이 정의할 수 있다.\n\nlikelihood 기반:\n\n\\[\nA_{\\text{MoVAE}}(x) = -\\log \\left( \\sum_{k=1}^K \\pi_k(x)\\, p_{\\theta_k}(x) \\right)\n\\]\n\nreconstruction 기반 가중합:\n\n\\[\nA_{\\text{MoVAE}}(x) = \\sum_{k=1}^K \\pi_k(x)\\, A_k(x)\n\\]\n두 정의는 실험에서 비교 가능하며,\n도메인 특성에 따라 더 좋은 score 정의를 선택할 수 있다.\n\n\n\nMixture-of-VAEs에서는 불확실성이 두 층으로 나뉜다.\n\nexpert 내부 불확실성 (in-expert uncertainty)\n\n각 expert \\(k\\)의 VAE에서 variance, MC 샘플 분산 등을 이용해\n\\(U_k(x)\\)를 정의 (Base VAE와 동일 방식).\n\n모드 불확실성 (between-expert / mode uncertainty)\n\ngating 확률 벡터 \\(\\pi(x) = (\\pi_1(x),\\dots,\\pi_K(x))\\)의 엔트로피:\n\n\n\\[\nH_\\pi(x) = -\\sum_{k=1}^K \\pi_k(x)\\log \\pi_k(x)\n\\]\n\n\\(\\pi_k(x)\\)가 한 모드에 집중되면 \\(H_\\pi(x)\\)가 작고,\n여러 모드에 고르게 분산되면 \\(H_\\pi(x)\\)가 커진다.\n→ “이 샘플이 어느 모드에 속하는지 모델이 헷갈리는 정도”로 해석 가능.\n\n\n종합 불확실성 정의 예시\n\n\\[\nU_{\\text{MoVAE}}(x) = \\alpha \\sum_{k=1}^K \\pi_k(x)\\, U_k(x) + \\beta H_\\pi(x)\n\\]\n여기서 \\(\\alpha, \\beta\\)는 모드 내부 불확실성과 모드 불확실성의 상대적 중요도를 조절하는 하이퍼파라미터이다.\n\n\n\n\n\n\n\n각 샘플 \\(x\\)에 대하여, 세 가지 행동 중 하나를 선택한다고 가정한다.\n\n\\(\\delta(x) \\in \\{\\text{IGNORE}, \\text{CHECK}, \\text{STOP}\\}\\)\n\n실제 상태 \\(y \\in \\{\\text{normal}, \\text{anomaly}\\}\\)에 대해,\n각 행동에 대한 비용을 \\(C(\\delta(x), y)\\)로 정의한다.\n예시:\n\n정상인데 STOP → 불필요한 정지, false positive 비용\n\n이상치인데 IGNORE → 사고/고장, false negative 비용 (가장 큼)\n\nCHECK → 사람/추가 검사 비용 (중간 수준)\n\n전체 기대 위험도(risk)는 다음과 같이 정의할 수 있다.\n\\[\nR(\\delta) = \\mathbb{E}_{(x,y)}\\big[\\,C(\\delta(x), y)\\,\\big]\n\\]\n실제 구현에서는 validation set 상에서의 경험적 위험 \\(\\hat R(\\delta)\\)를 최소화하는 규칙을 찾는다.\n\n\n\nBase VAE 및 MoVAE 모두, 이상치 점수 \\(A(x)\\)와 불확실성 \\(U(x)\\)를 기반으로 다음과 같은 규칙을 정의할 수 있다.\n예시 규칙:\n\\[\n\\delta(x) =\n\\begin{cases}\n\\text{STOP} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) \\le \\tau_U \\\\\n\\text{CHECK} & \\text{if } A(x) \\ge \\tau_A \\text{ and } U(x) &gt; \\tau_U \\\\\n\\text{IGNORE} & \\text{if } A(x) &lt; \\tau_A\n\\end{cases}\n\\]\n여기서 \\((\\tau_A, \\tau_U)\\)는 validation set에서\n경험적 위험 \\(\\hat R(\\tau_A,\\tau_U)\\)를 최소화하도록 탐색한다.\nMixture-of-VAEs의 경우,\n\\(U(x)\\)를 \\(U_{\\text{MoVAE}}(x)\\)로 두거나,\n모드 엔트로피 \\(H_\\pi(x)\\)를 추가 입력으로 사용하는 변형도 고려할 수 있다.\n\n\n\n\n\n\n프레임워크: PyTorch (필수), 필요 시 fastai로 학습/실험 루프 관리\n구성 요소\n\nmodels/ : VAE, Mixture-of-VAEs, gating network 모듈\n\ndatasets/ : 시계열/탭형 multivariate anomaly dataset 로더\n\ntraining/ : 학습 루프, ELBO 계산, threshold search, risk 계산\n\nanalysis/ : ROC, PR, risk–coverage, 의사결정 시뮬레이션, 시각화"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#실험-계획",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#실험-계획",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "Synthetic multivariate 데이터\n\n다변량 Gaussian, mixture, non-linear manifold 데이터 생성\n\n단일 모드 vs 다중 모드 환경에서 VAE와 MoVAE 비교\n\n공개 multivariate anomaly dataset\n\n예: 서버/센서/시계열 관련 공개 데이터셋 (SMD, MSL, SWaT 등)\n\n도메인에 따라 tabular/multivariate time series 데이터 추가 검토\n\n\n\n\n\n\nBaseline 모델\n\n단순 Autoencoder 기반 이상치 탐지\n\nVAE (불확실성 고려하지 않는 score-only 버전)\n\n필요시 다른 딥러닝 기반 anomaly detection 방법\n\n성능 지표\n\n이상치 탐지:\n\nAUROC, AUPR, F1-score, FPR@95TPR 등\n\n의사결정 / risk 관점:\n\nrisk–coverage curve\n\nfalse alarm 수, missed anomaly 수\n\nCHECK(사람 검토) 비율 대비 risk 감소 정도"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-일정-12개월-기준-예시",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#연구-일정-12개월-기준-예시",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "1–2개월차: 문헌 조사 및 문제 정의\n\n키워드 기반 선행 연구 수집 및 정리\n\n관련 연구 요약 및 연구 질문(RQ) 확정\n\n3–4개월차: 수식 정식화 및 모델 설계\n\nVAE / Mixture-of-VAEs 수식 정리 및 손실 함수 정의\n\n이상치 점수, 불확실성, decision rule 공식화\n\n간단한 이론적 성질(정의, lemma, risk–coverage 개념) 초안 작성\n\n5–7개월차: PyTorch 구현 및 초기 실험\n\nBase VAE 및 MoVAE 구현\n\nsynthetic 데이터 및 1개 공개 데이터셋에서 1차 검증\n\n코드 구조 안정화 및 hyperparameter 기본 설정\n\n8–9개월차: 본 실험 및 분석\n\n추가 데이터셋에 대한 본격 실험\n\nSingle VAE vs Mixture-of-VAEs 비교\n\nrisk-aware decision 관점에서의 성능 분석 및 ablation study\n\n10–11개월차: 논문 집필\n\n방법론(3–4장), 실험(5장)부터 집필\n\n서론·관련연구(1–2장), 결론(6장) 작성 및 통합\n\n지도교수 피드백 반영 및 수정\n\n12개월차: 최종 정리 및 제출\n\n논문 형식, 참고문헌, 그림/표 정리\n\n발표 자료 준비 및 최종 점검"
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#기대-효과-및-기여",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_2.html#기대-효과-및-기여",
    "title": "석사 학위 논문 연구 계획서 - Bayesian+AnomalyDetection",
    "section": "",
    "text": "모델링 기여\n\n다변량 데이터를 위한 딥러닝 기반 Bayesian VAE + Mixture-of-VAEs 구조를 설계하여,\n전역 및 변수별 이상치 점수와 계층적 불확실성(internal + mode uncertainty)을 동시에 제공한다.\n\n의사결정 기여\n\n이상치 점수와 불확실성을 활용한 risk-aware 3-way 의사결정(STOP / CHECK / IGNORE) 규칙을 제안하고,\n비용 구조를 반영한 위험도 관점에서 기존 방법보다 더 나은 성능을 보임을 보인다.\n\n범용성 기여\n\n공정/센서, 네트워크/트래픽, 일반 multivariate dataset 등\n서로 다른 도메인에 동일 프레임워크를 적용함으로써,\n범용적인 “이상치 + 불확실성 + 의사결정” 프레임워크로서의 가능성을 제시한다.\n\n실무 적용 가능성\n\n실제 시스템에서\n\n언제 자동으로 STOP할지,\n\n언제 사람에게 CHECK를 요청할지,\n\n언제 IGNORE해도 되는지\n를 정량적으로 판단하는 기준을 제공하여,\n신뢰 가능한 이상치 탐지 기반 의사결정 시스템 설계에 기여할 수 있다."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&AD_4_papers.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&AD_4_papers.html",
    "title": "Paper Lists - Bayesian+AnomalyDetection",
    "section": "",
    "text": "No.\nCategory\nReference (Authors, Title)\nWhy Relevant / Notes\n\n\n\n\n1\nAnomaly detection – classic survey\nChandola et al., “Anomaly Detection: A Survey” (ACM Computing Surveys)\n고전적인 이상치 탐지 전반 개요. 전통 기법들과 용어 정리용.\n\n\n2\nDeep anomaly detection – survey\nPang et al., “Deep Learning for Anomaly Detection: A Review”\n딥러닝 기반 AD를 종합적으로 정리. 딥 모델 분류·비교 구조 잡을 때 중요.\n\n\n3\nImage/video anomaly – survey\nMohammadi et al., “Deep Learning for Video Anomaly Detection – A Survey”\n영상 도메인 위주지만, 딥 AD 패턴과 실험 관행 참고용.\n\n\n4\nGraph anomaly – survey\nXu et al., “A Comprehensive Survey on Graph Anomaly Detection with Deep Learning”\n그래프 도메인이지만, deep AD 설계 아이디어·평가 지표 참고 가능.\n\n\n5\nGeneral anomaly – survey\nSalehi et al., “A Comprehensive Survey of Anomaly Detection Algorithms”\n통계·머신러닝·딥러닝 AD 기법을 넓게 개관.\n\n\n6\nMultivariate time series AD\nMalhotra et al., “LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection”\n다변량 시계열 + LSTM AE 구조. baseline 및 시계열 세팅 참고.\n\n\n7\nMultivariate time series AD\nHundman et al., “Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding”\nNASA/spacecraft 시계열 AD. thresholding 전략까지 포함해 실전 감각 참고.\n\n\n8\nMultivariate time series AD (deep)\nAudibert et al., “USAD: UnSupervised Anomaly Detection on Multivariate Time Series”\nUSAD 구조. 다변량 시계열 AD 대표적인 딥 모델 중 하나.\n\n\n9\nDeep generative AD (AE+GMM)\nZong et al., “Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection”\nAE + GMM 조합. latent mixture 아이디어 참고 (Mixture-of-VAEs와 연결).\n\n\n10\nTime-series anomaly – survey\nBraei & Wagner, “Anomaly Detection in Univariate Time Series: A Survey on the State-of-the-Art”\n시계열 AD 전반 survey. 데이터셋·지표·평가 관행 정리용.\n\n\n11\nTime-series anomaly – survey\nBlázquez-García et al., “A Review on Outlier/Anomaly Detection in Time Series Data”\n시계열 이상치 탐지 종합 리뷰. 논문 인용·관련연구 작성에 유용.\n\n\n12\nVAE – 기본 이론\nKingma & Welling, “Auto-Encoding Variational Bayes”\nVAE 이론의 원 논문. ELBO, reparameterization 등 수식의 기반.\n\n\n13\nVAE for anomaly detection (초기)\nAn & Cho, “Variational Autoencoder based Anomaly Detection using Reconstruction Probability”\nVAE를 AD에 직접 적용한 초창기 아이디어. reconstruction probability 개념.\n\n\n14\nVAE AD – 비교 연구\nNguyen et al., “Variational Autoencoder for Anomaly Detection: A Comparative Study”\n여러 VAE 기반 AD 변형을 비교. 어떤 변형을 baseline으로 잡을지 참고 가능.\n\n\n15\nClassification-based AD\nBergman & Hoshen, “Classification-Based Anomaly Detection for General Data”\n분류 기반 AD 접근. VAE/모델링과는 다른 관점의 비교 대상으로 참고.\n\n\n16\nDeep one-class AD\nXu et al., “Deep One-Class Classification”\nDeep SVDD류. one-class 관점의 AD 이론·구조 참고.\n\n\n17\nDeep semi-supervised AD\nRuff et al., “Deep Semi-Supervised Anomaly Detection”\n일부 라벨이 있는 경우 AD 설계. 비지도/반지도 경계 정리하는 데 도움.\n\n\n18\nGM-VAE / mixture latent\nDilokthanakul et al., “Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders”\nlatent space에 GMM을 둔 VAE. Mixture-of-VAEs/클러스터링 설계에 기초.\n\n\n19\nEntangled Mixture-of-VAEs\nCaciularu & Goldberger, “An Entangled Mixture of Variational Autoencoders Approach to Deep Clustering”\n여러 VAE의 mixture로 클러스터링. 우리가 말한 Mixture-of-VAEs와 매우 직접적으로 연결.\n\n\n20\nMixture-of-VAEs for clustering\n(OpenReview) “A Mixture of Variational Autoencoders for Deep Clustering”\nMoVAE 구조를 직접 다루는 논문. 모드별 VAE·게이팅 설계 참고.\n\n\n21\nVAE + Gamma mixture latent\nLi et al., “Deep Clustering Analysis via VAE with Gamma Mixture Latent Model (GamMM-VAE)”\nlatent mixture를 변형한 모델. 모드 표현/클러스터링 관점에서 아이디어 참고.\n\n\n22\nMoE + (C)VAE for AD\nMoradi et al., “Mixture of Experts with Convolutional and Variational Autoencoders for Anomaly Detection”\nCNN+VAE 기반 expert mixture로 AD 수행. MoE와 AD를 직접 연결한 사례.\n\n\n23\nBayesian DL – MC Dropout\nGal & Ghahramani, “Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning”\nMC Dropout으로 epistemic UQ 추정. VAE/encoder/decoder에 바로 적용 가능.\n\n\n24\nUQ (aleatoric/epistemic) in DL\nKendall & Gal, “What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?”\naleatoric vs epistemic 구분 + loss에 UQ 넣는 방법. 이상치 + UQ 해석에 핵심.\n\n\n25\nDeep ensembles for UQ\nLakshminarayanan et al., “Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles”\nEnsemble 기반 UQ. VAE/decoder ensemble 설계 시 참고 가능.\n\n\n26\nUQ under dataset shift\nOvadia et al., “Can You Trust Your Model’s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift”\nUQ의 신뢰성 평가. 제안 모델 UQ를 어떻게 검증할지 아이디어 제공.\n\n\n27\nBayesian DL – thesis\nGal, “Uncertainty in Deep Learning” (PhD thesis)\nBayesian DL 전반 정리. 이론 챕터(정의·정리) 쓸 때 구조 참고.\n\n\n28\nSelective prediction – theory\nGeifman & El-Yaniv, “Selective Classification for Deep Neural Networks”\nrisk–coverage, abstention 개념의 정석 논문. STOP/CHECK/IGNORE 이론 기반.\n\n\n29\nSelective prediction in NLP\nXin et al., “The Art of Abstention: Selective Prediction and Error Regularization for NLP”\nselective prediction을 딥 모델에 적용한 실전 예. loss 설계·실험 세팅 참고.\n\n\n30\nSelective classification + AUC\nPugnana et al., “AUC-based Selective Classification”\n선택적 분류에서 AUC 기반 기준 제안. selective rule 평가 지표 설계에 참고 가능."
  },
  {
    "objectID": "posts/IDEAs/2025_11_13 Bayes&MetaLearning_2_papers.html",
    "href": "posts/IDEAs/2025_11_13 Bayes&MetaLearning_2_papers.html",
    "title": "Paper Lists - Bayesian+MetaLearning",
    "section": "",
    "text": "No.\n카테고리\n제목 / 정보\n저자 / 연도\n메모(간단)\n\n\n\n\n1\nMeta-learning 개관\nMeta-Learning in Neural Networks: A Survey\nHospedales et al., 2020\n메타러닝 전반 서베이, taxonomy·응용 정리\n\n\n2\nMeta-learning (gradient)\nModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (MAML)\nFinn et al., 2017\n대표 gradient-based meta-learning\n\n\n3\nMeta-learning (metric)\nMatching Networks for One Shot Learning\nVinyals et al., 2016\n초기 few-shot metric 기반 모델\n\n\n4\nMeta-learning (metric)\nPrototypical Networks for Few-shot Learning\nSnell et al., 2017\n간단·강력한 metric-based baseline\n\n\n5\nMeta-learning (model-based)\nNeural Processes\nGarnelo et al., 2018\n함수 분포 기반, GP+NN 아이디어\n\n\n6\nMeta-learning (model-based)\nAttentive Neural Processes\nKim et al., 2019\nNP에 attention 도입, 성능·안정성 개선\n\n\n7\nGradient↔︎Bayes 연결\nRecasting Gradient-Based Meta-Learning as Hierarchical Bayes\nGrant et al., 2018\nMAML을 계층 베이지안으로 재해석\n\n\n8\nBayesian meta-learning\nGradient-EM Bayesian Meta-Learning\nZou & Lu, 2020\ngradient-EM 기반 베이지안 메타러닝\n\n\n9\nBayesian meta-learning\nA Hierarchical Bayesian Model for Few-Shot Meta Learning\nKim & Hospedales, ICLR 2024\n계층 베이지안 few-shot 모형 제안\n\n\n10\nBayesian meta-learning\nBayesian Meta-Learning Through Variational Gaussian Processes (VMGP)\nFortuin et al., 2021\n변분 GP 기반 베이지안 메타러닝\n\n\n11\nBayesian meta-learning (응용)\nLearning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks\n(AITRICS), 약 2021–2022\n불균형·OOD task에서 pooling 비율 조절\n\n\n12\nMulti-task GP 토대\nLearning Gaussian Processes from Multiple Tasks\nBonilla et al., ICML 2005\nmulti-task GP의 초기 계층 Bayes 정식화\n\n\n13\nMulti-task GP 토대\nMulti-task Gaussian Process Prediction\nBonilla et al., NIPS 2007\nICM/코리저널라이제이션 구조 대표 논문\n\n\n14\nMulti-task GP 토대\nMulti-task Learning with Gaussian Processes\nK. M. A. Chai, 2010\nmulti-task GP 전반 비교·분석\n\n\n15\nMulti-task GP (딥 커널)\nMultitask Gaussian Processes (deep BNN kernels)\n(여러 저자), 2019\ndeep BNN에서 유도된 multitask GP 커널\n\n\n16\nMulti-task GP 이론\nLearning Curves for Multi-task Gaussian Process Regression\nAshton & Sollich, NIPS 2012\nmulti-task GP 학습 곡선(Bayes error) 분석\n\n\n17\nMulti-task GP 이론\nGeneralization Errors and Learning Curves for Regression with Multi-task Gaussian Processes\n(Ashton 등), 2008\ntask 상관구조 vs 일반화오차\n\n\n18\nMulti-task GP 구조\nMulti-output Gaussian Processes: Coregionalization Models Using Hadamard Product (ICM/LCM)\nBonilla 계열 / 관련 저자\n코리저널라이제이션 구조 기술\n\n\n19\nMulti-task GP (scalable)\nScalable Multi-task Gaussian Processes with Neural Embedding of Coregionalization\n(예: Nguyen 등), 2022\n신경 임베딩으로 풍부한 task 공분산 학습\n\n\n20\nGP 기반 meta-learning\nLearning to Learn with Gaussian Processes (GPML)\nNguyen, Low, Jaillet, UAI 2021\n대표 GP 기반 meta-learning, task kernel\n\n\n21\nGP 기반 meta-learning\nLearning to Learn Dense Gaussian Processes for Few-Shot Learning\n(NeurIPS), 2021\ndense inducing points 활용 GP meta-learning\n\n\n22\nGP + uncertainty calibration\nMeta-learning to Calibrate Gaussian Processes with Deep Kernels for Regression Uncertainty Estimation\n(2024)\ndeep kernel GP 불확실성 calibration\n\n\n23\nGP + meta-learning (응용)\nMeta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction (ADKF-IFT)\nChen et al., ICLR 2023\n분자 property 예측용 deep kernel GP meta\n\n\n24\nPAC-Bayes meta-learning 이론\nScalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior\nRothfuss et al., JMLR 2023\nPACOH, PAC-Bayes 기반 meta-generalization\n\n\n25\nPAC-Bayes meta-learning 이론\nPACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees\nRothfuss et al., 2021\nPACOH 초기 버전, GP base learner\n\n\n26\nPAC-Bayes + BNN prior\nMeta-Learning Bayesian Neural Network Priors Based on PAC-Bayesian Theory\n(예: Rothfuss/관련 저자), 2020\nPAC-Bayes bound로 BNN prior meta-learning\n\n\n27\nPAC-Bayes + 함수공간 prior\nMeta-Learning Reliable Priors in the Function Space (F-PACOH)\nFortuin et al., NeurIPS 2021\n함수공간 stochastic process prior 학습\n\n\n28\nTask similarity + meta-learning\nTask-Similarity Aware Meta-learning through Nonparametric Kernel Regression\nVenkitaraman, Hansson, Wahlberg, 2020\ntask를 RKHS에 두고 커널로 similarity 모델\n\n\n29\nTask similarity + Bayesian meta\nBayesian Meta-Learning for Task Adaptation Using Expert-Inferred Task Similarities\nAalto Univ. MSc Thesis, 2024\n전문가가 준 similarity를 prior에 반영\n\n\n30\nTask similarity + 계층 Bayes\nCausal Similarity-Based Hierarchical Bayesian Models (Meta-Learning with Similarity of Causal Mechanisms)\nWharrie & Kaski, 2023\n인과 메커니즘 유사도로 pooling 결정"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]