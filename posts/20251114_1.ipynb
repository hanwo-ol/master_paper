{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ae49d2",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\"\n",
    "date: 2025-11-14       \n",
    "description: \"메타 러닝 관련 논문 요약 및 주요 내용\"\n",
    "categories: [MetaLearning, MAML, Review]\n",
    "author: \"김한울\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704331b",
   "metadata": {},
   "source": [
    "```\n",
    "@inproceedings{finn2017model,\n",
    "  title={Model-agnostic meta-learning for fast adaptation of deep networks},\n",
    "  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},\n",
    "  booktitle={International conference on machine learning},\n",
    "  pages={1126--1135},\n",
    "  year={2017},\n",
    "  organization={PMLR}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fa05b",
   "metadata": {},
   "source": [
    "# 초록 (Abstract)\n",
    "\n",
    "본 논문은 경사 하강법(gradient descent)으로 훈련되는 어떠한 모델과도 호환되며 분류, 회귀, 강화학습 등 다양한 학습 문제에 적용할 수 있다는 점에서 **모델에 구애받지 않는(model-agnostic) 메타 러닝 알고리즘**을 제안합니다. 메타 러닝의 목표는 다양한 학습 과제(task)에 대해 모델을 훈련함으로써, 적은 수의 훈련 샘플만으로도 새로운 과제를 해결할 수 있도록 하는 것입니다.\n",
    "\n",
    "우리가 제안하는 방식은 새로운 과제에 대한 소량의 훈련 데이터와 몇 번의 경사 하강 단계(gradient step)만으로도 해당 과제에서 우수한 일반화 성능을 달성할 수 있도록 모델의 파라미터를 명시적으로 훈련합니다. 다시 말해, 본 방법은 모델이 **미세조정(fine-tuning)에 용이하도록 훈련**하는 것입니다.\n",
    "\n",
    "본 논문은 이 접근법이 두 개의 퓨샷(few-shot) 이미지 분류 벤치마크에서 최고 수준(state-of-the-art)의 성능을 달성하고, 퓨샷 회귀 문제에서도 우수한 결과를 보이며, 신경망 정책을 사용하는 정책 경사(policy gradient) 강화학습의 미세조정 속도를 크게 향상시킨다는 것을 입증합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0561a54",
   "metadata": {},
   "source": [
    "# 1. 서론 (Introduction)\n",
    "\n",
    "## 인간 지능의 핵심적인 특징과 AI agent에게 바라는 것\n",
    "\n",
    "+ 적은 수의 예시만으로 사물을 인식하거나, 단 몇 분의 경험만으로 새로운 기술을 습득하는 등, 빠르게 학습하는 능력\n",
    "+ 우리가 만드는 인공 에이전트 역시 인간의 지능과 같은 특징을 가지면 좋다.   \n",
    "\n",
    "즉, 소수의 예시만으로도 신속하게 학습하고 적응하며, 더 많은 데이터가 주어짐에 따라 지속적으로 적응해 나가야 함. \n",
    "\n",
    "## 빠르고 유연한 학습은 어려운 과제\n",
    "\n",
    "+ 에이전트는 새로운 데이터에 과적합(overfitting)되는 것을 피해야 하고, \n",
    "+ 기존의 경험을 소량의 새로운 정보와 통합해야 한다. \n",
    "+ 더욱이, 사전 경험(prior experiments)과 새로운 데이터의 형태는 과제(task)에 따라 달라진다.    \n",
    "\n",
    "따라서 최대한의 적용 가능성을 확보하기 위해서는, '학습하는 방법을 학습'하는 메커니즘(즉, 메타 러닝)이 특정 과제나 연산 형태에 국한되지 않고 범용적(general)이어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854da7c3",
   "metadata": {},
   "source": [
    "## 제안: **모델에 구애받지 않는(model-agnostic)** 메타 러닝 알고리즘\n",
    "\n",
    "+ 경사 하강법(gradient descent)으로 훈련되는 어떠한 학습 문제와 모델에도 직접 적용될 수 있다는 의미. \n",
    "+ 심층 신경망 모델(deep neural network models)에 초점을 맞추고 있긴 하지만, 본 논문이 제안하는 접근법(MAML)은 최소한의 수정만으로도 분류, 회귀, 정책 경사(policy gradient) 강화학습 등 다양한 아키텍처와 문제 설정에 얼마나 쉽게 적용될 수 있는지를 보여줌. \n",
    "\n",
    "메타 러닝에서 훈련된 모델의 목표는 적은 양의 새로운 데이터만으로 새로운 과제를 신속하게 학습하는 것이며, 모델은 메타 학습기에 의해 수많은 다른 과제에 대해 학습할 수 있도록 훈련됩니다.\n",
    "\n",
    "## 핵심 아이디어 of MAML   \n",
    "\n",
    "새로운 과제에서 얻은 소량의 데이터로 계산된 한 번 이상의 경사 하강 단계를 거쳐 파라미터가 업데이트되었을 때, 해당 과제에서 모델의 성능이 극대화되도록 모델의 **초기 파라미터**를 훈련하는 것입니다. \n",
    "\n",
    "+ 업데이트 함수나 학습 규칙을 학습하는 기존의 메타 러닝 방법들[1]과 달리, MAML 알고리즘은 학습해야 할 파라미터의 수를 늘리지 않으며, 순환 모델(recurrent model) [2]이나 샴 네트워크(Siamese network)[3]를 요구하는 것처럼 모델 아키텍처에 제약을 가하지도 않습니다. \n",
    "    + [1] (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017)   \n",
    "    + [2] (Santoro et al., 2016)    \n",
    "    + [3] (Koch, 2015)   \n",
    "+ 또한, 완전 연결(fully connected), 컨볼루션(convolutional), 순환(recurrent) 신경망 등과 쉽게 결합할 수 있습니다. \n",
    "+ 미분 가능한 지도 학습 손실 함수는 물론, 미분 불가능한 강화학습 목표 함수를 포함한 다양한 종류의 손실 함수와도 함께 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d9c16",
   "metadata": {},
   "source": [
    "\n",
    "단 몇 번의 경사 하강 단계만으로, 혹은 단 한 번의 단계만으로도 새로운 과제에서 좋은 결과를 낼 수 있도록 모델의 파라미터를 훈련하는 과정은, **특징 학습(feature learning)**의 관점에서 볼 때 여러 과제에 폭넓게 적용 가능한 내부 표현(internal representation)을 구축하는 것으로 해석할 수 있습니다.    \n",
    "\n",
    "+ 만약 내부 표현이 여러 과제에 적합하다면, 파라미터를 약간만 미세조정하는 것(예: 피드포워드 모델의 마지막 레이어 가중치를 주로 수정하는 것)만으로도 좋은 결과를 얻을 수 있습니다.   \n",
    "+ 결과적으로, 우리 절차는 쉽고 빠르게 미세조정될 수 있는 모델을 최적화하여, 신속한 학습에 적합한 공간에서 적응이 일어나도록 만듭니다. \n",
    "\n",
    "**동적 시스템(dynamical systems)** 관점에서 보면, 우리의 학습 과정은 파라미터에 대한 새로운 과제들의 손실 함수의 민감도(sensitivity)를 극대화하는 것으로 볼 수 있습니다.    \n",
    "\n",
    "+ 민감도가 높을 때, 파라미터의 작은 국소적 변화가 과제 손실(task loss)을 크게 개선할 수 있기 때문입니다.   \n",
    "\n",
    "> maximizing the sensitivity of the loss functions of new tasks with respect to the parameters?\n",
    "\n",
    "\n",
    "## 이 연구의 주된 기여   \n",
    "+ 적은 횟수의 경사 하강 업데이트만으로 새로운 과제에 대한 빠른 학습이 가능하도록 모델의 파라미터를 훈련하는, 단순하면서도 모델과 과제에 구애받지 않는 메타 러닝 알고리즘. \n",
    "+ 이 알고리즘을 완전 연결 신경망과 컨볼루션 신경망을 포함한 다양한 모델 유형과, 퓨샷(few-shot) 회귀, 이미지 분류, 강화학습 등 여러 영역에서 시연. \n",
    "\n",
    "평가는 제안된 메타 러닝 알고리즘이 지도 분류를 위해 특별히 설계된 최신 원샷(one-shot) 학습 방법들과 비교하여 더 적은 파라미터를 사용하면서도 우수한 성능을 보이며, 회귀 문제에도 쉽게 적용될 수 있고, 과제 가변성이 존재하는 상황에서 강화학습을 가속화하여 초기화 방식으로서의 직접적인 사전 훈련(pretraining)보다 월등히 뛰어난 성능을 보인다는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26f10b",
   "metadata": {},
   "source": [
    "# 1.0 서론 짚고 넘어가기\n",
    "\n",
    "> **maximizing the sensitivity of the loss functions**\n",
    "\n",
    "## 핵심 개념: 민감도(Sensitivity) = 기울기(Gradient)의 크기\n",
    "\n",
    "수학, 특히 최적화 문제에서 어떤 함수의 \"파라미터에 대한 민감도\"는 **기울기(gradient)**로 표현됩니다. 기울기는 파라미터를 아주 약간 변경했을 때 함수 값이 얼마나, 그리고 어느 방향으로 변하는지를 나타냅니다.\n",
    "\n",
    "- **기울기의 방향**: 함수 값이 가장 가파르게 증가하는 방향\n",
    "- **기울기의 크기(magnitude)**: 그 가파른 정도. 즉, **민감도**\n",
    "\n",
    "따라서 \"파라미터(θ)에 대한 새로운 과제의 손실 함수(L)의 민감도를 극대화한다\"는 것은, 손실 함수의 기울기 벡터 $\\nabla_{\\theta} \\mathcal{L}$의 크기(norm), 즉 $\\Vert \\nabla_{\\theta} \\mathcal{L} \\Vert$ 를 크게 만드는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492b74f",
   "metadata": {},
   "source": [
    "## 수식을 통한 설명\n",
    "\n",
    "1.  **기본 설정**\n",
    "* 모델 파라미터: $\\theta$\n",
    "* 새로운 (임의의) 과제 $\\mathcal{T}_i$에 대한 손실 함수: $\\mathcal{L}_{\\mathcal{T}_i}(\\theta)$\n",
    "\n",
    "2.  **민감도(Sensitivity)의 수학적 표현**   \n",
    "\n",
    "파라미터 $\\theta$에 대한 손실 함수 $\\mathcal{L}_{\\mathcal{T}_i}$의 민감도는 기울기(gradient)의 크기(norm)로 나타낼 수 있습니다.\n",
    "\n",
    "$$ \\text{Sensitivity} = \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\| $$\n",
    "\n",
    "+ 이 값이 크다는 것은 손실 함수의 \"경사면\"이 매우 가파르다는 것을 의미합니다.\n",
    "\n",
    "3.  **파라미터의 작은 변화와 손실의 큰 개선**\n",
    "\n",
    "경사 하강법에서는 파라미터를 다음과 같이 업데이트합니다.\n",
    "\n",
    "$$ \\theta' = \\theta - \\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) $$\n",
    "\n",
    "여기서 $\\alpha$는 학습률(learning rate)입니다.\n",
    "\n",
    "+ 이때, 업데이트 후의 손실 값 $\\mathcal{L}_{\\mathcal{T}_i}(\\theta')$는 1차 테일러 근사(first-order Taylor approximation)를 통해 다음과 같이 예측할 수 있습니다.\n",
    "\n",
    "$$ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (\\theta' - \\theta)^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) $$\n",
    "\n",
    "위 식에 $\\theta' - \\theta = -\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)$를 대입하면,\n",
    "\n",
    "$$ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) + (-\\alpha \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) $$\n",
    "\n",
    "$$ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta))^T (\\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)) $$\n",
    "\n",
    "벡터와 자신의 내적(dot product)은 크기의 제곱이므로,\n",
    "\n",
    "$$ \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 $$\n",
    "\n",
    "4.  **결론: 손실 개선량**\n",
    "\n",
    "위 식을 정리하여 한 번의 업데이트로 인한 **손실 개선량**을 살펴보면 다음과 같습니다.\n",
    "\n",
    "$$ \\text{Loss Improvement} = \\mathcal{L}_{\\mathcal{T}_i}(\\theta) - \\mathcal{L}_{\\mathcal{T}_i}(\\theta') \\approx \\alpha \\| \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta) \\|^2 $$\n",
    "\n",
    "이 수식은 매우 중요한 점을 시사합니다.\n",
    "\n",
    "> **손실 개선량은 민감도(기울기의 크기)의 제곱에 비례합니다.**\n",
    "\n",
    "따라서 MAML의 학습 과정은 어떤 새로운 과제 $\\mathcal{T}_i$가 주어지더라도, 현재 파라미터 $\\theta$ 위치에서 손실 함수의 기울기 크기 $\\vert \\nabla_\\theta \\mathcal{L}_{\\mathcal{T}_i}(\\theta)\\vert$가 크도록 만드는 것입니다. \n",
    "\n",
    "+ 이렇게 되면 단 한 번의 경사 하강 단계만으로도 손실 값을 **크게** 줄일 수 있어, 빠르고 효율적인 적응(adaptation)이 가능해집니다.\n",
    "\n",
    "## 비유를 통한 이해\n",
    "\n",
    "-   **나쁜 초기 파라미터 (낮은 민감도)**: 넓은 고원이나 평지에 서 있는 것과 같습니다. 어느 방향으로 한 걸음 내딛어도 고도(손실)는 거의 변하지 않습니다. 최저점(최적해)에 도달하려면 수많은 걸음을 옮겨야 합니다.\n",
    "-   **좋은 초기 파라미터 (높은 민감도, MAML의 목표)**: 여러 계곡(각 과제의 최적해)으로 내려가는 길이 시작되는 **산등성이의 중앙**에 서 있는 것과 같습니다. 어떤 계곡으로 내려가야 할지 목표가 주어지면, 그 방향은 매우 가파르기 때문에 단 몇 걸음만으로도 고도(손실)를 크게 낮출 수 있습니다.\n",
    "\n",
    "MAML은 바로 이 \"산등성이의 중앙\"과 같은 초기 파라미터 $\\theta$를 찾는 알고리즘이라고 할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
