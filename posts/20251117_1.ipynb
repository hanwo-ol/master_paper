{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f71f682",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Parameter Initialization - from survey paper\"\n",
    "date: 2025-11-17       \n",
    "description: \"초록 탐구\"\n",
    "categories: [MetaLearning, Survey, Review]\n",
    "author: \"김한울\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8cdcd",
   "metadata": {},
   "source": [
    "# Parameter Initialization Paper\n",
    "\n",
    "In this Page, I will Read these papers' Abstracts\n",
    "\n",
    "> (1) C.Finn,P. Abbeel, and S. Levine, “Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks,” in ICML, 2017.\n",
    "\n",
    ">(2) C. Finn, K. Xu, and S. Levine, “Probabilistic Model-agnostic Meta-learning,” in NeurIPS, 2018.\n",
    "\n",
    ">(3) C. Finn, A. Rajeswaran, S. Kakade, and S. Levine, “Online Meta learning,” ICML, 2019.\n",
    "\n",
    ">(4) S. C. Yoonho Lee, “Gradient-Based Meta-Learning With Learned Layerwise Metric And Subspace,” in ICML, 2018.\n",
    "\n",
    ">(5) A. A. Rusu, D. Rao, J. Sygnowski, O. Vinyals, R. Pascanu, S. Osindero, and R. Hadsell, “Meta-Learning With Latent Embedding Optimization,” ICLR, 2019.\n",
    "\n",
    ">(6) S. Qiao, C. Liu, W. Shen, and A. L. Yuille, “Few-Shot Image Recognition By Predicting Parameters From Activations,” CVPR, 2018.\n",
    "\n",
    ">(7) A. Antoniou and A. Storkey, “Learning To Learn By Self Critique,” NeurIPS, 2019.\n",
    "\n",
    ">(8) Q. Sun, Y. Liu, T.-S. Chua, and B. Schiele, “Meta-Transfer Learning For Few-Shot Learning,” in CVPR, 2018. \n",
    "\n",
    ">(9) R. Vuorio, S.-H. Sun, H. Hu, and J. J. Lim, “Multimodal Model-Agnostic Meta-Learning Via Task-Aware Modulation,” in NeurIPS, 2019.\n",
    "\n",
    ">(10) H. Yao, Y. Wei, J. Huang, and Z. Li, “Hierarchically Structured  Meta-learning,” ICML, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f673d",
   "metadata": {},
   "source": [
    "# Model-Agnostic Meta-learning For Fast Adaptation Of Deep Networks\n",
    "\n",
    "## 초록\n",
    "\n",
    "메타학습을 위한 알고리즘을 제안하며, 이는 모델에 구애받지 않는다는 점에서 경사하강법으로 학습되는 모든 모델과 호환되고 분류, 회귀, 강화학습을 포함한 다양한 학습 문제에 적용 가능합니다. 메타학습의 목표는 다양한 학습 과제에 대해 모델을 학습시켜, 소수의 학습 샘플만으로 새로운 학습 과제를 해결할 수 있도록 하는 것입니다. 본 접근법에서는 모델의 파라미터가 명시적으로 학습되어, 새로운 과제로부터 소량의 학습 데이터로 소수의 경사 단계만으로 해당 과제에 대한 좋은 일반화 성능을 생성하도록 합니다. 사실상, 본 방법은 모델이 미세조정하기 쉽도록 학습시킵니다. 두 개의 few-shot 이미지 분류 벤치마크에서 최첨단 성능을 달성하고, few-shot 회귀에서 좋은 결과를 생성하며, 신경망 정책을 사용한 정책 경사 강화학습의 미세조정을 가속화함을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7f013",
   "metadata": {},
   "source": [
    "\n",
    "## Main Equations\n",
    "\n",
    "### Meta-Learning Problem Set-Up\n",
    "\n",
    "**목표**: Few-shot 메타학습의 목표는 소수의 데이터 포인트와 학습 반복만으로 새로운 과제에 빠르게 적응할 수 있는 모델을 학습시키는 것입니다.\n",
    "\n",
    "**메타학습의 기본 구조**: 모델(또는 학습자)은 메타학습 단계에서 과제들의 집합에 대해 학습되며, 이를 통해 학습된 모델은 소수의 예시나 시행만으로 새로운 과제에 빠르게 적응할 수 있습니다. 사실상, 메타학습 문제는 전체 과제를 학습 예시로 취급합니다.\n",
    "\n",
    "**모델 정의**: 모델 $f$는 관측값 $x$를 출력 $a$로 매핑합니다.\n",
    "\n",
    "**과제(Task) 정의**: 각 과제 $T$는 다음으로 구성됩니다:\n",
    "\n",
    "$$\n",
    "T = \\{\\mathcal{L}(\\mathbf{x}_1, \\mathbf{a}_1, \\ldots, \\mathbf{x}_H, \\mathbf{a}_H), q(\\mathbf{x}_1), q(\\mathbf{x}_{t+1}|\\mathbf{x}_t, \\mathbf{a}_t), H\\}\n",
    "$$\n",
    "\n",
    "여기서:\n",
    "\n",
    "- $\\mathcal{L}$: 손실 함수\n",
    "- $q(\\mathbf{x}_1)$: 초기 관측값에 대한 분포\n",
    "- $q(\\mathbf{x}_{t+1}|\\mathbf{x}_t, \\mathbf{a}_t)$: 전이 분포\n",
    "- $H$: 에피소드 길이\n",
    "\n",
    "i.i.d.가정하에 지도학습 문제에서는 $H=1$로 설정합니다. 모델은 각 시간 $t$에서 출력 $\\mathbf{a}_t$를 선택하여 길이 $H$의 샘플을 생성할 수 있습니다. 손실 $\\mathcal{L}(\\mathbf{x}_1, \\mathbf{a}_1, \\ldots, \\mathbf{x}_H, \\mathbf{a}_H) \\in \\mathbb{R}$은 과제별 피드백을 제공하며, 이는 오분류 손실 형태이거나 Markov 결정 과정의 비용 함수일 수 있습니다.\n",
    "\n",
    "**메타학습 시나리오**: 과제에 대한 분포 $p(\\mathcal{T})$를 고려하며, 모델이 이에 적응할 수 있기를 원합니다. $K$-shot 학습 설정에서, 모델은 $p(\\mathcal{T})$로부터 추출된 새로운 과제 $\\mathcal{T}_i$를 $q_i$로부터 추출된 $K$개의 샘플과 \n",
    "$\\mathcal{T}_i$에 의해 생성된 피드백 $\\mathcal{L}_{\\mathcal{T}_i}$만으로 학습하도록 훈련됩니다.\n",
    "\n",
    "**메타-훈련 과정**:\n",
    "\n",
    "1. 과제 $\\mathcal{T}_i$가 $p(\\mathcal{T})$로부터 샘플링됨\n",
    "2. 모델이 $K$개의 샘플과 $\\mathcal{T}_i$로부터의 손실 $\\mathcal{L}_{\\mathcal{T}_i}$를 사용하여 학습됨\n",
    "3. 그 후 $\\mathcal{T}_i$로부터의 새로운 샘플에 대해 테스트됨\n",
    "4. 모델 $f$는 $q_i$로부터의 새로운 데이터에 대한 테스트 오차가 파라미터에 대해 어떻게 변화하는지를 고려하여 개선됨\n",
    "\n",
    "**메타-테스팅**: 메타-훈련이 끝나면, 새로운 과제들이 $p(\\mathcal{T})$로부터 샘플링되고, 메타-성능은 $K$개의 샘플로부터 학습한 후 모델의 성능으로 측정됩니다. 일반적으로 메타-테스팅에 사용되는 과제들은 메타-훈련 중에는 제외됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad88f22",
   "metadata": {},
   "source": [
    "\n",
    "### A Model-Agnostic Meta-Learning Algorithm\n",
    "\n",
    "**기본 아이디어**: 모델이 경사 기반 학습 규칙을 사용하여 미세조정될 것이므로, $p(\\mathcal{T})$에서 추출한 새로운 과제에서 과적합 없이 빠른 진전을 이룰 수 있도록 모델을 학습시킵니다. 일부 내부 표현이 다른 것들보다 더 전이 가능하다는 직관에 기반합니다.\n",
    "\n",
    "**핵심 접근법**: 모델 파라미터가 과제의 변화에 민감하도록 찾는 것을 목표로 합니다. 즉, $p(\\mathcal{T})$에서 추출한 모든 과제의 손실 함수에서, 해당 손실의 경사 방향으로 변경될 때 파라미터의 작은 변경이 큰 개선을 이끌어낼 수 있도록 합니다.\n",
    "\n",
    "**노테이션**:\n",
    "\n",
    "- $\\theta$: 모델의 파라미터\n",
    "- $f_{\\theta}$: 파라미터 $\\theta$로 표현된 모델\n",
    "- $\\theta_i$: 새로운 과제 $\\mathcal{T}_i$에 적응할 때의 파라미터\n",
    "- $\\alpha$: 단계 크기 (스텝 사이즈), 하이퍼파라미터로 고정되거나 메타-학습될 수 있음\n",
    "\n",
    "**파라미터 업데이트**: 하나의 경사 업데이트를 사용할 때, 업데이트된 파라미터는 다음과 같이 계산됩니다:\n",
    "\n",
    "$$\n",
    "\\theta_i' = \\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta})\n",
    "$$\n",
    "\n",
    "**메타-목적 함수**: 모델 파라미터는 $p(\\mathcal{T})$로부터 샘플링된 과제들에 대해 $f_{\\theta'_i}$의 성능을 $\\theta$에 대해 최적화함으로써 학습됩니다. 더 구체적으로, 메타-목적 함수는 다음과 같습니다:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta'_i}) = \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta})})\n",
    "$$\n",
    "\n",
    "**핵심 특징**: 메타-최적화는 모델 파라미터 $\\theta$에 대해 수행되지만, 목적 함수는 업데이트된 모델 파라미터 $\\theta'$를 사용하여 계산됩니다. 사실상, 제안된 방법은 하나 또는 소수의 경사 단계가 새로운 과제에서 최대한 효과적인 행동을 생성하도록 모델 파라미터를 최적화합니다.\n",
    "\n",
    "**메타-최적화**: 과제들에 걸친 메타-최적화는 확률적 경사 하강법(SGD)을 통해 수행되며, 모델 파라미터는 다음과 같이 업데이트됩니다:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\beta \\nabla_{\\theta} \\sum_{\\mathcal{T}_i \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_i}(f_{\\theta'_i})\n",
    "$$\n",
    "\n",
    "여기서 $\\beta$는 메타 단계 크기(meta step size)입니다.\n",
    "\n",
    "**Algorithm 1: Model-Agnostic Meta-Learning**\n",
    "\n",
    "\n",
    "Require: p(T): 과제에 대한 분포\n",
    "Require: α, β: 단계 크기 하이퍼파라미터\n",
    "\n",
    "``` \n",
    "1: θ를 무작위로 초기화\n",
    "2: while not done do\n",
    "3:    과제 배치 {Ti}를 p(T)로부터 샘플링\n",
    "4:    for all Ti do\n",
    "5:       K개의 예시를 사용하여 L_Ti(f_θ)를 평가\n",
    "6:       경사 하강법으로 적응된 파라미터를 계산:\n",
    "          θ'_i = θ - α∇_θ L_Ti(f_θ)\n",
    "7:    end for\n",
    "8:    메타-업데이트:\n",
    "       θ ← θ - β∇_θ Σ_{Ti~p(T)} L_Ti(f_{θ'_i})\n",
    "9: end while\n",
    "```\n",
    "\n",
    "**계산적 고려사항**: MAML 메타-경사 업데이트는 경사를 통한 경사(gradient through a gradient)를 포함합니다. 계산적으로 이는 Hessian-벡터 곱을 계산하기 위해 $f$를 통한 추가 역전파 과정이 필요하며, 이는 TensorFlow와 같은 표준 딥러닝 라이브러리에서 지원됩니다.\n",
    "\n",
    "**모델 가정**: MAML은 모델의 형태에 대해 가정하지 않으며, 파라미터 벡터 $\\theta$로 파라미터화되고 손실 함수가 $\\theta$에 대해 충분히 매끄러워 경사 기반 학습 기법을 사용할 수 있다는 것만 가정합니다.\n",
    "\n",
    "**해석**:\n",
    "\n",
    "- **특징 학습 관점**: 모델의 파라미터를 학습시켜 소수의 경사 단계, 또는 단 하나의 경사 단계만으로 새로운 과제에서 좋은 결과를 생성할 수 있도록 하는 과정은, 많은 과제에 광범위하게 적합한 내부 표현을 구축하는 것으로 볼 수 있습니다. 내부 표현이 많은 과제에 적합하다면, 파라미터를 약간 미세조정하는 것만으로(예: feedforward 모델의 최상위 레이어 가중치를 주로 수정) 좋은 결과를 생성할 수 있습니다.\n",
    "\n",
    "- **동적 시스템 관점**: 학습 과정은 새로운 과제의 손실 함수의 파라미터에 대한 민감도를 최대화하는 것으로 볼 수 있습니다. 민감도가 높을 때, 파라미터에 대한 작은 국소적 변경이 과제 손실에서 큰 개선을 이끌어낼 수 있습니다.\n",
    "\n",
    "이러한 메타학습 프레임워크는 분류, 회귀, 강화학습을 포함한 여러 문제 설정에 최소한의 수정만으로 쉽게 적용될 수 있으며, 완전 연결, 합성곱, 순환 신경망과 결합될 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f456a9b",
   "metadata": {},
   "source": [
    "\n",
    "## (1) What is new in the work\n",
    "\n",
    "본 연구의 주요 새로운 점은 다음과 같습니다:\n",
    "\n",
    "**모델에 구애받지 않는 메타학습 접근법**: MAML은 경사하강법으로 학습되는 모든 모델에 직접 적용될 수 있는 일반적이고 모델에 구애받지 않는 메타학습 알고리즘을 제안합니다. 이전 메타학습 방법들이 업데이트 함수나 학습 규칙을 학습하는 것과 달리, MAML은 학습된 파라미터의 수를 늘리지 않으며 모델 아키텍처에 제약을 두지 않습니다.\n",
    "\n",
    "**초기 파라미터 최적화**: 모델의 초기 파라미터 $\\theta$를 학습시켜, 소수의 경사 단계 또는 단 하나의 경사 단계만으로 새로운 과제에서 좋은 결과를 생성할 수 있도록 합니다. 이는 메타-최적화가 모델 파라미터 $\\theta에 대해 수행되지만, 목적 함수는 업데이트된 모델 파라미터 $\\theta'_i$를 사용하여 계산됩니다.\n",
    "\n",
    "**범용 적용성**: 분류, 회귀, 강화학습을 포함한 여러 문제 설정에 최소한의 수정만으로 쉽게 적용될 수 있으며, 완전 연결, 합성곱, 순환 신경망과 결합될 수 있습니다.\n",
    "\n",
    "## (2) Why is the work important\n",
    "\n",
    "본 연구는 다음과 같은 이유로 중요합니다:\n",
    "\n",
    "**빠른 적응 능력**: 인간 지능의 특징인 빠른 학습 능력을 인공 에이전트에 부여하는 것이 중요합니다. 소수의 예시만으로 객체를 인식하거나 몇 분의 경험만으로 새로운 기술을 배우는 능력을 모방합니다.\n",
    "\n",
    "**실용적 가치**: 소량의 데이터만으로 새로운 과제에 빠르게 적응할 수 있어, 데이터 수집이 어렵거나 비용이 많이 드는 실제 응용 분야에서 유용합니다. 특히 few-shot learning 문제에서 에이전트가 소량의 새로운 정보를 과거 경험과 통합하면서 새로운 데이터에 과적합을 피해야 하는 도전적인 문제를 해결합니다.\n",
    "\n",
    "**범용성**: 과제와 모델에 구애받지 않는 특성으로 인해 다양한 도메인에 적용 가능하여, 딥러닝과 강화학습에서 다중 과제 초기화를 표준 요소로 만들 수 있는 잠재력을 가집니다.\n",
    "\n",
    "## (3) What is the literature gap\n",
    "\n",
    "논문에서 식별한 문헌의 격차는 다음과 같습니다:\n",
    "\n",
    "**기존 방법의 제한사항**: 이전 메타학습 방법들은 전체 데이터셋을 수집하는 순환 신경망을 학습시키거나, 테스트 시 비모수적 방법과 결합될 수 있는 특징 임베딩을 학습했습니다. 이러한 방법들은 특정 과제(예: few-shot classification)를 염두에 두고 설계되어 강화학습과 같은 다른 도메인에 쉽게 적용할 수 없었습니다.\n",
    "\n",
    "**아키텍처 제약**: 일부 방법들은 순환 모델이나 Siamese 네트워크와 같은 특정 모델 아키텍처를 요구했습니다. 메모리 증강 신경망과 같은 순환 메타학습 모델들도 MAML처럼 여러 과제에 적용 가능하지만, MAML이 5-way Omniglot과 MiniImagenet 분류에서 이들을 크게 능가했습니다.\n",
    "\n",
    "**추가 파라미터**: 많은 방법들이 메타학습을 위해 추가 학습 파라미터를 도입했습니다. 예를 들어, 업데이트 함수나 학습 규칙을 학습하는 방법들이 있었습니다.\n",
    "\n",
    "## (4) How is the gap filled\n",
    "\n",
    "MAML은 다음과 같은 방식으로 격차를 메웁니다:\n",
    "\n",
    "**단순하고 일반적인 접근법**: 모델이 경사 기반 학습 규칙을 사용하여 미세조정될 것이므로, 이 경사 기반 학습 규칙이 $p(T)$에서 추출한 새로운 과제에서 과적합 없이 빠른 진전을 이룰 수 있도록 모델을 학습시킵니다. 실제로 $p(T)$에서 추출한 모든 과제의 손실 함수에서, 해당 손실의 경사 방향으로 변경될 때 파라미터의 작은 변경이 큰 개선을 이끌어낼 수 있도록 과제 변화에 민감한 모델 파라미터를 찾는 것을 목표로 합니다.\n",
    "\n",
    "**메타-목적 함수**: 메타-목적 함수는 다음과 같이 정의됩니다:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{T_i \\sim p(T)} \\mathcal{L}_{T_i}(f_{\\theta'_i}) = \\sum_{T_i \\sim p(T)} \\mathcal{L}_{T_i}(f_{\\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{T_i}(f_{\\theta})})\n",
    "$$\n",
    "\n",
    "여기서 $\\theta'_i = \\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}_{T_i}(f_{\\theta})$입니다. 이는 하나 또는 소수의 경사 단계가 새로운 과제에서 최대한 효과적인 행동을 생성하도록 모델 파라미터를 최적화합니다.\n",
    "\n",
    "**아키텍처 독립성**: MAML은 모델의 형태에 대해 가정하지 않으며, 파라미터 벡터 $\\theta$로 파라미터화되고 손실 함수가 $\\theta$에 대해 충분히 매끄러워 경사 기반 학습 기법을 사용할 수 있다는 것만 가정합니다. 완전 연결, 합성곱, 또는 순환 신경망과 쉽게 결합될 수 있습니다.\n",
    "\n",
    "## (5) What is achieved with the new method\n",
    "\n",
    "새로운 방법으로 달성한 성과는 다음과 같습니다:\n",
    "\n",
    "**Few-shot Classification 성능**:\n",
    "\n",
    "- Omniglot: 5-way 1-shot에서 98.7±0.4%, 5-shot에서 99.9±0.1%; 20-way 1-shot에서 95.8±0.3%, 5-shot에서 98.9±0.2%를 달성했습니다\n",
    "- MiniImagenet: 5-way 1-shot에서 48.70±1.84%, 5-shot에서 63.11±0.92%를 달성하여 matching networks와 meta-learner LSTM을 능가했습니다\n",
    "\n",
    "**회귀 성능**: 진폭과 위상이 변하는 사인파 회귀 과제에서, MAML로 학습된 모델은 5개의 데이터 포인트만으로 빠르게 적응할 수 있었으며, K 데이터 포인트가 모두 입력 범위의 한쪽 절반에 있을 때도 다른 절반의 진폭과 위상을 추론할 수 있었습니다. 이는 모델이 사인파의 주기적 구조를 학습했음을 보여줍니다.\n",
    "\n",
    "**강화학습 성능**:\n",
    "\n",
    "- 2D Navigation: MAML은 단 하나의 정책 경사 업데이트로 새로운 목표 위치에 훨씬 더 빠르게 적응할 수 있었습니다\n",
    "- Locomotion (Half-cheetah와 Ant): MAML은 단 하나의 경사 업데이트만으로도 속도와 방향을 빠르게 적응시킬 수 있었으며, 더 많은 경사 단계로 계속 개선되었습니다. MAML 초기화가 무작위 초기화와 사전학습을 크게 능가했으며, 사전학습은 경우에 따라 무작위 초기화보다 나쁜 경우도 있었습니다\n",
    "\n",
    "**효율성**: MAML은 matching networks와 meta-learner LSTM에 비해 더 적은 전체 파라미터를 사용하며, 알고리즘이 분류기 자체의 가중치를 넘어서는 추가 파라미터를 도입하지 않습니다.\n",
    "\n",
    "## (6) What data are used\n",
    "\n",
    "논문에서 사용된 데이터는 다음과 같습니다:\n",
    "\n",
    "**회귀 과제**:\n",
    "\n",
    "- 사인파 함수: 진폭은 [0.1, 5.0] 범위에서, 위상은 [0, π] 범위에서 변합니다. 학습 및 테스트 중에 데이터 포인트 x는 [−5.0, 5.0]에서 균일하게 샘플링됩니다. K-shot 회귀 과제에서는 각 과제에 대해 K개의 입력/출력 쌍이 제공됩니다.\n",
    "\n",
    "**분류 과제**:\n",
    "\n",
    "- **Omniglot 데이터셋**: 50개의 다른 알파벳에서 1623개의 문자로 구성되며, 각각 20개의 인스턴스가 있습니다. 각 인스턴스는 다른 사람이 그렸습니다. 학습을 위해 1200개의 문자를 무작위로 선택하고 나머지는 테스트에 사용했습니다. 데이터셋은 90도 배수로 회전하여 증강되었습니다.\n",
    "- **MiniImagenet 데이터셋**: 64개의 학습 클래스, 12개의 검증 클래스, 24개의 테스트 클래스를 포함합니다. N-way 분류의 경우, N개의 클래스에서 각각 K개의 다른 인스턴스가 모델에 제공됩니다.\n",
    "\n",
    "**강화학습 과제**:\n",
    "\n",
    "- **2D Navigation**: 포인트 에이전트가 단위 정사각형 내에서 무작위로 선택된 2D 목표 위치로 이동해야 합니다. 관측은 현재 2D 위치이고, 행동은 [−0.1, 0.1] 범위로 제한된 속도 명령에 해당합니다. 보상은 목표까지의 음의 제곱 거리이며, 에피소드는 에이전트가 목표의 0.01 이내에 있거나 H = 100의 지평에 도달하면 종료됩니다.\n",
    "- **Locomotion (MuJoCo 시뮬레이터)**: 평면 cheetah와 3D quadruped(\"ant\")가 특정 방향 또는 특정 속도로 달리도록 요구합니다. 목표 속도 실험에서 보상은 에이전트의 현재 속도와 목표 사이의 음의 절댓값이며, 목표는 cheetah의 경우 0.0과 2.0 사이에서, ant의 경우 0.0과 3.0 사이에서 균일하게 무작위로 선택됩니다. 목표 방향 실험에서 보상은 전진 또는 후진 방향의 속도 크기이며, 각 과제마다 무작위로 선택됩니다. 지평은 H = 200이고, 모든 문제에 대해 경사 단계당 20개의 rollout을 사용했습니다(ant forward/backward 과제는 단계당 40개의 rollout 사용).\n",
    "\n",
    "## (7) What are the limitations\n",
    "\n",
    "논문에서 명시적으로 언급된 제한사항은 다음과 같습니다:\n",
    "\n",
    "**계산 비용**: MAML 메타-경사 업데이트는 경사를 통한 경사를 포함합니다. 계산적으로 이는 Hessian-벡터 곱을 계산하기 위해 $f$를 통한 추가 역전파 과정이 필요하며, 이는 TensorFlow와 같은 표준 딥러닝 라이브러리에서 지원됩니다.\n",
    "\n",
    "**1차 근사**: 이러한 2차 도함수를 생략한 1차 근사를 실험했으며, 결과 방법은 여전히 업데이트 후 파라미터 값 $\\theta'_i$에서 메타-경사를 계산합니다. MiniImagenet에서 1차 근사의 성능은 전체 2차 도함수를 사용한 것과 거의 동일했으며, 이는 MAML의 개선 대부분이 업데이트 후 파라미터 값에서 목적 함수의 경사에서 나온다는 것을 시사합니다. ReLU 신경망이 국소적으로 거의 선형이라는 과거 연구는 2차 도함수가 대부분의 경우 0에 가까울 수 있음을 시사하며, 이는 1차 근사의 좋은 성능을 부분적으로 설명합니다. 이 근사는 추가 역전파 과정에서 Hessian-벡터 곱을 계산할 필요를 제거하며, 네트워크 계산에서 약 33%의 속도 향상을 가져왔습니다.\n",
    "\n",
    "**강화학습에서의 샘플 요구사항**: 정책 경사가 on-policy 알고리즘이므로, $f_{\\theta}$의 적응 중 각 추가 경사 단계는 현재 정책 $f_{\\theta'_i}$로부터 새로운 샘플을 필요로 합니다. 이는 감독학습 과제와 달리 각 경사 단계가 환경으로부터 추가 샘플을 필요로 함을 의미합니다.\n",
    "\n",
    "**3차 도함수 회피**: 강화학습 실험에서 3차 도함수 계산을 피하기 위해 TRPO를 위한 Hessian-벡터 곱을 계산하는 데 유한 차분을 사용했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7faba9",
   "metadata": {},
   "source": [
    "## (8) MAML 한계점의 해소 방안\n",
    "\n",
    "MAML 논문에서 언급된 주요 한계점들에 대해 2024-2025년 최신 연구들은 다음과 같은 해결책을 제시하고 있습니다.\n",
    "\n",
    "### 1. 계산 비용 문제 (Second-Order Gradient Computation)\n",
    "\n",
    "**Directed-MAML (2025)**: **Task-directed 근사 기법**을 도입하여 2차 도함수 계산 전에 1차 task-directed 근사를 적용합니다. 이 방법은 대표 과제의 1차 경사만 계산하여 2차 경사의 효과를 근사하므로, 여러 과제에 대한 2차 경사 계산보다 필요한 자원이 적습니다. CartPole-v1, LunarLander-v2 실험에서 MAML 대비 1.77배의 수렴 속도 향상을 달성했으며, 에폭당 실행 시간은 약간 증가했지만(2.52초 vs 2.34초) 수렴까지의 총 시간은 0.22시간으로 MAML의 0.39시간보다 크게 단축되었습니다.\n",
    "\n",
    "**Hessian-Free 접근법**: ES-MAML(2019)은 Evolution Strategies를 활용하여 2차 도함수 추정을 완전히 피하며, 2024년 연구에서는 zeroth-order 최적화 기법을 활용한 Model-Agnostic Meta-Policy Optimization이 제안되었습니다. 이 방법은 Stein's Gaussian smoothing 기법을 사용하여 정책 Hessian 추정을 생략하고, 안정성과 높은 계산 비용 문제를 동시에 해결합니다.[2][3]\n",
    "\n",
    "**Implicit Gradients (2024)**: Meta-learning with implicit gradients 접근법은 메타-경사 계산을 내부 루프 최적화 선택으로부터 분리합니다. 이론적으로 단일 내부 루프 경사 계산에 필요한 것 이상의 메모리 사용 없이 정확한 메타-경사를 계산할 수 있으며, 전체 계산 비용도 증가하지 않습니다.[4] \n",
    "\n",
    "### 2. 1차 근사의 성능 개선\n",
    "\n",
    "**First-Order MAML with Controllable Bias (2024)**: 새로운 1차 MAML 변형은 MAML 목적 함수의 정상점으로 수렴할 것이 증명되었으며, 이는 기존 1차 변형들(FO-MAML, Reptile)과 다릅니다. 연구진은 MAML 목적 함수가 이전 연구에서 가정한 평활성(smoothness) 가정을 만족하지 않으며, 평활성 상수가 메타-경사의 norm과 함께 증가한다는 것을 보였습니다. 이는 이론적으로 일반 경사 방법보다 정규화되거나 clipped-gradient 방법의 사용을 시사합니다.[5]\n",
    "\n",
    "**Enhancing Model Agnostic Meta-Learning (2024)**: Approximate Hessian Effect 프레임워크 내에서 코사인 유사도와 제곱 오차(L2 loss)를 손실 함수로 사용하는 연구가 제안되었습니다. 연구진은 1차 메타학습 알고리즘이 계산 효율성과 확장성을 약속한다고 강조하며, Sign-MAML과 같은 방법들이 sign-based 최적화 전략을 활용하여 1차 기법으로 메타학습 과제를 다룹니다.[6]\n",
    "\n",
    "### 3. 강화학습에서의 샘플 효율성 문제\n",
    "\n",
    "**Model-Based Meta-RL (MAMBA, 2024)**: 모델 기반 접근법을 메타-RL에 적용하여 샘플 효율성을 크게 향상시켰습니다. MAMBA는 Dreamer 아키텍처를 활용하여 기존 메타-RL 및 모델 기반 RL 베이스라인 대비 최대 15배의 샘플 효율성 향상을 달성했습니다. 전체 메타-에피소드 인코딩, 선택적 잠재 상태 최적화, 스케줄된 world model horizon을 통해 계산 부담을 줄이면서 장기 메모리 요구사항을 해결했습니다.[7][8][9]\n",
    "\n",
    "**Coreset-Based Task Selection (2025)**: 과제 선택을 통해 메타-RL의 샘플 효율성을 향상시키는 연구입니다. 경사 공간에서 과제의 다양성에 기반하여 가중치가 부여된 과제 부분집합을 선택하며, 가장 정보가 풍부하고 다양한 과제를 우선시합니다. 이는 $\\epsilon$-가까운 정상 해를 찾는 데 필요한 샘플 수를 $O(1/\\epsilon)$ 배율로 감소시킵니다.[10]\n",
    "\n",
    "**Off-Policy Meta-RL (2024)**: Efficient off-policy meta-RL 알고리즘들이 과제 추론과 제어를 분리하고, 잠재 과제 변수의 온라인 확률적 필터링을 수행하여 적은 양의 경험으로 새로운 과제를 해결하는 방법을 추론합니다. Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP, 2024)는 비용 효율적인 샘플 생성을 통해 메타-테스팅의 샘플 효율성을 크게 향상시켰습니다.[11][12]\n",
    "\n",
    "### 4. 메모리 효율성 개선\n",
    "\n",
    "**Memory-Efficient Gradient Computation (2024-2025)**: DP-GRAPE는 gradient projection을 활용하여 메모리 사용량을 크게 줄입니다. RoBERTa-Large 미세조정 시 DP-Adam 대비 70% 이상의 메모리 사용량 감소(24.4GB vs 78.1GB)를 달성했습니다. 샘플 경사 메모리를 $B\\sum_{\\ell=1}^{L}m_{\\ell}n_{\\ell}$에서 $Br\\sum_{\\ell=1}^{L}n_{\\ell}$로 줄입니다.[13]\n",
    "\n",
    "**META-LORA (2025)**: 샘플 재가중치를 위한 메모리 효율적인 접근법으로, 경사 유사도를 저차원 활성화 상태와 해당 경사의 곱으로 분해하여 7,552배의 메모리 사용량 감소를 달성했습니다. 메모리 소비는 4%만 증가하면서 최대 5%의 성능 향상을 보였습니다.[14]\n",
    "\n",
    "### 5. 메타-연속 학습에서의 분산 감소\n",
    "\n",
    "**Variance Reduced Meta-CL (VR-MCL, 2024)**: 메타-연속 학습이 Hessian을 온라인 방식으로 암묵적으로 근사하지만 무작위 메모리 버퍼 샘플링으로 인한 높은 분산 문제를 겪는다는 점을 발견했습니다. VR-MCL은 적시성 있고 정확한 Hessian 근사를 동시에 달성하여 지식 전이와 망각 사이의 최적화된 균형을 제공합니다.[15]\n",
    "\n",
    "### 6. Automatic Differentiation 최적화\n",
    "\n",
    "**Optimizing AD with Deep RL (2024)**: Cross-country elimination과 심층 강화학습을 활용하여 Jacobian 계산에 필요한 곱셈 횟수를 최적화합니다. 효율적인 제거 순서를 찾아 새로운 자동 미분 알고리즘과 실질적인 실행 시간 이득을 달성했습니다.[16]\n",
    "\n",
    "### 7. 대규모 병렬화 지원\n",
    "\n",
    "**Massively Parallelized Multi-Task RL (2024)**: GPU 가속 시뮬레이터를 활용한 대규모 병렬화(>>1000 시뮬레이션) 훈련 패러다임이 등장했습니다. 단일 GPU에서 과제당 고정된 수의 환경을 할당하여 동시에 다양한 데이터 수집과 end-to-end MTRL 훈련을 가능하게 합니다. 실험 결과, wall-clock 효율성이 샘플 효율성보다 더 중요하며, 경험 수집이 더 많은 GPU로 쉽게 확장되기 때문입니다.[17]\n",
    "\n",
    "이러한 최신 연구들은 MAML의 원래 한계점들을 다양한 각도에서 해결하고 있으며, 특히 계산 효율성, 메모리 사용량, 샘플 효율성 측면에서 실질적인 개선을 제공하고 있습니다.\n",
    "\n",
    "[1](https://arxiv.org/html/2510.00212v1)\n",
    "[2](https://arxiv.org/html/2503.00385v1)\n",
    "[3](https://arxiv.org/abs/1910.01215)\n",
    "[4](https://dl.acm.org/doi/10.5555/3454287.3454298)\n",
    "[5](https://arxiv.org/html/2409.03682v1)\n",
    "[6](https://scholarworks.bwise.kr/cau/bitstream/2019.sw.cau/72909/1/Enhancing%20Model%20Agnostic%20Meta-Learning%20via%20Gradient%20Similarity%20Loss.pdf)\n",
    "[7](https://arxiv.org/pdf/2403.09859.pdf)\n",
    "[8](https://www.themoonlight.io/en/review/mamba-an-effective-world-model-approach-for-meta-reinforcement-learning)\n",
    "[9](https://github.com/zoharri/mamba)\n",
    "[10](https://arxiv.org/abs/2502.02332)\n",
    "[11](https://arxiv.org/html/2506.04399v1)\n",
    "[12](https://www.semanticscholar.org/paper/Efficient-Off-Policy-Meta-Reinforcement-Learning-Rakelly-Zhou/4625628163a2ee0e6cd320cd7a14b4ccded2a631)\n",
    "[13](https://arxiv.org/html/2506.15588v1)\n",
    "[14](https://aclanthology.org/2025.coling-main.568.pdf)\n",
    "[15](https://openreview.net/forum?id=TpD2aG1h0D)\n",
    "[16](https://proceedings.neurips.cc/paper_files/paper/2024/file/06cbd2e81dfbd3bb4cb0abce95b32584-Paper-Conference.pdf)\n",
    "[17](https://arxiv.org/html/2507.23172v2)\n",
    "[18](https://www.nature.com/articles/s41598-025-22058-3)\n",
    "[19](https://www.sciencedirect.com/science/article/abs/pii/S0004370224001206)\n",
    "[20](https://aclanthology.org/2025.uncertainlp-main.17.pdf)\n",
    "[21](https://peerj.com/articles/cs-2757/)\n",
    "[22](https://www.emergentmind.com/topics/model-agnostic-meta-learning-maml)\n",
    "[23](https://www.ijcai.org/proceedings/2024/500)\n",
    "[24](https://johnjaejunlee95.github.io/meta_learning_2/)\n",
    "[25](https://proceedings.iclr.cc/paper_files/paper/2024/file/0b6df1a973b82b3cf7fadca6c387ae5a-Paper-Conference.pdf)\n",
    "[26](https://rlj.cs.umass.edu/2025/papers/RLJ_RLC_2025_218.pdf)\n",
    "[27](https://openreview.net/forum?id=if2vRbS8Ew)\n",
    "[28](https://www.semanticscholar.org/paper/283f975e221f56974f30a3b12c7fb015c0c77377)\n",
    "[29](https://www.semanticscholar.org/paper/On-First-Order-Meta-Learning-Algorithms-Nichol-Achiam/90dc22818bd2d97d8deaff168b0137b75a962767)\n",
    "[30](https://www.nowpublishers.com/article/DownloadSummary/MAL-080)\n",
    "[31](https://nips.cc/virtual/2024/poster/95734)\n",
    "[32](https://ieeexplore.ieee.org/document/10649914/)\n",
    "[33](https://www.sciencedirect.com/science/article/abs/pii/S0952197624021250)\n",
    "[34](https://ieeexplore.ieee.org/abstract/document/10839866/)\n",
    "[35](https://proceedings.mlr.press/v235/huang24a.html)\n",
    "[36](https://arxiv.org/html/2504.08277v2)\n",
    "[37](https://dl.acm.org/doi/10.1145/3466772.3467038)\n",
    "[38](http://hcisj.com/articles/issue_view.php?wr_id=577&page=3)\n",
    "[39](https://proceedings.neurips.cc/paper_files/paper/2024/file/5706668422bd0d82588998ebe1067133-Paper-Conference.pdf)\n",
    "[40](https://arxiv.org/pdf/2409.03682.pdf)\n",
    "[41](https://openreview.net/pdf?id=5trmyvtkeo)\n",
    "[42](https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p317.pdf)\n",
    "[43](https://wonyeol.github.io/papers/2024-iclr.pdf)\n",
    "[44](https://www.ijcai.org/proceedings/2024/0500.pdf)\n",
    "[45](https://www.sciencedirect.com/science/article/abs/pii/S0893608023001582)\n",
    "[46](https://aclanthology.org/2024.naacl-long.282.pdf)\n",
    "[47](https://openreview.net/forum?id=vUuUPszknz)\n",
    "[48](https://ieeexplore.ieee.org/document/10667211/)\n",
    "[49](https://www.sciencedirect.com/science/article/pii/S0098135425002443)\n",
    "[50](https://www.ijcai.org/proceedings/2025/0711.pdf)\n",
    "[51](https://ai.meta.com/research/publications/federated-multi-task-learning-for-competing-constraints/)\n",
    "[52](https://ieeexplore.ieee.org/document/10643964)\n",
    "[53](https://research.tue.nl/en/publications/model-based-meta-reinforcement-learning-for-hyperparameter-optimi)\n",
    "[54](https://hdsr.mitpress.mit.edu/pub/lgmkutcd)\n",
    "[55](https://dl.acm.org/doi/10.1145/3659947)\n",
    "[56](https://www.sciencedirect.com/science/article/pii/S0950705125014820)\n",
    "[57](https://www.sciencedirect.com/science/article/abs/pii/S1361841522001281)\n",
    "[58](https://www.biorxiv.org/content/10.1101/2025.07.10.664201v1.full.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a9975",
   "metadata": {},
   "source": [
    "# Probabilistic Model-agnostic Meta-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b48b2",
   "metadata": {},
   "source": [
    "## 초록\n",
    "\n",
    "메타러닝에서 few-shot learning이란 이전의 다양한 작업과 경험들로부터 사전(prior)을 획득하고 이를 통해 적은 데이터만으로 새로운 작업을 학습하는 것을 의미합니다. 그러나 few-shot 학습의 중요한 과제 중 하나는 작업의 모호성입니다. 강력한 사전이 다수의 작업에서 메타러닝될지라도, 새로운 작업을 위한 소량의 데이터로는 단일 모델(예를 들어 정확한 분류기)을 도출하기 어려울 수 있습니다. 본 논문에서는 새로운 작업에 대해 모델 분포로부터 샘플링할 수 있는 확률적 메타러닝 알고리즘을 제안합니다. 본 접근법은 gradient descent로 새로운 작업에 적응하는 model-agnostic meta-learning을 확장하여, 파라미터 분포를 변분 하한(variational lower bound)으로 학습하도록 설계했습니다. 메타 테스트 시에는 gradient descent에 노이즈를 주입하는 간단한 적응 절차를 사용하며, 메타 학습 시에는 이 절차가 근사 모델의 사후분포로부터 샘플을 생성하도록 최적화합니다. 실험 결과, 본 방법이 모호한 few-shot 학습 문제에서 타당한 분류기 및 회귀 모델을 샘플링할 수 있음을 보이고, 이러한 모호성 인식이 downstream active learning 문제에도 활용될 수 있음을 제시합니다.\n",
    "\n",
    "\n",
    "## (1) What is new in the work\n",
    "- 기존의 MAML(Model-Agnostic Meta-Learning)에 '확률적 모형'을 결합시켜, 모호한 few-shot 문제 상황에서 여러 모델을 샘플링할 수 있는 방법(PLATIPUS)을 제안했습니다.\n",
    "- Gradient descent에 확률적 분포(노이즈)를 주입하는 간단한 적응절차와 변분추론 기반 학습 과정을 도입했습니다.\n",
    "\n",
    "## (2) Why is the work important\n",
    "- Few-shot 상황은 데이터가 적어 모형 설정에 불확실성이 큽니다. 여러 후보 모델을 \"샘플링\"하며 불확실성을 추정할 수 있어, 안전성이나 human-in-the-loop 학습(예: 의료 이미지 분류)에서 신뢰도와 데이터 선정에 중요한 의미를 가집니다.\n",
    "- 능동적 학습(active learning) 등 downstream 응용에서 불확실성 기반 데이터 선택이 가능해집니다.\n",
    "\n",
    "## (3) What is the literature gap\n",
    "- Bayesian 모델 기반 과거 접근(예: 신경통계학자 neural statistician 등)은 네트워크가 단순할 때만 합리적으로 불확실성을 모델링했으나, 대규모 신경망에서는 수식적으로나 계산적으로 비효율적이었습니다.\n",
    "- MAML 포함 최근 메타러닝들은 높은 표현력(대규모 신경망 등)에서는 '확률적 분포'를 무시하고 결정적(deterministic) 추정에만 집중했습니다.\n",
    "\n",
    "## (4) How is the gap filled\n",
    "- PLATIPUS에서는 MAML을 확률적 그래프 모델/변분추론 관점으로 재해석함으로써, 기존 deep learning 기반 모델에 확률적 분포 추정 및 샘플링을 효과적으로 도입했습니다.\n",
    "- 단순 gradient descent에 노이즈를 주입하는 방식으로 확률적 추론을 실제 네트워크에 적용할 수 있도록 함—수식적으로는 변분 하한(variational lower bound)를 사용하며, 분포 모형은 Gaussian 분포로 설정합니다.\n",
    "- 부족한 정보에 대해 다양한 후보 작업/모형을 샘플링함으로써 다중 모드(task ambiguity/multimodal task) 문제를 해결합니다.\n",
    "\n",
    "## (5) What is achieved with the new method\n",
    "- 모호한 few-shot 문제에서도 다양한 분류기·회귀 모델을 효과적으로 샘플링할 수 있습니다.\n",
    "- 실제 실험(1D 회귀, 2D 이진 분류, 이미지 분류)에서 PLATIPUS는 불확실성이 큰 부분에서는 다양한 함수 형태(선형, 사인 등)와 다양한 결정 경계(원 크기/위치) 샘플을 생성함을 보였습니다.\n",
    "- MAML 대비 ambiguous task에서 더 많은 모드(mode)를 커버하면서, 성능(accuracy)은 동일하거나 향상됨을 보였습니다.\n",
    "- 불확실성을 활용해 능동적 데이터 선택(active learning)에서도 MAML 대비 더 빠르게 오차를 줄임을 보였습니다.\n",
    "\n",
    "## (6) What data are used\n",
    "- 1D 회귀(선형/사인 함수 task)와 2D 분류(원이 결정 경계인 task)로 구성된 인공 데이터셋.\n",
    "- 실세계 데이터로는 CelebA 얼굴 속성 이미지 분류(다중 attribute 기반 ambiguous task), MiniImagenet 5-way, 1-shot benchmark를 사용했습니다.\n",
    "\n",
    "## (7) What are the limitations\n",
    "- 현재 방식은 posterior 분산 추정이 상대적으로 단순하여, 각 작업마다 모호성이 다를 때 최적의 불확실성 추정이 어려울 수 있습니다.\n",
    "- variance estimator를 few-shot 트레인셋에 의존하도록 개선하면 더 나을 수 있으나, 파라미터 효율적 설계가 추가 연구 과제입니다.\n",
    "- RL(강화학습) 등으로 확장시 structured exploration에서 어떻게 모델링할지 추가 연구가 필요함을 언급합니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
