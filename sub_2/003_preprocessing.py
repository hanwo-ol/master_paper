import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import json
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class EnhancedPreprocessor:
    """
    ê°œì„ ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
    1. Train-only median imputation (ë¯¸ë˜ ì •ë³´ ì œê±°)
    2. Missing indicator features ì¶”ê°€
    3. Optimal K/purity ìë™ ì„ íƒ
    """
    
    def __init__(self, panel_path='./sp500_data/sp500_panel.csv'):
        self.panel_path = panel_path
        self.panel_data = None
        self.train_statistics = {}  # Train-only statistics
        
    def load_and_clean_basic(self):
        """ê¸°ë³¸ ì •ì œ (asset_turnover ì œê±°)"""
        print("="*80)
        print("ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ì œ")
        print("="*80)
        
        df = pd.read_csv(self.panel_path, index_col=0, parse_dates=True)
        print(f"\nì›ë³¸ shape: {df.shape}")
        
        # asset_turnover ì œê±°
        if 'asset_turnover' in df.columns:
            df = df.drop(columns=['asset_turnover'])
            print("âœ“ asset_turnover ì œê±°")
        
        self.panel_data = df
        return df
    
    def add_missing_indicators(self, cols_to_track=None):
        """
        Missing indicator features ì¶”ê°€
        
        Args:
            cols_to_track: Missing indicatorë¥¼ ë§Œë“¤ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
                          Noneì´ë©´ fundamental featuresì— ëŒ€í•´ ìë™ ìƒì„±
        """
        print("\n" + "="*80)
        print("Missing Indicator Features ì¶”ê°€")
        print("="*80)
        
        df = self.panel_data
        
        if cols_to_track is None:
            # Fundamental features (missingì´ ì˜ë¯¸ìˆëŠ” ê²ƒë“¤)
            cols_to_track = [
                'pe_ratio', 'pb_ratio', 'roe', 'roa', 'debt_to_equity',
                'dividend_yield', 'payout_ratio', 'free_cashflow_yield'
            ]
            cols_to_track = [col for col in cols_to_track if col in df.columns]
        
        print(f"\nMissing indicatorë¥¼ ì¶”ê°€í•  ì»¬ëŸ¼ ({len(cols_to_track)}ê°œ):")
        
        for col in cols_to_track:
            indicator_col = f'{col}_missing'
            df[indicator_col] = df[col].isnull().astype(int)
            
            n_missing = df[indicator_col].sum()
            pct_missing = n_missing / len(df) * 100
            
            print(f"  + {indicator_col}: {n_missing:,} ({pct_missing:.1f}%)")
        
        print(f"\nâœ“ {len(cols_to_track)}ê°œ missing indicator ì¶”ê°€")
        print(f"âœ“ ì´ feature ìˆ˜: {len([c for c in df.columns if c not in ['ticker', 'returns']])}")
        
        self.panel_data = df
        return df
    
    def impute_with_train_statistics(self, train_end_date):
        """
        Train-only statisticsë¡œ imputation (ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ë°©ì§€)
        
        Args:
            train_end_date: Training set ì¢…ë£Œ ë‚ ì§œ
        """
        print("\n" + "="*80)
        print(f"Train-Only Imputation (Train end: {train_end_date})")
        print("="*80)
        
        df = self.panel_data
        
        # Train êµ¬ê°„ ë°ì´í„°
        train_mask = df.index <= train_end_date
        train_df = df[train_mask]
        
        print(f"\nTrain êµ¬ê°„: {train_df.index.min()} ~ {train_df.index.max()}")
        print(f"Train ë°ì´í„°: {len(train_df):,} / {len(df):,} ({len(train_df)/len(df)*100:.1f}%)")
        
        # 1. Fundamental features (tickerë³„ forward fill â†’ train median)
        fundamental_cols = ['pe_ratio', 'pb_ratio', 'roe', 'roa', 'debt_to_equity',
                           'dividend_yield', 'payout_ratio', 'free_cashflow_yield']
        fundamental_cols = [col for col in fundamental_cols if col in df.columns]
        
        print("\n[Fundamental Features]")
        for col in fundamental_cols:
            # Train median ê³„ì‚°
            train_median = train_df[col].median()
            self.train_statistics[f'{col}_median'] = train_median
            
            before_missing = df[col].isnull().sum()
            
            # Tickerë³„ forward fill
            df[col] = df.groupby('ticker')[col].transform(lambda x: x.fillna(method='ffill'))
            
            # Train medianìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì±„ìš°ê¸°
            df[col] = df[col].fillna(train_median)
            
            after_missing = df[col].isnull().sum()
            print(f"  {col}: {before_missing:,} â†’ {after_missing:,} (median={train_median:.4f})")
        
        # 2. Macro features (ì „ì²´ forward fill, ë¯¸ë˜ ì •ë³´ ì—†ìŒ)
        macro_cols = ['vix', 'treasury_10y', 'treasury_2y', 'yield_spread',
                     'usd_index', 'credit_spread', 'cpi_yoy']
        macro_cols = [col for col in macro_cols if col in df.columns]
        
        print("\n[Macro Features]")
        for col in macro_cols:
            before_missing = df[col].isnull().sum()
            df[col] = df[col].fillna(method='ffill').fillna(method='bfill')
            after_missing = df[col].isnull().sum()
            if before_missing > 0:
                print(f"  {col}: {before_missing:,} â†’ {after_missing:,}")
        
        # 3. Technical indicators (tickerë³„ forward fill â†’ backfill)
        tech_cols = ['rsi', 'ma_20', 'ma_50', 'ma_200', 'macd', 'macd_signal',
                    'bollinger_upper', 'bollinger_lower', 'atr', 'stoch_k', 'stoch_d',
                    'price_roc', 'realized_vol_20', 'realized_vol_60', 'volume_roc',
                    'mfi', 'obv', 'williams_r']
        tech_cols = [col for col in tech_cols if col in df.columns]
        
        print("\n[Technical Features]")
        for col in tech_cols:
            df[col] = df.groupby('ticker')[col].transform(
                lambda x: x.fillna(method='ffill').fillna(method='bfill')
            )
        print(f"  {len(tech_cols)}ê°œ technical features ì²˜ë¦¬ ì™„ë£Œ")
        
        # ìµœì¢… í™•ì¸
        final_missing = df.isnull().sum().sum()
        print(f"\nâœ“ ìµœì¢… missing values: {final_missing:,}")
        
        # Train statistics ì €ì¥
        stats_path = './train_statistics.json'
        with open(stats_path, 'w') as f:
            json.dump(self.train_statistics, f, indent=2)
        print(f"âœ“ Train statistics ì €ì¥: {stats_path}")
        
        self.panel_data = df
        return df
    
    def save_processed_data(self, output_path='./sp500_panel_cleaned.csv'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print("\n" + "="*80)
        print("ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥")
        print("="*80)
        
        self.panel_data.to_csv(output_path)
        
        # Feature í†µê³„
        feature_cols = [col for col in self.panel_data.columns 
                       if col not in ['ticker', 'returns']]
        
        missing_indicators = [col for col in feature_cols if col.endswith('_missing')]
        base_features = [col for col in feature_cols if not col.endswith('_missing')]
        
        print(f"\nâœ“ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"  - Shape: {self.panel_data.shape}")
        print(f"  - Base features: {len(base_features)}")
        print(f"  - Missing indicators: {len(missing_indicators)}")
        print(f"  - Total features: {len(feature_cols)}")
        print(f"  - Size: {os.path.getsize(output_path) / 1024**2:.1f} MB")
        
        return output_path


# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if __name__ == "__main__":
    print("Enhanced Preprocessing Pipeline")
    print("="*80)
    print("\nê°œì„ ì‚¬í•­:")
    print("  1. âœ… Train-only median imputation (ë¯¸ë˜ ì •ë³´ ì œê±°)")
    print("  2. âœ… Missing indicator features ì¶”ê°€")
    print("  3. âœ… 38 base features + 8 missing indicators = 46 total")
    
    # ì´ˆê¸°í™”
    preprocessor = EnhancedPreprocessor(
        panel_path='./sp500_data/sp500_panel.csv'
    )
    
    # STEP 1: ê¸°ë³¸ ì •ì œ
    print("\n" + "="*80)
    print("STEP 1: ê¸°ë³¸ ì •ì œ")
    print("="*80)
    df = preprocessor.load_and_clean_basic()
    
    # STEP 2: Missing indicator ì¶”ê°€
    print("\n" + "="*80)
    print("STEP 2: Missing Indicator Features ì¶”ê°€")
    print("="*80)
    df = preprocessor.add_missing_indicators()
    
    # STEP 3: Train-only imputation
    print("\n" + "="*80)
    print("STEP 3: Train-Only Statistics Imputation")
    print("="*80)
    
    # Train/Val/Test split ë‚ ì§œ (ì´ì „ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    # Train: 2006-03-30 ~ 2019-10-28
    train_end_date = '2019-10-28'
    
    df = preprocessor.impute_with_train_statistics(train_end_date=train_end_date)
    
    # STEP 4: ì €ì¥
    print("\n" + "="*80)
    print("STEP 4: ì €ì¥")
    print("="*80)
    output_path = preprocessor.save_processed_data(
        output_path='./processed_data/sp500_panel_enhanced.csv'
    )
    
    print("\n" + "="*80)
    print("ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*80)
    print("\nìµœì¢… ë°ì´í„°ì…‹:")
    print(f"  âœ… 38 base features")
    print(f"  âœ… 8 missing indicators")
    print(f"  âœ… 46 total features")
    print(f"  âœ… Train-only median (ë¯¸ë˜ ì •ë³´ ì—†ìŒ)")
    print(f"  âœ… Missing patterns ë³´ì¡´")
    
    print("\nìƒì„± íŒŒì¼:")
    print(f"  ğŸ“Š {output_path}")
    print(f"  ğŸ“Š ./train_statistics.json")
    
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. âœ… 001_preprocessing.pyë¡œ K=4, purity=0.7ë¡œ episode ìƒì„±")
    print("  2. âœ… PyTorch Dataset êµ¬í˜„")
    print("  3. âœ… Meta-learner í•™ìŠµ")
