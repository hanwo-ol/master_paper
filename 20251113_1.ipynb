{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cbe264",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e4bdf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58a99913",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a961cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "283ac1ff",
   "metadata": {},
   "source": [
    "# Paper Review: Meta Learning in Neural Networks: A Survey\n",
    "\n",
    "``` \n",
    "@article{hospedales2021meta,\n",
    "  title={Meta-learning in neural networks: A survey},\n",
    "  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},\n",
    "  journal={IEEE transactions on pattern analysis and machine intelligence},\n",
    "  volume={44},\n",
    "  number={9},\n",
    "  pages={5149--5169},\n",
    "  year={2021},\n",
    "  publisher={IEEE}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55623d30",
   "metadata": {},
   "source": [
    "## 초록\n",
    "\n",
    "`Learning-to-learn`이라고도 불리는 메타-러닝 분야는 최근 몇 년간 관심이 급격히 증가해왔습니다. \n",
    "고정된 학습 알고리즘을 사용하여 처음부터 과제를 해결하는 기존의 AI 접근 방식과는 대조적으로, \n",
    "메타-러닝은 다수의 학습 에피소드 경험을 바탕으로 **학습 알고리즘 자체를 개선하는 것을 목표**로 합니다. \n",
    "이 패러다임은 데이터 및 계산 병목 현상, 그리고 일반화 성능 등 딥러닝의 여러 기존 난제들을 해결할 기회를 제공합니다. \n",
    "본 서베이는 현대 메타-러닝의 전반적인 동향을 기술합니다. 먼저 메타-러닝의 정의를 논하고, 전이 학습(transfer learning) 및 하이퍼파라미터 최적화(hyperparameter optimization)와 같은 관련 분야와 비교하여 그 위치를 정립합니다. \n",
    "다음으로, 오늘날의 메타-러닝 방법 공간을 더 포괄적으로 분석하는 새로운 분류 체계를 제안합니다. \n",
    "또한 퓨샷 러닝(few-shot learning) 및 강화 학습(reinforcement learning)과 같은 메타-러닝의 유망한 응용 분야와 성공 사례들을 살펴봅니다. 마지막으로, 아직 해결되지 않은 과제들과 향후 연구를 위한 유망한 영역들에 대해 논의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86612c05",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c56ad5",
   "metadata": {},
   "source": [
    "메타러닝은 머신러닝 모델이 여러 학습 에피소드를 통해 경험을 쌓고, \n",
    "이 경험을 바탕으로 미래의 학습 성능을 향상시키는 대안적인 패러다임을 제공하게 됨.    \n",
    "+ 'Learning-to-learn'은 데이터 및 컴퓨팅 효율성과 같은 다양한 이점을 가져올 수 있음.   \n",
    "+ 학습 전략이 일생과 진화의 시간 척도 모두에서 향상되는 인간과 동물의 학습 방식과 더 잘 부합.   \n",
    "\n",
    "역사적으로 \n",
    "+ 머신러닝의 성공은 사람이 직접 설계한 특징(hand-engineered features)의 선택에 의해 주도되었습니다. \n",
    "+ 딥러닝은 특징과 모델을 함께 학습하는 가능성을 실현하여 많은 과제에서 성능을 크게 향상시켰습니다. \n",
    "\n",
    "신경망에서의 메타러닝은 특징, 모델, 그리고 알고리즘을 함께 학습하는 다음 단계의 통합을 목표로 하는 것으로 볼 수 있습니다.\n",
    "+ 특히 메타러닝은 데이터 효율성, 지식 전이, 비지도 학습을 개선함으로써 현대 딥러닝의 주요 비판점들 다수를 완화할 잠재력을 가지고 있습니다. \n",
    "\n",
    "메타러닝은 \n",
    "+ 과제군(a family of tasks)에서 과제에 구애받지 않는(task-agnostic) 지식을 추출하여 해당 과제군 내의 새로운 과제 학습을 개선하는 다중 과제 시나리오 와 \n",
    "+ 단일 문제를 반복적으로 해결하며 여러 에피소드에 걸쳐 개선해 나가는 단일 과제 시나리오 모두에서 유용성이 입증되었습니다. \n",
    "성공적인 응용 사례는 퓨샷 이미지 인식, 비지도 학습, 데이터 효율 개선 및 자기 주도적 강화 학습(RL), 하이퍼파라미터 최적화, 신경망 구조 탐색(NAS) 등 다양한 분야에서 입증되었습니다.\n",
    "\n",
    "Thrun은 learning-to-learn을 '주어진 과제군에서 추출된 과제를 해결하는 학습자의 성능이 접하는 과제의 수에 따라 향상될 때' 발생하는 것으로 조작적으로 정의합니다. \n",
    "+  단일 과제에서 더 많은 데이터를 볼수록 성능이 향상되는 기존의 머신러닝과는 대조적입니다. \n",
    "\n",
    "이러한 관점은 메타러닝을 '공짜 점심은 없다(no free lunch)' 정리에 대처하는 도구라고 볼 수 있게 됩니다. \n",
    "주어진 문제 또는 문제군에 가장 적합한 알고리즘(귀납적 편향)을 탐색하여 일반화 성능을 향상시키는 도구로 봅니다. \n",
    "\n",
    "하지만 이 정의는 오늘날 일반적으로 메타러닝으로 간주되지 않는 전이 학습, 다중 과제 학습, 특징 선택, 모델 앙상블 학습까지 포함할 수 있습니다. \n",
    "메타러닝의 또 다른 용례는 데이터셋의 특징에 기반한 알고리즘 선택을 다루는데, 이는 **자동화된 머신러닝(AutoML)** 과 구별하기 어려워집니다.\n",
    "본 논문에서는 현대의 신경망 메타러닝에 초점을 맞춥니다. \n",
    "+ 특히 명시적으로 정의된 목적 함수(예: 교차 엔트로피 손실)의 종단간(end-to-end) 학습을 통해 달성되는 경우에 집중합니다. \n",
    "+ 단일 과제 메타러닝을 고려하고, 강건성(robustness) 및 컴퓨팅 효율성과 같은 더 넓고 다양한 (메타) 목적 함수에 대해서도 논의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d18a2c",
   "metadata": {},
   "source": [
    "## 배경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db3d45",
   "metadata": {},
   "source": [
    "메타러닝은 현대 신경망 문헌 내에서조차 다양하고 일관성 없는 방식으로 사용되어 왔기 때문에 정의하기가 어렵습니다. 이 섹션에서는 우리의 정의와 주요 용어를 소개하고, 관련 분야와 비교하여 메타러닝의 위상을 정립하겠습니다.\n",
    "\n",
    "가장 일반적으로 **'학습하는 방법을 학습하는 것(learning to learn)'으로 이해**되며, 이는 **여러 학습 에피소드에 걸쳐 학습 알고리즘을 개선하는 과정을 의미**합니다. \n",
    "\n",
    "- 기존의 머신러닝이 여러 데이터 인스턴스에 걸쳐 모델 예측을 개선하는 것과 대조적. \n",
    "\n",
    "**기반 학습(base learning)** 중에는 **내부(inner)** (또는 하위/기반) 학습 알고리즘이 이미지 분류와 같은 과제를 해결하며, 이는 데이터셋과 목적 함수에 의해 정의됩니다. **메타러닝** 중에는 **외부(outer)**(또는 상위/메타) 알고리즘이 내부 학습 알고리즘을 업데이트하여, 그것이 학습하는 모델이 외부 목적 함수를 개선하도록 만듭니다. 예를 들어, 이 목적 함수는 내부 알고리즘의 일반화 성능이나 학습 속도가 될 수 있습니다. (기반 알고리즘, 학습된 모델, 성능) 튜플로 구성된 기반 과제의 학습 에피소드들은 외부 알고리즘이 기반 학습 알고리즘을 학습하는 데 필요한 인스턴스를 제공하는 것으로 볼 수 있습니다.\n",
    "\n",
    "```\n",
    "During base learning, an inner (or lower/base) learning algorithm solves a task such as image classification [13], defined by a dataset and objective.\n",
    "\n",
    "During meta-learning, an outer (or upper/meta) algorithm updates the inner learning algorithm such that the model it learns improves an outer objective.\n",
    "```\n",
    "> Base learning은 메타러닝의 **내부 루프(inner loop)** 에서 일어나는 개별적인 단일 과제(single task)에 대한 학습 과정을 의미함.\n",
    "> 1.  **내부 수준 (Inner Level) = Base Learning (기반 학습)**\n",
    ">    *   **목표**: 주어진 **하나의 특정 과제**를 해결하는 것 (예: '고양이'와 '개' 이미지를 분류하는 문제).\n",
    ">    *   **구성 요소**: 이 과제를 해결하기 위한 데이터셋(고양이/개 이미지)과 목적 함수(분류 정확도를 높이는 손실 함수)가 주어집니다.\n",
    ">    *   **알고리즘**: **`inner learning algorithm`** (기반 학습 알고리즘)이 이 데이터셋을 사용하여 모델 파라미터($\\theta$)를 최적화합니다. 우리가 흔히 아는 경사 하강법(Gradient Descent) 같은 최적화 과정이 여기서 일어납니다.\n",
    "\n",
    "> 2.  **외부 수준 (Outer Level) = Meta-Learning (메타러닝)**\n",
    ">    *   **목표**: Base learning 자체를 **더 잘하게 만드는 것**입니다. 즉, 새로운 과제가 주어졌을 때 더 빠르거나, 더 적은 데이터로, 더 정확하게 학습할 수 있도록 **학습 알고리즘 자체($\\omega$)를 개선**하는 것입니다.\n",
    ">    *   **알고리즘**: **`outer algorithm`** (메타 학습 알고리즘)이 여러 번의 base learning 에피소드를 관찰하고, 그 결과를 바탕으로 `inner learning algorithm`을 업데이트합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab93424",
   "metadata": {},
   "source": [
    "위에 정의된 대로라면, 교차 검증을 통한 하이퍼파라미터의 무작위 탐색과 같은 많은 기존 알고리즘이 메타러닝의 정의에 포함될 수 있습니다. \n",
    "\n",
    "현대 신경망 메타러닝의 두드러진 특징은 **명시적으로 정의된 메타 수준의 목적 함수**와, 이 목적 함수에 대한 내부 알고리즘의 **종단간(end-to-end) 최적화** 입니다. \n",
    "종종 메타러닝은 과제군(task family)에서 샘플링된 학습 에피소드에 대해 수행되어, 이 과제군에서 샘플링된 새로운 과제에 대해 좋은 성능을 보이는 기반 학습 알고리즘을 만듭니다. \n",
    "하지만, 극한의 경우 모든 훈련 에피소드가 단일 과제에서 샘플링될 수도 있습니다. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a75cd8",
   "metadata": {},
   "source": [
    "### 2.1 메타러닝의 정형화\n",
    "\n",
    "#### **기존 머신러닝** \n",
    "\n",
    "기존의 지도(supervised) 머신러닝에서는 (입력 이미지, 출력 레이블) 쌍과 같은 훈련 데이터셋 $D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}$이 주어집니다. \n",
    "우리는 $\\theta$로 매개변수화된 예측 모델 $\\hat{y} = f_{\\theta}(x)$를 다음 식을 풀어 훈련시킬 수 있습니다:\n",
    "\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(D; \\theta, \\omega) \\quad (1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41a1f7",
   "metadata": {},
   "source": [
    "* $\\mathcal{L}$은 실제 레이블과 $f_{\\theta}(\\cdot)$가 예측한 값 사이의 오차를 측정하는 손실 함수입니다. \n",
    "* $\\omega$에 대한 조건은 이 해법이 $\\theta$에 대한 최적화기(optimizer)나 함수 $f$의 클래스 선택과 같은 '학습 방법'에 대한 가정에 의존함을 나타냅니다. 일반화 성능은 알려진 레이블을 가진 여러 테스트 포인트를 평가하여 측정됩니다.\n",
    "\n",
    "기존의 가정은 이 최적화가 모든 문제 $D$에 대해 처음부터 수행되고, $\\omega$는 사전에 지정된다는 것입니다. 그러나 $\\omega$의 **사양**은 정확도나 데이터 효율성과 같은 성능 지표에 큰 영향을 미칠 수 있습니다. \n",
    "메타러닝은 이러한 지표를 개선하기 위해 학습 알고리즘 자체를 사전에 지정하고 고정하는 대신 학습함으로써 개선하고자 합니다. 이는 종종 위의 첫 번째 가정을 재검토하고, 처음부터 학습하는 대신 과제 분포로부터 학습함으로써 달성됩니다.\n",
    "\n",
    "* 사양? 학습 알고리즘의 구체적인 내용과 구성이라고 할 수 있음\n",
    "> 최적화기(Optimizer)의 종류: SGD, Adam, RMSprop 등 어떤 것을 쓸 것인가?    \n",
    "> 학습률(Learning Rate): 학습률을 얼마로 설정할 것인가?   \n",
    "> 모델 구조(Model Architecture): 어떤 종류의 신경망(CNN, RNN 등)을 사용할 것인가?   \n",
    "> 정규화(Regularization) 방법: L1, L2, Dropout 등 어떤 정규화 기법을 적용할 것인가?   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf44c58",
   "metadata": {},
   "source": [
    "\n",
    "#### **메타러닝: 과제 분포 관점** \n",
    "\n",
    "메타러닝에 대한 일반적인 관점은 과제 전반에 걸쳐 일반화할 수 있고, 이상적으로는 각각의 새로운 과제를 이전보다 더 잘 학습할 수 있게 하는 범용 학습 알고리즘을 배우는 것입니다. 우리는 과제 분포 $p(\\mathcal{T})$에 대한 $\\omega$의 성능을 평가할 수 있습니다. 여기서 과제를 데이터셋과 손실 함수의 조합인 $\\mathcal{T} = \\{D, L\\}$로 느슨하게 정의합니다. 따라서 학습 방법을 학습하는 것은 다음과 같이 됩니다:\n",
    "\n",
    "$$\n",
    "\\min_{\\omega} \\mathbb{E}_{\\mathcal{T} \\sim p(\\mathcal{T})} \\mathcal{L}(D; \\omega) \\quad (2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8901fb",
   "metadata": {},
   "source": [
    "\n",
    "여기서 $\\mathcal{L}(D; \\omega)$는 데이터셋 $D$에서 $\\omega$를 사용하여 훈련된 모델의 성능을 측정합니다. '학습 방법', 즉 $\\omega$는 종종 **과제 전반의 지식(across-task knowledge)** 또는 **메타 지식(meta-knowledge)** 이라고 불립니다.\n",
    "\n",
    "실제로 이 문제를 해결하기 위해, 우리는 종종 $p(\\mathcal{T})$에서 샘플링된 소스 과제(source tasks) 집합에 접근할 수 있다고 가정합니다. 공식적으로, 메타 훈련 단계에서 사용되는 $M$개의 소스 과제 집합을 $\\mathcal{D}_{\\text{source}} = \\{(D_{\\text{train}}^{\\text{source}}, D_{\\text{val}}^{\\text{source}})^{(i)}\\}_{i=1}^M$로 표기하며, 각 과제는 훈련 데이터와 검증 데이터를 모두 가집니다. 종종 소스 훈련 및 검증 데이터셋은 각각 **서포트셋(support set)** 과 **쿼리셋(query set)** 이라고 불립니다. '학습 방법을 학습하는' 메타 훈련 단계는 다음과 같이 쓸 수 있습니다:\n",
    "\n",
    "$$\n",
    "\\omega^* = \\arg\\max_{\\omega} \\log p(\\omega|\\mathcal{D}_{\\text{source}}) \\quad (3)\n",
    "$$\n",
    "\n",
    "이제 메타 테스트 단계에서 사용되는 $Q$개의 타겟 과제(target tasks) 집합을 $\\mathcal{D}_{\\text{target}} = \\{(D_{\\text{train}}^{\\text{target}}, D_{\\text{test}}^{\\text{target}})^{(i)}\\}_{i=1}^Q$로 표기하며, 각 과제는 훈련 데이터와 테스트 데이터를 모두 가집니다. 메타 테스트 단계에서는 학습된 메타 지식 $\\omega^*$를 사용하여 이전에 보지 못한 각 타겟 과제 $i$에 대한 기반 모델을 훈련합니다:\n",
    "\n",
    "$$\n",
    "\\theta^{*(i)} = \\arg\\max_{\\theta} \\log p(\\theta|\\omega^*, D_{\\text{train}}^{\\text{target}}(i)) \\quad (4)\n",
    "$$\n",
    "\n",
    "식 (1)의 기존 학습과 대조적으로, 타겟 과제 $i$의 훈련 세트에 대한 학습은 이제 사용할 알고리즘에 대한 메타 지식 $\\omega^*$의 이점을 얻습니다. 이것은 초기 파라미터의 추정치[16]일 수도 있고, 전체 학습 모델[38] 또는 최적화 전략[39]일 수도 있습니다. 우리는 각 타겟 과제의 테스트 스플릿 $D_{\\text{test}}^{\\text{target}}(i)$에 대한 $\\theta^{*(i)}$의 성능으로 메타 학습기의 정확도를 평가할 수 있습니다.\n",
    "\n",
    "이러한 설정은 기존의 과소적합 및 과적합과 유사한 개념인 **메타 과소적합(meta-underfitting)** 과 **메타 과적합(meta-overfitting)** 으로 이어집니다. 특히, 메타 과적합은 소스 과제에서 학습된 메타 지식이 타겟 과제로 일반화되지 않는 문제입니다. 이는 비교적 흔하며, 특히 소수의 소스 과제만 사용할 수 있는 경우에 그렇습니다. 이것은 가설 공간 $\\theta$를 소스 과제의 해법 주변으로 너무 강하게 제약하는 귀납적 편향 $\\omega$를 학습하는 것으로 볼 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
