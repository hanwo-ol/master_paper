이상치 탐지 등의 모형에 Uncertainty 를 출력 시키면 Decision making에 좋지 않나


## 1. 왜 이상치 탐지에 Uncertainty를 붙이면 좋냐?

보통 이상치 탐지는

* 점수 `s(x)`만 주고
* 임계값 `τ` 넘으면 “이상치”라고 함.

여기에 **불확실성 `u(x)`**까지 나오면:

1. **경계 케이스 구분**

   * 점수는 높지만 불확실성이 엄청 크면:
     → 모델이 “자신 없는데 일단 이상치 같다고 해본 것”
     → 사람 검토 대상으로 보내기 좋음.
   * 점수는 애매하지만 불확실성이 작으면:
     → 모델이 “이건 거의 정상(또는 이상치)이야”라고 확신하는 구간.

2. **우선순위 정렬**

   * 모니터링/알람 시스템에서

     * `s(x)` 큰 순서 + `u(x)` 큰 순서를 섞어서
       → “심각하고, 동시에 모델도 헷갈리는” 사례를 제일 위로 올릴 수 있음.

3. **Active Learning / Labeling 전략**

   * 라벨링 budget이 제한된 상황에서

     * **이상치 점수도 높고, 불확실성도 높은** 샘플만 골라 사람이 라벨→ 재학습.
   * 결국 **데이터 효율을 올리는 용도**로도 유용.

4. **운영 단계에서 신뢰도 제공**

   * 산업/의료에서 “왜 이게 이상치냐?”보다
     **“이 판단을 얼마나 믿어도 되냐?”**가 중요.
   * Uncertainty는 일종의 confidence interval이라, 운영자 설득에 도움이 됨.

---

## 2. 어떤 식 모델 구조를 생각해볼 수 있나?

### (1) 베이지안 이상치 탐지

#### a. Bayesian Autoencoder / VAE 기반

* Autoencoder나 VAE를 베이지안화해서

  * **재구성 오류(reconstruction error)** +
  * **latent / decoder의 predictive uncertainty**를 같이 사용.
* 예:

  * 입력 `x`에 대해

    * reconstruction error `r(x)`
    * MC Dropout 또는 BNN 통해 여러 번 forward → 출력 분포의 분산 `u(x)`
* 이상치 점수 예시:

  * `score(x) = α · r(x) + β · u(x)`
  * 또는 2D로 두 축을 따로 보고 threshold를 각각 설정.

#### b. Bayesian One-Class Classifier

* One-Class SVM 스타일 대신

  * Normal data를 중심으로 하는 **Bayesian density model (예: Bayesian GMM, GP, BNN density estimator)**
  * 예측 밀도 `p(x)`와 함께 “밀도 추정의 불확실성”을 같이 뽑는 형태.

---

### (2) Deep Ensemble + 이상치 스코어

Bayesian 딥러닝이 아니어도,
**Deep Ensemble**로 꽤 쓸만한 Uncertainty를 얻을 수 있어 보임.

* 서로 다른 초기값/부트스트랩으로 모델 여러 개 학습:

  * 예) Autoencoder 5개, 이상치 분류기 5개.
* 입력 `x`에 대해:

  * 각 모델의 이상치 점수 `s_i(x)`
  * 평균 `E[s(x)]` = 대표 점수
  * 분산 `Var[s(x)]` = epistemic uncertainty 근사
* 활용:

  * `E[s(x)]`가 높고 `Var[s(x)]`가 높다 → “위험 + 자신 없음 → 반드시 검토”
  * `E[s(x)]` 높고 `Var[s(x)]` 낮다 → “위험하지만 꽤 확신 있음”

---

### (3) Normalizing Flow / Density Estimator + UQ

이상치 탐지에서는 **likelihood-based model**도 많이 쓰긴 함함.
예: Flow, Autoregressive model, Energy-based model.

여기에 UQ를 섞는 방식:

1. **Bayesian Flow**:

   * Flow의 파라미터에 prior를 두고 variational inference/MC Dropout 등으로
   * 입력에 대한 **likelihood의 분포**를 추정 → 평균/분산.

2. **Ensemble Flow**:

   * 서로 다르게 학습된 flow 여러 개
   * 각자의 `log p_i(x)` 평균·분산을 가지고 score + uncertainty.

재미있는 점은,

* 일부 연구들에서 **likelihood만으로는 OOD 구분이 잘 안 된다**는 문제를 지적했기 때문에
* UQ를 추가해서 “likelihood는 높은데, 모델이 이 영역을 잘 모른다” 같은 케이스를 잡아낼 수 있을 가능성이 큼.

---

### (4) Classification 기반 OOD + UQ

만약 **이상치 = inlier/outlier binary classification**으로 보는 세팅이면:

* inlier만으로 학습한 classifier(예: one-class) 대신
* 다중 클래스 분류 + out-of-distribution detection 세팅으로 전환하고
* MC Dropout / BNN / Ensemble로 predictive entropy, mutual information 등을 이용:

  * `p(y | x)`의 entropy → aleatoric + epistemic 섞인 overall uncertainty
  * BALD(MI) 등 → epistemic 쪽 강조.

이때 이상치 점수는:

* logits 기반 (max-softmax, energy 등) + uncertainty 지표 같이 제공.

---

## 3. 평가/실험 관점에서 고려할 점

Uncertainty를 같이 제공하면, 평가도 더 rich해지는 장점이 있음.

1. **기존 이상치 탐지 metric**

   * AUROC, AUPR, FPR@95TPR 등은 계속 사용.

2. **Uncertainty 관련 metric**

   * Calibration (ECE, NLL)
   * Uncertainty vs. Error correlation:

     * 이상치 탐지 decision이 틀린 샘플에서 `u(x)`가 큰지 확인.

3. **Risk-aware metric**

   * 예: threshold를 바꿔가며

     * “불확실성이 높은 샘플은 사람에게 보내고, 나머지는 자동 처리”라는 정책에서의
       전체 error / human load / missed anomaly 등 trade-off 분석.

---

## 4. 아이디어 구체화

예를 들어 **시계열 이상치 탐지**라고 가정하면:

1. **기본 구조**

   * LSTM/Transformer 기반 예측 모델 또는 Autoencoder.

2. **Bayesian화**

   * Dropout을 training + inference에서 모두 켬(MC Dropout).
   * 같은 입력 구간 `x`에 대해 `T`번 forward →

     * reconstruction/prediction error의 평균 `μ_r`, 분산 `σ_r^2`.

3. **점수 정의**

   * 이상치 점수: `A(x) = μ_r`
   * 불확실성: `U(x) = σ_r^2`
   * 최종 의사결정:

     * `A(x)` > τ₁ 이고 `U(x)` > τ₂ → “Critical (사람 검토 필수)”
     * `A(x)` > τ₁ 이고 `U(x)` ≤ τ₂ → “자동 알람”
     * 나머지 → “정상 또는 low-priority”

4. **훈련 시**

   * reconstruction loss 최소화
   * * 필요하다면 calibration을 위한 auxiliary loss(예: temperature scaling은 사후에 적용).

---

## 5. 연구 아이디어로서의 포지셔닝

* **문제 정의**

  * 기존 이상치 탐지 모델은 score만 제공 →
    “얼마나 믿을 수 있는가?”에 대한 정보 부재.
* **기여**

  1. (모델 측면)

     * 베이지안/Ensemble 기반 이상치 탐지 모델 설계
     * 이상치 점수와 함께 calibrated uncertainty 제공.
  2. (평가 측면)

     * “Risk-aware anomaly detection benchmark”를 제안
     * 예: 사람-in-the-loop 세팅에서

       * 일정 human budget 하에서 최대한 많은 true anomaly를 잡는 문제로 정식화.
  3. (실험 측면)

     * 시계열 / 이미지 / 의료 데이터 셋에서

       * 기존 deterministic anomaly detector vs. 제안한 UQ-aware detector 비교.

---
